{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "# os.environ[\"PYTORCH_TRANSFORMERS_SDP_BACKEND\"] = \"flash\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e4a42ffa924e94bc91a41c658cc8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen2MoeForCausalLM(\n",
       "  (model): Qwen2MoeModel(\n",
       "    (embed_tokens): Embedding(151936, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2MoeDecoderLayer(\n",
       "        (self_attn): Qwen2MoeSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): Qwen2MoeRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MoeSparseMoeBlock(\n",
       "          (gate): Linear(in_features=2048, out_features=60, bias=False)\n",
       "          (experts): ModuleList(\n",
       "            (0-59): 60 x Qwen2MoeMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
       "              (down_proj): Linear(in_features=1408, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (shared_expert): Qwen2MoeMLP(\n",
       "            (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "            (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "            (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (shared_expert_gate): Linear(in_features=2048, out_features=1, bias=False)\n",
       "        )\n",
       "        (input_layernorm): Qwen2MoeRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2MoeRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2MoeRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2MoeRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(model_name=\"Qwen/Qwen1.5-MoE-A2.7B\"):\n",
    "    # device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_expert_weights(model, layer_idx, expert_idx):\n",
    "#     \"\"\"\n",
    "#     Print the weights of a specific expert MLP at a given layer.\n",
    "    \n",
    "#     Args:\n",
    "#         model: The OLMoE model\n",
    "#         layer_idx: Index of the layer containing the expert\n",
    "#         expert_idx: Index of the expert within the layer\n",
    "#     \"\"\"\n",
    "#     gate_proj = f'model.layers.{layer_idx}.mlp.experts.{expert_idx}.gate_proj.weight'\n",
    "#     up_proj = f'model.layers.{layer_idx}.mlp.experts.{expert_idx}.up_proj.weight'\n",
    "#     down_proj = f'model.layers.{layer_idx}.mlp.experts.{expert_idx}.down_proj.weight'\n",
    "    \n",
    "#     print(\"\\nGate Projection:\")\n",
    "#     print(model.state_dict()[gate_proj])\n",
    "#     print(\"\\nUp Projection:\") \n",
    "#     print(model.state_dict()[up_proj])\n",
    "#     print(\"\\nDown Projection:\")\n",
    "#     print(model.state_dict()[down_proj])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_input(file_path, chunk_size=1000, tokenizer=None):\n",
    "    \"\"\"    \n",
    "    args :\n",
    "        file_path (str): Path to the input text file\n",
    "        chunk_size (int): Number of tokens per chunk\n",
    "        tokenizer: HuggingFace tokenizer (if None, will split on whitespace)\n",
    "        \n",
    "    output : List of text chunks of approximately chunk_size tokens\n",
    "    \"\"\"\n",
    "    device = 'cpu'\n",
    "    \n",
    "    # Read the full text file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    if tokenizer:\n",
    "        # Tokenize the full text\n",
    "        tokens = tokenizer.encode(text)\n",
    "        tokens_tensor = torch.tensor(tokens).to(device)\n",
    "        \n",
    "        # Split into chunks\n",
    "        chunks = []\n",
    "        for i in range(0, len(tokens), chunk_size):\n",
    "            chunk_tokens = tokens_tensor[i:i + chunk_size]\n",
    "            # Move to CPU for decoding\n",
    "            chunk_tokens = chunk_tokens.cpu()\n",
    "            # Decode tokens back to text\n",
    "            chunk_text = tokenizer.decode(chunk_tokens)\n",
    "            chunks.append(chunk_text)\n",
    "            \n",
    "    else:\n",
    "        # Simple whitespace tokenization\n",
    "        words = text.split()\n",
    "        \n",
    "        # Split into chunks\n",
    "        chunks = []\n",
    "        for i in range(0, len(words), chunk_size):\n",
    "            chunk = ' '.join(words[i:i + chunk_size])\n",
    "            chunks.append(chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_router_logits(model, input_text: str, k: int = 1):\n",
    "    \"\"\"\n",
    "    args :\n",
    "        model: OlmoeForCausalLM model\n",
    "        input_text: Text string to analyze\n",
    "        k: Number of top experts to return per token\n",
    "        \n",
    "    output : dictionary mapping layer indices to lists of [token_text, expert_index, router_probability] for each token in that layer\n",
    "    \"\"\"\n",
    "    device = \"cpu\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Forward pass with router logits enabled\n",
    "    outputs = model(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        output_router_logits=True,\n",
    "        return_dict=True,\n",
    "    )\n",
    "    \n",
    "    # Get router logits for all layers\n",
    "    router_logits = outputs.router_logits\n",
    "    \n",
    "    all_layer_results = {}\n",
    "    for layer_idx, layer_router_logits in enumerate(router_logits):\n",
    "        # Apply softmax to get probabilities\n",
    "        probs = torch.nn.functional.softmax(layer_router_logits.detach(), dim=-1)\n",
    "        # Reshape to [seq_len, num_experts] since batch_size=1\n",
    "        probs = probs.reshape(inputs['input_ids'].size(1), -1)\n",
    "        # Get top k probabilities and indices for each token\n",
    "        top_probs, top_indices = torch.topk(probs, k=k)\n",
    "        \n",
    "        # Move tensors to CPU for post-processing\n",
    "        top_probs = top_probs.cpu()\n",
    "        top_indices = top_indices.cpu()\n",
    "        \n",
    "        # Convert token IDs to text\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].cpu())\n",
    "        \n",
    "        # Create list of [token, expert, prob] for each token\n",
    "        layer_tokens = []\n",
    "        for i in range(len(tokens)):\n",
    "            for j in range(k):\n",
    "                # Clean special characters from token text\n",
    "                clean_token = tokens[i].replace('Ä ', '')\n",
    "                layer_tokens.append([\n",
    "                    clean_token,\n",
    "                    top_indices[i][j].item(),\n",
    "                    top_probs[i][j].item()\n",
    "                ])\n",
    "        \n",
    "        all_layer_results[layer_idx] = layer_tokens\n",
    "    \n",
    "    return all_layer_results # Dictionary mapping layer index to list of [token, expert_number, probability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_router_logits_json(results, domain, device='cpu'):\n",
    "    \"\"\"\n",
    "    args :\n",
    "        results: Dictionary mapping layer index to list of [token, expert_number, probability]\n",
    "        domain: String indicating the domain (e.g., 'arxiv', 'code')\n",
    "        device: Device to use for tensor operations ('cuda' or 'cpu')\n",
    "    output : updated json file with new tokens\n",
    "    \"\"\"\n",
    "    if domain == 'arxiv':\n",
    "        json_path = 'arxiv_all_layers.json'\n",
    "    elif domain == 'github':\n",
    "        json_path = 'github_all_layers.json'\n",
    "    elif domain == 'math':\n",
    "        json_path = 'math_all_layers.json'\n",
    "    elif domain == 'physics':\n",
    "        json_path = 'physics_all_layers.json'\n",
    "    elif domain == 'biology':\n",
    "        json_path = 'biology_all_layers.json'\n",
    "    elif domain == 'legal':\n",
    "        json_path = 'legal_all_layers.json'\n",
    "    elif domain == 'swap':\n",
    "        json_path = 'swap_all_layers.json'\n",
    "    elif domain == 'mix':\n",
    "        json_path = 'mix_all_layers.json'\n",
    "    elif domain == 'mix-swap':\n",
    "        json_path = 'mix_swap_all_layers.json'\n",
    "    elif domain == 'instruct':\n",
    "        json_path = 'instruct_all_layers.json'\n",
    "    elif domain == 'qwen-arxiv':\n",
    "        json_path = 'qwen_arxiv_all_layers.json'\n",
    "\n",
    "    \n",
    "    # Initialize an empty dictionary for existing results\n",
    "    existing_results = {}\n",
    "    \n",
    "    if os.path.exists(json_path):\n",
    "        # Load existing results\n",
    "        with open(json_path, 'r') as f:\n",
    "            try:\n",
    "                existing_results = json.load(f)\n",
    "                # Convert string keys to integers\n",
    "                existing_results = {int(k): v for k, v in existing_results.items()}\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: {json_path} is empty or corrupted. Starting with an empty dictionary.\")\n",
    "    \n",
    "    # Move results to GPU if available\n",
    "    if torch.cuda.is_available() and device == 'cuda':\n",
    "        for layer_idx, layer_tokens in results.items():\n",
    "            # Convert lists to tensors and move to GPU\n",
    "            tokens_tensor = torch.tensor([[t[0], t[1], t[2]] for t in layer_tokens]).cuda()\n",
    "            results[layer_idx] = tokens_tensor.tolist()\n",
    "    \n",
    "    # Combine existing and new results for each layer\n",
    "    for layer_idx, layer_tokens in results.items():\n",
    "        if layer_idx in existing_results:\n",
    "            existing_results[layer_idx].extend(layer_tokens)\n",
    "        else:\n",
    "            existing_results[layer_idx] = layer_tokens\n",
    "    \n",
    "    # Save updated results with integer keys\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(existing_results, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    return existing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_expert_distribution(domain, device='cpu'):\n",
    "    \"\"\"    \n",
    "    args :\n",
    "        json_path: Path to the JSON file containing expert counts\n",
    "        device: Device to use for tensor operations ('cuda' or 'cpu')\n",
    "    output : heatmap showing distribution of tokens across experts and layers\n",
    "    \"\"\"\n",
    "    if domain == 'arxiv':\n",
    "        json_path = 'arxiv_all_layers.json'\n",
    "    elif domain == 'github':\n",
    "        json_path = 'github_all_layers.json'\n",
    "    elif domain == 'math':\n",
    "        json_path = 'math_all_layers.json'\n",
    "    elif domain == 'physics':\n",
    "        json_path = 'physics_all_layers.json'\n",
    "    elif domain == 'biology':\n",
    "        json_path = 'biology_all_layers.json'\n",
    "    elif domain == 'legal':\n",
    "        json_path = 'legal_all_layers.json'\n",
    "    elif domain == 'swap':\n",
    "        json_path = 'swap_all_layers.json'\n",
    "    elif domain == 'mix':\n",
    "        json_path = 'mix_all_layers.json'\n",
    "    elif domain == 'mix-swap':\n",
    "        json_path = 'mix_swap_all_layers.json'\n",
    "    elif domain == 'instruct':\n",
    "        json_path = 'instruct_all_layers.json'\n",
    "    elif domain == 'qwen-arxiv':\n",
    "        json_path = 'qwen_arxiv_all_layers.json'\n",
    "\n",
    "    # Read JSON file\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Create a 16x64 matrix to store percentages\n",
    "    expert_matrix = np.zeros((16, 64))\n",
    "    \n",
    "    # Process each layer\n",
    "    for layer in range(16):\n",
    "        if str(layer) not in data:\n",
    "            continue\n",
    "            \n",
    "        layer_results = data[str(layer)]\n",
    "        total_assignments = len(layer_results)\n",
    "        \n",
    "        # Count expert assignments for this layer\n",
    "        expert_counts = defaultdict(int)\n",
    "        if torch.cuda.is_available() and device == 'cuda':\n",
    "            layer_results = torch.tensor(layer_results).cuda()\n",
    "            for _, expert, _ in layer_results.cpu().numpy():\n",
    "                expert_counts[int(expert)] += 1\n",
    "        else:\n",
    "            for _, expert, _ in layer_results:\n",
    "                expert_counts[expert] += 1\n",
    "                \n",
    "        # Calculate percentages for each expert\n",
    "        for expert in range(64):\n",
    "            expert_matrix[layer][expert] = expert_counts[expert] / total_assignments * 100\n",
    "    \n",
    "    # Create and return a single heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=expert_matrix,\n",
    "        x=[str(i) for i in range(64)],\n",
    "        y=[str(i) for i in range(16)],\n",
    "        colorscale='Reds'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Distribution of Tokens Across Experts and Layers',\n",
    "        xaxis_title='Expert Index',\n",
    "        yaxis_title='Layer',\n",
    "        width=800,\n",
    "        height=800,\n",
    "        xaxis=dict(\n",
    "            tickangle=-45,\n",
    "            constrain='domain'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            scaleanchor='x',\n",
    "            scaleratio=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def swap_experts(model, expert_idx, target_layer_idx, source_layer_idx=0, source_expert_idx=0):\n",
    "#     \"\"\"\n",
    "#     Swap experts between two layers in the OLMoE model.\n",
    "    \n",
    "#     Args:\n",
    "#         model: The OLMoE model\n",
    "#         expert_idx: Index of the expert in target layer to swap with\n",
    "#         target_layer_idx: Index of the layer containing the expert to swap with\n",
    "#         source_layer_idx: Index of the source layer (default 0)\n",
    "#         source_expert_idx: Index of the source expert (default 0)\n",
    "\n",
    "#     \"\"\"\n",
    "#     # Access the decoder layers\n",
    "#     decoder_layers = model.model.layers\n",
    "#     print(decoder_layers[0].mlp.experts[0].gate_proj.weight.shape)\n",
    "    \n",
    "#     # Verify indices are valid\n",
    "#     num_layers = len(decoder_layers)\n",
    "#     if target_layer_idx >= num_layers or source_layer_idx >= num_layers:\n",
    "#         raise ValueError(f\"Layer index out of range. Model has {num_layers} layers.\")\n",
    "    \n",
    "#     # Get the MoE blocks from both layers\n",
    "#     source_moe = decoder_layers[source_layer_idx].mlp\n",
    "#     target_moe = decoder_layers[target_layer_idx].mlp\n",
    "    \n",
    "#     # Verify expert indices are valid\n",
    "#     num_experts = len(source_moe.experts)\n",
    "#     if expert_idx >= num_experts or source_expert_idx >= num_experts:\n",
    "#         raise ValueError(f\"Expert index out of range. Each layer has {num_experts} experts.\")\n",
    "        \n",
    "#     # Swap the expert weights\n",
    "#     source_expert = source_moe.experts[source_expert_idx]\n",
    "#     target_expert = target_moe.experts[expert_idx]\n",
    "    \n",
    "#     # Swap gate projection weights\n",
    "#     source_expert.gate_proj.weight, target_expert.gate_proj.weight = \\\n",
    "#         target_expert.gate_proj.weight, source_expert.gate_proj.weight\n",
    "        \n",
    "#     # Swap up projection weights\n",
    "#     source_expert.up_proj.weight, target_expert.up_proj.weight = \\\n",
    "#         target_expert.up_proj.weight, source_expert.up_proj.weight\n",
    "        \n",
    "#     # Swap down projection weights  \n",
    "#     source_expert.down_proj.weight, target_expert.down_proj.weight = \\\n",
    "#         target_expert.down_proj.weight, source_expert.down_proj.weight\n",
    "    \n",
    "#     return {\n",
    "#         'swapped_experts': {\n",
    "#             'source': {\n",
    "#                 'layer': source_layer_idx,\n",
    "#                 'expert': source_expert_idx\n",
    "#             },\n",
    "#             'target': {\n",
    "#                 'layer': target_layer_idx,\n",
    "#                 'expert': expert_idx\n",
    "#             }\n",
    "#         }\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Layer 0 swaps\n",
    "# source_experts = [0, 21, 41, 36, 15, 10, 38, 31]\n",
    "# target_experts = [39, 7, 9, 57, 20, 12, 28, 23]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=0, source_layer_idx=0, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 0, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 1 swaps\n",
    "# source_experts = [47, 18, 15, 25, 16, 7, 61, 27]\n",
    "# target_experts = [57, 35, 10, 43, 63, 14, 41, 38]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=1, source_layer_idx=1, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 1, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 2 swaps\n",
    "# source_experts = [60, 5, 45, 63, 26, 15, 40, 36]\n",
    "# target_experts = [2, 47, 13, 37, 53, 59, 58, 4]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=2, source_layer_idx=2, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 2, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 3 swaps\n",
    "# source_experts = [35, 15, 43, 39, 51, 9, 30, 63]\n",
    "# target_experts = [10,25,58,53,21,55,23,22]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=3, source_layer_idx=3, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 3, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 4 swaps\n",
    "# source_experts = [17, 25, 19, 6, 21, 46, 16, 55]\n",
    "# target_experts = [12, 36, 45, 47, 11, 53, 54, 18]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=4, source_layer_idx=4, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 4, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 5 swaps\n",
    "# source_experts = [0,31,42,53,2,38,35,57]\n",
    "# target_experts = [46,33,40,60,26,3,37,45]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=5, source_layer_idx=5, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 5, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 6 swaps\n",
    "# source_experts = [52, 57, 18, 5, 62, 24, 1, 40]\n",
    "# target_experts = [45, 0, 14, 51, 41, 15, 38, 27]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=6, source_layer_idx=6, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 6, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 7 swaps\n",
    "# source_experts = [2, 17, 58, 0, 59, 4, 36, 45]\n",
    "# target_experts = [8, 25, 55, 51, 3, 62, 44, 28]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=7, source_layer_idx=7, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 7, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 8 swaps\n",
    "# source_experts = [14, 16, 54, 18, 3, 44, 61, 32]\n",
    "# target_experts = [13, 59, 34, 29, 43, 39, 58, 8]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=8, source_layer_idx=8, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 8, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 9 swaps\n",
    "# source_experts = [5, 4, 46, 28, 8, 57, 51, 20]\n",
    "# target_experts = [12, 3, 56, 41, 29, 25, 17, 15]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=9, source_layer_idx=9, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 9, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 10 swaps\n",
    "# source_experts = [43, 56, 11, 19, 28, 48, 60, 13]\n",
    "# target_experts = [31, 6, 54, 63, 51, 33, 40, 25]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=10, source_layer_idx=10, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 10, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 11 swaps\n",
    "# source_experts = [27, 47, 23, 33, 54, 62, 46, 12]\n",
    "# target_experts = [1, 6, 14, 25, 21, 38, 52, 53]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=11, source_layer_idx=11, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 11, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 12 swaps\n",
    "# source_experts = [43, 38, 59, 31, 55, 8, 10, 44]\n",
    "# target_experts = [63, 16, 11, 21, 22, 61, 5, 25]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=12, source_layer_idx=12, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 12, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 13 swaps\n",
    "# source_experts = [20, 2, 25, 62, 57, 5, 61, 7]\n",
    "# target_experts = [56, 37, 36, 16, 40, 63, 52, 33]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=13, source_layer_idx=13, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 13, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 14 swaps\n",
    "# source_experts = [6, 9, 33, 58, 24, 38, 48, 19]\n",
    "# target_experts = [3, 25, 21, 2, 51, 0, 55, 59]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=14, source_layer_idx=14, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 14, expert {source_experts[i]} with expert {target_experts[i]}\")\n",
    "\n",
    "# # Layer 15 swaps\n",
    "# source_experts = [34, 1, 17, 44, 8, 57, 24, 30]\n",
    "# target_experts = [25, 26, 56, 27, 10, 14, 49, 59]\n",
    "# for i in range(len(source_experts)):\n",
    "#     swap_experts(model, expert_idx=target_experts[i], target_layer_idx=15, source_layer_idx=15, source_expert_idx=source_experts[i])\n",
    "#     print(f\"Swapped experts at layer 15, expert {source_experts[i]} with expert {target_experts[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/49\n",
      "Processing chunk 2/49\n",
      "Processing chunk 3/49\n",
      "Processing chunk 4/49\n",
      "Processing chunk 5/49\n",
      "Processing chunk 6/49\n",
      "Processing chunk 7/49\n",
      "Processing chunk 8/49\n",
      "Processing chunk 9/49\n",
      "Processing chunk 10/49\n",
      "Processing chunk 11/49\n",
      "Processing chunk 12/49\n",
      "Processing chunk 13/49\n",
      "Processing chunk 14/49\n",
      "Processing chunk 15/49\n",
      "Processing chunk 16/49\n",
      "Processing chunk 17/49\n",
      "Processing chunk 18/49\n",
      "Processing chunk 19/49\n",
      "Processing chunk 20/49\n",
      "Processing chunk 21/49\n",
      "Processing chunk 22/49\n",
      "Processing chunk 23/49\n",
      "Processing chunk 24/49\n",
      "Processing chunk 25/49\n",
      "Processing chunk 26/49\n",
      "Processing chunk 27/49\n",
      "Processing chunk 28/49\n",
      "Processing chunk 29/49\n",
      "Processing chunk 30/49\n",
      "Processing chunk 31/49\n",
      "Processing chunk 32/49\n",
      "Processing chunk 33/49\n",
      "Processing chunk 34/49\n",
      "Processing chunk 35/49\n",
      "Processing chunk 36/49\n",
      "Processing chunk 37/49\n",
      "Processing chunk 38/49\n",
      "Processing chunk 39/49\n",
      "Processing chunk 40/49\n",
      "Processing chunk 41/49\n",
      "Processing chunk 42/49\n",
      "Processing chunk 43/49\n",
      "Processing chunk 44/49\n",
      "Processing chunk 45/49\n",
      "Processing chunk 46/49\n",
      "Processing chunk 47/49\n",
      "Processing chunk 48/49\n",
      "Processing chunk 49/49\n"
     ]
    }
   ],
   "source": [
    "# Read and chunk input file\n",
    "file_path = 'data/qwen_arxiv_25k.txt'\n",
    "domain = 'qwen-arxiv'\n",
    "chunks = prepare_text_input(file_path, chunk_size=512, tokenizer=tokenizer)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = 'cpu'\n",
    "model = model.to(device)  # Move model to GPU if available\n",
    "\n",
    "# Process all chunks\n",
    "all_results = []\n",
    "with torch.inference_mode():\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f'Processing chunk {i+1}/{len(chunks)}')\n",
    "        # print(f'Sample text: {chunk[:10]}...')  \n",
    "    \n",
    "        # Get router logits for the chunk\n",
    "        results = get_router_logits(model, chunk)\n",
    "        all_results.append(results)\n",
    "        \n",
    "        # Save intermediate results \n",
    "        update_router_logits_json(results, domain=domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(255,245,240)"
          ],
          [
           0.125,
           "rgb(254,224,210)"
          ],
          [
           0.25,
           "rgb(252,187,161)"
          ],
          [
           0.375,
           "rgb(252,146,114)"
          ],
          [
           0.5,
           "rgb(251,106,74)"
          ],
          [
           0.625,
           "rgb(239,59,44)"
          ],
          [
           0.75,
           "rgb(203,24,29)"
          ],
          [
           0.875,
           "rgb(165,15,21)"
          ],
          [
           1,
           "rgb(103,0,13)"
          ]
         ],
         "type": "heatmap",
         "x": [
          "0",
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63"
         ],
         "y": [
          "0",
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15"
         ],
         "z": [
          [
           0.37907505686125853,
           1.93926818562707,
           1.6439886676509319,
           1.209049918199593,
           1.1412154343402099,
           0.18355213279597782,
           4.429192769642073,
           1.0773712142372611,
           1.4843781173935597,
           1.4444754798292168,
           1.4245241610470452,
           1.3965923147520052,
           0.8339651250947688,
           0.41498743066916727,
           2.246518494872511,
           0.8219943338254659,
           0.2753281991939667,
           0.5386856071186306,
           0.9736243565699693,
           1.157176489365947,
           0.7781014325046886,
           0.7022864211324369,
           1.9632097681656757,
           1.5083196999321655,
           3.252064961493955,
           2.39415825386058,
           2.0150831969993215,
           0.5227245520928934,
           1.6399984038944975,
           2.138781373448785,
           0.558636925900802,
           3.9024779537927454,
           1.8035992179083038,
           0.19153266030884641,
           1.54024180998364,
           0.5546466621443678,
           1.4045728422648738,
           1.6399984038944975,
           4.321455648218348,
           1.4644267986113881,
           1.3646702047005308,
           1.368660468456965,
           3.2560552252503894,
           3.387733929212721,
           0.929731455249192,
           0.8419456526076374,
           2.8889509596584335,
           1.2290012369817644,
           0.518734288336459,
           0.6224811460037508,
           3.3398507641355093,
           1.592115238817286,
           4.301504329436176,
           0.43892901320777306,
           0.6025298272215793,
           1.157176489365947,
           5.921551414548501,
           2.992697817325725,
           0.8579067076333746,
           3.0764933562108454,
           0,
           0,
           0,
           0
          ],
          [
           1.2329915007381989,
           0.5626271896572363,
           0.6623837835680938,
           4.5927935836558795,
           0.48282191452855033,
           0.42296795818203586,
           0.7381987949403456,
           0.2912892542197039,
           0.9177606639798891,
           0.8658872351462432,
           1.157176489365947,
           1.3886117872391366,
           1.5881249750608517,
           3.455568413072104,
           2.0789274171022702,
           0.3272016280276126,
           4.836199672798372,
           1.5841347113044173,
           0.969634092813535,
           1.3247675671361876,
           1.9073460755755955,
           3.667052392163122,
           0.9536730377877978,
           1.3048162483540162,
           0.3112405730018754,
           4.050117712780814,
           5.175372092095287,
           4.321455648218348,
           0.6424324647859223,
           3.571286062008699,
           2.3343042975140658,
           2.074937153345836,
           0.22744503411675512,
           2.3303140337576314,
           0.997565939108575,
           0.8180040700690316,
           1.56817365627868,
           0.7062766848888712,
           1.564183392522246,
           0.5346953433621963,
           1.448465743585651,
           0.8140138063125973,
           1.3207773033797534,
           0.8219943338254659,
           2.22656717609034,
           2.0589760983200986,
           1.1930888631738559,
           1.9153266030884641,
           2.9807270260564223,
           0.44690954072064165,
           0.9616535653006664,
           1.4444754798292168,
           1.3965923147520052,
           5.24320657595467,
           1.1811180719045529,
           1.3926020509955708,
           0.19153266030884641,
           0.043892901320777306,
           1.0933322692629983,
           3.2839870715454293,
           0,
           0,
           0,
           0
          ],
          [
           5.119508399505207,
           0.2753281991939667,
           5.043693388132955,
           0.23143529787318942,
           0.2952795179761382,
           0.41897769442560157,
           2.733330673157496,
           3.0365907186465027,
           0.5706077171701049,
           1.0215075216471807,
           2.677466980567415,
           4.014205338972906,
           1.3886117872391366,
           0.8419456526076374,
           2.2505087586289454,
           1.7836478991261322,
           3.5952276445473044,
           0.09576633015442321,
           2.22656717609034,
           1.3088065121104504,
           0.41897769442560157,
           1.1771278081481187,
           0.6424324647859223,
           1.1930888631738559,
           7.250309245441124,
           3.132357048800926,
           1.6439886676509319,
           2.1347911096923506,
           0.2912892542197039,
           3.4874905231235784,
           2.1587326922309567,
           1.8155700091776066,
           1.7118231515103148,
           0.6703643110809625,
           0.16759107777024063,
           0.16759107777024063,
           0.5785882446829735,
           0.7022864211324369,
           0.45489006823351025,
           0.17158134152667492,
           3.978292965164997,
           0.6105103547344479,
           0.3950361118869958,
           2.9168828059534735,
           1.9751805594349785,
           1.0494393679422211,
           0.23542556162962372,
           3.4755197318542757,
           0.5346953433621963,
           0.5905590359522764,
           0.46686085950281314,
           1.6399984038944975,
           1.2170304457124617,
           0.77012090499182,
           4.485056462232154,
           0.46287059574637884,
           0.9257411914927577,
           0.6184908822473165,
           3.347831291648378,
           1.4045728422648738,
           0,
           0,
           0,
           0
          ],
          [
           2.0310442520250587,
           1.4005825785084394,
           3.96233191013926,
           2.074937153345836,
           1.8754239655241212,
           1.11328358804517,
           3.7947408323690195,
           1.687881568971709,
           1.9991221419735843,
           3.7827700410997167,
           0.21547424284745223,
           1.3926020509955708,
           1.6399984038944975,
           1.157176489365947,
           2.621603287977335,
           1.8315310642033438,
           2.0031124057300187,
           2.3861777263477117,
           0.38306532061769283,
           0.09576633015442321,
           0.6264714097601851,
           0.5027732333107218,
           0.37508479310482423,
           1.073380950480827,
           0.9576633015442321,
           1.847492119229081,
           2.481944056502135,
           0.319221100514744,
           0.849926180120506,
           0.638442201029488,
           6.308606998922629,
           1.7517257890746578,
           0.42695822193847016,
           2.047005307050796,
           1.0813614779936955,
           0.23143529787318942,
           0.37907505686125853,
           2.234547703603208,
           1.3846215234827022,
           0.37508479310482423,
           1.9632097681656757,
           0.8778580264155461,
           1.54024180998364,
           1.8514823829855154,
           1.2928454570847132,
           1.4245241610470452,
           1.3048162483540162,
           1.847492119229081,
           5.115518135748773,
           2.5936714416822952,
           0.8858385539284147,
           5.071625234427995,
           2.3103627149754598,
           1.1092933242887355,
           1.979170823191413,
           0.7581501137225171,
           0.6783448385938311,
           1.979170823191413,
           1.6000957663301545,
           0.47484138701568174,
           0,
           0,
           0,
           0
          ],
          [
           1.9193168668448983,
           0.6663740473245281,
           0.10374685766729182,
           0.05187342883364591,
           1.4724073261242567,
           0.41099716691273297,
           2.019073460755756,
           0.23941582538605802,
           0.1636008140138063,
           0.9337217190056263,
           1.16914728063525,
           3.0405809824029366,
           0.159610550257372,
           0.48681217828498463,
           0.638442201029488,
           1.4803878536371253,
           2.402138781373449,
           2.8091456845297476,
           2.677466980567415,
           6.683691792027453,
           0.1436494952316348,
           1.7357647340489206,
           3.060532301185108,
           1.3646702047005308,
           1.564183392522246,
           1.2609233470332388,
           0.17557160528310922,
           0.18754239655241212,
           0.9257411914927577,
           0.08379553888512031,
           0.5267148158493277,
           5.87366824947129,
           0.6583935198116595,
           0.2513866166553609,
           0.2593671441682295,
           1.544232073740074,
           0.7102669486453055,
           3.124376521288057,
           2.8650093771198275,
           1.7836478991261322,
           4.022185866485774,
           0.05187342883364591,
           5.311041059814054,
           2.230557439846774,
           0.5386856071186306,
           1.2569330832768046,
           2.597661705438729,
           3.072503092454411,
           1.3008259845975818,
           1.8395115917162124,
           0.17158134152667492,
           1.2409720282510674,
           2.070946889589402,
           1.3327480946490562,
           0.9217509277363234,
           1.739754997805355,
           4.987829695542875,
           0.77012090499182,
           6.5560033518215555,
           0.35912373807908704,
           0,
           0,
           0,
           0
          ],
          [
           0.18754239655241212,
           0.1236981764494633,
           1.288855193328279,
           5.765931128047564,
           1.1053030605323013,
           7.09867922269662,
           0.5227245520928934,
           0.19153266030884641,
           0.638442201029488,
           1.3088065121104504,
           1.2968357208411476,
           1.0294880491600493,
           1.3247675671361876,
           0.5346953433621963,
           0.5905590359522764,
           1.153186225609513,
           0.7621403774789514,
           1.6439886676509319,
           0.8698774989026775,
           2.749291728183233,
           1.979170823191413,
           0.319221100514744,
           1.4524560073420854,
           4.896053629144887,
           0.17158134152667492,
           2.2066158573081682,
           3.3438410278919437,
           0.889828817684849,
           0.45089980447707595,
           0.8738677626591118,
           0.5546466621443678,
           1.6439886676509319,
           2.6654961892981124,
           2.3582458800526713,
           2.3542556162962374,
           0.20749371533458363,
           0.20749371533458363,
           2.6854475080802844,
           0.08778580264155461,
           6.919117353657077,
           1.2250109732253303,
           1.488368381149994,
           5.227245520928933,
           1.1731375443916843,
           1.807589481664738,
           4.748413870156817,
           1.6838913052152749,
           0.5107537608235904,
           1.6838913052152749,
           2.5298272215793465,
           0.7621403774789514,
           2.8490483220940903,
           0.4947927057978532,
           0.279318462950401,
           0.9895854115957065,
           1.2609233470332388,
           1.2170304457124617,
           0.9456925102749292,
           2.2066158573081682,
           0.46287059574637884,
           0,
           0,
           0,
           0
          ],
          [
           0.1516300227445034,
           4.445153824667811,
           2.3462750887833685,
           2.1148397909101795,
           1.0813614779936955,
           0.6663740473245281,
           0.37109452934838993,
           1.5242807549579027,
           0.6982961573760026,
           1.3127967758668848,
           1.0254977854036151,
           0.20749371533458363,
           2.0150831969993215,
           1.2689038745461074,
           0.9417022465184949,
           0.1636008140138063,
           1.1452056980966443,
           0.530705079605762,
           3.2041817964167434,
           0.7501695862096485,
           1.6559594589202347,
           3.950361118869957,
           2.3183432424883286,
           0.6065200909780136,
           6.791428913451179,
           0.279318462950401,
           3.854594788715534,
           2.3343042975140658,
           0.9217509277363234,
           0.4947927057978532,
           0.730218267427477,
           5.730018754239655,
           2.110849527153745,
           1.0893420055065641,
           1.0254977854036151,
           2.1786840110131283,
           1.1452056980966443,
           3.3159091815969037,
           1.2329915007381989,
           1.0015562028650093,
           2.0988787358844423,
           0.7541598499660828,
           0.9656438290571007,
           2.019073460755756,
           0.8339651250947688,
           0.782091696261123,
           0.43094848569490446,
           2.2505087586289454,
           1.4763975898806911,
           0.6065200909780136,
           0.7581501137225171,
           1.99513187821715,
           1.0654004229679583,
           3.615178963329476,
           4.0820398228322885,
           0.9177606639798891,
           1.9632097681656757,
           0.9935756753521408,
           1.7756673716132636,
           1.8834044930369898,
           0,
           0,
           0,
           0
          ],
          [
           0.35114321056621844,
           1.488368381149994,
           1.5362515462272055,
           1.9632097681656757,
           1.4963489086628625,
           1.4245241610470452,
           0.730218267427477,
           0.7621403774789514,
           1.1332349068273413,
           1.0654004229679583,
           0.21148397909101793,
           1.0773712142372611,
           0.2912892542197039,
           1.6439886676509319,
           0.5386856071186306,
           1.0414588404293523,
           0.6344519372730537,
           0.849926180120506,
           1.0135269941343121,
           1.4285144248034796,
           2.342284825026934,
           3.2999481265711665,
           0.638442201029488,
           2.035034515781493,
           0.23143529787318942,
           1.8115797454211724,
           1.3606799409440964,
           4.397270659590599,
           3.543354215713659,
           1.3566896771876622,
           4.445153824667811,
           1.3487091496747936,
           2.7293404094010616,
           2.5457882766050837,
           1.2290012369817644,
           0.43892901320777306,
           1.276884402058976,
           1.0055464666214435,
           2.166713219743825,
           0.3152308367583097,
           0.41498743066916727,
           1.819560272934041,
           0.8140138063125973,
           12.673077690435338,
           1.2250109732253303,
           0.5466661346314992,
           1.288855193328279,
           2.8490483220940903,
           2.481944056502135,
           3.0365907186465027,
           1.7158134152667492,
           0.6145006184908822,
           4.030166393998643,
           0.6145006184908822,
           0.41498743066916727,
           1.0654004229679583,
           1.1332349068273413,
           0.8339651250947688,
           1.3646702047005308,
           1.8634531742548182,
           0,
           0,
           0,
           0
          ],
          [
           0.929731455249192,
           1.8754239655241212,
           0.8978093451977176,
           0.6863253661066997,
           0.23542556162962372,
           0.8778580264155461,
           0.4947927057978532,
           1.620047085112326,
           7.158533179043134,
           1.9352779218706355,
           1.5482223374965085,
           2.8809704321455647,
           0.7381987949403456,
           0.34715294680978415,
           1.9472487131399385,
           2.2664698136546826,
           1.580144447547983,
           2.246518494872511,
           0.6504129922987909,
           3.93440006384422,
           0.9057898727105862,
           1.7876381628825666,
           3.870555843741271,
           0.9417022465184949,
           0.9057898727105862,
           0.969634092813535,
           1.1412154343402099,
           2.669486453054547,
           3.2480746977375206,
           0.9177606639798891,
           6.27269462511472,
           0.2992697817325725,
           1.4444754798292168,
           0.5825785084394078,
           3.8625753162284027,
           0.690315629863134,
           1.4404852160727823,
           1.544232073740074,
           0.35114321056621844,
           2.258489286141814,
           0.9935756753521408,
           1.19707912693029,
           3.643110809624516,
           0.638442201029488,
           1.0534296316986553,
           1.4285144248034796,
           2.7413112006703644,
           0.33917241929691555,
           0.8738677626591118,
           0.7381987949403456,
           2.25449902238538,
           0.4947927057978532,
           1.2728941383025418,
           2.0270539882686243,
           1.1890985994174215,
           3.044571246159371,
           0.6224811460037508,
           0.6025298272215793,
           0.37508479310482423,
           3.5154223694186184,
           0,
           0,
           0,
           0
          ],
          [
           5.78987271058617,
           1.6799010414588404,
           2.725350145644627,
           1.5123099636885997,
           0.5107537608235904,
           6.8113802322333505,
           1.0334783129164837,
           1.7836478991261322,
           1.6000957663301545,
           0.6025298272215793,
           0.40700690315629867,
           0.9496827740313635,
           0.8060332787997287,
           1.9153266030884641,
           1.899365548062727,
           1.248952555763936,
           2.777223574478273,
           1.4644267986113881,
           0.997565939108575,
           1.4684170623678225,
           1.819560272934041,
           2.749291728183233,
           2.697418299349587,
           0.49080244204141893,
           1.767686844100395,
           1.8235505366904752,
           0.7940624875304259,
           2.621603287977335,
           1.4444754798292168,
           0.5706077171701049,
           0.5905590359522764,
           1.4005825785084394,
           0.8379553888512031,
           1.4045728422648738,
           1.2728941383025418,
           1.8674434380112526,
           3.124376521288057,
           2.9168828059534735,
           0.9895854115957065,
           0.8978093451977176,
           1.3886117872391366,
           1.500339172419297,
           0.77012090499182,
           0.6304616735166194,
           0.7182474761581741,
           0.46686085950281314,
           2.3702166713219746,
           2.3382945612705,
           2.430070627668489,
           0.7581501137225171,
           1.129244643070907,
           0.45089980447707595,
           1.592115238817286,
           0.6184908822473165,
           3.411675511751327,
           0.6464227285423566,
           4.848170464067675,
           1.7956186903954352,
           1.0334783129164837,
           1.037468576672918,
           0,
           0,
           0,
           0
          ],
          [
           0.41897769442560157,
           3.112405730018754,
           1.6399984038944975,
           0.8778580264155461,
           2.597661705438729,
           0.8180040700690316,
           3.623159490842345,
           0.37109452934838993,
           1.2170304457124617,
           6.50412992298791,
           2.0390247795379275,
           3.1044252025058854,
           1.7996089541518694,
           1.8115797454211724,
           0.33518215554048125,
           0.45489006823351025,
           0.7022864211324369,
           0.46686085950281314,
           1.1252543793144727,
           7.3580463668648495,
           1.3127967758668848,
           3.1682694226088346,
           0.8419456526076374,
           1.6240373488687603,
           1.0015562028650093,
           1.8794142292805553,
           0.7781014325046886,
           1.608076293843023,
           1.2409720282510674,
           1.153186225609513,
           1.3207773033797534,
           2.1786840110131283,
           1.2968357208411476,
           2.3462750887833685,
           0.38306532061769283,
           1.9911416144607157,
           0.9097801364670205,
           0.5067634970671561,
           1.8115797454211724,
           1.3207773033797534,
           1.1053030605323013,
           0.530705079605762,
           1.0294880491600493,
           0.7781014325046886,
           1.9512389768963727,
           3.1403375763137946,
           2.976736762299988,
           1.5322612824707713,
           1.0135269941343121,
           0.530705079605762,
           0.13566896771876621,
           2.1188300546666134,
           1.4524560073420854,
           0.849926180120506,
           2.501895375284306,
           0.969634092813535,
           1.3487091496747936,
           4.225689318063925,
           2.262479549898248,
           0.4947927057978532,
           0,
           0,
           0,
           0
          ],
          [
           0.8219943338254659,
           0.8858385539284147,
           2.589681177925861,
           0.44690954072064165,
           0.8579067076333746,
           0.9576633015442321,
           0.5546466621443678,
           0.4030166393998644,
           2.1308008459359167,
           1.448465743585651,
           0.7501695862096485,
           1.2728941383025418,
           2.230557439846774,
           4.700530705079606,
           7.4617932245321414,
           1.5841347113044173,
           1.2170304457124617,
           1.3766409959698336,
           0.8020430150432944,
           0.46686085950281314,
           1.5083196999321655,
           0.41897769442560157,
           1.687881568971709,
           1.1851083356609873,
           0.3232113642711783,
           1.9312876581142013,
           1.5362515462272055,
           1.0175172578907465,
           1.6399984038944975,
           0.9137704002234548,
           1.6719205139459719,
           0.638442201029488,
           2.645544870515941,
           0.47085112325924744,
           0.8020430150432944,
           2.1866645385259966,
           1.3487091496747936,
           1.5841347113044173,
           1.3606799409440964,
           0.44690954072064165,
           0.3232113642711783,
           0.9536730377877978,
           4.692550177566737,
           0.7102669486453055,
           1.96720003192211,
           0.782091696261123,
           1.073380950480827,
           2.1347911096923506,
           1.0973225330194327,
           2.4420414189377917,
           5.757950600534696,
           5.47464187382786,
           1.101312796775867,
           3.1802402138781374,
           3.2720162802761266,
           1.316787039623319,
           1.5522126012529427,
           1.0654004229679583,
           1.1771278081481187,
           1.647978931407366,
           0,
           0,
           0,
           0
          ],
          [
           1.4803878536371253,
           0.889828817684849,
           2.805155420773313,
           2.0430150432943615,
           2.2744503411675514,
           3.112405730018754,
           1.3367383584054906,
           1.6519691951638005,
           0.7342085311839113,
           2.074937153345836,
           0.8539164438769403,
           6.540042296795819,
           2.36622640756554,
           0.2912892542197039,
           0.5626271896572363,
           0.46287059574637884,
           0.3950361118869958,
           1.5482223374965085,
           0.8978093451977176,
           3.6630621284066875,
           0.6464227285423566,
           1.276884402058976,
           0.6464227285423566,
           0.9217509277363234,
           1.4325046885599138,
           1.4803878536371253,
           2.725350145644627,
           1.0693906867243925,
           1.620047085112326,
           1.4923586449064283,
           6.755516539643271,
           1.6240373488687603,
           0.9536730377877978,
           1.6399984038944975,
           0.518734288336459,
           1.061410159211524,
           2.458002473963529,
           1.0175172578907465,
           2.1427716372052195,
           1.276884402058976,
           1.3606799409440964,
           1.0414588404293523,
           1.1212641155580385,
           1.460436534854954,
           1.6559594589202347,
           4.050117712780814,
           1.7237939427796178,
           0.6464227285423566,
           3.3797534016998525,
           0.9616535653006664,
           1.4404852160727823,
           0.8858385539284147,
           1.7078328877538806,
           0.47484138701568174,
           1.699852360241012,
           0.6663740473245281,
           1.5482223374965085,
           1.380631259726268,
           2.258489286141814,
           1.7916284266390008,
           0,
           0,
           0,
           0
          ],
          [
           0.8140138063125973,
           2.553768804117952,
           1.0135269941343121,
           1.899365548062727,
           1.101312796775867,
           0.9417022465184949,
           0.8219943338254659,
           0.6184908822473165,
           2.2944016599497226,
           1.2050596544431587,
           1.887394756793424,
           0.969634092813535,
           1.3048162483540162,
           5.13147919077451,
           3.224133115198915,
           0.16759107777024063,
           7.884761182714177,
           0.6344519372730537,
           1.153186225609513,
           0.9417022465184949,
           0.6863253661066997,
           1.2010693906867245,
           0.929731455249192,
           2.2385379673596426,
           0.9337217190056263,
           1.9113363393320297,
           1.488368381149994,
           1.248952555763936,
           3.303938390327601,
           1.4245241610470452,
           2.258489286141814,
           2.0589760983200986,
           1.8514823829855154,
           1.101312796775867,
           0.8938190814412833,
           0.782091696261123,
           1.9193168668448983,
           2.4699732652328317,
           1.9113363393320297,
           1.7118231515103148,
           1.0813614779936955,
           2.7732333107218388,
           1.7557160528310922,
           1.2808746658154104,
           0.6943058936195683,
           0.7940624875304259,
           1.4724073261242567,
           0.6184908822473165,
           1.2649136107896732,
           0.8818482901719804,
           1.1452056980966443,
           1.2329915007381989,
           3.1523083675830974,
           2.964765971030685,
           1.528271018714337,
           1.93926818562707,
           2.246518494872511,
           0.8339651250947688,
           1.276884402058976,
           2.174693747256694,
           0,
           0,
           0,
           0
          ],
          [
           2.972746498543554,
           0.8738677626591118,
           1.288855193328279,
           0.6504129922987909,
           1.3127967758668848,
           1.1332349068273413,
           3.0326004548900682,
           1.3526994134312278,
           2.110849527153745,
           2.262479549898248,
           3.268026016519692,
           0.6424324647859223,
           1.6559594589202347,
           1.7038426239974462,
           1.0135269941343121,
           1.5761541837915487,
           1.0454491041857867,
           2.4141095726427517,
           1.4724073261242567,
           1.380631259726268,
           1.847492119229081,
           4.50899804477076,
           0.9616535653006664,
           1.3487091496747936,
           2.829097003311919,
           1.328757830892622,
           1.117273851801604,
           2.4101193088863173,
           2.8091456845297476,
           0.782091696261123,
           1.0454491041857867,
           0.43892901320777306,
           1.1053030605323013,
           1.0853517417501297,
           0.35912373807908704,
           0.6623837835680938,
           3.50744184190575,
           2.9248633334663423,
           0.48282191452855033,
           0.9895854115957065,
           2.2505087586289454,
           0.7342085311839113,
           1.6639399864331033,
           1.061410159211524,
           0.8060332787997287,
           1.8275408004469096,
           0.6823351023502654,
           0.3950361118869958,
           0.6264714097601851,
           0.38306532061769283,
           4.19376720801245,
           1.9153266030884641,
           1.6679302501895377,
           1.4564462710985195,
           1.11328358804517,
           8.846414748014844,
           2.138781373448785,
           0.5905590359522764,
           0.6823351023502654,
           1.2569330832768046,
           0,
           0,
           0,
           0
          ],
          [
           1.2529428195203702,
           0.6065200909780136,
           0.44291927696420735,
           0.9097801364670205,
           1.7716771078568294,
           1.6799010414588404,
           1.1611667531223815,
           1.580144447547983,
           1.4644267986113881,
           3.307928654084035,
           0.9776146203264036,
           4.923985475439927,
           0.7142572124017398,
           0.18754239655241212,
           2.6096324967080324,
           2.537807749092215,
           1.564183392522246,
           1.6240373488687603,
           0.5546466621443678,
           1.6679302501895377,
           1.117273851801604,
           1.2409720282510674,
           1.6160568213558917,
           1.4524560073420854,
           1.1851083356609873,
           2.4779537927457005,
           0.5107537608235904,
           1.4564462710985195,
           0.47883165077211604,
           0.9456925102749292,
           0.8180040700690316,
           1.1890985994174215,
           1.0215075216471807,
           0.7860819600175573,
           1.6360081401380633,
           3.4196560392641953,
           2.7812138382347076,
           0.5267148158493277,
           1.807589481664738,
           3.455568413072104,
           1.9751805594349785,
           1.0334783129164837,
           1.9552292406528071,
           7.166513706556003,
           1.1092933242887355,
           3.112405730018754,
           1.592115238817286,
           1.6160568213558917,
           1.8395115917162124,
           1.979170823191413,
           1.248952555763936,
           0.6184908822473165,
           0.44291927696420735,
           2.070946889589402,
           1.19707912693029,
           4.090020350345157,
           2.070946889589402,
           0.7581501137225171,
           1.0414588404293523,
           1.620047085112326,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "height": 800,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of Tokens Across Experts and Layers"
        },
        "width": 800,
        "xaxis": {
         "constrain": "domain",
         "tickangle": -45,
         "title": {
          "text": "Expert Index"
         }
        },
        "yaxis": {
         "scaleanchor": "x",
         "scaleratio": 1,
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "domain = 'qwen-arxiv'\n",
    "\n",
    "# Plot expert distribution for all processed data\n",
    "# with torch.cuda.amp.autocast():  # Enable automatic mixed precision\n",
    "fig = plot_expert_distribution(domain=domain)\n",
    "fig.show()\n",
    "\n",
    "# Save plot as HTML and image\n",
    "fig.write_html(f'plots-qwen-arxiv/{domain}_expert_dist.html')\n",
    "fig.write_image(f'plots-qwen-arxiv/{domain}_expert_dist.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
