Intersection Bodies and Generalized Cosine Transforms Intersection bodies represent a remarkable class of geometric objects associated with sections of star bodies and invoking Radon transforms, generalized cosine transforms, and the relevant Fourier analysis. The main focus of this article is interrelation between generalized cosine transforms of different kinds in the context of their application to investigation of a certain family of intersection bodies, which we call $\lam$-intersection bodies. The latter include $k$-intersection bodies (in the sense of A. Koldobsky) and unit balls of finite-dimensional subspaces of $L_p$-spaces. In particular, we show that restrictions onto lower dimensional subspaces of the spherical Radon transforms and the generalized cosine transforms preserve their integral-geometric structure. We apply this result to the study of sections of $\lam$-intersection bodies. New characterizations of this class of bodies are obtained and examples are given. We also review some known facts and give them new proofs. Excision for K-theory of connective ring spectra We extend Geisser and Hesselholt's result on ``bi-relative K-theory'' from discrete rings to connective ring spectra. That is, if $\mathcal A$ is a homotopy cartesian $n$-cube of ring spectra (satisfying connectivity hypotheses), then the $(n+1)$-cube induced by the cyclotomic trace $$K(\mathcal A)\to TC(\mathcal A)$$ is homotopy cartesian after profinite completion. In other words, the fiber of the profinitely completed cyclotomic trace satisfies excision. Local spin dynamic arising from the non-perturbative SU(2) gauge field of the spin orbit effect We use the non-perturbative gauge field approach to study the effects of spin orbit coupling on the dynamic of magnetic moment. We present a general equation of motion (EOM) which unifies i) the spin orbit coupling effect derived from the SU(2) spin gauge field, and ii) the moment chirality effect previously derived from the topological U(1)xU(1) rotation gauge under the adiabatic condition. We present a modified Landau-Liftshitz-Gilbert equation and discuss the implication of the modified EOM in various technological applications, such as current-induced switching and trajectory of magnetic moments in spin-valve multilayers, magnetic memory and diluted magnetic semiconductor. Measurement of the p\bar{p}\to WZ + X cross section at \sqrt{s}=1.96 TeV and limits on WWZ trilinear gauge couplings We present measurements of the process $p\bar{p} \to WZ+X \to \ell^{\prime} \nu_{\ell^{\prime}} \ell \bar{\ell}$ at $\sqrt{s}=1.96$ TeV, where $\ell$ and $\ell^{\prime}$ are electrons or muons. Using 1 fb$^{-1}$ of data from the D0 experiment, we observe 13 candidates with an expected background of $4.5\pm0.6$ events and measure a cross section $\sigma(WZ)=2.7^{+1.7}_{-1.3}$ pb. From the number of observed events and the $Z$ boson transverse momentum distribution, we limit the trilinear $WWZ$ gauge couplings to $-0.17 \le \lambda_Z \le 0.21$ $(\Delta \kappa_Z = 0)$ at the 95% C.L. for a form factor scale $\Lambda=2$ TeV. Further, assuming that $\Delta g^Z_1 = \Delta\kappa_Z$, we find $-0.12 \le \Delta\kappa_Z \le 0.29$ $(\lambda_Z=0)$ at the 95% C.L. These are the most restrictive limits on the $WWZ$ couplings available to date. Radiation Hydrodynamics in Kerr Spacetime: Equations without Coordinate Singularity at the Event Horizon Equations of fully general relativistic radiation hydrodynamics around a rotating black hole are derived by using the Kerr-Schild coordinate where there is no coordinate singularity at the event horizon. Since the radiation interacts with matter moving with relativistic velocities near the event horizon, the interplay between the radiation and the matter should be described fully relativistically. In the formalism used in this study, while the interactions between matter and radiation are introduced in the comoving frame, the equations and the equations and the derivatives for the description of the global evolution of both matter and the radiation are given in the Kerr-Schild frame (KSF) which is a frame fixed to the coordinate describing the central black hole. As a frame fixed to the coordinate, we use the locally non-rotating reference frame (LNRF) representing a radially falling frame when the Kerr-Schild coordinate is used. Around the rotating black hole, both the matter and the radiation are affected by the frame-dragging effects. Width of Radio-Loud and Radio-Quiet CMEs In the present paper we report on the difference in angular sizes between radio-loud and radio-quiet CMEs. For this purpose we compiled these two samples of events using Wind/WAVES and SOHO/LASCO observations obtained during 1996-2005. It is shown that the radio-loud CMEs are almost two times wider than the radio-quiet CMEs (considering expanding parts of CMEs). Furthermore we show that the radio-quiet CMEs have a narrow expanding bright part with a large extended diffusive structure. These results were obtained by measuring the CME widths in three different ways. Test of CZT Detectors with Different Pixel Pitches and Thicknesses The Modified Horizontal Bridgman (MHB) process produces Cadmium Zinc Telluride (CZT) crystals with high yield and excellent homogeneity. Various groups,including our own, previously reported on the test of 2x2x0.5 cm3 MHB CZT detectors grown by the company Orbotech and read out with 8x8 pixels. In this contribution, we describe the optimization of the photolithographic process used for contacting the CZT detector with pixel contacts. The optimized process gives a high yield of good pixels down to pixel diameters/pitches of 50 microns. Furthermore, we discuss the performance of 0.5 cm and 0.75 cm thick detectors contacted with 64 and 225 pixel read out with the RENA-3 ASICs from the company NOVA R&D. Quantum Circuits Architecture We present a method for optimizing quantum circuits architecture. The method is based on the notion of "quantum comb", which describes a circuit board in which one can insert variable subcircuits. The method allows one to efficiently address novel kinds of quantum information processing tasks, such as storing-retrieving, and cloning of channels. A Method for Deriving Transverse Masses Using Lagrange Multipliers We use Lagrange multipliers to extend the traditional definition of Transverse Mass used in experimental high energy physics. We demonstrate the method by implementing it to derive a new Transverse Mass that can be used as a discriminator to distinguish between top decays via a charged W or a charged Higgs Boson. Superfluid pairing between fermions with unequal masses We consider a superfluid state in a two-component gas of fermionic atoms with equal densities and unequal masses in the BCS limit. We develop a perturbation theory along the lines proposed by Gorkov and Melik-Barkhudarov and find that for a large difference in the masses of heavy ($M$) and light ($m$) atoms one has to take into account both the second-order and third-order contributions. The result for the critical temperature and order parameter is then quite different from the prediction of the simple BCS approach. Moreover, the small parameter of the theory turns out to be $(p_{F}|a|)/\hbar)\sqrt{M/m}\ll1$, where $p_{F}$ is the Fermi momentum, and $a$ the scattering length. Thus, for a large mass ratio $M/m$ the conventional perturbation theory requires significantly smaller Fermi momenta (densities) or scattering lengths than in the case of $M\sim m$, where the small parameter is $(p_{F}|a|)/\hbar)\ll1$. We show that 3-body scattering resonances appearing at a large mass ratio due to the presence of 3-body bound Efimov states do not influence the result, which in this sense becomes universal.
Opportunistic Scheduling and Beamforming for MIMO-OFDMA Downlink Systems with Reduced Feedback Opportunistic scheduling and beamforming schemes with reduced feedback are proposed for MIMO-OFDMA downlink systems. Unlike the conventional beamforming schemes in which beamforming is implemented solely by the base station (BS) in a per-subcarrier fashion, the proposed schemes take advantages of a novel channel decomposition technique to perform beamforming jointly by the BS and the mobile terminal (MT). The resulting beamforming schemes allow the BS to employ only {\em one} beamforming matrix (BFM) to form beams for {\em all} subcarriers while each MT completes the beamforming task for each subcarrier locally. Consequently, for a MIMO-OFDMA system with $Q$ subcarriers, the proposed opportunistic scheduling and beamforming schemes require only one BFM index and $Q$ supportable throughputs to be returned from each MT to the BS, in contrast to $Q$ BFM indices and $Q$ supportable throughputs required by the conventional schemes. The advantage of the proposed schemes becomes more evident when a further feedback reduction is achieved by grouping adjacent subcarriers into exclusive clusters and returning only cluster information from each MT. Theoretical analysis and computer simulation confirm the effectiveness of the proposed reduced-feedback schemes. The long-range interaction in massless (lambda Phi^4)_4 theory Does massless (lambda Phi^4)_4 theory exhibit spontaneous symmetry breaking (SSB)? The raw 1-loop result implies that it does, but the "RG-improved" result implies the opposite. I argue that the appropriate "low-energy effective theory" is a nonlocal field theory involving an attractive, long-range interaction Phi^2(x) Phi^2(y)/z^4, where z=|x-y|. RG improvement then requires running couplings for both this interaction and the original pointlike interaction. A crude calculation in this framework yields SSB even after "RG improvement" and closely agrees with the raw 1-loop result. Hot accretion with outflow and thermal conduction We present self-similar solutions for advection -dominated accretion flows with thermal conduction in the presence of outflows. Possible effects of outflows on the accretion flow are parametrized and a saturated form of thermal conduction, as is appropriate for the weakly-collisional regime of interest, is included in our model. While the cooling effect of outflows is noticeable, thermal conduction provides an extra heating source. In comparison to accretion flows without winds, we show that the disc rotates faster and becomes cooler because of the angular momentum and energy flux which are taking away by the winds. But thermal conduction opposes the effects of winds and not only decreases the rotational velocity, but increases the temperature. However, reduction of the surface density and the enhanced accretion velocity are amplified by both of the winds and the thermal conduction. We find that for stronger outflows, a higher level of saturated thermal conduction is needed to significantly modify the physical profiles of the accretion flow. The Geometry of Filtering Geometry arising from two diffusion operators (smooth semi-elliptic, second order differential operators) on different spaces but intertwined by a smooth map is described. Particular cases arise from Riemannian submersions when the operators are Laplace-Beltrami operators, from equivariant operators on the total space of a principal bundle, and for the operators on the diffeomorphism group arising from stochastic flows. Classical non-linear filtering problems also lead to such conffigurations. A basic tool is the, possibly, non-linear "semi-connection" induced by this set up, leading to a canonical decomposition of the operator on the domain space. Topics discussed include: generalised Wietzenbock curvatures arising in the equivariant case, skew -product decompositions of diffusion processes, conditioned processes, classical filtering, decomposition of stochastic flows, and connections determined by stochastic differential equations. Ordering dynamics in the presence of multiple phases The dynamics of the 2D Potts ferromagnet when quenched below the transition temperature is investigated in the case of discontinuous phase transition, which is interesting for understandingthe non equilibrium dynamics of systems with many competing equivalent low temperature phases, that appears to be not much explored. After briefly reviewing some recent findings, we focus on the numerical study of quenches just below the transition temperature on square lattices. We show that, up to a certain time, metastable states can be observed for which energy stays constant above the equilibrium energy and the self-correlation function displays a fast decay. On the neutrality issue in the Polyakov-loop NJL model We elucidate how the color neutrality is harmed in the Polyakov Nambu-Jona Lasinio (PNJL) model at finite density within the adopted mean field approximation. Also we point out how usual assumption about the diagonal form of the Wilson loop may fail in the presence of the diquark condensate on several grounds. Duality considerations about the Maxwell-Podolsky theory through the symplectic embedding formalism and spectrum analysis We find the dual equivalent (gauge invariant) version of the Maxwell theory in D=4 with a Proca-like mass term by using the symplectic embedding method. The dual theory obtained (Maxwell-Podolsky) includes a higher-order derivative term and preserve the gauge symmetry. We also furnish an investigation of the pole structure of the vector propagator by the residue matrix which considers the eventual existence of the negative-norm of the theory. On the derivation of structural models with general thermomechanical prestress The vibrating behaviour of thin structures is affected by prestress states. Hence, the effects of thermal prestress are important research subjects in view of ambient vibration monitoring of civil structures. The interaction between prestress, geometrically non-linear behaviour, as well as damping and its coupling with the aforementioned phenomena has to be taken into account for a comprehensive understanding of the structural behaviour. Since the literature on this subject lacks a clear procedure to derive models of thin prestressed and damped structures from 3D continuum mechanics, this paper presents a new derivation of models for thin structures accounting for generic prestress, moderate rotations and viscous damping. Although inspired by classical approaches, the proposed procedure is quite different, because of (i) the definition of a modified Hu-Washizu (H-W) functional, accounting for stress constraints associated with Lagrange multipliers, in order to derive lower-dimensional models in a convenient way; (ii) an original definition of a (mechanical and thermal) strain measure and a rotation measure enabling one to identify the main terms in the strain energy and to derive a cascade of lower-dimensional models (iii) a new definition of "strain-rotation domains" providing a clear interpretation of the classical assumptions of "small perturbations" and "small strains and moderate rotations"; (iv) the introduction of a pseudo-potential with stress constraints to account for viscous damping. The proposed procedure is applied to thin beams. Boosted high harmonics pulse from a double-sided relativistic mirror An ultra-bright high-intensity X- and gamma-radiation source is proposed. A high-density thin plasma slab, accelerating in the radiation pressure dominant regime by a co-propagating ultra-intense electromagnetic wave, reflects a counter-propagating relativistically strong electromagnetic wave, producing strongly time-compressed and intensified radiation due to the double Doppler effect. The reflected light contains relativistic harmonics generated at the plasma slab, all upshifted with the same factor as the fundamental mode of the incident light. Resonant Photonic Quasicrystalline and Aperiodic Structures We have theoretically studied propagation of exciton-polaritons in deterministic aperiodic multiple-quantum-well structures, particularly, in the Fibonacci and Thue-Morse chains. The attention is concentrated on the structures tuned to the resonant Bragg condition with two-dimensional quantum-well exciton. The superradiant or photonic-quasicrystal regimes are realized in these structures depending on the number of the wells. The developed theory based on the two-wave approximation allows one to describe analytically the exact transfer-matrix computations for transmittance and reflectance spectra in the whole frequency range except for a narrow region near the exciton resonance.
In this region the optical spectra and the exciton-polariton dispersion demonstrate scaling invariance and self-similarity which can be interpreted in terms of the ``band-edge'' cycle of the trace map, in the case of Fibonacci structures, and in terms of zero reflection frequencies, in the case of Thue-Morse structures. {\it Ab initio} nuclear structure - the large sparse matrix eigenvalue problem The structure and reactions of light nuclei represent fundamental and formidable challenges for microscopic theory based on realistic strong interaction potentials. Several {\it ab initio} methods have now emerged that provide nearly exact solutions for some nuclear properties. The {\it ab initio} no core shell model (NCSM) and the no core full configuration (NCFC) method, frame this quantum many-particle problem as a large sparse matrix eigenvalue problem where one evaluates the Hamiltonian matrix in a basis space consisting of many-fermion Slater determinants and then solves for a set of the lowest eigenvalues and their associated eigenvectors. The resulting eigenvectors are employed to evaluate a set of experimental quantities to test the underlying potential. For fundamental problems of interest, the matrix dimension often exceeds $10^{10}$ and the number of nonzero matrix elements may saturate available storage on present-day leadership class facilities. We survey recent results and advances in solving this large sparse matrix eigenvalue problem. W also outline the challenges that lie ahead for achieving further breakthroughs in fundamental nuclear theory using these {\it ab initio} approaches. Arbitrarily Accurate Dynamical Control in Open Quantum Systems We show that open-loop dynamical control techniques may be used to synthesize unitary transformations in open quantum systems in such a way that decoherence is perturbatively compensated for to a desired (in principle arbitrarily high) level of accuracy, which depends only on the strength of the relevant errors and the achievable rate of control modulation. Our constructive and fully analytical solution employs concatenated dynamically corrected gates, and is applicable independently of detailed knowledge of the system-environment interactions and environment dynamics. Explicit implications for boosting quantum gate fidelities in realistic scenarios are addressed. Reevaluation of the hadronic contribution to the muon magnetic anomaly using new e+e- -> pi+pi- cross section data from BABAR Using recently published, high-precision pi+pi- cross section data by the BABAR experiment from the analysis of e+e- events with high-energy photon radiation in the initial state, we reevaluate the lowest order hadronic contribution a_mu[had,LO] to the anomalous magnetic moment of the muon. We employ newly developed software featuring improved data interpolation and averaging, more accurate error propagation and systematic validation. With the new data, the discrepancy between the e+e- and tau-based results for the dominant two-pion mode reduces from previously 2.4 sigma to 1.5 sigma in the dispersion integral, though significant local discrepancies in the spectra persist. We obtain for the e+e- based evaluation amu[had,LO] = (695.5 +- 4.1) 10^-10, where the error accounts for all sources. The full Standard Model prediction of a_mu differs from the experimental value by 3.2 sigma. Revealing evolved massive stars with Spitzer Massive evolved stars loss a large fraction of their mass via copious stellar wind or instant outbursts and during certain evolutionary phases they can be identified via the presence of their circumstellar nebulae. In this paper, we present the results of search for compact nebulae (reminiscent of circumstellar nebulae around evolved massive stars) using archival 24 $\mu$m data obtained with the Multiband Imaging Photometer for Spitzer. We discovered 115 nebulae, most of which bear a striking resemblance to the circumstellar nebulae associated with Luminous Blue Variables (LBVs) and late WN-type (WNL) Wolf-Rayet (WR) stars in the Milky Way and the Large Magellanic Cloud (LMC). We interpret this similarity as an indication that the central stars of detected nebulae are either LBVs or related evolved massive stars. Our interpretation is supported by follow-up spectroscopy of two dozens of these central stars, most of which turns out to be either candidate LBVs (cLBVs), blue supergiants or WNL stars. We expect that the forthcoming spectroscopy of the remaining objects from our list, accompanied by the spectrophotometric monitoring of the already discovered cLBVs, will further increase the known population of Galactic LBVs, which in turn would have profound consequences for better understanding the LBV phenomenon and its role in the transition between hydrogen burning O stars and helium burning WR stars. We also report the detection of an arc-like structure attached to the cLBV HD326823 and an arc associated with the LBV R99 (HD269445) in the LMC. Quasi-Fuchsian 3-Manifolds and Metrics on Teichm\"{u}ller Space An almost Fuchsian 3-manifold is a quasi-Fuchsian manifold which contains an incompressible closed minimal surface with principal curvatures in the range of $(-1,1)$. Such a 3-manifold $M$ admits a foliation of parallel surfaces, whose locus in Teichm\"{u}ller space is represented as a path $\gamma$, we show that $\gamma$ joins the conformal structures of the two components of the conformal boundary of $M$. Moreover, we obtain an upper bound for the Teichm\"{u}ller distance between any two points on $\gamma$, in particular, the Teichm\"{u}ller distance between the two components of the conformal boundary of $M$, in terms of the principal curvatures of the minimal surface in $M$. We also establish a new potential for the Weil-Petersson metric on Teichm\"{u}ller space. Quasiparticles of spatially anisotropic triangular antiferromagnets in a magnetic field The spectral properties of the spin-1/2 Heisenberg antiferromagnet on an anisotropic triangular lattice in a magnetic field are investigated using a weak-interchain-coupling approach combined with exact solutions of a chain. Dominant modes induced by interchain interactions in a magnetic field behave as quasiparticles which show distinctive features such as anomalous incommensurate ordering and high-energy modes. In terms of them, various unusual features observed in the anisotropic triangular antiferromagnet Cs_2CuCl_4 in a magnetic field are quantitatively explained in a unified manner. Higher-order properties and Bell-inequality violation for the three-mode enhanced squeezed state By extending the usual two-mode squeezing operator $S_{2}=\exp [ i\lambda (Q_{1}P_{2}+Q_{2}P_{1}) ] $ to the three-mode squeezing operator $S_{3}=\exp {i\lambda [ Q_{1}(P_{2}+P_{3}) +Q_{2}(P_{1}+P_{3}) +Q_{3}(P_{1}+P_{2}) ]} $, we obtain the corresponding three-mode squeezed coherent state. The state's higher-order properties, such as higher-order squeezing and higher-order sub-Possonian photon statistics, are investigated. It is found that the new squeezed state not only can be squeezed to all even orders but also exhibits squeezing enhancement comparing with the usual cases. In addition, we examine the violation of Bell-inequality for the three-mode squeezed states by using the formalism of Wigner representation. Automatic Detection of Limb Prominences in 304 A EUV Images A new algorithm for automatic detection of prominences on the solar limb in 304 A EUV images is presented, and results of its application to SOHO/EIT data discussed. The detection is based on the method of moments combined with a classifier analysis aimed at discriminating between limb prominences, active regions, and the quiet corona. This classifier analysis is based on a Support Vector Machine (SVM). Using a set of 12 moments of the radial intensity profiles, the algorithm performs well in discriminating between the above three categories of limb structures, with a misclassification rate of 7%.
Pixels detected as belonging to a prominence are then used as starting point to reconstruct the whole prominence by morphological image processing techniques. It is planned that a catalogue of limb prominences identified in SOHO and STEREO data using this method will be made publicly available to the scientific community. Energy Parity Games Energy parity games are infinite two-player turn-based games played on weighted graphs. The objective of the game combines a (qualitative) parity condition with the (quantitative) requirement that the sum of the weights (i.e., the level of energy in the game) must remain positive. Beside their own interest in the design and synthesis of resource-constrained omega-regular specifications, energy parity games provide one of the simplest model of games with combined qualitative and quantitative objective. Our main results are as follows: (a) exponential memory is necessary and sufficient for winning strategies in energy parity games; (b) the problem of deciding the winner in energy parity games can be solved in NP \cap coNP; and (c) we give an algorithm to solve energy parity by reduction to energy games. We also show that the problem of deciding the winner in energy parity games is polynomially equivalent to the problem of deciding the winner in mean-payoff parity games, while optimal strategies may require infinite memory in mean-payoff parity games. As a consequence we obtain a conceptually simple algorithm to solve mean-payoff parity games. Semi-direct Gauge Mediation in Conformal Windows of Vector-like Gauge Theories Direct gauge mediation models using the Intriligator-Seiberg-Shih (ISS) metastable vacua suffer from the Landau pole problem of the standard model gauge couplings and the existence of R symmetry forbidding gaugino masses. These problems may be solved by using the recently proposed SUSY breaking models in a conformal window of the vector-like $SU(N_C)$ gauge theory with gauge singlets. In this paper we propose a model of gauge mediation based on the SUSY-breaking model in the conformal window, and study the dynamics for the SUSY breaking. In the model, there are massive vector-like bifundamental fields charged under both $SU(N_C)$ and the standard model gauge group, and our model can be regarded as a semi-direct gauge mediation model. The color number $N_C$ can be small to avoid the Landau pole problem, and the R symmetry is also broken under a reasonable assumption on the strong dynamics of the model. The model possesses only one free parameter, and the gaugino and sfermion masses are naturally of the same order. Dusty Disks around White Dwarfs I: Origin of Debris Disks A significant fraction of the mature FGK stars have cool dusty disks at least an orders of magnitudes brighter than the solar system's outer zodiacal light. Since such dusts must be continually replenished, they are generally assumed to be the collisional fragments of residual planetesimals analogous to the Kuiper Belt objects. At least 10% of solar type stars also bear gas giant planets. The fraction of stars with known gas giants or detectable debris disks (or both) appears to increase with the stellar mass. Here, we examine the dynamical evolution of systems of long-period gas giant planets and residual planetesimals as their host stars evolve off the main sequence, lose mass, and form planetary nebula around remnant white dwarf cores. The orbits of distant gas giant planets and super-km-size planetesimals expand adiabatically. During the most intense AGB mass loss phase, sub-meter-size particles migrate toward their host stars due to the strong hydrodynamical drag by the intense stellar wind. Along their migration paths, gas giant planets capture and sweep up sub-km-size planetesimals onto their mean-motion resonances. These planetesimals also acquire modest eccentricities which are determined by the mass of the perturbing planets, the rate and speed of stellar mass loss. The swept-up planetesimals undergo disruptive collisions which lead to the production of grains with an extended size range. The radiation drag on these particles is ineffective against the planets' resonant barrier and they form 30-to-150-AU-sizes rings which can effective reprocess the stellar irradiation in the form of FIR continuum. We identify the recently discovered dust ring around the white dwarf WD 2226-210 at the center of the Helix nebula as a prototype of such disks and suggest such rings may be common. Average case performance of heuristics for multi-dimensional assignment problems We consider multi-dimensional assignment problems in a probabilistic setting. Our main results are: (i) A new efficient algorithm for the 3-dimensional planar problem, based on enumerating and selecting from a set of "alternating-path trees"; (ii) A new efficient matching-based algorithm for the 3-dimensional axial problem. Effects of high pressure on the physical properties of MgB2 The synthesis of MgB2-based materials under high pressure gave the possibility to suppress the evaporation of magnesium and to obtain near theoretically dense nanograined structures with high superconducting, thermal conducting, and mechanical characteristics: critical current densities of 1.8-1.0 \cdot 106 A/cm2 in the self field and 103 A/cm2 in a magnetic field of 8 T at 20 K, 5-3 \cdot 105 A/cm2 in self field at 30 K, the corresponding critical fields being HC2 = 15 T at 22 K and irreversible fields Hirr =13 T at 20 K, and Hirr =3.5 T at 30 K, thermal conduction of 53+/-2 W/(m \cdot \kappa), the Vickers hardness Hv=10.12+/-0.2 GPa under a load of 148.8 N and the fracture toughness K1C = 7.6+/-2.0 MPa m0.5 under the same load, the Young modulus E=213 GPa. Estimation of quenching current and AC losses allowed the conclusion that highpressure-prepared materials are promising for application in transformer-type fault current limiters working at 20-30 K. Face Synthesis (FASY) System for Generation of a Face Image from Human Description This paper aims at generating a new face based on the human like description using a new concept. The FASY (FAce SYnthesis) System is a Face Database Retrieval and new Face generation System that is under development. One of its main features is the generation of the requested face when it is not found in the existing database, which allows a continuous growing of the database also. An associative star-three-product and applications to M two/M five-brane theory The star-product between functions enable us to take the large $N$ limit in a controlled way. At finite $N$ it serves as a substitute for matrix multiplications. Non-abelian gauge theory can be deconstructed from lower dimensional gauge theories using star-products. In this paper we extend the star-product to a star-three-product. We then apply the star-three-product to realize hermitian three-algebra of ABJM theory. We define a fuzzy three-torus. We deconstruct Abelian M five-brane in a constant background three-form potential on a fuzzy three-torus. We deconstruct non-Abelian extensions which might be related with multiple M five branes. We also mention the fuzzy three-sphere case. Ion-assisted ground-state cooling of a trapped polar molecule We propose and analyze a scheme for sympathetic cooling of the translational motion of polar molecules in an optical lattice, interacting one by one with laser-cooled ions in a radio-frequency trap. The energy gap between the excitation spectra of the particles in their respective trapping potentials is bridged by means of a parametric resonance, provided by the additional modulation of the RF field. We analyze two scenarios: simultaneous laser cooling and energy exchange between the ion and the molecule, and a scheme when these two processes take place separately. We calculate the lowest final energy of the molecule and the cooling rate depending on the amplitude of the parametric modulation. For small parametric modulation, the dynamics can be solved analytically within the rotating wave approximation.
Two distinct quasiparticle inelastic scattering rates in the $t-J$ model and their relevance for high-$T_c$ cuprates superconductors The recent findings about two distinct quasiparticle inelastic scattering rates in angle-dependent magnetoresistance (ADMR) experiments in overdoped high-$T_c$ cuprates superconductors have motivated many discussions related to the link between superconductivity, pseudogap, and transport properties in these materials. After computing dynamical self-energy corrections in the framework of the $t-J$ model the inelastic scattering rate was introduced as usual. Two distinct scattering rates were obtained showing the main features observed in ADMR experiments. Predictions for underdoped cuprates are discussed. The implicances of these two scattering rates on the resistivity were also studied as a function of doping and temperature and confronted with experimental measurements. On H-groups and their applications to topological homotopy groups This paper develops a basic theory of H-groups. We introduce a special quotient of H-groups and extend some algebraic constructions of topological groups to the category of H-groups and H-maps. We use these constructions to prove some advantages in topological homotopy groups. Also, we present a family of spaces that their topological fundamental groups are indiscrete topological group and find out a family of spaces whose topological fundamental group is a topological group. Study of the heating effect contribution to the nonlinear dielectric response of a supercooled liquid We present a detailed study of the heating effects in dielectric measurements carried out on a liquid. Such effects come from the dissipation of the electric power in the liquid and give a contribution to the nonlinear third harmonics susceptibility chi_3 which depends on the frequency and temperature. This study is used to evaluate a possible `spurious' contribution to the recently measured nonlinear susceptibility of an archetypical glassforming liquid (Glycerol). Those measurements have been shown to give a direct evaluation of the number of dynamically correlated molecules temperature dependence close to the glass transition temperature T_g~190K (Crauste-Thibierge et al., Phys. Rev. Lett 104,165703(2010)). We show that the heating contribution is totally negligible (i) below 204K at any frequency; (ii) for any temperature at the frequency where the third harmonics response chi_3 is maximum. Besides, this heating contribution does not scale as a function of f/f_{\alpha}, with f_{\alpha}(T) the relaxation frequency of the liquid. In the high frequency range, when f/f_{\alpha} >= 1, we find that the heating contribution is damped because the dipoles cannot follow instantaneously the temperature modulation due to the heating phenomenon. An estimate of the magnitude of this damping is given. Thermal field theory derivation of the source term induced by a fast parton from the quark energy-momentum tensor I derive the distribution of energy and momentum transmitted from a fast parton to a medium of thermalized quarks, or the source term, in perturbative thermal field theory directly from the quark energy-momentum tensor. The fast parton is coupled to the medium by adding an interaction term to the Lagrangian. The thermal expectation value of the energy-momentum tensor source term is then evaluated using standard Feynman rules at finite temperature. It is found that local excitations, which are important for exciting an observable Mach cone structure, fall sharply as a function of the energy of the fast parton. This may have implications for the trigger $p_T$ dependence of measurements of azimuthal dihadron particle correlations in heavy-ion collisions. In particular, a conical emission pattern would be less likely to be observed for increasing trigger $p_T$. I show that the results presented in this paper can be generalized to more realistic modeling of fast parton propagation, such as through a time dependent interaction term, in future studies. Exceptional collections on toric Fano threefolds and birational geometry Bernardi and Tirabassi show the existence of full strong exceptional collections consisting of line bundles on smooth toric Fano $3$-folds under assuming Bondal's conjecture, which states that the Frobenius push-forward of the structure sheaf $\mc O_X$ generates the derived category $D^b(X)$ for smooth projective toric varieties $X$. In this article, we show Bondal's conjecture for smooth toric Fano $3$-folds and also improve their result, using birational geometry. THz driven quantum wells: Coulomb interactions and Stark shifts in the ultrastrong coupling regime We investigate the near infrared interband absorption of semiconductor quantum wells driven by intense terahertz radiation in the regime of ultrastrong coupling, where the Rabi frequency is a significant fraction of the frequency of the strongly driven transition. With the driving frequency tuned just below the lowest frequency transition between valence subbands, a particularly interesting phenomenon is observed. As the THz power increases, a new peak emerges above the frequency of the undriven exciton peak which grows and eventually becomes the larger of the two. This reversal of relative peak intensity is inconsistent with the Autler-Townes effect in a three-state system while within the rotating wave approximation (RWA). In the samples investigated, the Bloch-Siegert shift (associated with abandoning the RWA), exciton binding energy, the Rabi energy, and non-resonant AC Stark effects are all of comparable magnitude. Solution of a semiconductor Bloch model with one conduction and multiple valence subbands indicates that the AC Stark effect is predominantly responsible for the observed phenomenon. A Novel Approach for Fast Detection of Multiple Change Points in Linear Models A change point problem occurs in many statistical applications. If there exist change points in a model, it is harmful to make a statistical analysis without any consideration of the existence of the change points and the results derived from such an analysis may be misleading. There are rich literatures on change point detection. Although many methods have been proposed for detecting multiple change points, using these methods to find multiple change points in a large sample seems not feasible. In this article, a connection between multiple change point detection and variable selection through a proper segmentation of data sequence is established, and a novel approach is proposed to tackle multiple change point detection problem via the following two key steps: (1) apply the recent advances in consistent variable selection methods such as SCAD, adaptive LASSO and MCP to detect change points; (2) employ a refine procedure to improve the accuracy of change point estimation. Five algorithms are hence proposed, which can detect change points with much less time and more accuracy compared to those in literature. In addition, an optimal segmentation algorithm based on residual sum of squares is given. Our simulation study shows that the proposed algorithms are computationally efficient with improved change point estimation accuracy. The new approach is readily generalized to detect multiple change points in other models such as generalized linear models and nonparametric models. Supersolid Phase of Cold Fermionic Polar Molecules in 2D Optical Lattices We study a system of ultra-cold fermionic polar molecules in a two-dimensional square lattice interacting via both the long-ranged dipole-dipole interaction and a short-ranged on-site attractive interaction. Singlet superfluid, charge density wave, and supersolid phases are found to exist in the system. We map out the zero temperature phase diagram and find that the supersolid phase is considerably stabilized by the dipole-dipole interaction and thus can exist over a large region of filling factors. We study the melting of the supersolid phase with increasing temperature, map out a finite temperature phase diagram of the system at fixed filling, and determine the parameter region where the supersolid phase can possibly be observed in experiments. Most-attractive-channel study for bulk and brane fermions in warped space The idea of the self-breaking of the standard model gauge symmetry is applied to a gauge theory in a warped space. We systematically examine the gauge couplings of bulk and brane fermions. The constraint on the masses of bulk fermions is found under the conditions that the ordinary four-dimensional massless gluon is not condensed and that color-triplet scalar bound states are not formed. For bulk fermions with zero modes for the left- and right-handed components, the mass parameters are required to be at least $c\simg 1/2$ and $c\siml -1/2$, respectively. Then possible vacuum expectation values arise only from weak-doublet scalar bound states which trigger electroweak symmetry breaking.
Asymptotically AdS Magnetic Branes in (n+1)-dimensional Dilaton Gravity We present a new class of asymptotically AdS magnetic solutions in ($n+1$)-dimensional dilaton gravity in the presence of an appropriate combination of three Liouville-type potentials. This class of solutions is asymptotically AdS in six and higher dimensions and yields a spacetime with longitudinal magnetic field generated by a static brane. These solutions have no curvature singularity and no horizons but have a conic geometry with a deficit angle. We find that the brane tension depends on the dilaton field and approaches a constant as the coupling constant of dilaton field goes to infinity. We generalize this class of solutions to the case of spinning magnetic solutions and find that, when one or more rotation parameters are nonzero, the brane has a net electric charge which is proportional to the magnitude of the rotation parameters. Finally, we use the counterterm method inspired by AdS/CFT correspondence and compute the conserved quantities of these spacetimes. We found that the conserved quantities do not depend on the dilaton field, which is evident from the fact that the dilaton field vanishes on the boundary at infinity. Control Complexity in Bucklin and Fallback Voting Electoral control models ways of changing the outcome of an election via such actions as adding/deleting/partitioning either candidates or voters. To protect elections from such control attempts, computational complexity has been investigated and the corresponding NP-hardness results are termed "resistance." It has been a long-running project of research in this area to classify the major voting systems in terms of their resistance properties. We show that fallback voting, an election system proposed by Brams and Sanver (2009) to combine Bucklin with approval voting, is resistant to each of the common types of control except to destructive control by either adding or deleting voters. Thus fallback voting displays the broadest control resistance currently known to hold among natural election systems with a polynomial-time winner problem. We also study the control complexity of Bucklin voting and show that it performs at least almost as well as fallback voting in terms of control resistance. As Bucklin voting is a special case of fallback voting, each resistance shown for Bucklin voting strengthens the corresponding resistance for fallback voting. Such worst-case complexity analysis is at best an indication of security against control attempts, rather than a proof. In practice, the difficulty of control will depend on the structure of typical instances. We investigate the parameterized control complexity of Bucklin and fallback voting, according to several parameters that are often likely to be small for typical instances. Our results, though still in the worst-case complexity model, can be interpreted as significant strengthenings of the resistance demonstrations based on NP-hardness. Majorana representation of symmetric multiqubit states As early as 1932, Majorana had proposed that a pure permutation symmetric state of N spin- 1 2 particles can be represented by N spinors, which correspond geometrically to N points on the Bloch sphere. Several decades after its conception, the Majorana representation has recently attracted a great deal of attention in connection with multiparticle entanglement. A novel use of this represen- tation led to the classification of entanglement families of permutation symmetric qubits - based on the number of distinct spinors and their arrangement in constituting the multiqubit state. An elegant approach to explore how correlation information of the whole pure symmetric state gets imprinted in its parts is developed for specific entanglement classes of symmetric states. More- over, an elegant and simplified method to evaluate geometric measure of entanglement in N-qubit states obeying exchange symmetry has been developed based on the distribution of the constituent Majorana spionors over the unit sphere. Multiparticle entanglement being a key resource in sev- eral quantum information processing tasks, its deeper understanding is essential. In this review, we present a detailed description of the Majorana representation of pure symmetric states and its applicability in investigating various aspects of multiparticle entanglement. Soft QCD results from ATLAS and CMS The ATLAS and CMS Collaborations have measured properties of minimum bias events and have determined characteristics of the underlying event in proton-proton collisions at three LHC centre-of-mass energies. Comparisons to common phenomenological models and partially to other experiments have been made. The production of the strange particles K0s, Lambda and Xi is discussed. Particle correlation studies, in particular Bose-Einstein as well as long- and short-range angular correlations in proton-proton and lead ion events are explained. Comment on "Energy and information in Hodgkin-Huxley neurons" In a recent paper [A. Moujahid, A. d'Anjou, F. J. Torrealdea and F. Torrealdea, Phys. Rev. E {\bf 83}, 031912 (2011)], the authors have calculated the energy consumed in firing neurons by using the Hodgkin-Huxley (HH) model. The energy consumption rate adopted for the HH model yields a {\it negative} energy consumption meaning an energy transfer from an HH neuron to a source which is physically strange, although they have interpreted it as a biochemical energy cost. I propose an alternative expression for the power consumption which leads to a {\it positive} energy consumed in an HH neuron, presenting some model calculations which are compared to those in their paper. Determination of the Shear Viscosity Relaxation Time at Weak and Strong Coupling We investigate the microscopic origin of the relaxation time coefficient in relativistic fluid dynamics. We show that the extraction of the shear viscosity relaxation time via the gradient expansion is ambiguous and in general fails to give the correct result. The correct value for the shear viscosity relaxation time is extracted from the slowest non-hydrodynamic pole of the corresponding retarded Green's function, if such a pole is purely imaginary. According to the AdS/CFT correspondence, in strongly-coupled $\mathcal{N}=4$ SYM the non-hydrodynamic poles of the shear stress tensor nearest to the origin have a nonzero real part, which implies that the transient fluid-dynamical equations for this gauge theory are not equivalent to the well-known Israel-Stewart equations. Efficient terahertz emission from InAs nanowires We observe intense pulses of far-infrared electromagnetic radiation emitted from arrays of InAs nanowires. The THz radiation power efficiency of these structures is about 15 times higher compared to a planar InAs substrate. This is explained by the preferential orientation of coherent plasma motion to the wire surface, which overcomes radiation trapping by total-internal reflection. We present evidence that this radiation originates from a low-energy acoustic surface plasmon mode of the nanowire. This is supported by independent measurements of electronic transport on individual nanowires, ultrafast THz spectroscopy and theoretical analysis. Our combined experiments and analysis further indicate that these plasmon modes are specific to high aspect ratio geometries. Toward ensemble asteroseismology of ZZ Ceti stars with fully evolutionary models ZZ Ceti stars form the most numerous group of degenerate variable stars. They are otherwise normal DA (H-rich atmospheres) white dwarfs that exhibit pulsations. Here, we present an asteroseismological analysis for 44 bright ZZ Ceti stars based on a new set of fully evolutionary DA white dwarf models characterized by detailed chemical profiles from the centre to the surface. One of our targets is the archetypal ZZ Ceti star G117$-$B15A, for which we obtain an asteroseismological model with an effective temperature and a surface gravity in excellent agreement with the spectroscopy. The asteroseismological analysis of a set of 44 ZZ Ceti stars has the potential to characterize the global properties of the class, in particular the thicknesses of the hydrogen envelope and the stellar masses. Our results support the belief that white dwarfs in the solar neighbourhood harbor a broad range of hydrogen-layer thickness. On the Rate of Convergence to the Marchenko--Pastur Distribution Let $\mathbf X=(X_{jk})$ denote $n\times p$ random matrix with entries $X_{jk}$, which are independent for $1\le j\le n,1\le k\le p$.
We consider the rate of convergence of empirical spectral distribution function of the matrix $\mathbf W=\frac1p\mathbf X\mathbf X^*$ to the Marchenko--Pastur law. We assume that $\mathbf E X_{jk}=0$, $\mathbf E X_{jk}^2=1$ and that the distributions of the matrix elements $X_{jk}$ have a uniformly sub exponential decay in the sense that there exists a constant $\varkappa>0$ such that for any $1\le j \le n,\,1\le k\le p $ and any $t\ge 1$ we have $$ \mathbf{ Pr}\{|X_{jk}|>t\}\le \varkappa^{-1}\exp\{-t^{\varkappa}\}. $$ By means of a recursion argument it is shown that the Kolmogorov distance between the empirical spectral distribution of the sample covariance matrix $\mathbf W$ and the Marchenko--Pastur distribution is of order $O(n^{-1}\log^{4+\frac4{\varkappa}} n)$ with high probability. More congruences from Apery-like formulae We present some congruences modulo $p^{6-d}$ for sums of the type $\sum_{k=0}^{(p-3)/2}x^k{2k\choose k}/(2k+1)^d$, for $d=1,2,3$ where $p>5$ is a prime. Parametric Estimation of the Ultimate Size of Hypercomputers The performance of the emerging petaflops-scale supercomputers of the nearest future (hypercomputers) will be governed not only by the clock frequency of the processing nodes or by the width of the system bus, but also by such factors as the overall power consumption and the geometric size. In this paper, we study the influence of such parameters on one of the most important characteristics of a general purpose computer - on the degree of multithreading that must be present in an application to make the use of the hypercomputer justifiable. Our major finding is that for the class of applications with purely random memory access patterns "super-fast computing" and "high-performance computing" are essentially synonyms for "massively-parallel computing." Implications of Family Nonuniversal $Z^\prime$ Model on B -->K_0^* pi Decays Within the QCD factorization formalism, we study the possible impacts of the nonuniversal $Z^\prime$ model, which provides a flavor-changing neutral current at the tree level, on rare decays $B \to K_0^*\pi$. Under two different scenarios (S1 and S2) for identifying the scalar meson $K_0^*(1430)$, the branching ratios, CP asymmetries, and isospin asymmetries are calculated in both the standard model (SM) and the family nonuniversal $Z^\prime$ model. We find that the branching ratios and CP asymmetries are sensitive to weak annihilation. In the SM, with $\rho_A=1$ and $\phi_A\in[-30^\circ, 30^\circ]$, the branching ratios of S1 (S2) are smaller (larger) than the experimental data. Adding the contribution of the $Z^\prime$ boson in two different cases (Case-I and Case-II), for S1, the branching ratios are still far away from experiment. For S2, in Case-II, the branching ratios become smaller and can accommodate the data; in Case-I, although the center values are enhanced, they can also explain the data with large uncertainties. Similar conclusions are also reached for CP asymmetries. Our results indicate that S2 is more favored than S1, even after considering new physics effects. Moreover, if there exists a nonuniversal $Z^\prime$ boson, Case-II is preferred. All results can be tested in the LHC-b experiment and forthcoming super-B factory. Rovibrational dynamics of the strontium molecule in the A^1\Sigma_u^+, c^3\Pi_u, and a^3\Sigma_u^+ manifold from state-of-the-art ab initio calculations State-of-the-art ab initio techniques have been applied to compute the potential energy curves for the electronic states in the A^1\Sigma_u^+, c^3\Pi_u, and a^3\Sigma_u^+ manifold of the strontium dimer, the spin-orbit and nonadiabatic coupling matrix elements between the states in the manifold, and the electric transition dipole moment from the ground X^1\Sigma_g^+ to the nonrelativistic and relativistic states in the A+c+a manifold. The potential energy curves and transition moments were obtained with the linear response (equation of motion) coupled cluster method limited to single, double, and linear triple excitations for the potentials and limited to single and double excitations for the transition moments. The spin-orbit and nonadiabatic coupling matrix elements were computed with the multireference configuration interaction method limited to single and double excitations. Our results for the nonrelativistic and relativistic (spin-orbit coupled) potentials deviate substantially from recent ab initio calculations. The potential energy curve for the spectroscopically active (1)0_u^+ state is in quantitative agreement with the empirical potential fitted to high-resolution Fourier transform spectra [A. Stein, H. Knoeckel, and E. Tiemann, Eur. Phys. J. D 64, 227 (2011)]. The computed ab initio points were fitted to physically sound analytical expressions, and used in converged coupled channel calculations of the rovibrational energy levels in the A+c+a manifold and line strengths for the A^1\Sigma_u^+ <-- X^1\Sigma_g^+ transitions. Positions and lifetimes of quasi-bound Feshbach resonances lying above the ^1S + ^3P_1 dissociation limit were also obtained. Our results reproduce (semi)quantitatively the experimental data observed thus far. Predictions for on-going and future experiments are also reported. Nonequilibrium phase transitions and stationary state solutions of a three-dimensional random-field Ising model under a time dependent periodic external field Nonequilibrium behavior and dynamic phase transition properties of a kinetic Ising model under the influence of periodically oscillating random-fields have been analyzed within the framework of effective field theory (EFT) based on a decoupling approximation (DA). Dynamic equation of motion has been solved for a simple cubic lattice ($q=6$) by utilizing a Glauber type stochastic process. Amplitude of the sinusoidally oscillating magnetic field is randomly distributed on the lattice sites according to bimodal and trimodal distribution functions. For a bimodal type of amplitude distribution, it is found in the high frequency regime that the dynamic phase diagrams of the system in temperature versus field amplitude plane resemble the corresponding phase diagrams of pure kinetic Ising model. Our numerical results indicate that for a bimodal distribution, both in the low and high frequency regimes, the dynamic phase diagrams always exhibit a coexistence region in which the stationary state (ferro or para) of the system is completely dependent on the initial conditions whereas for a trimodal distribution, coexistence region disappears depending on the values of system parameters. Forecasting Value-at-Risk with Time-Varying Variance, Skewness and Kurtosis in an Exponential Weighted Moving Average Framework This paper provides an insight to the time-varying dynamics of the shape of the distribution of financial return series by proposing an exponential weighted moving average model that jointly estimates volatility, skewness and kurtosis over time using a modified form of the Gram-Charlier density in which skewness and kurtosis appear directly in the functional form of this density. In this setting VaR can be described as a function of the time-varying higher moments by applying the Cornish-Fisher expansion series of the first four moments. An evaluation of the predictive performance of the proposed model in the estimation of 1-day and 10-day VaR forecasts is performed in comparison with the historical simulation, filtered historical simulation and GARCH model. The adequacy of the VaR forecasts is evaluated under the unconditional, independence and conditional likelihood ratio tests as well as Basel II regulatory tests. The results presented have significant implications for risk management, trading and hedging activities as well as in the pricing of equity derivatives.
An efficient hierarchical graph based image segmentation Hierarchical image segmentation provides region-oriented scalespace, i.e., a set of image segmentations at different detail levels in which the segmentations at finer levels are nested with respect to those at coarser levels. Most image segmentation algorithms, such as region merging algorithms, rely on a criterion for merging that does not lead to a hierarchy, and for which the tuning of the parameters can be difficult. In this work, we propose a hierarchical graph based image segmentation relying on a criterion popularized by Felzenzwalb and Huttenlocher. We illustrate with both real and synthetic images, showing efficiency, ease of use, and robustness of our method. Possibility of Gravitational Tempering in Colloidal Epitaxy to Obtain a Perfect Crystal We have performed Monte Carlo simulations of hard spheres on a pattern under gravity. We have found that a crystal formed at a moderate gravity strength contains essentially no defects while one formed at a higher strength gravity contains a significant amount of defects. This result suggests the possibility of using gravitational-tempering in a colloidal epitaxy to reduce the number of defects in colloidal crystals. Moreover, we wish to emphasize the possibility to obtain a perfect crystal. Local orthogonality as a multipartite principle for quantum correlations In recent years, the use of information principles to understand quantum correlations has been very successful. Unfortunately, all principles considered so far have a bipartite formulation, but intrinsically multipartite principles, yet to be discovered, are necessary for reproducing quantum correlations. Here, we introduce local orthogonality, an intrinsically multipartite principle stating that events involving different outcomes of the same local measurement must be exclusive, or orthogonal. We prove that it is equivalent to no-signaling in the bipartite scenario but more restrictive for more than two parties. By exploiting this non-equivalence, it is then demonstrated that some bipartite supra-quantum correlations do violate local orthogonality when distributed among several parties. Finally, we show how its multipartite character allows revealing the non-quantumness of correlations for which any bipartite principle fails. We believe that local orthogonality is a crucial ingredient for understanding no-signaling and quantum correlations. Bounds for the regularity of local cohomology of bigraded modules Let $M$ be a finitely generated bigraded module over the standard bigraded polynomial ring $S=K[x_1,...,x_m, y_1,...,y_n]$, and let $Q=(y_1,...,y_n)$. The local cohomology modules $H^k_Q(M)$ are naturally bigraded, and the components $H^k_Q(M)_j=\Dirsum_iH^k_Q(M)_{(i,j)}$ are finitely generated graded $K[x_1,...,x_m]$-modules. In this paper we study the regularity of $H^k_Q(M)_j$, and show in several cases that $\reg H^k_Q(M)_j$ is linearly bounded as a function of $j$. Multi-frequency Calderon-Zygmund analysis and connexion to Bochner-Riesz multipliers In this work, we describe several results exhibited during a talk at the El Escorial 2012 conference. We aim to pursue the development of a multi-frequency Calderon-Zygmund analysis introduced in [9]. We set a definition of general multi-frequency Calderon-Zygmund operator. Unweighted estimates are obtained using the corresponding multi-frequency decomposition of [9]. Involving a new kind of maximal sharp function, weighted estimates are obtained. On Watts' Cascade Model with Random Link Weights We study an extension of Duncan Watts' 2002 model of information cascades in social networks where edge weights are taken to be random, an innovation motivated by recent applications of cascade analysis to systemic risk in financial networks. The main result is a probabilistic analysis that characterizes the cascade in an infinite network as the fixed point of a vector-valued mapping, explicit in terms of convolution integrals that can be efficiently evaluated numerically using the fast Fourier transform algorithm. A second result gives an approximate probabilistic analysis of cascades on "real world networks", finite networks based on a fixed deterministic graph. Extensive cross testing with Monte Carlo estimates shows that this approximate analysis performs surprisingly well, and provides a flexible microscope that can be used to investigate properties of information cascades in real world networks over a wide range of model parameters. Thermodynamics of Extended Gravity Black Holes Thermodynamics of extended gravity static spherically symmetric black hole solutions is investigated. The energy issue is discussed making use of the derivation of Clausius relation from equations of motion, evaluating the black hole entropy by the Wald method and computing the related Hawking temperature. General Solution to Unidimensional Hamilton-Jacobi Equation A method for finding the general solution to the partial differential equations: \ $F(u_x,u_y)=0$; \ $F(f(x)\:u_x,u_y)=0$ \ (or \ $F(u_x,h(y)\:u_y)=0$) \ is presented, founded on a Legendre like transformation and a theorem for Pfaffian differential forms. As the solution obtained depends on an arbitrary function, then it is a general solution. As an extension of the method it is obtained a general solution to PDE: \ $F(f(x)\:u_x,u_y)=G(x)$, and then applied to unidimensional Hamilton-Jacobi equation. The chromo-Weibel instability in an expanding background In this proceedings contribution we review recent calculations of the dynamics of the chromo-Weibel instability in the quark gluon plasma. This instability is present in gauge theories with a one-particle distribution function which is momentum-space anisotropic in the local rest frame. The conditions necessary for triggering this instability can be present already in the color-glass-condensate initial state or dynamically generated by the rapid longitudinal expansion of the matter created in a heavy-ion collision. Using the hard-loop framework we study the case that the one-particle distribution function possesses an arbitrary initial momentum anisotropy that increases in time due to longitudinal free streaming. The resulting three-dimensional dynamical equations for the chromofield evolution are solved numerically. We find that there is regeneration of the longitudinal pressure due to unstable plasma modes; nevertheless, the system seems to maintain a high-degree of momentum-space anisotropy. Despite this anisotropy, we find that there is rapid longitudinal thermalization of the plasma due to the non-linear mode couplings inherent in the unstable evolution. On the Invariant Density of the Random Beta-Transformation We construct a Lebesgue measure preserving natural extension of the random beta-transformation. This allows us to give a formula for the density of the absolutely continuous invariant probability measure, answering a question of Dajani and de Vries, and also to evaluate some estimates on the typical branching rate of the set of beta-expansions of a real number. Unveiling the nature of the unidentified gamma-ray sources I: a new method for the association of gamma-ray blazars We present a new method for identifying blazar candidates by examining the locus, i.e. the region occupied by the Fermi gamma-ray blazars in the three-dimensional color space defined by the WISE infrared colors. This method is a refinement of our previous approach that made use of the two-dimensional projection of the distribution of WISE gamma-ray emitting blazars (the Strip) in the three WISE color-color planes (Massaro et al. 2012a). In this paper, we define the three-dimensional locus by means of a Principal Component (PCs) analysis of the colors distribution of a large sample of blazars composed by all the ROMA-BZCAT sources with counterparts in the WISE All-Sky Catalog and associated to gamma-ray source in the second Fermi LAT catalog (the WISE Fermi Blazars sample, WFB). Our new procedure yields a total completeness of c~81% and total efficiency of e~97%. We also obtain local estimates of the efficiency and completeness as functions of the WISE colors and galactic coordinates of the candidate blazars.
The catalog of all WISE candidate blazars associated to the WFB sample is also presented, complemented by archival multi-frequency information for the alternative associations. Finally, we apply the new association procedure to all gamma-ray blazars in the 2FGL and provide a catalog containing all the gamma-ray candidates blazars selected according to our procedure. A Dust-Obscured Massive Maximum-Starburst Galaxy at a Redshift of 6.34 Massive present-day early-type (elliptical and lenticular) galaxies probably gained the bulk of their stellar mass and heavy elements through intense, dust-enshrouded starbursts - that is, increased rates of star formation - in the most massive dark matter halos at early epochs. However, it remains unknown how soon after the Big Bang such massive starburst progenitors exist. The measured redshift distribution of dusty, massive starbursts has long been suspected to be biased low in redshift owing to selection effects, as confirmed by recent findings of systems out to redshift z~5. Here we report the identification of a massive starburst galaxy at redshift 6.34 through a submillimeter color-selection technique. We unambiguously determined the redshift from a suite of molecular and atomic fine structure cooling lines. These measurements reveal a hundred billion solar masses of highly excited, chemically evolved interstellar medium in this galaxy, which constitutes at least 40% of the baryonic mass. A "maximum starburst" converts the gas into stars at a rate more than 2,000 times that of the Milky Way, a rate among the highest observed at any epoch. Despite the overall downturn of cosmic star formation towards the highest redshifts, it seems that environments mature enough to form the most massive, intense starbursts existed at least as early as 880 million years after the Big Bang. OH (1720 MHz) Masers: A Multiwavelength Study of the Interaction between the W51C Supernova Remnant and the W51B Star Forming Region We present a comprehensive view of the W51B HII region complex and the W51C supernova remnant (SNR) using new radio observations from the VLA, VLBA, MERLIN, JCMT, and CSO along with archival data from Spitzer, ROSAT, ASCA, and Chandra. Our VLA data include the first 400 cm (74 MHz) continuum image of W51 at high resolution (88 arcsec). The 400 cm image shows non-thermal emission surrounding the G49.2-0.3 HII region, and a compact source of non-thermal emission (W51B_NT) coincident with the previously-identified OH (1720 MHz) maser spots, non-thermal 21 and 90 cm emission, and a hard X-ray source. W51B_NT falls within the region of high likelihood for the position of TeV gamma-ray emission. Using the VLBA three OH (1720 MHz) maser spots are detected in the vicinity of W51B_NT with sizes of 60 to 300 AU and Zeeman effect magnetic field strengths of 1.5 to 2.2 mG. The multiwavelength data demonstrate that the northern end of the W51B HII region complex has been partly enveloped by the advancing W51C SNR and this interaction explains the presence of W51B_NT and the OH masers. This interaction also appears in the thermal molecular gas which partially encircles W51B_NT and exhibits narrow pre-shock (DeltaV 5 km/s) and broad post-shock (DeltaV 20 km/s) velocity components. RADEX radiative transfer modeling of these two components yield physical conditions consistent with the passage of a non-dissociative C-type shock. Confirmation of the W51B/W51C interaction provides additional evidence in favor of this region being one of the best candidates for hadronic particle acceleration known thus far. Computer-Assisted Proofs of Some Identities for Bessel Functions of Fractional Order We employ computer algebra algorithms to prove a collection of identities involving Bessel functions with half-integer orders and other special functions. These identities appear in the famous Handbook of Mathematical Functions, as well as in its successor, the DLMF, but their proofs were lost. We use generating functions and symbolic summation techniques to produce new proofs for them. Priority arguments via true strages We describe a variation of Ash's $\eta$-system, and give a new proof of Ash's metatheorem. As an application, we prove a generalization of Ash and Knight's theorem on pairs of structures. Force-Induced Unzipping Transitions in an Athermal Crowded Environment Using theoretical arguments and extensive Monte Carlo (MC) simulations of a coarse-grained three-dimensional off-lattice model of a \beta-hairpin, we demonstrate that the equilibrium critical force, $F_c$, needed to unfold the biopolymer increases non-linearly with increasing volume fraction occupied by the spherical macromolecular crowding agent. Both scaling arguments and MC simulations show that the critical force increases as $F_c \approx \varphi_c^{\alpha}$. The exponent $\alpha$ is linked to the Flory exponent relating the size of the unfolded state of the biopolymer and the number of amino acids. The predicted power law dependence is confirmed in simulations of the dependence of the isothermal extensibility and the fraction of native contacts on $\varphi_c$. We also show using MC simulations that $F_c$ is linearly dependent on the average osmotic pressure ($\mathrm{P}$) exerted by the crowding agents on the \beta-hairpin. The highly significant linear correlation coefficient of 0.99657 between $F_c$ and $\mathrm{P}$ makes it straightforward to predict the dependence of the critical force on the density of crowders. Our predictions are amenable to experimental verification using Laser Optical Tweezers. Spatial Fluid Limits for Stochastic Mobile Networks We consider Markov models of large-scale networks where nodes are characterized by their local behavior and by a mobility model over a two-dimensional lattice. By assuming random walk, we prove convergence to a system of partial differential equations (PDEs) whose size depends neither on the lattice size nor on the population of nodes. This provides a macroscopic view of the model which approximates discrete stochastic movements with continuous deterministic diffusions. We illustrate the practical applicability of this result by modeling a network of mobile nodes with on/off behavior performing file transfers with connectivity to 802.11 access points. By means of an empirical validation against discrete-event simulation we show high quality of the PDE approximation even for low populations and coarse lattices. In addition, we confirm the computational advantage in using the PDE limit over a traditional ordinary differential equation limit where the lattice is modeled discretely, yielding speed-ups of up to two orders of magnitude. Relativistic Viscous Hydrodynamics for High Energy Heavy Ion Collisions It has been over a decade since the first experimental data from gold nuclei collisions at the Relativistic Heavy Ion Collider suggested hydrodynamic behavior. While early ideal hydrodynamical models were surprisingly accurate in their predictions, they ignored that the large longitudinal velocity gradient meant that even small shear viscosity would produce large corrections to the transverse dynamics. In addition, much less was known about the equation of state predicted by lattice calculations of quantum chromodynamics, which predicts a soft region as the degrees of freedom change from quarks to hadrons but no first-order phase transition. Furthermore, the effects of late, dilute stage rescattering were handled within the hydrodynamic framework to temperatures where local kinetic equilibrium is difficult to justify. This dissertation presents a three-dimensional viscous hydrodynamics code with a realistic equation of state coupled consistently to a hadron resonance gas calculation. The code presented here is capable of making significant comparisons to experimental data as part of an effort to learn about the structure of experimental constraints on the microscopic interactions of dense, hot quark matter.
Formality of Kapranov's brackets in K\"ahler geometry via pre-Lie deformation theory We recover some recent results by Dotsenko, Shadrin and Vallette on the Deligne groupoid of a pre-Lie algebra, showing that they follow naturally by a pre-Lie variant of the PBW Theorem. As an application, we show that Kapranov's $L_\infty$ algebra structure on the Dolbeault complex of a K\"ahler manifold is homotopy abelian and independent on the choice of K\"ahler metric up to an $L_\infty$ isomorphism, by making the trivializing homotopy and the $L_\infty$ isomorphism explicit. A scattering theory of ultrarelativistic solitons We construct a perturbative framework for understanding the collision of solitons (more precisely, solitary waves) in relativistic scalar field theories. Our perturbative framework is based on the suppression of the space-time interaction area proportional to $1/(\gamma v)$, where $v$ is the relative velocity of an incoming solitary wave and $\gamma = 1/\sqrt{1-v^2} \gg 1$. We calculate the leading order results for collisions of (1+1) dimensional kinks in periodic potentials, and provide explicit, closed form expressions for the phase shift and the velocity change after the collisions. We find excellent agreement between our results and detailed numerical simulations. Crucially, our perturbation series is controlled by a kinematic parameter, and hence not restricted to small deviations around integrable cases such as the Sine-Gordon model. A unified Lense-Thirring precession model for optical and X-ray quasi-periodic oscillations in black hole binaries Recent observations of accreting black holes reveal the presence of quasi-periodic oscillations (QPO) in the optical power density spectra. The corresponding oscillation periods match those found in the X-rays, implying a common origin. Among the numerous suggested X-ray QPO mechanisms, some may also work in the optical. However, their relevance to the broadband -- optical through X-ray -- spectral properties have not been investigated. For the first time, we discuss the QPO mechanism in the context of the self-consistent spectral model. We propose that the QPOs are produced by Lense-Thirring precession of the hot accretion flow, whose outer parts radiate in the optical wavelengths. At the same time, its innermost parts are emitting the X-rays, explaining the observed connection of QPO periods. We predict that the X-ray and optical QPOs should be either in phase or shifted by half a period, depending on the observer position. We investigate the QPO harmonic content and find that the variability amplitudes at the fundamental frequency are larger in the optical, while the X-rays are expected to have strong harmonics. We then discuss the QPO spectral dependence and compare the expectations to the existing data. Topological strings and 5d T_N partition functions We evaluate the Nekrasov partition function of 5d gauge theories engineered by webs of 5-branes, using the refined topological vertex on the dual Calabi-Yau threefolds. The theories include certain non-Lagrangian theories such as the T_N theory. The refined topological vertex computation generically contains contributions from decoupled M2-branes which are not charged under the 5d gauge symmetry engineered. We argue that, after eliminating them, the refined topological string partition function agrees with the 5d Nekrasov partition function. We explicitly check this for the T_3 theory as well as Sp(1) gauge theories with N_f = 2, 3, 4 flavors. In particular, our method leads to a new expression of the Sp(1) Nekrasov partition functions without any contour integrals. We also develop prescriptions to calculate the partition functions of theories obtained by Higgsing the T_N theory. We compute the partition function of the E_7 theory via this prescription, and find the E_7 global symmetry enhancement. We finally discuss a potential application of the refined topological vertex to non-toric web diagrams. Maxwell's Equations, The Euler Index and Morse Theory We show show that the singularities of the Fresnel surface for Maxwell's equation on an anisotrpic material can be accounted from purely topological considerations. The importance of these singularities is that they explain the phenomenon of conical refraction predicted by Hamilton. We show how to de-singularise the Fresnel surface, which will allow us to use Morse theory to find lower bounds for the number of critical wave velocities inside the material under consideration. Finally, we propose a program to generalise the results obtained to the general case of hyperbolic differential operators on differentiable bundles. Imaginary time propagation code for large-scale two-dimensional eigenvalue problems in magnetic fields We present a code for solving the single-particle, time-independent Schr\"odinger equation in two dimensions. Our program utilizes the imaginary time propagation (ITP) algorithm, and it includes the most recent developments in the ITP method: the arbitrary order operator factorization and the exact inclusion of a (possibly very strong) magnetic field. Our program is able to solve thousands of eigenstates of a two-dimensional quantum system in reasonable time with commonly available hardware. The main motivation behind our work is to allow the study of highly excited states and energy spectra of two-dimensional quantum dots and billiard systems with a single versatile code, e.g., in quantum chaos research. In our implementation we emphasize a modern and easily extensible design, simple and user-friendly interfaces, and an open-source development philosophy. Bounding quantum theory with the exclusivity principle in a two-city experiment Why do correlations between the results of measurements performed on physical systems violate Bell and non-contextuality inequalities up to some specific limits? The answer may follow from the observation that in quantum theory, unlike in other theories, whenever there is an experiment to measure $A$ simultaneously with $B$, another to measure $B$ with $C$, and another to measure $A$ with $C$, there is always an experiment to measure all of them simultaneously. This property implies that quantum theory satisfies a seemingly irrelevant restriction called the exclusivity (E) principle which, surprisingly, explains the set of quantum correlations in some fundamental scenarios. An open problem is whether the E principle explains the maximum quantum violation of the Bell-CHSH inequality. Here we show experimentally that the E principle imposes an upper bound to the violation of the Bell-CHSH inequality that matches the maximum predicted by quantum theory. For that, we use the result of an independent experiment testing a specific non-contextuality inequality. We perform both experiments: the Bell-CHSH inequality experiment on polarization entangled states of pairs of photons in Stockholm and, to demonstrate independence, the non-contextuality inequality experiment on single photons' orbital angular momentum states in Rome. The observed results provide the first experimental evidence that the E principle determines the limits of quantum correlations and prove that hypothetical super-quantum violations for either experiment would violate the E principle. This supports the conclusion that the E principle captures a fundamental limitation of nature. If this is true, much of quantum theory trivially follow from merely taking the E principle to be a fundamental truth, and various information-theoretic postulates are also simplified and/or strengthened. Primary Cyclic Matrices in Irreducible Matrix Subalgebras Primary Cyclic matrices were used (but not named) by Holt and Rees in their version of Parker's MEAT-AXE algorithm to test irreducibility of finite matrix groups and algebras. They are matrices $X$ with at least one cyclic component in the primary decomposition of the underlying vector space as an $X$-module. Let $\operatorname{M}(c,q^b)$ be an irreducible subalgebra of $\operatorname{M}(n,q)$, where $n=bc >c$. We prove a generalisation of the Kung-Stong Cycle Index, and use it to obtain a lower bound for the proportion of primary cyclic matrices in $\operatorname{M}(c,q^b)$. This extends work of Glasby and the second author on the case $b=1$. Tri-Dirac Surface Modes in Topological Superconductors We propose a new type of topological surface modes having cubic dispersion in three-dimensional topological superconductors. Lower order dispersions are prohibited by the threefold rotational symmetry and time-reversal symmetry.
Cooper pairing in the bulk changes sign under improper rotations, akin to$^{3}$He-B. The surface manifestations are a divergent surface density of states at the Fermi level and isospins that rotate three times as they circle the origin in momentum space. We propose that Heusler alloys with band inversion are candidate materials to harbor the novel topological superconductivity. Lifshitz black holes in Einstein-Yang-Mills theory We find that the four dimensional cosmological Einstein-Yang-Mills theory with $SU(2)$ gauge group admits Lifshitz spacetime as a base solution for the dynamical exponent $z>1$. Motivated by this, we next demonstrate numerically that the field equations admit black hole solutions which behave regularly on the horizon and at spatial infinity for different horizon topologies. The solutions depend on one parameter, the strength of the gauge field at the horizon, which is fine-tuned to capture the Lifshitz asymptotics at infinity. We also discuss the behavior of solutions and the change in Hawking temperature for black holes that are large or small with respect to the length scale $L$, which is itself fixed by the value of the cosmological constant. Overcoming Auger recombination in nanocrystal quantum dot laser using spontaneous emission enhancement We propose a method to overcome Auger recombination in nanocrystal quantum dot lasers using cavity-enhanced spontaneous emission. We derive a numerical model for a laser composed of nanocrystal quantum dots coupled to optical nanocavities with small mode-volume. Using this model, we demonstrate that spontaneous emission enhancement of the biexciton transition lowers the lasing threshold by reducing the effect of Auger recombination. We analyze a photonic crystal nanobeam cavity laser as a realistic device structure that implements the proposed approach. Beam Extraction and Transport This chapter gives an introduction to low-energy beam transport systems, and discusses the typically used magnetostatic elements (solenoid, dipoles and quadrupoles) and electrostatic elements (einzel lens, dipoles and quadrupoles). The ion beam emittance, beam space-charge effects and the physics of ion source extraction are introduced. Typical computer codes for analysing and designing ion optical systems are mentioned, and the trajectory tracking method most often used for extraction simulations is described in more detail. Characterizing the quiescent X-ray variability of the black hole low mass x-ray binary V404 Cyg We conducted the first long-term (75 days) X-ray monitoring of the black hole low mass X-ray binary V404 Cyg, with the goal of understanding and characterizing its variability during quiescence. The X-ray light curve of V404 shows several flares on timescales of hours with a count rate change of a factor of about 5-8. The root mean square variability is Fvar = 57.0(3.2) percent. The first order structure function is consistent with both a power spectrum of index -1 (flicker noise), or with a power spectrum of index 0 (white noise), implying that the light curve is variable on timescales from days to months. The X-ray spectrum is well fitted by a power law with spectral index {\Gamma} = 2.10 - 2.35, and we found that the spectral shape remains roughly constant as the flux changes. A constant spectral shape with respect to a change in the X-ray flux may favour a scenario in which the X-ray emission is dominated by synchrotron radiation produced in a jet. GeV WIMPs scattering off of OH impurities cannot explain the DAMA signal In the presence of OH impurities in the DAMA crystals, GeV-scale WIMPs elastically scattering off of hydrogen nuclei with a spin independent cross section of $\sim 10^{-33}\ {\rm cm}^2$ might explain the annual modulation observed by the DAMA experiment, while being consistent with other direct dark matter searches, as scattering would occur at energies below the energy threshold of other detectors. In this work we examine this possibility and show that, independent of the level of OH impurities in the DAMA crystals, for several reasons this scenario does not provide a viable explanation to the DAMA signal. A discrete uniformization theorem for polyhedral surfaces II A discrete conformality for hyperbolic polyhedral surfaces is introduced in this paper. This discrete conformality is shown to be computable. It is proved that each hyperbolic polyhedral metric on a closed surface is discrete conformal to a unique hyperbolic polyhedral metric with a given discrete curvature satisfying Gauss-Bonnet formula. Furthermore, the hyperbolic polyhedral metric with given curvature can be obtained using a discrete Yamabe flow with surgery. In particular, each hyperbolic polyhedral metric on a closed surface with negative Euler characteristic is discrete conformal to a unique hyperbolic metric. Channeling of Electrons in a Crossed Laser Field In this article a new analytical description of the effective interaction potential for a charged particle in the field of two interfering laser beams is presented. The potential dependence on the lasers intensities, orientation and parameters of the particle entering the considered system is analyzed. It is shown for the case of arbitrary lasers crossing angle that for different values of projectile velocity the attracting potential becomes a scattering one so that the channel axes and borders interchange each other. In addition the projectile radiation spectral distribution is given and general estimations on the expected beam radiation yield are outlined. Dynamics of stellar black holes in young star clusters with different metallicities - II. Black hole-black hole binaries In this paper, we study the formation and dynamical evolution of black hole-black hole (BH-BH) binaries in young star clusters (YSCs), by means of N-body simulations. The simulations include metallicity-dependent recipes for stellar evolution and stellar winds, and have been run for three different metallicities (Z = 0.01, 0.1 and 1 Zsun). Following recent theoretical models of wind mass-loss and core-collapse supernovae, we assume that the mass of the stellar remnants depends on the metallicity of the progenitor stars. We find that BH-BH binaries form efficiently because of dynamical exchanges: in our simulations, we find about 10 times more BH-BH binaries than double neutron star binaries. The simulated BH-BH binaries form earlier in metal-poor YSCs, which host more massive black holes (BHs) than in metal-rich YSCs. The simulated BH-BH binaries have very large chirp masses (up to 80 Msun), because the BH mass is assumed to depend on metallicity, and because BHs can grow in mass due to the merger with stars. The simulated BH-BH binaries span a wide range of orbital periods (10^-3-10^7 yr), and only a small fraction of them (0.3 per cent) is expected to merge within a Hubble time. We discuss the estimated merger rate from our simulations and the implications for Advanced VIRGO and LIGO. On the Edge-Balanced Index Sets of Odd/Even Complete Bipartite Graphs In 2009, Kong, Wang, and Lee began work on the problem of finding the edge-balanced index sets of complete bipartite graphs $K_{m,n}$ by solving the cases where $n=1$, $2$, $3$, $4$, and $5$, and also the case where $m=n$. In an article soon to be published, Krop, Minion, Patel, and Raridan concluded the edge-balanced index set problem for complete bipartite graphs with both parts of odd cardinality. In this paper, we conclude the problem for complete bipartite graphs where the larger part is of odd cardinality and the smaller is of even cardinality. Probing the $\nu=2/3$ fractional quantum Hall edge by momentum-resolved tunneling The nature of the fractional quantum Hall state with filling factor $\nu=2/3$ and its edge modes continues to remain an open problem in low-dimensional condensed matter physics. Here, we suggest an experimental setting to probe the $\nu=2/3$ edge by tunnel-coupling it to a $\nu=1$ integer quantum Hall edge in another layer of a two-dimensional electron gas (2DEG).
In this double-layer geometry, the momentum of tunneling electrons may be boosted by an auxiliary magnetic field parallel to the two planes of 2DEGs. We evaluate the current as a function of bias voltage and the boosting magnetic field. Its threshold behavior yields information about the spectral function of the $\nu=2/3$ edge, in particular about the nature of the chiral edge modes. Our theory accounts also for the effects of Coulomb interaction and disorder. Quantum signaling game We present a quantum approach to a signaling game; a special kind of extensive games of incomplete information. Our model is based on quantum schemes for games in strategic form where players perform unitary operators on their own qubits of some fixed initial state and the payoff function is given by a measurement on the resulting final state. We show that the quantum game induced by our scheme coincides with a signaling game as a special case and outputs nonclassical results in general. As an example, we consider a quantum extension of the signaling game in which the chance move is a three-parameter unitary operator whereas the players' actions are equivalent to classical ones. In this case, we study the game in terms of Nash equilibria and refine the pure Nash equilibria adapting to the quantum game the notion of a weak perfect Bayesian equilibrium. Dual hidden landscapes in Anderson localization on discrete lattices The localization subregions of stationary waves in continuous disordered media have been recently demonstrated to be governed by a hidden landscape that is the solution of a Dirichlet problem expressed with the wave operator. In this theory, the strength of Anderson localization confinement is determined by this landscape, and continuously decreases as the energy increases. However, this picture has to be changed in discrete lattices in which the eigenmodes close to the edge of the first Brillouin zone are as localized as the low energy ones. Here we show that in a 1D discrete lattice, the localization of low and high energy modes is governed by two different landscapes, the high energy landscape being the solution of a dual Dirichlet problem deduced from the low energy one using the symmetries of the Hamiltonian. We illustrate this feature using the one-dimensional tight-binding Hamiltonian with random on-site potentials as a prototype model. Moreover we show that, besides unveiling the subregions of Anderson localization, these dual landscapes also provide an accurate overal estimate of the localization length over the energy spectrum, especially in the weak disorder regime. Perspectives of Open Charm Physics at $\bar PANDA$ The $\bar PANDA$ experiment at FAIR (Facility for Antiproton and Ion Research) in Darmstadt (Germany) is designed for $\bar p p$ annihilation studies and it will investigate fundamental questions of hadron and nuclear physics in interactions of antiprotons with nucleons and nuclei. Gluonic excitations and the physics of hadrons with strange and charm quarks will be accessible with unprecedented accuracy, thereby allowing high precision tests of the strong interactions. In particular, the $D_{s0}^*(2317)^+$ and $D_{s1}(2460)^+$ are still of high interest 11 years after their discovery, because they can not be simply understood in term of potential models. The available statistics and resolution of the past experiments did not allow to clarify their nature. Recently LHCb at CERN has made progresses in this respect, but still not at the level of precision required in order to clarify the puzzle of the $cs$-spectrum. $\bar PANDA$ will be able to achieve a factor 20 higher mass resolution than attained at the B-factories, which is expected to be decisive on these and second-order open questions. The technique to evaluate the width from the excitation function of the cross section of the $D_s$ mesons will be presented, and ongoing simulations performed with $PandaRoot$ will be shown. Impurity-mediated early condensation of an atomic layer electronic crystal While impurity has been known widely to affect phase transitions, the atomistic mechanisms have rarely been disclosed. We directly show in atomic scale how impurity atoms induces the condensation of a representative electronic phase, charge density wave (CDW), with scanning tunneling microscopy. Oxygen impurity atoms on the self-assembled metallic atomic wire array on a silicon crystal condense CDW locally even above the transition temperature, More interestingly, the CDW along the wires is induced not by a single atomic impurity but by the cooperation of multiple impurities. First principles calculations disclose the mechanism of the cooperation as the coherent superposition of the local lattice strain induced by impurities, stressing the coupled electronic and lattice degrees of freedom for CDW. This newly discovered mechanism can widely be applied to various important electronic orders coupled to lattice, opening the possibility of the atomic scale strain engineering. Potential of Thin Films for use in Charged Particle Tracking Detectors Thin Film technology has widespread applications in everyday electronics, notably Liquid Crystal Display screens, solar cells, and organic light emitting diodes. We explore the potential of this technology as charged particle radiation tracking detectors for use in High Energy Physics experiments such as those at the Large Hadron Collider or the Relativistic Heavy Ion Collider. Through modern fabrication techniques, a host of semiconductor materials are available to construct thin, flexible detectors with integrated electronics with pixel sizes on the order of a few microns. We review the material properties of promising candidates, discuss the potential benefits and challenges associated with this technology, and review previously demonstrated applicability as a neutron detector. Pi-Pi Scattering with Nf=2+1+1 Twisted Mass Fermions Pi-Pi scattering is investigated for the first time for Nf=2+1+1 dynamical quark flavours using Wilson twisted mass fermions. L\"uscher's finite size method is used to relate energy shifts in finite volume to scattering quantities like the scattering length in the I=2 channel. The computation is performed at several pion masses and lattice spacings utilising the stochastic LapH method. Entanglement thermodynamics for an excited state of Lifshitz system A class of (2+1)-dimensional quantum many body system characterized by an anisotropic scaling symmetry (Lifshitz symmetry) near their quantum critical point can be described by a (3+1)-dimensional dual gravity theory with negative cosmological constant along with a massive vector field, where the scaling symmetry is realized by the metric as an isometry. We calculate the entanglement entropy of an excited state of such a system holographically, i.e., from the asymptotic perturbation of the gravity dual using the prescription of Ryu and Takayanagi, when the subsystem is sufficiently small. With suitable identifications, we show that this entanglement entropy satisfies an energy conservation relation analogous to the first law of thermodynamics. The non-trivial massive vector field here plays a crucial role and contributes to an additional term in the energy relation. The irreducible modules and fusion rules for the parafermion vertex operator algebras The irreducible modules for the parafermion vertex operator algebra associated to any finite dimensional Lie algebra and any positive integer are identified, the quantum dimensions are computed and the fusion rules are determined. Determining cyclicity of finite modules We present a deterministic polynomial-time algorithm that determines whether a finite module over a finite commutative ring is cyclic, and if it is, outputs a generator. Solvability and nilpotency for algebraic supergroups We study solvability, nilpotency and splitting property for algebraic supergroups over an arbitrary field $K$ of characteristic $\mathrm{char}\, K \ne 2$. Our first main theorem tells us that an algebraic supergroup $\mathbb{G}$ is solvable if the associated algebraic group $\mathbb{G}_{ev}$ is trigonalizable. To prove it we determine the algebraic supergroups $\mathbb{G}$ such that $\dim \mathrm{Lie}(\mathbb{G})_1=1$; their representations are studied when $\mathbb{G}_{ev}$ is diagonalizable. The second main theorem characterizes nilpotent connected algebraic supergroups. A super-analogue of the Chevalley Decomposition Theorem is proved, though it must be in a weak form. An appendix is given to characterize smooth Noetherian superalgebras as well as smooth Hopf superalgebras. Rational Kernels for Arabic Stemming and Text Classification In this paper, we address the problems of Arabic Text Classification and stemming using Transducers and Rational Kernels.
We introduce a new stemming technique based on the use of Arabic patterns (Pattern Based Stemmer). Patterns are modelled using transducers and stemming is done without depending on any dictionary. Using transducers for stemming, documents are transformed into finite state transducers. This document representation allows us to use and explore rational kernels as a framework for Arabic Text Classification. Stemming experiments are conducted on three word collections and classification experiments are done on the Saudi Press Agency dataset. Results show that our approach, when compared with other approaches, is promising specially in terms of Accuracy, Recall and F1. Experimental and ab initio studies of the novel piperidine-containing acetylene glycols Synthesis routes of novel piperidine-containing diacetylene are presented. The new molecules are expected to exhibit plant growth stimulation properties. In particular, the yield in a situation of drought is expected to increase. The synthesis makes use of the Favorskii reaction between cycloketones/piperidone and triple-bond containing glycols. The geometries of the obtained molecules were determined using nuclear magnetic resonance (NMR). The electronic structure and geometries of the molecules were studied theoretically using first-principles calculations based on density functional theory. The calculated geometries agree very well with the experimentally measured ones, and also allow us to determine bond lengths, angles and charge distributions inside the molecules. The stability of the OH-radicals located close to the triple bond and the piperidine/cyclohexane rings was proven by both experimental and theoretical analyses. The HOMO/LUMO analysis was done in order to characterize the electron density of the molecule. The calculations show that triple bond does not participate in intermolecular reactions which excludes the instability of novel materials as a reason for low production rate. Scaling hypothesis for the Euclidean bipartite matching problem II. Correlation functions We analyze the random Euclidean bipartite matching problem on the hypertorus in $d$ dimensions with quadratic cost and we derive the two--point correlation function for the optimal matching, using a proper ansatz introduced by Caracciolo et al. to evaluate the average optimal matching cost. We consider both the grid--Poisson matching problem and the Poisson--Poisson matching problem. We also show that the correlation function is strictly related to the Green's function of the Laplace operator on the hypertorus. A Nonlinear Singular Diffusion Equation with Source In this paper, the existence, uniqueness and dependence on initial value of solution for a singular diffusion equation with nonlinear boundary condition are discussed. It is proved that there exists a unique global smooth solution which depends on initial data continuously. Wide-area Wireless Communication Challenges for the Internet of Things Aided by the ubiquitous wireless connectivity, declining communication costs, and the emergence of cloud platforms, the deployment of Internet of Things (IoT) devices and services is accelerating. Most major mobile network operators view machine-to-machine (M2M) communication networks for supporting IoT as a significant source of new revenue. In this paper, we motivate the need for wide-area M2M wireless networks, especially for short data packet communication to support a very large number of IoT devices. We first present a brief overview of current and emerging technologies for supporting wide area M2M, and then using communication theory principles, discuss the fundamental challenges and potential solutions for these networks, highlighting tradeoffs and strategies for random and scheduled access. We conclude with recommendations for how future 5G networks should be designed for efficient wide-area M2M communications. Fibers of Cyclic Covering Fibrations of a Ruled Surface We give an algorithm to classify singular fibers of finite cyclic covering fibrations of a ruled surface by using singularity diagrams. As the first application, we classify all fibers of 3-cyclic covering fibrations of genus 4 of a ruled surface and show that the signature of a complex surface with this fibration is non-positive by computing the local signature for any fiber. As the second application, we classify all fibers of hyperelliptic fibrations of genus 3 into 12 types according to the Horikawa index. We also prove that finite cyclic covering fibrations of a ruled surface have no multiple fibers if the degree of the covering is greater than 3. ML Detection in Phase Noise Impaired SIMO Channels with Uplink Training The problem of maximum likelihood (ML) detection in training-assisted single-input multiple-output (SIMO) systems with phase noise impairments is studied for two different scenarios, i.e. the case when the channel is deterministic and known (constant channel) and the case when the channel is stochastic and unknown (fading channel). Further, two different operations with respect to the phase noise sources are considered, namely, the case of identical phase noise sources and the case of independent phase noise sources over the antennas. In all scenarios the optimal detector is derived for a very general parametrization of the phase noise distribution. Further, a high signal-to-noise-ratio (SNR) analysis is performed to show that symbol-error-rate (SER) floors appear in all cases. The SER floor in the case of identical phase noise sources (for both constant and fading channels) is independent of the number of antenna elements. In contrast, the SER floor in the case of independent phase noise sources is reduced when increasing the number of antenna elements (for both constant and fading channels). Finally, the system model is extended to multiple data channel uses and it is shown that the conclusions are valid for these setups, as well. Fog Computing based Radio Access Networks: Issues and Challenges A fog computing based radio access network (F-RAN) is presented in this article as a promising paradigm for the fifth generation (5G) wireless communication system to provide high spectral and energy efficiency. The core idea is to take full advantages of local radio signal processing, cooperative radio resource management, and distributed storing capabilities in edge devices, which can decrease the heavy burden on fronthaul and avoid large-scale radio signal processing in the centralized baseband unit pool. This article comprehensively presents the system architecture and key techniques of F-RANs. In particular, key techniques and their corresponding solutions, including transmission mode selection and interference suppression, are discussed. Open issues in terms of edge caching, software-defined networking, and network function virtualization, are also identified. Hall viscosity from elastic gauge fields in Dirac crystals The combination of Dirac physics and elasticity has been explored at length in graphene where the so--called "elastic gauge fields" have given rise to an entire new field of research and applications: Straintronics. The fact that these elastic fields couple to fermions as the electromagnetic field, implies that many electromagnetic responses will have elastic counterparts not explored before. In this work we will first show that the presence of elastic gauge fields will be the rule rather than the exception in most of the topologically non--trivial materials in two and three dimensions. In particular we will extract the elastic gauge fields associated to the recently observed Weyl semimetals, the "three dimensional graphene". As it is known, quantum electrodynamics suffers from the chiral anomaly whose consequences have been recently explored in matter systems. We will show that, associated to the physics of the anomalies, and as a counterpart of the Hall conductivity, elastic materials will have a Hall viscosity in two and three dimensions with a coefficient orders of magnitude bigger than the previously studied response. The magnitude and generality of the new effect will greatly improve the chances for the experimental observation of this topological, non dissipative response. Photometric evolution and peculiar dust formation in the gamma-ray Nova Sco 2012 (V1324 Sco) Optical (BVRI) and infrared (JHK) photometry of the gamma-ray nova Nova Sco 2012 (V1324 Sco) is presented and the lightcurve reconstructed and discussed. An interstellar reddening E(B-V)=1.23 is derived. Dust begun to form at an early date in the nova, only one magnitude down and 20 days past maximum optical brightness and caused an extinction of at least 6 magnitudes in V band, that cleared some months later. This unusual early dust formation compromises the application of the magnitude at maximum versus rate of decline (MMRD) relations in estimating the distance to the nova.
A new equivalence relation to classify the fuzzy subgroups of finite groups In this paper a new equivalence relation $\approx$ to classify the fuzzy subgroups of finite groups is introduced and studied. This generalizes the equivalence relation $\sim$ defined on the lattice of fuzzy subgroups of a finite group that has been used in our previous papers (see e.g. \cite{16,24}). Explicit formulas for the number of distinct fuzzy subgroups with respect to $\approx$ are obtained in some particular cases. Performance Analysis for Energy Harvesting Communication Systems: From Throughput to Energy Diversity Energy harvesting (EH) based communication has raised great research interests due to its wide application and the feasibility of commercialization. In this paper, we consider wireless communications with EH constraints at the transmitter. First, for delay-tolerant traffic, we investigate the long-term average throughput maximization problem and analytically compare the throughput performance against that of a system supported by conventional power supplies. Second, for delay-sensitive traffic, we analyze the outage probability by studying its asymptotic behavior in the high energy arrival rate regime, where the new concept of energy diversity is formally introduced. Moreover, we show that the speed of outage probability approaching zero, termed energy diversity gain, varies under different power supply models. Bell numbers, partition moves and the eigenvalues of the random-to-top shuffle in Dynkin Types A, B and D Let $B_t(n)$ be the number of set partitions of a set of size~$t$ into at most $n$ parts and let $B'_t(n)$ be the number of set partitions of $\{1,\ldots, t\}$ into at most $n$ parts such that no part contains both $1$ and~$t$ or both $i$ and $i+1$ for any $i \in \{1,\ldots,t-1\}$. We give two new combinatorial interpretations of the numbers $B_t(n)$ and $B'_t(n)$ using sequences of random-to-top shuffles, %that leave a deck of cards invariant, and sequences of box moves on the Young diagrams of partitions. Using these ideas we obtain a very short proof of a generalization of a result of Phatarfod on the eigenvalues of the random-to-top shuffle. We also prove analogous results for random-to-top shuffles that may flip certain cards. The proofs use the Solomon descent algebras of Types A, B and~D. We give generating functions and asymptotic results for all the combinatorial quantities studied in this paper. Some topological properties of Charming spaces In this paper, we mainly discuss the class of charming spaces, which was introduced by A.V. Arhangel'skii in [Remainders of metrizable spaces and a generalization of Lindel\"of $\Sigma$-spaces, Fund. Math., 215(2011), 87-100]. First, we show that there exists a charming space $X$ such that $X^{2}$ is not a charming space. Then we discuss some properties of charming spaces and give some characterizations of some class of charming spaces. Finally, we show that the Suslin number of an arbitrary charming rectifiable space $G$ is countable. OCReP: An Optimally Conditioned Regularization for Pseudoinversion Based Neural Training In this paper we consider the training of single hidden layer neural networks by pseudoinversion, which, in spite of its popularity, is sometimes affected by numerical instability issues. Regularization is known to be effective in such cases, so that we introduce, in the framework of Tikhonov regularization, a matricial reformulation of the problem which allows us to use the condition number as a diagnostic tool for identification of instability. By imposing well-conditioning requirements on the relevant matrices, our theoretical analysis allows the identification of an optimal value for the regularization parameter from the standpoint of stability. We compare with the value derived by cross-validation for overfitting control and optimisation of the generalization performance. We test our method for both regression and classification tasks. The proposed method is quite effective in terms of predictivity, often with some improvement on performance with respect to the reference cases considered. This approach, due to analytical determination of the regularization parameter, dramatically reduces the computational load required by many other techniques. Proposal for a Domain Wall Nano-Oscillator driven by Non-uniform Spin Currents We propose a new mechanism and a related device concept for a robust, magnetic field tunable radio-frequency (rf) oscillator using the self oscillation of a magnetic domain wall subject to a uniform static magnetic field and a spatially non-uniform vertical dc spin current. The self oscillation of the domain wall is created as it translates periodically between two unstable positions, one being in the region where both the dc spin current and the magnetic field are present, and the other, being where only the magnetic field is present. The vertical dc spin current pushes it away from one unstable position while the magnetic field pushes it away from the other. We show that such oscillations are stable under noise and can exhibit a quality factor of over 1000. A domain wall under dynamic translation, not only being a source for rich physics, is also a promising candidate for advancements in nanoelectronics with the actively researched racetrack memory architecture, digital and analog switching paradigms as candidate examples. Devising a stable rf oscillator using a domain wall is hence another step towards the realization of an all domain wall logic scheme. The Inverse Problem for the Dipole Field The Inverse problem for an electromagnetic field produced by a dipole is solved. It is assumed that the field of an arbitrary changing dipole is known. Obtained formulae allow calculation of the position and dynamics of the dipole which produces the measured field. The derived results can be used in investigations on radiative process in solids caused by changing of the charge distribution. For example, generation of the electromagnetic field caused by oscillations of atoms or electron gas at the trace of a particle channeling in a crystal, or fields arising at solids cracking or dislocation formation -- in any case when one is interested in the details of the dipole field source. Classification of two-dimensional algebraic projective semigroups In this article, we address the classification of smooth projective algebraic surfaces over complex numbers admitting algebraic semigroup structures. We give a full description of those surfaces $S$, which has at least one non-trivial algebraic semigroup structure, when the Kodaira dimension of $S$ is $ -\infty$ and $ 0$. For the case "$ \kappa (S)=1$", we give a description of one special type of elliptic surfaces which admit non-trivial algebraic semigroup laws. \\ For a given surface $S$, it is an interesting problem to describe all algebraic semigroup structures on it and determine the dimension of this moduli. In this article, we solve this problem for case "$ \kappa (S)\ge 0$". The divisor function in arithmetic progressions modulo prime powers We study the average value of the divisor function $\tau(n)$ for $n\le x$ with $n \equiv a \bmod q$. The divisor function is known to be evenly distributed over arithmetic progressions for all $q$ that are a little smaller than $x^{2/3}$. We show how to go past this barrier when $q=p^k$ for odd primes $p$ and any fixed integer $k\ge 7$. Assessing the multivariate normal approximation of the maximum likelihood estimator from high-dimensional, heterogeneous data The asymptotic normality of the maximum likelihood estimator (MLE) under regularity conditions is a cornerstone of statistical theory. In this paper, we give explicit upper bounds on the distributional distance between the distribution of the MLE of a vector parameter, and the multivariate normal distribution. We work with possibly high-dimensional, independent but not necessarily identically distributed random vectors. In addition, we obtain explicit upper bounds even in cases where the MLE cannot be expressed analytically. Experimental Adaptive Quantum Tomography of Two-Qubit States We report an experimental realization of adaptive Bayesian quantum state tomography for two-qubit states. Our implementation is based on the adaptive experimental design strategy proposed in [F.Husz\'ar and N.M.T.Houlsby, Phys.Rev.A 85, 052120 (2012)] and provides an optimal measurement approach in terms of the information gain.
We address the practical questions, which one faces in any experimental application: the influence of technical noise, and behavior of the tomographic algorithm for an easy to implement class of factorized measurements. In an experiment with polarization states of entangled photon pairs we observe a lower instrumental noise floor and superior reconstruction accuracy for nearly-pure states of the adaptive protocol compared to a non-adaptive. At the same time we show, that for the mixed states the restriction to factorized measurements results in no advantage for adaptive measurements, so general measurements have to be used. CosmoBolognaLib: C++ libraries for cosmological calculations We present the CosmoBolognaLib, a large set of Open Source C++ numerical libraries for cosmological calculations. CosmoBolognaLib is a living project aimed at defining a common numerical environment for cosmological investigations of the large-scale structure of the Universe. In particular, one of the primary focuses of this software is to help in handling astronomical catalogues, both real and simulated, measuring one-point, two-point and three-point statistics in configuration space, and performing cosmological analyses. In this paper, we discuss the main features of this software, providing an overview of all the available C++ classes implemented up to now. Both the CosmoBolognaLib and their associated doxygen documentation can be freely downloaded at https://github.com/federicomarulli/CosmoBolognaLib. We provide also some examples to explain how these libraries can be included in either C++ or Python codes. $h^0(125GeV) \to c \bar{c}$ as a test case for quark flavor violation in the MSSM We calculate the decay width of $h^0(125GeV) \to c \bar{c}$ in the Minimal Supersymmetric Standard Model (MSSM) with non-minimal quark flavor violation (QFV) at full one-loop level. We adopt the $\overline{\rm DR}$ renormalization scheme. We study the effects of the mixing of the second and third squark generations (i.e. scharm-stop mixing) on the decay width, respecting the experimental constraints from B-meson data, the Higgs mass measurement and supersymmetric (SUSY) particle searches. We show that the decay width $\Gamma (h^0 \to c \bar{c})$ at the full one-loop level is very sensitive to the SUSY QFV parameters. In a scenario with large scharm-stop mixing, the decay width can differ up to $\sim \pm 35\%$ from its SM prediction. After taking into account the experimental and theoretical uncertainties of the decay width, we conclude that these QFV SUSY effects can be observed at a future $e^+ e^-$ collider such as ILC (International Linear Collider). Lattice simulation of $QC_2D$ with $N_f=2$ at non-zero baryon density The lattice simulations of $QC_2D$ with two flavors of staggered fermions and non-zero quark chemical potential $\mu_q$ have been performed. Dependencies of the Polyakov loop, chiral condensate and baryon number density on $\mu_q$ were studied. We found that an increase of the baryon chemical potential leads to chiral symmetry restoration. At small values of $\mu_q$, our results for the baryon number density agree with ChPT predictions. Deforming a convex hypersurface with low entropy by its Gauss curvature We prove the asymptotic roundness under normalized Gauss curvature flow provided entropy is initially small enough. Slow quenching of star formation in OMEGAWINGS clusters: galaxies in transition in the local universe The star formation quenching depends on environment, but a full understanding of what mechanisms drive it is still missing. Exploiting a sample of galaxies with masses $M_\ast>10^{9.8}M_\odot$, drawn from the WIde-field Nearby Galaxy-cluster Survey (WINGS) and its recent extension OMEGAWINGS, we investigate the star formation rate (SFR) as a function of stellar mass (M$_*$) in galaxy clusters at $0.04<z<0.07$. We use non-member galaxies at 0.02$<$z$<$0.09 as field control sample. Overall, we find agreement between the SFR-M$_*$ relation in the two environments, but detect a population of cluster galaxies with reduced SFRs which is rare in the field. These {\it transition} galaxies are mainly found within the cluster virial radius ($R_{200}$) but they impact on the SFR-M$_*$ relation only within 0.6R$_{200}$. The ratio of transition to PSF galaxies strongly depends on environment, being larger than 0.6 within 0.3R$_{200}$ and rapidly decreasing with distance, while it is almost flat with $M_*$. As galaxies move downward from the SFR-M$_*$ main sequence, they become redder and present older luminosity and mass weighted ages. These trends, together with the analysis of the star formation histories, suggest that transition galaxies have had a reduced SFR for the past 2-5 Gyr. Our results are consistent with the hypothesis that the interaction of galaxies with the intracluster medium via strangulation causes a gradual shut down of star formation, giving birth to an evolved population of galaxies in transition from being star forming to becoming passive. Measuring pattern retention in anonymized data -- where one measure is not enough In this paper, we explore how modifying data to preserve privacy affects the quality of the patterns discoverable in the data. For any analysis of modified data to be worth doing, the data must be as close to the original as possible. Therein lies a problem -- how does one make sure that modified data still contains the information it had before modification? This question is not the same as asking if an accurate classifier can be built from the modified data. Often in the literature, the prediction accuracy of a classifier made from modified (anonymized) data is used as evidence that the data is similar to the original. We demonstrate that this is not the case, and we propose a new methodology for measuring the retention of the patterns that existed in the original data. We then use our methodology to design three measures that can be easily implemented, each measuring aspects of the data that no pre-existing techniques can measure. These measures do not negate the usefulness of prediction accuracy or other measures -- they are complementary to them, and support our argument that one measure is almost never enough. A strongly robust Weyl fermion semimetal state in Ta$_{3}$S$_{2}$ Weyl semimetals are extremely interesting. Although the first Weyl semimetal was recently discovered in TaAs, research progress is still significantly hindered due to the lack of robust and ideal materials candidates. In order to observe the many predicted exotic phenomena that arise from Weyl fermions, it is of critical importance to find robust and ideal Weyl semimetals, which have fewer Weyl nodes and more importantly whose Weyl nodes are well separated in momentum space and are located close to the chemical potential in energy. In this paper, we propose by far the most robust and ideal Weyl semimetal candidate in the inversion breaking, single crystalline compound tantalum sulfide Ta$_3$S$_2$ with new and novel properties beyond TaAs. We find that Ta$_3$S$_2$ has only 8 Weyl nodes, all of which have the same energy that is merely 10 meV below the chemical potential. Crucially, our results show that Ta$_3$S$_2$ has the largest $k$-space separation between Weyl nodes among known Weyl semimetal candidates, which is about twice larger than TaAs and twenty times larger than the predicted value in WTe$_2$. Moreover, we predict that increasing the lattice by $<4\%$ can annihilate all Weyl nodes, driving a novel topological metal-to-insulator transition from a Weyl semimetal state to a topological insulator state. We further discover that changing the lattice constant can move the Weyl nodes and the van Hove singularities with enhanced density of states to the chemical potential. Our prediction provides a critically needed robust candidate for this rapidly developing field. The well separated Weyl nodes, the topological metal-to-insulator transition and the remarkable tunabilities suggest Ta$_3$S$_2$'s potential as the ideal platform in future device-applications based on Weyl semimetals. P vs.
NP The method for analyzing algorithmic runtime complexity using decision trees is discussed using the sorting algorithm. This method is then extended to optimal algorithms which may find all cliques of size q in network N, or simply the first clique of size q in network N. Finally, the lower bound of such decision trees is demonstrated to not be in P. A functional relation for L-functions of graphs equivalent to the Riemann Hypothesis for Dirichlet L-functions In this note we define L-functions of finite graphs and study the particular case of finite cycles in the spirit of a previous paper that studied spectral zeta functions of graphs. The main result is a suggestive equivalence between an asymptotic functional equation for these L-functions and the corresponding case of the Generalized Riemann Hypothesis. We also establish a relation between the positivity of such functions and the existence of real zeros in the critical strip of the classical Dirichlet L-functions with the same character. Thermodynamic properties of pure and doped (B, N) graphene Ab-initio density functional perturbation theory (DFPT) has been employed to study thermodynamical properties of pure and doped graphene sheet and the results have been compared with available theoretical and experimental data. The concentration of B and N has been varied upto 50% of the carbon atoms in graphene. Phonon frequencies are essential ingredients entering into such a calculation, which have been computed by using the dynamical matrix provided by VASP software in combination with phonopy code in the harmonic approximation. This easily provides us the Helmholtz free energy and leads us to numerical estimates of various thermodynamical properties. The results for specific heat are in good agreement with various theoretical and experimental studies obtained earlier for pure graphene. Interesting new results have been reported for B and N substituted structure. It has been observed that specific heat decreases with the increase in concentration of doping while the entropy increases. Further, large doping concentrations result in unstable sheets resulting in imaginary frequencies in the transverse directions. The instability needs to be compensated by external strains and that has been assumed while carrying out Brilluoin summations. These results will be useful for calculation of thermal conductivity of doped graphene and thus feasibility of using these for device applications. Our preliminary results for thermal expansion have indicated negative thermal expansion behavior of pure graphene at low temperatures which needs investigation on doped graphene as well. Monomial convergence for holomorphic functions on $\ell\_r$ Let $\mathcal F$ be either the set of all bounded holomorphic functions or the set of all $m$-homogeneous polynomials on the unit ball of $\ell\_r$. We give a systematic study of the sets of all $u\in\ell\_r$ for which the monomial expansion $\sum\_{\alpha}\frac{\partial^\alpha f(0)}{\alpha !}u^\alpha$ of every $f\in\mathcal F$ converges. Inspired by recent results from the general theory of Dirichlet series, we establish as our main tool, independently interesting, upper estimates for the unconditional basis constants of spaces of polynomials on $\ell\_r$ spanned by finite sets of monomials. Collective neutrino flavor conversion: Recent developments Neutrino flavor evolution in core-collapse supernovae, neutron-star mergers, or the early universe is dominated by neutrino-neutrino refraction, often spawning "self-induced flavor conversion", i.e., shuffling of flavor among momentum modes. This effect is driven by collective run-away modes of the coupled "flavor oscillators" and can spontaneously break the initial symmetries such as axial symmetry, homogeneity, isotropy, and even stationarity. Moreover, the growth rates of unstable modes can be of the order of the neutrino-neutrino interaction energy instead of the much smaller vacuum oscillation frequency: self-induced flavor conversion does not always require neutrino masses. We illustrate these newly found phenomena in terms of simple toy models. What happens in realistic astrophysical settings is up to speculation at present. Distribution of dislocations in twisted bars An asymptotically exact continuum dislocation theory of single crystal bars under torsion is proposed. The dislocation distribution minimizing energy of the bar with zero torque is shown to be uniform. If the applied torque is non-zero, the minimizer exhibits a dislocation-free zone at the outer ring of the bar's cross-section. The non-uniform distribution of dislocations in equilibrium as well as the twist angle per unit length are found in terms of the given torque. With the energy dissipation being taken into account, there exists an elastic core region, while dislocation are concentrated in a ring between two dislocation-free zones. This leads to the change of the stress distribution increasing the critical threshold of the torque. Multihead Multitrack Detection with Reduced-State Sequence Estimation To achieve ultra-high storage capacity, the data tracks are squeezed more and more on the magnetic recording disks, causing severe intertrack interference (ITI). The multihead multitrack (MHMT) detector is proposed to better combat ITI. Such a detector, however, has prohibitive implementation complexity. In this paper we propose to use the reduced-state sequence estimation (RSSE) algorithm to significantly reduce the complexity, and render MHMT practical. We first consider a commonly used symmetric two-head two-track (2H2T) channel model. The effective distance between two input symbols is redefined. It provides a better distance measure and naturally leads to an unbalanced set partition tree. Different trellis configurations are obtained based on the desired performance/complexity tradeoff. Simulation results show that the reduced MHMT detector can achieve near maximum-likelihood (ML) performance with a small fraction of the original number of trellis states. Error event analysis is given to explain the behavior of RSSE algorithm on 2H2T channel. Search results of dominant RSSE error events for different channel targets are presented. We also study an asymmetric 2H2T system. The simulation results and error event analysis show that RSSE is applicable to the asymmetric channel. Search for Hyper Infrared-Luminous Dust Obscured Galaxies selected with WISE and SDSS We aim to search for hyperliminous infrared (IR) galaxies (HyLIRGs) with IR luminosity $L_{{\rm IR}}$ $>$ 10$^{13}$ $L_{\odot}$ by applying the selection method of Dust Obscured Galaxies (DOGs). They are spatially rare but could correspond to a maximum phase of cosmic star formation and/or active galactic nucleus (AGN) activity, hence they are a crucial population for understanding the star formation and mass assembly history of galaxies. Combining the optical and IR catalogs obtained from Sloan Digital Sky Survey (SDSS) and Wide-field Infrared Survey Explorer (WISE), we performed the extensive HyLIRGs survey; we selected 5,311 IR-bright DOGs with $i$ -- [22] $>$ 7.0 and flux at 22 $\mu$m $>$ 3.8 mJy in 14,555 deg$^2$, where $i$ and [22] are $i$-band and 22 $\mu$m AB magnitudes, respectively. Among them, 67 DOGs have reliable spectroscopic redshifts that enable us to estimate their total IR luminosity based on the SED fitting. Consequently, we successfully discovered 24 HyLIRGs among the 67 spectroscopically-confirmed DOGs. We found that (i) $i$ - [22] color of IR-bright DOGs correlates with the total IR luminosity and (ii) surface number density of HyLIRGs is $>$ 0.17 deg$^{-2}$. A high fraction ($\sim$ 73%) of IR-bright DOGs with $i$ - [22] $>$ 7.5 shows $L_{{\rm IR}}$ $>$ 10$^{13}$ $L_{\odot}$, and the DOGs criterion we adopted could be independently-effective against "W1W2-dropout method" based on four WISE bands, for searching hyper IR luminous populations of galaxies. Random Locations of Periodic Stationary Processes We consider a family of random locations, called intrinsic location functionals, of periodic stationary processes. This family includes but is not limited to the location of the path supremum and first/last hitting times. We first show that the set of all possible distributions of intrinsic location functionals for periodic stationary processes is the convex hull generated by a specific group of distributions.
We then focus on two special subclasses of these random locations. For the first subclass, the density has a uniform lower bound; for the second subclass, the possible distributions are closely related to the concept of joint mixability. Role of CT in the Survival of Small and Medium Scale Enterprises in Ghana Evidence from selected Small and Medium Scale Enterprises in New Juaben Municipality Koforidua This study is to examine the role of ICT in the survival of selected SMEs in Koforidua, Ghana The study employed descriptive technique to conduct the survey. Using a sample of 100 SMEs, an accidental sampling of a non-probability technique was used to gathered data and information. The study argues out that majority of the SMEs operators do use at least one ICT tool in supporting their operations within the New Juaben Municipality. The study revealed that ICT is good and helps business survival in difficult times and become competitive in support of literature r ;eviewed. The study suggested that periodic training in the form of workshops and sensitization programs on the benefits and the use ICT resources in business growth strategies should be organized by National Board for Small-Scale Industries (NBSSI). SME operators, can also outsource their ICT delivery systems by engaging ICT consultants in order to avoid the problem of funding relating to the setting up of their own ICT system which usually requires huge initial capital outlay. The primary policy recommendation arising out of this is that applications for SMEs need to be developed using mobile phones. Quantitative Tverberg theorems over lattices and other discrete sets This paper presents a new variation of Tverberg's theorem. Given a discrete set $S$ of $R^d$, we study the number of points of $S$ needed to guarantee the existence of an $m$-partition of the points such that the intersection of the $m$ convex hulls of the parts contains at least $k$ points of $S$. The proofs of the main results require new quantitative versions of Helly's and Carath\'eodory's theorems. Edge effects in the magnetic interference pattern of a ballistic SNS junction We investigate the Josephson critical current $I_c(\Phi)$ of a wide superconductor-normal metal-superconductor (SNS) junction as a function of the magnetic flux $\Phi$ threading it. Electronic trajectories reflected from the side edges alter the function $I_c(\Phi)$ as compared to the conventional Fraunhofer-type dependence. At weak magnetic fields, $B\lesssim \Phi_0/d^2$, the edge effect lifts zeros in $I_c(\Phi)$ and gradually shifts the minima of that function toward half-integer multiples of the flux quantum. At $B>\Phi_0/d^2$, the edge effect leads to an accelerated decay of the critical current $I_c(\Phi)$ with increasing $\Phi$. At larger fields, eventually, the system is expected to cross into a regime of "classical" mesoscopic fluctuations that is specific for wide ballistic SNS junctions with rough edges. Ringed Substructure and a Gap at 1 AU in the Nearest Protoplanetary Disk We present long-baseline Atacama Large Millimeter/submillimeter Array (ALMA) observations of the 870 micron continuum emission from the nearest gas-rich protoplanetary disk, around TW Hya, that trace millimeter-sized particles down to spatial scales as small as 1 AU (20 mas). These data reveal a series of concentric ring-shaped substructures in the form of bright zones and narrow dark annuli (1-6 AU) with modest contrasts (5-30%). We associate these features with concentrations of solids that have had their inward radial drift slowed or stopped, presumably at local gas pressure maxima. No significant non-axisymmetric structures are detected. Some of the observed features occur near temperatures that may be associated with the condensation fronts of major volatile species, but the relatively small brightness contrasts may also be a consequence of magnetized disk evolution (the so-called zonal flows). Other features, particularly a narrow dark annulus located only 1 AU from the star, could indicate interactions between the disk and young planets. These data signal that ordered substructures on ~AU scales can be common, fundamental factors in disk evolution, and that high resolution microwave imaging can help characterize them during the epoch of planet formation. A ParaBoost Stereoscopic Image Quality Assessment (PBSIQA) System The problem of stereoscopic image quality assessment, which finds applications in 3D visual content delivery such as 3DTV, is investigated in this work. Specifically, we propose a new ParaBoost (parallel-boosting) stereoscopic image quality assessment (PBSIQA) system. The system consists of two stages. In the first stage, various distortions are classified into a few types, and individual quality scorers targeting at a specific distortion type are developed. These scorers offer complementary performance in face of a database consisting of heterogeneous distortion types. In the second stage, scores from multiple quality scorers are fused to achieve the best overall performance, where the fuser is designed based on the parallel boosting idea borrowed from machine learning. Extensive experimental results are conducted to compare the performance of the proposed PBSIQA system with those of existing stereo image quality assessment (SIQA) metrics. The developed quality metric can serve as an objective function to optimize the performance of a 3D content delivery system. Life, Intelligence and Multiverse Hypothetical existence of other universes gives an opportunity not only to extend the scope of physics, but the scope of biology, SETI, and METI as well. Some steps of the development of alien life concept shall be briefly summarized, then the multiverse proposal shall be used as a framework of interpretation to introduce an extended taxonomy of possible or at least imaginable types of life and intelligence based on either different biochemistry or physics. Some consequences shall be presented about SETI and METI in connection with both multiverse hypothesis and anthropic principle. The fundamental advantages of temporal networks Despite the traditional focus of network science on static networks, most networked systems of scientific interest are characterized by temporal links. By disrupting the paths, link temporality has been shown to frustrate many dynamical processes on networks, from information spreading to accessibility. Considering the ubiquity of temporal networks in nature, we must ask: Are there any advantages of the networks' temporality? Here we develop an analytical framework to explore the control properties of temporal networks, arriving at the counterintuitive conclusion that temporal networks, compared to their static (i.e. aggregated) counterparts, reach controllability faster, demand orders of magnitude less control energy, and the control trajectories, through which the system reaches its final states, are significantly more compact than those characterizing their static counterparts. The combination of analytical, numerical and empirical results demonstrates that temporality ensures a degree of flexibility that would be unattainable in static networks, significantly enhancing our ability to control them. One-vs-Each Approximation to Softmax for Scalable Estimation of Probabilities The softmax representation of probabilities for categorical variables plays a prominent role in modern machine learning with numerous applications in areas such as large scale classification, neural language modeling and recommendation systems. However, softmax estimation is very expensive for large scale inference because of the high cost associated with computing the normalizing constant. Here, we introduce an efficient approximation to softmax probabilities which takes the form of a rigorous lower bound on the exact probability. This bound is expressed as a product over pairwise probabilities and it leads to scalable estimation based on stochastic optimization. It allows us to perform doubly stochastic estimation by subsampling both training instances and class labels. We show that the new bound has interesting theoretical properties and we demonstrate its use in classification problems. Normative properties of multi-criteria choice procedures and their superpositions: I We consider different choice procedures such as scoring rules, rules, using majority relation, value function and tournament matrix, which are used in social and multi-criteria choice problems. We focus on the study of the properties that show how the final choice is changed due to changes of preferences or a set of feasible alternatives. As a result a theorem is provided showing which normative properties (rationality, monotonicity, non-compensability) are satisfied for the given choice procedures.
Asymmetric Dark Matter and Baryogenesis from Pseudoscalar Inflation We show that both the baryon asymmetry of the Universe and the dark matter abundance can be explained within a single framework that makes use of maximally helical hypermagnetic fields produced during pseudoscalar inflation and the chiral anomaly in the Standard Model. We consider a minimal asymmetric dark matter model free from anomalies and constraints. We find that the observed baryon and the dark matter abundances are achieved for a wide range of inflationary parameters, and the dark matter mass ranges between 7-15 GeV. The novelty of our mechanism stems from the fact that the same source of CP violation occurring during inflation explains both baryonic and dark matter in the Universe with two inflationary parameters, hence addressing all the initial condition problems in an economical way. On the Content Security Policy Violations due to the Same-Origin Policy Modern browsers implement different security policies such as the Content Security Policy (CSP), a mechanism designed to mitigate popular web vulnerabilities, and the Same Origin Policy (SOP), a mechanism that governs interactions between resources of web pages. In this work, we describe how CSP may be violated due to the SOP when a page contains an embedded iframe from the same origin. We analyse 1 million pages from 10,000 top Alexa sites and report that at least 31.1% of current CSP-enabled pages are potentially vulnerable to CSP violations. Further considering real-world situations where those pages are involved in same-origin nested browsing contexts, we found that in at least 23.5% of the cases, CSP violations are possible. During our study, we also identified a divergence among browsers implementations in the enforcement of CSP in srcdoc sandboxed iframes, which actually reveals a problem in Gecko-based browsers CSP implementation. To ameliorate the problematic conflicts of the security mechanisms, we discuss measures to avoid CSP violations. Local Structure of Gromov-Hausdorff Space near Finite Metric Spaces in General Position We investigate the local structure of the space $\mathcal{M}$ consisting of isometry classes of compact metric spaces, endowed with the Gromov-Hausdorff metric. We consider finite metric spaces of the same cardinality and suppose that these spaces are in general position, i.e., all nonzero distances in each of the spaces are distinct, and all triangle inequalities are strict. We show that sufficiently small balls in $\mathcal{M}$ centered at these spaces and having the same radii are isometric. As consequences, we prove that the cones over such spaces (with the vertices at one-point space) are isometrical; the isometry group of each sufficiently small ball centered at a general position $n$-points space, $n\ge3$, contains a subgroup isomorphic to the group $S_n$ of permutations of a set containing $n$ points. B field in OB stars (BOB): The outstandingly strong magnetic field in the evolved He-strong star CPD-62 2124 The origin and evolution of magnetism in OB stars is far from being well understood. With approximately 70 magnetic OB stars known, any new object with unusual characteristics may turn out to be a key piece of the puzzle. We report the detection of an exceptionally strong magnetic field in the He-strong B2IV star CPD-62 2124. Spectropolarimetric FORS2 and HARPSpol observations were analysed by two independent teams and procedures, concluding on a strong longitudinal magnetic field of approximately 5.2 kG. The quantitative characterisation of the stellar atmosphere yields an effective temperature of 23650$\pm$250 K, a surface gravity of 3.95$\pm$0.10 dex and a surface helium fraction of 0.35$\pm$0.02 by number. The metal composition is in agreement with the cosmic abundance standard, except for Mg, Si and S, which are slightly non-solar. The strong and broad ($\sim$300 km/s) disc-like emission displayed by the H$\alpha$ line suggests a centrifugal magnetosphere supported by the strong magnetic field. Our results imply that CPD-62 2124 is an early B-type star hosting one of the strongest magnetic fields discovered to date, and one of the most evolved He-strong stars known, with a fractional main-sequence lifetime of approximately 0.6. The variance of the locally measured Hubble parameter explained with different estimators We study the expected variance of measurements of the Hubble constant, $H_0$, as calculated in either linear perturbation theory or using non-linear velocity power spectra derived from $N$-body simulations. We compare the variance with that obtained by carrying out mock observations in the N-body simulations, and show that the estimator typically used for the local Hubble constant in studies based on perturbation theory is different from the one used in studies based on N-body simulations. The latter gives larger weight to distant sources, which explains why studies based on N-body simulations tend to obtain a smaller variance than that found from studies based on the power spectrum. Although both approaches result in a variance too small to explain the discrepancy between the value of $H_0$ from CMB measurements and the value measured in the local universe, these considerations are important in light of the percent determination of the Hubble constant in the local universe. The importance of thermodynamics for molecular systems, and the importance of molecular systems for thermodynamics Improved understanding of molecular systems has only emphasised the sophistication of networks within the cell. Simultaneously, the advance of nucleic acid nanotechnology, a platform within which reactions can be exquisitely controlled, has made the development of artificial architectures and devices possible. Vital to this progress has been a solid foundation in the thermodynamics of molecular systems. In this pedagogical review and perspective, I will discuss how thermodynamics determines both the overall potential of molecular networks, and the minute details of design. I will then argue that, in turn, the need to understand molecular systems is helping to drive the development of theories of thermodynamics at the microscopic scale. Inelastic Light Scattering Spectroscopy of Magnons and Phonons in Nickel Oxide: Effects of Temperature We report results of an investigation of the temperature dependence of the magnon and phonon frequencies in NiO. A combination of Brillouin - Mandelstam and Raman spectroscopies allowed us to elucidate the evolution of the phonon and magnon spectral signatures from the Brillouin zone center (GHz range) to the second-order peaks from the zone boundary (THz range). The temperature-dependent behavior of the magnon and phonon bands in the NiO spectrum indicates the presence of antiferromagnetic (AF) order fluctuation or a persistent AF state at temperatures above the Neel temperature (T=523 K). Tuning the intensity of the excitation laser provides a method for disentangling the features of magnons from acoustic phonons without the application of a magnetic field. Our results are useful for interpretation of the inelastic-light scattering spectrum of NiO, and add to the knowledge of its magnon properties important for THz spintronic devices. On flare-CME characteristics from Sun to Earth combining remote-sensing image data with in-situ measurements supported by modeling We analyze the well observed flare-CME event from October 1, 2011 (SOL2011-10-01T09:18) covering the complete chain of action - from Sun to Earth - for a better understanding of the dynamic evolution of the CME and its embedded magnetic field. We study the solar surface and atmosphere associated with the flare-CME from SDO and ground-based instruments, and also track the CME signature off-limb from combined EUV and white-light data with STEREO. By applying 3D reconstruction techniques (GCS, total mass) to stereoscopic STEREO-SoHO coronagraph data, we track the temporal and spatial evolution of the CME in interplanetary space and derive its geometry and 3D-mass. We combine the GCS and Lundquist model results to derive the axial flux and helicity of the MC from in-situ measurements (Wind).
This is compared to nonlinear force-free (NLFF) model results as well as to the reconnected magnetic flux derived from the flare ribbons (flare reconnection flux) and the magnetic flux encompassed by the associated dimming (dimming flux). We find that magnetic reconnection processes were already ongoing before the start of the impulsive flare phase, adding magnetic flux to the flux rope before its final eruption. The dimming flux increases by more than 25% after the end of the flare, indicating that magnetic flux is still added to the flux rope after eruption. Hence, the derived flare reconnection flux is most probably a lower limit for estimating the magnetic flux within the flux rope. We find that the magnetic helicity and axial magnetic flux are reduced in interplanetary space by ~50% and 75%, respectively, possibly indicating to an erosion process. A mass increase of 10% for the CME is observed over the distance range from ~4-20 Rs. The temporal evolution of the CME associated core dimming regions supports the scenario that fast outflows might supply additional mass to the rear part of the CME. TTT in CFT: Trace Identities and the Conformal Anomaly Effective Action Stress-energy correlation functions in a general Conformal Field Theory (CFT) in four dimensions are described in a fully covariant approach, as metric variations of the quantum effective action in an arbitrary curved space background field. All Conservation, Trace and Conformal Ward Identities (CWIs), including contact terms, are completely fixed in this covariant approach. The Trace and CWIs are anomalous. Their anomalous contributions may be computed unambiguously by metric variation of the exact 1PI quantum effective action determined by the conformal anomaly of $\left\langle T^{\mu\nu}\right\rangle$ in $d = 4$ curved space. This action implies the existence of massless propagator poles in three and higher point correlators of $T^{\mu\nu}$ . The metric variations of the anomaly effective action in its local form in terms of a scalar conformalon field are carried out explicitly for the case of the correlator of three CFT stress-energy tensors, and the result is shown to coincide with the algebraic reconstruction of $\left\langle TTT\right\rangle$ from its transverse, tracefree parts, determined independently by the solution of the CWIs in d dimensional flat space in the momentum representation. This demonstrates that the specific analytic structure and massless poles predicted by the general curved space anomaly effective action are in fact a necessary feature of the exact solution of the anomalous CWIs in any $d = 4$ CFT. The effect of phase change on stability of convective flow in a layer of volatile liquid driven by a horizontal temperature gradient Buoyancy-thermocapillary convection in a layer of volatile liquid driven by a horizontal temperature gradient arises in a variety of situations. Recent studies have shown that the composition of the gas phase, which is typically a mixture of vapour and air, has a noticeable effect on the critical Marangoni number describing the onset of convection as well as on the observed convection pattern. Specifically, as the total pressure or, equivalently, the average concentration of air is decreased, the threshold of the instability leading to the emergence of convective rolls is found to increase rather significantly. We present a linear stability analysis of the problem which shows that this trend can be readily understood by considering the transport of heat and vapour through the gas phase. In particular, we show that transport in the gas phase has a noticeable effect even at atmospheric conditions, when phase change is greatly suppressed. Semiclassical cosmology with polymer matter In loop quantum cosmology, polymer quantization is applied to gravity and Schrodinger quantization to matter. This approach misses interesting cosmological dynamics coming from the polymer quantization of matter. We demonstrate this in semiclassical cosmology with a scalar field and pressureless dust: gravity is kept classical, dust is used to fix the time gauge, and polymer quantization effects are isolated in the scalar field. The resulting dynamics shows a period of inflation, both with and without a scalar potential, and the emergence of a classical universe at late times. Since gravity is not quantized, the cosmological singularity is not resolved, but our results suggest that polymer quantization of both gravity and matter are important for a complete picture. Symmetric Convex Sets with Minimal Gaussian Surface Area Let $\Omega\subset\mathbb{R}^{n+1}$ have minimal Gaussian surface area among all sets satisfying $\Omega=-\Omega$ with fixed Gaussian volume. Let $A=A_{x}$ be the second fundamental form of $\partial\Omega$ at $x$, i.e. $A$ is the matrix of first order partial derivatives of the unit normal vector at $x\in\partial\Omega$. For any $x=(x_{1},\ldots,x_{n+1})\in\mathbb{R}^{n+1}$, let $\gamma_{n}(x)=(2\pi)^{-n/2}e^{-(x_{1}^{2}+\cdots+x_{n+1}^{2})/2}$. Let $\|A\|^{2}$ be the sum of the squares of the entries of $A$, and let $\|A\|_{2\to 2}$ denote the $\ell_{2}$ operator norm of $A$. It is shown that if $\Omega$ or $\Omega^{c}$ is convex, and if either $$\int_{\partial\Omega}(\|A_{x}\|^{2}-1)\gamma_{n}(x)dx>0\qquad\mbox{or}\qquad \int_{\partial\Omega}\Big(\|A_{x}\|^{2}-1+2\sup_{y\in\partial\Omega}\|A_{y}\|_{2\to 2}^{2}\Big)\gamma_{n}(x)dx<0,$$ then $\partial\Omega$ must be a round cylinder. That is, except for the case that the average value of $\|A\|^{2}$ is slightly less than $1$, we resolve the convex case of a question of Barthe from 2001. The main tool is the Colding-Minicozzi theory for Gaussian minimal surfaces, which studies eigenfunctions of the Ornstein-Uhlenbeck type operator $L= \Delta-\langle x,\nabla \rangle+\|A\|^{2}+1$ associated to the surface $\partial\Omega$. A key new ingredient is the use of a randomly chosen degree 2 polynomial in the second variation formula for the Gaussian surface area. Our actual results are a bit more general than the above statement. Also, some of our results hold without the assumption of convexity. Generalized Extension of Watson's theorem for the series $_{3}F_{2}(1)$ The $_{3}F_{2}$ hypergeometric function plays a very significant role in the theory of hypergeometric and generalized hypergeometric series. Despite that $_{3}F_{2}$ hypergeometric function has several applications in mathematics, also it has a lot of applications in physics and statistics. The fundamental purpose of this research paper is to find out the explicit expression of the $_{3}F_{2}$ Watson's classical summation theorem of the form: \[ _{3}F_{2}\left[ \begin{array} [c]{ccccc}% a, & b, & c & & \\ & & & ; & 1\\ \frac{1}{2}(a+b+i+1), & 2c+j & & & \end{array} \right] \] with arbitrary $i$ and $j$, where for $i=j=0$, we get the well known Watson's theorem for the series $_{3}F_{2}(1)$. Quantum localized states in photonic flat-band lattices The localization of light in flat-band lattices has been recently proposed and experimentally demonstrated in several configurations, assuming a classical description of light. Here, we study the problem of light localization in the quantum regime. We focus on quasi one-dimensional and two-dimensional lattices which exhibit a perfect flat-band inside their linear spectrum. Localized quantum states are constructed as eigenstates of the interaction Hamiltonian with a vanishing eigenvalue and a well defined total photon number. These are superpositions of Fock states with probability amplitudes given by positive as well as negative square roots of multinomial coefficients. The classical picture can be recovered by considering poissonian superpositions of localized quantum states with different total photon number.
We also study the separability properties of flat band quantum states and apply them to the transmission of information via multi-core fibers, where these states allow for the total passive suppression of photon crosstalk and exhibit robustness against photon losses. At the end, we propose a novel on-chip setup for the experimental preparation of localized quantum states of light for any number of photons. Material Budget Calculation of the new Inner Tracking System, ALICE The ALICE Collaboration aims at studying the physics of strongly interacting matter by building up a dedicated heavy-ion detector. The Inner Tracking System (ITS) is located in the heart of the ALICE Detector surrounding the interaction point. Now, ALICE has a plan to upgrade the inner tracking system for rare probes at low transverse momentum. The new ITS composes of seven layers of silicon pixel sensor on the supporting structure. One goal of the new design is to reduce the material budget ($X/X_0$) per layer to 0.3$\%$ for inner layers and 0.8$\%$ for middle and outer layers. In this work, we perform the calculations based on detailed geometry descriptions of different supporting structures for inner and outer barrel using ALIROOT. Our results show that it is possible to reduce the material budget of the inner and outer barrel to the value that we have expected. The manufacturing of such prototypes are also possible. On the localization properties of an RPWELL gas-avalanche detector A study of the localization properties of a single-element Resistive Plate WELL (RPWELL) detector is presented. The detector comprises of a single-sided THick Gaseous Electron Multiplier (THGEM) coupled to a segmented readout anode through a doped silicate-glass plate of 10$^{10}$ $\Omega\cdot$cm bulk resistivity. Operated in ambient Ne/(5$\%$CH$_4$) gas, the detector has been investigated with 150 GeV muons at CERN-SPS. Signals induced through the resistive plate on anode readout strips were recorded with APV25/SRS electronics. The experimental results are compared with that of Monte Carlo simulations. The effects of various physics phenomena on the position resolution are discussed. The measured position resolution in the present configuration is 0.28 mm RMS - compatible with the holes-pattern of the multiplier. Possible ways for improving the detector position resolution are suggested. Car sharing through the data analysis lens Car sharing is one the pillars of a smart transportation infrastructure, as it is expected to reduce traffic congestion, parking demands and pollution in our cities. From the point of view of demand modelling, car sharing is a weak signal in the city landscape: only a small percentage of the population uses it, and thus it is difficult to study reliably with traditional techniques such as households travel diaries. In this work, we depart from these traditional approaches and we rely on web-based, digital records about vehicle availability in 10 European cities for one of the major active car sharing operators. We discuss how vehicles are used, what are the main characteristics of car sharing trips, whether events happening in certain areas are predictable or not, and how the spatio-temporal information about vehicle availability can be used to infer how different zones in a city are used by customers. We conclude the paper by presenting a direct application of the analysis of the dataset, aimed at identifying where to locate maintenance facilities within the car sharing operational area. Hyers-Ulam stability of hyperbolic M\"obius difference equation Hyers-Ulam stability of the difference equation with the initial point $ z_0 $ as follows $$ z_{i+1} = \frac{az_i + b}{cz_i + d} $$ is investigated for complex numbers $ a,b,c $ and $ d $ where $ ad - bc = 1 $, $ c \neq 0 $ and $a + d \in \mathbb{R} \setminus [-2,2] $. The stability of the sequence $ \{z_n\}_{n \in \mathbb{N}_0} $ holds if the initial point is in the exterior of a certain disk of which center is $ -\frac{d}{c} $. Furthermore, the region for stability can be extended to the complement of some neighborhood of the line segment between $ -\frac{d}{c} $ and the repelling fixed point of the map $ z \mapsto \frac{az + b}{cz + d} $. This result is the generalization of Hyers-Ulam stability of Pielou logistic equation. Discriminative Similarity for Clustering and Semi-Supervised Learning Similarity-based clustering and semi-supervised learning methods separate the data into clusters or classes according to the pairwise similarity between the data, and the pairwise similarity is crucial for their performance. In this paper, we propose a novel discriminative similarity learning framework which learns discriminative similarity for either data clustering or semi-supervised learning. The proposed framework learns classifier from each hypothetical labeling, and searches for the optimal labeling by minimizing the generalization error of the learned classifiers associated with the hypothetical labeling. Kernel classifier is employed in our framework. By generalization analysis via Rademacher complexity, the generalization error bound for the kernel classifier learned from hypothetical labeling is expressed as the sum of pairwise similarity between the data from different classes, parameterized by the weights of the kernel classifier. Such pairwise similarity serves as the discriminative similarity for the purpose of clustering and semi-supervised learning, and discriminative similarity with similar form can also be induced by the integrated squared error bound for kernel density classification. Based on the discriminative similarity induced by the kernel classifier, we propose new clustering and semi-supervised learning methods. Interpreting Shared Deep Learning Models via Explicable Boundary Trees Despite outperforming the human in many tasks, deep neural network models are also criticized for the lack of transparency and interpretability in decision making. The opaqueness results in uncertainty and low confidence when deploying such a model in model sharing scenarios, when the model is developed by a third party. For a supervised machine learning model, sharing training process including training data provides an effective way to gain trust and to better understand model predictions. However, it is not always possible to share all training data due to privacy and policy constraints. In this paper, we propose a method to disclose a small set of training data that is just sufficient for users to get the insight of a complicated model. The method constructs a boundary tree using selected training data and the tree is able to approximate the complicated model with high fidelity. We show that traversing data points in the tree gives users significantly better understanding of the model and paves the way for trustworthy model sharing. On Closed Subsets of Free Groups We give two examples of a finitely generated subgroup of a free group and a subset, closed in the profinite topology of a free group, such that their product is not closed in the profinite topology of a free group. Improved theoretical description of Mueller-Navelet jets at LHC We present a method for improving the phenomenological description of Mueller-Navelet jets at LHC, which is based on matching the BFKL resummation with fixed order calculations. We point out the need of a consistent identification of jets between experimental measurements and theoretical descriptions. We hope as well to motivate an extensive analysis of MN jets at LHC in run 2. Mass density slope of elliptical galaxies from strong lensing and resolved stellar kinematics We discuss constraints on the mass density distribution (parameterized as $\rho\propto r^{-\gamma}$) in early-type galaxies provided by strong lensing and stellar kinematics data. The constraints come from mass measurements at two `pinch' radii. One `pinch' radius $r_1=2.2 R_{Einst}$ is defined such that the Einstein (i.e. aperture) mass can be converted to the spherical mass almost independently of the mass-model. Another `pinch' radius $r_2=R_{opt}$ is chosen so that the dynamical mass, derived from the line-of-sight velocity dispersion, is least sensitive to the anisotropy of stellar orbits. We verified the performance of this approach on a sample of simulated elliptical galaxies and on a sample of 15 SLACS lens galaxies at $0.01 \leq z \leq 0.35$, which have already been analysed in Barnabe et al. (2011) by the self-consistent joint lensing and kinematic code.
For massive simulated galaxies the density slope $\gamma$ is recovered with an accuracy of $\sim 13\%$, unless $r_1$ and $r_2$ happen to be close to each other. For SLACS galaxies, we found good overall agreement with the results of Barnabe et al. (2011) with a sample-averaged slope $\gamma=2.1\pm0.05$. While the two-pinch-radii approach has larger statistical uncertainties, it is much simpler and uses only few arithmetic operations with directly observable quantities. Waves Speed Averaging Impact on Godunov type Schemes for Hyperbolic Equations with Discontinuous Coefficients: The linear scalar case This paper deals with the waves speed averaging impact impact on Godunov type schemes for linear scalar hyperbolic equations with discontinuous coefficients. In many numerical schemes of Godunov type used in fluid dynamics, electromagnetic, electro-hydrodynamic problems and so on, usually a Riemann problem needs to be solved to estimate fluxes. The exact solution is generally not possible to obtain, but good approximations are provided in many situations like Roe and HLLC Riemann solvers in fluids. However all these solvers assume that the acoustic waves speed are continuous by considering some averaging. This could unfortunately lead to a wrong solution as we will show in this paper for the linear scalar case. Providing a Riemann solver in the general case of non-linear hyperbolic systems with discontinuous waves speed is a very hard task, therefore in this paper and as a first step, we focus on the linear and scalar case. In a previous work we proposed for such problems a Riemann solution that takes into account the discontinuities of the waves speed, we provided a numerical argument to show the validity of the solution. In this paper, first a new argument using regularization technique is provided to reinforce the validity of the proposed solution. Then, the corresponding Godunov scheme is derived and the effect of waves speed averaging is clearly demonstrated with a clear connection to the distribution product phenomenon. Fermi Large Area Telescope detection of gamma-ray emission from the direction of supernova iPTF14hls The remnant of supernova explosion is widely believed to be the acceleration site of high-energy cosmic ray particles. The acceleration timescale is, however, typically very long. Here we report the detection of a variable $\gamma$-ray source with the Fermi Large Area Telescope, which is positionally and temporally consistent with a peculiar supernova, iPTF14hls. A quasi-stellar object SDSS J092054.04+504251.5, which is probably a blazar according to the infrared data, is found in the error circle of the $\gamma$-ray source. More data about the $\gamma$-ray source and SDSS J092054.04+504251.5 are needed to confirm their association. On the other hand, if the association between the $\gamma$-ray source and the supernova is confirmed, this would be the first time to detect high-energy $\gamma$-ray emission from a supernova, suggesting very fast particle acceleration by supernova explosions. Is there a UV/X-ray connection in IRAS 13224-3809? We present results from the optical, ultraviolet and X-ray monitoring of the NLS1 galaxy IRAS 13224-3809 taken with Swift and XMM-Newton during 2016. IRAS 13224-3809 is the most variable bright AGN in the X-ray sky and shows strong X-ray reflection, implying that the X-rays strongly illuminate the inner disc. Therefore, it is a good candidate to study the relationship between coronal X-ray and disc UV emission. However, we find no correlation between the X-ray and UV flux over the available ~40 day monitoring, despite the presence of strong X-ray variability and the variable part of the UV spectrum being consistent with irradiation of a standard thin disc. This means either that the X-ray flux which irradiates the UV emitting outer disc does not correlate with the X-ray flux in our line of sight and/or that another process drives the majority of the UV variability. The former case may be due to changes in coronal geometry, absorption or scattering between the corona and the disc. A full general relativistic neutrino radiation-hydrodynamics simulation of a collapsing very massive star and the formation of a black hole We study the final fate of a very massive star by performing full general relativistic (GR), three-dimensional (3D) simulation with three-flavor multi-energy neutrino transport. Utilizing a 70 solar mass zero metallicity progenitor, we self-consistently follow the radiation-hydrodynamics from the onset of gravitational core-collapse until the second collapse of the proto-neutron star (PNS), leading to black hole (BH) formation. Our results show that the BH formation occurs at a post-bounce time of ~300 ms for the 70 Msun star. This is significantly earlier than those in the literature where lower mass progenitors were employed. At a few ~10 ms before BH formation, we find that the stalled bounce shock is revived by intense neutrino heating from the very hot PNS, which is aided by violent convection behind the shock. In the context of 3D-GR core-collapse modeling with multi-energy neutrino transport, our numerical results present the first evidence to validate a fallback BH formation scenario of the 70 Msun star. Energy-Efficient Resource Allocation in NOMA Heterogeneous Networks Non-orthogonal multiple access (NOMA) has attracted much recent attention owing to its capability for improving the system spectral efficiency in wireless communications. Deploying NOMA in heterogeneous network can satisfy users' explosive data traffic requirements, and NOMA will likely play an important role in the fifth-generation (5G) mobile communication networks. However, NOMA brings new technical challenges on resource allocation due to the mutual cross-tier interference in heterogeneous networks. In this article, to study the tradeoff between data rate performance and energy consumption in NOMA, we examine the problem of energy-efficient user scheduling and power optimization in 5G NOMA heterogeneous networks. The energy-efficient user scheduling and power allocation schemes are introduced for the downlink 5G NOMA heterogeneous network for perfect and imperfect channel state information (CSI) respectively. Simulation results show that the resource allocation schemes can significantly increase the energy efficiency of 5G NOMA heterogeneous network for both cases of perfect CSI and imperfect CSI. Fast computation of approximant bases in canonical form In this article, we design fast algorithms for the computation of approximant bases in shifted Popov normal form. We first recall the algorithm known as PM-Basis, which will be our second fundamental engine after polynomial matrix multiplication: most other fast approximant basis algorithms basically aim at efficiently reducing the input instance to instances for which PM-Basis is fast. Such reductions usually involve partial linearization techniques due to Storjohann, which have the effect of balancing the degrees and dimensions in the manipulated matrices. Following these ideas, Zhou and Labahn gave two algorithms which are faster than PM-Basis for important cases including Hermite-Pade approximation, yet only for shifts whose values are concentrated around the minimum or the maximum value. The three mentioned algorithms were designed for balanced orders and compute approximant bases that are generally not normalized. Here, we show how they can be modified to return the shifted Popov basis without impact on their cost bound; besides, we extend Zhou and Labahn's algorithms to arbitrary orders. Furthermore, we give an algorithm which handles arbitrary shifts with one extra logarithmic factor in the cost bound compared to the above algorithms. To the best of our knowledge, this improves upon previously known algorithms for arbitrary shifts, including for particular cases such as Hermite-Pade approximation. This algorithm is based on a recent divide and conquer approach which reduces the general case to the case where information on the output degree is available. As outlined above, we solve the latter case via partial linearizations and PM-Basis. Updated observational constraints on quintessence dark energy models The recent GW170817 measurement favors the simplest dark energy models, such as a single scalar field.
Quintessence models can be classified in two classes, freezing and thawing, depending on whether the equation of state decreases towards $-1$ or departs from it. In this paper we put observational constraints on the parameters governing the equations of state of tracking freezing, scaling freezing and thawing models using updated data, from the Planck 2015 release, joint light-curve analysis and baryonic acoustic oscillations. Because of the current tensions on the value of the Hubble parameter $H_0$, unlike previous authors, we let this parameter vary, which modifies significantly the results. Finally, we also derive constraints on neutrino masses in each of these scenarios. Influence of surface stoichiometry and quantum confinement on the electronic structure of small diameter InxGa1-xAs nanowires Electronic structures for InxGa1-xAs nanowires with [100], [110], and [111] orientations and critical dimensions of approximately 2 nm are treated within the framework of density functional theory. Explicit band structures are calculated and properties relevant to nanoelectronic design are extracted including band gaps, effective masses, and density of states. The properties of these III-V nanowires are compared to silicon nanowires of comparable dimensions as a reference system. In nonpolar semiconductors, quantum confinement and surface chemistry are known to play a key role in the determination of nanowire electronic structure. InxGa1-xAs nanowires have in addition effects due to alloy stoichiometry on the cation sublattice and due to the polar nature of the cleaved nanowire surfaces. The impact of these additional factors on the electronic structure for these polar semiconductor nanowires is shown to be significant and necessary for accurate treatment of electronic structure properties. Approximating the Region of Multi-Task Coordination via the Optimal Lyapunov-Like Barrier Function We consider the multi-task coordination problem for multi-agent systems under the following objectives: 1. collision avoidance; 2. connectivity maintenance; 3. convergence to desired destinations. The paper focuses on the safety guaranteed region of multi-task coordination (SG-RMTC), i.e., the set of initial states from which all trajectories converge to the desired configuration, while at the same time achieve the multi-task coordination and avoid unsafe sets. In contrast to estimating the domain of attraction via Lyapunov functions, the main underlying idea is to employ the sublevel sets of Lyapunov-like barrier functions to approximate the SG-RMTC. Rather than using fixed Lyapunov-like barrier functions, a systematic way is proposed to search an optimal Lyapunov-like barrier function such that the under-estimate of SG-RMTC is maximized. Numerical examples illustrate the effectiveness of the proposed method. The $\ell^\infty$-Cophenetic Metric for Phylogenetic Trees as an Interleaving Distance There are many metrics available to compare phylogenetic trees since this is a fundamental task in computational biology. In this paper, we focus on one such metric, the $\ell^\infty$-cophenetic metric introduced by Cardona et al. This metric works by representing a phylogenetic tree with $n$ labeled leaves as a point in $\mathbb{R}^{n(n+1)/2}$ known as the cophenetic vector, then comparing the two resulting Euclidean points using the $\ell^\infty$ distance. Meanwhile, the interleaving distance is a formal categorical construction generalized from the definition of Chazal et al., originally introduced to compare persistence modules arising from the field of topological data analysis. We show that the $\ell^\infty$-cophenetic metric is an example of an interleaving distance. To do this, we define phylogenetic trees as a category of merge trees with some additional structure; namely labelings on the leaves plus a requirement that morphisms respect these labels. Then we can use the definition of a flow on this category to give an interleaving distance. Finally, we show that, because of the additional structure given by the categories defined, the map sending a labeled merge tree to the cophenetic vector is, in fact, an isometric embedding, thus proving that the $\ell^\infty$-cophenetic metric is, in fact, an interleaving distance. Large Field Inflation/Quintessence and the Refined Swampland Distance Conjecture Attempts to construct string derived effective field theory models realizing large field inflation are plagued by control issues. Targeted at a broader audience, in this article we review recent progress in isolating the underlying conceptual reasons for this failure. Special emphasis is given to models of axion monodromy inflation and their relation to the Swampland Distance Conjecture. This discriminates effective actions that admit a UV completion, the landscape, from those that do not, the swampland. Since they are conceptually very similar, we also comment on implied challenges for axionic quintessence models. Long-time asymptotics for the Nonlocal mKdV equation In this paper, we study the Cauchy problem with decaying initial data for the nonlocal modified Korteweg-de Vries equation (nonlocal mKdV) \[q_t(x,t)+q_{xxx}(x,t)-6q(x,t)q(-x,-t)q_x(x,t)=0,\] which can be viewed as a generalization of the local classical mKdV equation. We first formulate the Riemann-Hilbert problem associated with the Cauchy problem of the nonlocal mKdV equation. Then we apply the Deift-Zhou nonlinear steepest-descent method to analyze the long-time asymptotics for the solution of the nonlocal mKdV equation. In contrast with the classical mKdV equation, we find some new and different results on long-time asymptotics for the nonlocal mKdV equation and some additional assumptions about the scattering data are made in our main results. Three and a half asymptotic properties We define and discuss transfinite asymptotic notions of smoothability, type, and equal norm type. We prove distinctness of these notions for a proper class of ordinals and that each class is an ideal. We also extend some results of Godefroy, Kalton, and Lancien to operators and ordinals greater than zero regarding the equivalence of equal norm asymptotic type and uniform renormings with power type smoothness. Finally, we discuss an extension of a non-linear result for quasi-reflexive, asymptotically $p$-smoothable Banach spaces to quasi-reflexive Banach spaces with asymptotic equal norm type $p$. Two-particle collisional coordinate shifts and hydrodynamic anomalous Hall effect in systems without Lorentz invariance We show that electrons undergoing a two-particle collision in a crystal experience a coordinate shift that depends on their single-particle Bloch wave functions, and derive a gauge-invariant expression for such shift, valid for arbitrary band structures, and arbitrary two-particle interaction potentials. As an application of the theory, we consider two-particle coordinate shifts for Weyl fermions in space of three spatial dimensions. We demonstrate that such shifts in general contribute to the anomalous Hall conductivity of a clean electron liquid. Category coding with neural network application In many applications of neural network, it is common to introduce huge amounts of input categorical features, as well as output labels. However, since the required network size should have rapid growth with respect to the dimensions of input and output space, there exists huge cost in both computation and memory resources. In this paper, we present a novel method called category coding (CC), where the design philosophy follows the principle of minimal collision to reduce the input and output dimension effectively. In addition, we introduce three types of category coding based on different Euclidean domains. Experimental results show that all three proposed methods outperform the existing state-of-the-art coding methods, such as standard cut-off and error-correct output coding (ECOC) methods. Strong and Tunable Spin Lifetime Anisotropy in Dual-Gated Bilayer Graphene We report the discovery of a strong and tunable spin lifetime anisotropy with excellent spin lifetimes up to 7.8 ns in dual-gated bilayer graphene. Remarkably, this realizes the manipulation of spins in graphene by electrically-controlled spin-orbit fields, which is unexpected due to graphene's weak intrinsic spin-orbit coupling. We utilize both the in-plane magnetic field Hanle precession and oblique Hanle precession measurements to directly compare the lifetimes of out-of-plane vs. in-plane spins.
We find that near the charge neutrality point, the application of a perpendicular electric field opens a band gap and generates an out-of-plane spin-orbit field that stabilizes out-of-plane spins against spin relaxation, leading to a large spin lifetime anisotropy. This intriguing behavior occurs because of the unique spin-valley coupled band structure of bilayer graphene. Our results demonstrate the potential for highly tunable spintronic devices based on dual-gated 2D materials. An alternative approach to the static spherically symmetric vacuum global solution to the Einstein's equations We propose an alternative description of the Schwarzschild black hole based on the requirement that the solution be static not only outside the horizon but also inside it. As a consequence of this assumption, we are led to a change of signature implying a complex transformation of an angle variable. There is a "phase transition" on the surface R=2m, producing a change in the symmetry as we cross this surface. Some consequences of this situation on the motion of test particles are investigated. Robustness of Two-Dimensional Line Spectral Estimation Against Spiky Noise The aim of two-dimensional line spectral estimation is to super-resolve the spectral point sources of the signal from time samples. In many associated applications such as radar and sonar, due to cut-off and saturation regions in electronic devices, some of the numbers of samples are corrupted by spiky noise. To overcome this problem, we present a new convex program to simultaneously estimate spectral point sources and spiky noise in two dimensions. To prove uniqueness of the solution, it is sufficient to show that a dual certificate exists. Construction of the dual certificate imposes a mild condition on the separation of the spectral point sources. Also, the number of spikes and detectable sparse sources are shown to be a logarithmic function of the number of time samples. Simulation results confirm the conclusions of our general theory. Non-Hermitian Hopf-Link Exceptional Line Semimetals We study a new class of non-Hermitian topological phases in three dimension in the absence of any symmetry, where the topological robust band degeneracies are Hopf-link exceptional lines. As a concrete example, we investigate the non-Hermitian band structures of nodal line semimetals under non-Hermitian perturbations, where the Fermi surfaces can transit from 1d nodal lines to 2d twisting surfaces with Hopf-link boundaries when the winding number defined along the nodal line is $\pm 1$. The linking numbers of these linked exceptional line phases are also proposed, based on the integral of Chern-Simons form over the Brillouin zone. Algorithm Selection for Collaborative Filtering: the influence of graph metafeatures and multicriteria metatargets To select the best algorithm for a new problem is an expensive and difficult task. However, there are automatic solutions to address this problem: using Metalearning, which takes advantage of problem characteristics (i.e. metafeatures), one is able to predict the relative performance of algorithms. In the Collaborative Filtering scope, recent works have proposed diverse metafeatures describing several dimensions of this problem. Despite interesting and effective findings, it is still unknown whether these are the most effective metafeatures. Hence, this work proposes a new set of graph metafeatures, which approach the Collaborative Filtering problem from a Graph Theory perspective. Furthermore, in order to understand whether metafeatures from multiple dimensions are a better fit, we investigate the effects of comprehensive metafeatures. These metafeatures are a selection of the best metafeatures from all existing Collaborative Filtering metafeatures. The impact of the most representative metafeatures is investigated in a controlled experimental setup. Another contribution we present is the use of a Pareto-Efficient ranking procedure to create multicriteria metatargets. These new rankings of algorithms, which take into account multiple evaluation measures, allow to explore the algorithm selection problem in a fairer and more detailed way. According to the experimental results, the graph metafeatures are a good alternative to related work metafeatures. However, the results have shown that the feature selection procedure used to create the comprehensive metafeatures is is not effective, since there is no gain in predictive performance. Finally, an extensive metaknowledge analysis was conducted to identify the most influential metafeatures. emrQA: A Large Corpus for Question Answering on Electronic Medical Records We propose a novel methodology to generate domain-specific large-scale question answering (QA) datasets by re-purposing existing annotations for other NLP tasks. We demonstrate an instance of this methodology in generating a large-scale QA dataset for electronic medical records by leveraging existing expert annotations on clinical notes for various NLP tasks from the community shared i2b2 datasets. The resulting corpus (emrQA) has 1 million question-logical form and 400,000+ question-answer evidence pairs. We characterize the dataset and explore its learning potential by training baseline models for question to logical form and question to answer mapping. Emergence of Human-comparable Balancing Behaviors by Deep Reinforcement Learning This paper presents a hierarchical framework based on deep reinforcement learning that learns a diversity of policies for humanoid balance control. Conventional zero moment point based controllers perform limited actions during under-actuation, whereas the proposed framework can perform human-like balancing behaviors such as active push-off of ankles. The learning is done through the design of an explainable reward based on physical constraints. The simulated results are presented and analyzed. The successful emergence of human-like behaviors through deep reinforcement learning proves the feasibility of using an AI-based approach for learning humanoid balancing control in a unified framework. Multileptonic signals of co-annihilating left-right supersymmetric dark matter We perform a comprehensive dark matter analysis of left-right supersymmetric scenarios that includes constraints from dark matter direct and indirect detection experiments and that presents distinctive features from those available in minimal supersymmetry. We concentrate on dark matter candidates which, while satisfying all constraints, are different from those of the minimal supersymmetric standard model. We consider in our analysis all possible co-annihilation channels relevant for setups in which several states are light and nearly degenerate, and devise a set of representative benchmark points, requiring co-annihilations, which satisfy all restrictions. We then study their consequent LHC signals, which exhibit promising new multileptonic signatures involving $W_R$, that if observed, would provide a strong support for left-right supersymmetry. Nongeometric heterotic strings and dual F-theory with enhanced gauge groups Eight-dimensional nongeometric heterotic strings were constructed as duals of F-theory on $\Lambda^{1,1}\oplus E_8\oplus E_7$ lattice polarized K3 surfaces by Malmendier and Morrison. We study the structure of the moduli space of this construction. There are special points in this space at which the ranks of the non-Abelian gauge groups on the 7-branes in F-theory are enhanced to 18. We demonstrate that the enhanced rank-18 non-Abelian gauge groups arise as a consequence of the coincident 7-branes, which deform stable degenerations on the F-theory side. This observation suggests that the non-geometric heterotic strings include nonperturbative effects of the coincident 7-branes on the F-theory side. The gauge groups that arise at these special points in the moduli space do not allow for perturbative descriptions on the heterotic side. We also construct a family of elliptically fibered Calabi-Yau 3-folds by fibering K3 surfaces with enhanced singularities over $\mathbb{P}^1$. Highly enhanced gauge groups arise in F-theory compactifications on the resulting Calabi-Yau 3-folds. A simplified static frequency converter model for electromechanical transient stability studies of 16$\frac{2}{3}$ Hz railways With increased share of Static Frequency Converters (SFCs) in 16$\frac{2}{3}$ Hz railway grids concerns about stability have increased. Stability studies for such low-frequency railway grids are few, and models that describe SFC dynamics are especially few. This paper presents an open SFC model for electromechanical stability studies in the phasor domain, suited for 16$\frac{2}{3}$ Hz synchronous railway grids. The developed and proposed SFC model is implemented in MatLab Simulink, together with grid and loads.
Numerical studies are made, in which the proposed SFC model is validated against both measured RMS-phasor amplitude of voltage and current at the railway grid side of an SFC. The SFC model developed is able to reproduce the measured RMS voltage and current with an acceptable accuracy. On conjugacy of Smale homeomorphisms Given closed topological $n$-manifold $M^n$, $n\geq 2$, one introduces the classes of Smale regular $SRH(M^n)$ and Smale semi-regular $SsRH(M^n)$ homeomorphisms of $M^n$ with $SRH(M^n)\subset~SsRH(M^n)$. The class $SRH(M^n)$ contains all Morse-Smale diffeomorphisms, while $SsRH(M^n)$ contains A-diffeomorphisms with trivial and some nontrivial basic sets provided $M^n$ admits a smooth structure. We select invariant sets that determine dynamics of Smale homeomorphisms. This allows us to get necessary and sufficient conditions of conjugacy for $SRH(M^n)$ and $SsRH(M^n)$. We deduce applications for some Morse-Smale diffeomorphisms and A-diffeomorphisms with codimension one expanding attractors. Fast mean-reversion asymptotics for large portfolios of stochastic volatility models We consider an SPDE description of a large portfolio limit model where the underlying asset prices evolve according to certain stochastic volatility models with default upon hitting a lower barrier. The asset prices and their volatilities are correlated via systemic Brownian motions, and the resulting SPDE is defined on the positive half-space with Dirichlet boundary conditions. We study the convergence of the loss from the system, a function of the total mass of a solution to this stochastic initial-boundary value problem under fast mean reversion of the volatility. We consider two cases. In the first case the volatility converges to a limiting distribution and the convergence of the system is in the sense of weak convergence. On the other hand, when only the mean reversion of the volatility goes to infinity we see a stronger form of convergence of the system to its limit. Our results show that in a fast mean-reverting volatility environment we can accurately estimate the distribution of the loss from a large portfolio by using an approximate constant volatility model which is easier to handle. Quantizing Euclidean motions via double-coset decomposition Concepts from mathematical crystallography and group theory are used here to quantize the group of rigid-body motions, resulting in a "motion alphabet" with which to express robot motion primitives. From these primitives it is possible to develop a dictionary of physical actions. Equipped with an alphabet of the sort developed here, intelligent actions of robots in the world can be approximated with finite sequences of characters, thereby forming the foundation of a language in which to articulate robot motion. In particular, we use the discrete handedness-preserving symmetries of macromolecular crystals (known in mathematical crystallography as Sohncke space groups) to form a coarse discretization of the space $\rm{SE}(3)$ of rigid-body motions. This discretization is made finer by subdividing using the concept of double-coset decomposition. More specifically, a very efficient, equivolumetric quantization of spatial motion can be defined using the group-theoretic concept of a double-coset decomposition of the form $\Gamma \backslash \rm{SE}(3) / \Delta$, where $\Gamma$ is a Sohncke space group and $\Delta$ is a finite group of rotational symmetries such as those of the icosahedron. The resulting discrete alphabet is based on a very uniform sampling of $\rm{SE}(3)$ and is a tool for describing the continuous trajectories of robots and humans. The general "signals to symbols" problem in artificial intelligence is cast in this framework for robots moving continuously in the world, and we present a coarse-to-fine search scheme here to efficiently solve this decoding problem in practice. Novel Quality Metric for Duration Variability Compensation in Speaker Verification using i-Vectors Automatic speaker verification (ASV) is the process to recognize persons using voice as biometric. The ASV systems show considerable recognition performance with sufficient amount of speech from matched condition. One of the crucial challenges of ASV technology is to improve recognition performance with speech segments of short duration. In short duration condition, the model parameters are not properly estimated due to inadequate speech information, and this results poor recognition accuracy even with the state-of-the-art i-vector based ASV system. We hypothesize that considering the estimation quality during recognition process would help to improve the ASV performance. This can be incorporated as a quality measure during fusion of ASV systems. This paper investigates a new quality measure for i-vector representation of speech utterances computed directly from Baum-Welch statistics. The proposed metric is subsequently used as quality measure during fusion of ASV systems. In experiments with the NIST SRE 2008 corpus, We have shown that inclusion of proposed quality metric exhibits considerable improvement in speaker verification performance. The results also indicate the potentiality of the proposed method in real-world scenario with short test utterances. SFQmap: A Technology Mapping Tool for Single Flux Quantum Logic Circuits Single flux quantum (SFQ) logic is a promising candidate to replace the CMOS logic for high speed and low power applications due to its superiority in providing high performance and energy efficient circuits. However, developing effective Electronic Design Automation (EDA) tools, which cater to special characteristics and requirements of SFQ circuits such as depth minimization and path balancing, are essential to automate the whole process of designing large SFQ circuits. In this paper, a novel technology mapping tool, called SFQmap, is presented, which provides optimization methods for minimizing first the circuit depth and path balancing overhead and then the worst-case stage delay of mapped SFQ circuits. Compared with the state-of-the-art technology mappers, SFQmap reduces the depth and path balancing overhead by an average of 14% and 31%, respectively. On the relevance of Reynolds stresses in resolvent analyses of turbulent wall-bounded flows The ability of linear stochastic response analysis to estimate coherent motions is investigated in turbulent channel flow at friction Reynolds number Re$_\tau$ = 1007. The analysis is performed for spatial scales characteristic of buffer-layer and large-scale motions by separating the contributions of different temporal frequencies. Good agreement between the measured spatio-temporal power spectral densities and those estimated by means of the resolvent is found when the effect of turbulent Reynolds stresses, modelled with an eddy-viscosity associated to the turbulent mean flow, is included in the resolvent operator. The agreement is further improved when the flat forcing power spectrum (white noise) is replaced with a power spectrum matching the measures. Such a good agreement is not observed when the eddy-viscosity terms are not included in the resolvent operator. In this case, the estimation based on the resolvent is unable to select the right peak frequency and wall-normal location of buffer-layer motions. Similar results are found when comparing truncated expansions of measured streamwise velocity power spectral densities based on a spectral proper orthogonal decomposition to those obtained with optimal resolvent modes. Stein Variational Online Changepoint Detection with Applications to Hawkes Processes and Neural Networks Bayesian online changepoint detection (BOCPD) (Adams & MacKay, 2007) offers a rigorous and viable way to identify changepoints in complex systems. In this work, we introduce a Stein variational online changepoint detection (SVOCD) method to provide a computationally tractable generalization of BOCPD beyond the exponential family of probability distributions. We integrate the recently developed Stein variational Newton (SVN) method (Detommaso et al., 2018) and BOCPD to offer a full online Bayesian treatment for a large number of situations with significant importance in practice. We apply the resulting method to two challenging and novel applications: Hawkes processes and long short-term memory (LSTM) neural networks. In both cases, we successfully demonstrate the efficacy of our method on real data.
Semi-Supervised Learning Detector for MU-MIMO Systems with One-bit ADCs We study an uplink multiuser multiple-input multiple-output (MU-MIMO) system with one-bit analog-to-digital converters (ADCs). For such system, a supervised-learning (SL) detector has been recently proposed by modeling a non-linear end-to-end system function into a parameterized Bernoulli-like model. Despite its attractive performance, the SL detector requires a large amount of labeled data (i.e., pilot signals) to estimate the parameters of the underlying model accurately. This is because the amount of the parameters grows exponentially with the number of users. To overcome this drawback, we propose a semi-supervised learning (SSL) detector where both pilot signals (i.e., labeled data) and some part of data signals (i.e., unlabeled data) are used to estimate the parameters via expectation-maximization (EM) algorithm. Via simulation results, we demonstrate that the proposed SSL detector can achieve the performance of the existing SL detector with significantly lower pilot-overhead. Security and Privacy Preserving Data Aggregation in Cloud Computing Smart metering is an essential feature of smart grids, allowing residential customers to monitor and reduce electricity costs. Devices called smart meters allows residential customers to monitor and reduce electricity costs, promoting energy saving, demand management, and energy efficiency. However, monitoring a households' energy consumption through smart meters poses serious privacy threats, and have thus become a major privacy issue. Hence, a significant amount of research has appeared recently with the purpose of providing methods and mechanisms to reconcile smart metering technologies and privacy requirements. However, most current approaches fall short in meeting one of several of the requirements for privacy preserving smart metering systems. In this paper we show how Intel SGX technology can be used to provide a simple and general solution for the smart metering privacy problem that meets all these requirements in a satisfactory way. Moreover, we present also an implementation of the proposed architecture as well as a series of experiments that have been carried out in order to assess how the proposed solution performs in comparison to a second implementation of the architecture that completely disregards privacy issues. A new lower bound on the maximum number of plane graphs using production matrices We use the concept of production matrices to show that there exist sets of $n$ points in the plane that admit $\Omega(42.11^n)$ crossing-free geometric graphs. This improves the previously best known bound of $\Omega(41.18^n)$ by Aichholzer et al. (2007). Variational Graph Methods for Efficient Point Cloud Sparsification In recent years new application areas have emerged in which one aims to capture the geometry of objects by means of three-dimensional point clouds. Often the obtained data consist of a dense sampling of the object's surface, containing many redundant 3D points. These unnecessary data samples lead to high computational effort in subsequent processing steps. Thus, point cloud sparsification or compression is often applied as a preprocessing step. The two standard methods to compress dense 3D point clouds are random subsampling and approximation schemes based on hierarchical tree structures, e.g., octree representations. However, both approaches give little flexibility for adjusting point cloud compression based on a-priori knowledge on the geometry of the scanned object. Furthermore, these methods lead to suboptimal approximations if the 3D point cloud data is prone to noise. In this paper we propose a variational method defined on finite weighted graphs, which allows to sparsify a given 3D point cloud while giving the flexibility to control the appearance of the resulting approximation based on the chosen regularization functional. The main contribution in this paper is a novel coarse-to-fine optimization scheme for point cloud sparsification, inspired by the efficiency of the recently proposed Cut Pursuit algorithm for total variation denoising. This strategy gives a substantial speed up in computing sparse point clouds compared to a direct application on all points as done in previous works and renders variational methods now applicable for this task. We compare different settings for our point cloud sparsification method both on unperturbed as well as noisy 3D point cloud data. Conformal Gauss Map Geometry and Application to Willmore Surfaces in Model Spaces In this paper we make a detailed and self-contained study of the conformalGauss map. Then, starting from the seminal work of R. Bryant and the notion of conformal Gauss map, we recover many fundamental properties of Willmore surfaces. We also get new results like some characterizations of minimal and constant meancurvature (CMC) surfaces in term of their conformal Gauss map behavior. HD 213885b: A transiting 1-day-period super-Earth with an Earth-like composition around a bright ($V=7.9$) star unveiled by TESS We report the discovery of the 1.008-day, ultra-short period (USP) super-Earth HD 213885b (TOI-141b) orbiting the bright ($V=7.9$) star HD 213885 (TOI-141, TIC 403224672), detected using photometry from the recently launched TESS mission. Using FEROS, HARPS and CORALIE radial-velocities, we measure a precise mass of $8.8\pm0.6$ $M_\oplus$ for this $1.74 \pm 0.05$ $R_\oplus$ exoplanet, which provides enough information to constrain its bulk composition, which is similar to Earth's but enriched in iron. The radius, mass and stellar irradiation of HD 213885b are, given our data, very similar to 55 Cancri e, making this exoplanet a good target to perform comparative exoplanetology of short period, highly irradiated super-Earths. Our precise radial-velocities reveal an additional $4.78$-day signal which we interpret as arising from a second, non-transiting planet in the system, HD 213885c (TOI-141c), whose minimum mass of $19.95\pm 1.4$ $M_\oplus$ makes it consistent with being a Neptune-mass exoplanet. The HD 213885 system is very interesting from the perspective of future atmospheric characterization, being the second brightest star to host an ultra-short period transiting super-Earth (with the brightest star being, in fact, 55 Cancri). Prospects for characterization with present and future observatories are discussed. Entropy Bounds on Effective Field Theory from Rotating Dyonic Black Holes We derive new bounds on higher-dimension operator coefficients in four-dimensional Einstein-Maxwell theory. Positivity of classically-generated corrections to the Wald entropy of thermodynamically stable, rotating dyonic black holes implies a multiparameter family of field basis invariant inequalities that exhibit electromagnetic duality and are satisfied by examples from field and string theory. These bounds imply that effective operators modify the extremality condition of large black holes so as to permit their decay to smaller ones, thus satisfying the weak gravity conjecture. Dynamic Anapole in Metasurfaces made of Sculptured Cylinders We present all-dielectric polaritonic metasurfaces consisting of properly sculptured cylinders to sustain the dynamic anapole, i.e. a non-radiating alternating current distribution. One way for the anapole to emerge, is by combining modes based on the first and the fourth Mie resonance of a cylinder made of high permittivity LiTaO$_3$ for operation in the low THz. The circular cross-section of each cylinder varies periodically along its length in a binary way, from small to large, while its overall circular symmetry has to be broken in order to remove parasitic magnetic modes. Small cross-sections are the main source of the \textit{electric dipole} Mie mode, while large cross-sections sustain the fourth, \textit{mixed toroidal dipole} Mie mode. With proper adjustment, the generated electric and toroidal moments interfere destructively producing a non-radiating source, the dynamic anapole, the existence of which is attested by a sharp dip in the reflection from the metasurface, due exclusively to electric and toroidal dipoles.
Moreover, we show that, by breaking the circular symmetry of each cylinder, a substantial toroidal dipole emerges from the \textit{magnetic quadrupole} Mie mode, which in combination with the electric dipole also produces the dynamic anapole. The sensitivity of the anapole states to the material dissipation losses is examined leading to the conclusion that the proposed metasurfaces offer a scheme for realistically implementing the anapole. Sound texture synthesis using convolutional neural networks The following article introduces a new parametric synthesis algorithm for sound textures inspired by existing methods used for visual textures. Using a 2D Convolutional Neural Network (CNN), a sound signal is modified until the temporal cross-correlations of the feature maps of its log-spectrogram resemble those of a target texture. We show that the resulting synthesized sound signal is both different from the original and of high quality, while being able to reproduce singular events appearing in the original. This process is performed in the time domain, discarding the harmful phase recovery step which usually concludes synthesis performed in the time-frequency domain. It is also straightforward and flexible, as it does not require any fine tuning between several losses when synthesizing diverse sound textures. A way of extending the synthesis in order to produce a sound of any length is also presented, after which synthesized spectrograms and sound signals are showcased. We also discuss on the choice of CNN, on border effects in our synthesized signals and on possible ways of modifying the algorithm in order to improve its current long computation time. Texture Fields: Learning Texture Representations in Function Space In recent years, substantial progress has been achieved in learning-based reconstruction of 3D objects. At the same time, generative models were proposed that can generate highly realistic images. However, despite this success in these closely related tasks, texture reconstruction of 3D objects has received little attention from the research community and state-of-the-art methods are either limited to comparably low resolution or constrained experimental setups. A major reason for these limitations is that common representations of texture are inefficient or hard to interface for modern deep learning techniques. In this paper, we propose Texture Fields, a novel texture representation which is based on regressing a continuous 3D function parameterized with a neural network. Our approach circumvents limiting factors like shape discretization and parameterization, as the proposed texture representation is independent of the shape representation of the 3D object. We show that Texture Fields are able to represent high frequency texture and naturally blend with modern deep learning techniques. Experimentally, we find that Texture Fields compare favorably to state-of-the-art methods for conditional texture reconstruction of 3D objects and enable learning of probabilistic generative models for texturing unseen 3D models. We believe that Texture Fields will become an important building block for the next generation of generative 3D models. Cosmic Inference: Constraining Parameters With Observations and Highly Limited Number of Simulations Cosmological probes pose an inverse problem where the measurement result is obtained through observations, and the objective is to infer values of model parameters which characterize the underlying physical system -- our Universe. Modern cosmological probes increasingly rely on measurements of the small-scale structure, and the only way to accurately model physical behavior on those scales, roughly 65 Mpc/h or smaller, is via expensive numerical simulations. In this paper, we provide a detailed description of a novel statistical framework for obtaining accurate parameter constraints by combining observations with a very limited number of cosmological simulations. The proposed framework utilizes multi-output Gaussian process emulators that are adaptively constructed using Bayesian optimization methods. We compare several approaches for constructing multi-output emulators that enable us to take possible inter-output correlations into account while maintaining the efficiency needed for inference. Using Lyman alpha forest flux power spectrum, we demonstrate that our adaptive approach requires considerably fewer --- by a factor of a few in Lyman alpha P(k) case considered here --- simulations compared to the emulation based on Latin hypercube sampling, and that the method is more robust in reconstructing parameters and their Bayesian credible intervals. Algebraic Statistics in Practice: Applications to Networks Algebraic statistics uses tools from algebra (especially from multilinear algebra, commutative algebra and computational algebra), geometry and combinatorics to provide insight into knotty problems in mathematical statistics. In this survey we illustrate this on three problems related to networks, namely network models for relational data, causal structure discovery and phylogenetics. For each problem we give an overview of recent results in algebraic statistics with emphasis on the statistical achievements made possible by these tools and their practical relevance for applications to other scientific disciplines. On the Approximability of Presidential Type Predicates Given a predicate $P: \{-1, 1\}^k \to \{-1, 1\}$, let $CSP(P)$ be the set of constraint satisfaction problems whose constraints are of the form $P$. We say that $P$ is approximable if given a nearly satisfiable instance of $CSP(P)$, there exists a probabilistic polynomial time algorithm that does better than a random assignment. Otherwise, we say that $P$ is approximation resistant. In this paper, we analyze presidential type predicates, which are balanced linear threshold functions where all of the variables except the first variable (the president) have the same weight. We show that almost all presidential-type predicates $P$ are approximable. More precisely, we prove the following result: for any $\delta_0 > 0$, there exists a $k_0$ such that if $k \geq k_0$, $\delta \in (\delta_0,1 - 2/k]$, and ${\delta}k + k - 1$ is an odd integer then the presidential type predicate $P(x) = sign({\delta}k{x_1} + \sum_{i=2}^{k}{x_i})$ is approximable. To prove this, we construct a rounding scheme that makes use of biases and pairwise biases. We also give evidence that using pairwise biases is necessary for such rounding schemes. Approaching the Kosterlitz-Thouless transition for the classical XY model with tensor networks We apply variational tensor-network methods for simulating the Kosterlitz-Thouless phase transition in the classical two-dimensional XY model. In particular, using uniform matrix product states (MPS) with non-abelian O(2) symmetry, we compute the universal drop in the spin stiffness at the critical point. In the critical low-temperature regime, we focus on the MPS entanglement spectrum to characterize the Luttinger-liquid phase. In the high-temperature phase, we confirm the exponential divergence of the correlation length and estimate the critical temperature with high precision. Our MPS approach can be used to study generic two-dimensional phase transitions with continuous symmetries. Distributed Deep Learning for Precipitation Nowcasting Effective training of Deep Neural Networks requires massive amounts of data and compute. As a result, longer times are needed to train complex models requiring large datasets, which can severely limit research on model development and the exploitation of all available data. In this paper, this problem is investigated in the context of precipitation nowcasting, a term used to describe highly detailed short-term forecasts of precipitation and other hazardous weather. Convolutional Neural Networks (CNNs) are a powerful class of models that are well-suited for this task; however, the high resolution input weather imagery combined with model complexity required to process this data makes training CNNs to solve this task time consuming. To address this issue, a data-parallel model is implemented where a CNN is replicated across multiple compute nodes and the training batches are distributed across multiple nodes. By leveraging multiple GPUs, we show that the training time for a given nowcasting model architecture can be reduced from 59 hours to just over 1 hour. This will allow for faster iterations for improving CNN architectures and will facilitate future advancement in the area of nowcasting. Getting Gender Right in Neural Machine Translation Speakers of different languages must attend to and encode strikingly different aspects of the world in order to use their language correctly (Sapir, 1921; Slobin, 1996). One such difference is related to the way gender is expressed in a language. Saying "I am happy" in English, does not encode any additional knowledge of the speaker that uttered the sentence.
However, many other languages do have grammatical gender systems and so such knowledge would be encoded. In order to correctly translate such a sentence into, say, French, the inherent gender information needs to be retained/recovered. The same sentence would become either "Je suis heureux", for a male speaker or "Je suis heureuse" for a female one. Apart from morphological agreement, demographic factors (gender, age, etc.) also influence our use of language in terms of word choices or even on the level of syntactic constructions (Tannen, 1991; Pennebaker et al., 2003). We integrate gender information into NMT systems. Our contribution is two-fold: (1) the compilation of large datasets with speaker information for 20 language pairs, and (2) a simple set of experiments that incorporate gender information into NMT for multiple language pairs. Our experiments show that adding a gender feature to an NMT system significantly improves the translation quality for some language pairs. Observing EeV neutrinos through the Earth: GZK and the anomalous ANITA events Tau neutrinos are unique cosmic messengers, especially at extreme energies. When they undergo a charged-current interaction, the short lifetime of the produced tau gives rise to secondary tau neutrinos that carry a significant fraction of the primary neutrino energy. This effect, known as tau neutrino regeneration, has not been applied to its full potential in current generation neutrino experiments. In this work, we present an updated calculation of tau neutrino regeneration, and explore its implications for two scenarios: the recent anomalous ANITA events and the cosmogenic neutrino flux. For the former, we investigate the idea of localized emission and find that the maximum secondary neutrino flux allowed by IceCube measurements implies a primary flux that is incompatible with the ANITA observation, regardless of the assumed source energy spectrum. For the latter, we study the prospect of detecting the cosmogenic neutrino flux of regenerated PeV neutrinos with current and next generation neutrino detectors. Linear Stability of Katabatic Slope Flows with Ambient Wind Forcing We investigate the stability of katabatic slope flows over an infinitely wide and uniformly cooled planar surface subject to an additional forcing due to a uniform downslope wind field aloft. We adopt an extension of Prandtl's original model for slope flows (Lykosov & Gutman 1972) to derive the base flow, which constitutes an interesting basic state in stability analysis because it cannot be reduced to a single universal form independent of external parameters. We apply a linear modal analysis to this basic state to demonstrate that for a fixed Prandtl number and slope angle, two independent dimensionless parameters are sufficient to describe the flow stability. One of these parameters is the stratification perturbation number that we have introduced in Xiao & Senocak (2019). The second parameter, which we will henceforth designate the wind forcing number, is hitherto uncharted and can be interpreted as the ratio of the kinetic energy of the ambient wind aloft to the damping due to viscosity and stabilizing effect of the background stratification. For a fixed Prandtl number, stationary transverse and travelling longitudinal modes of instabilities can emerge, depending on the value of the slope angle and the aforementioned dimensionless numbers. The influence of ambient wind forcing on the base flow's stability is complicated as the ambient wind can be both stabilizing as well as destabilizing for a certain range of the parameters. Our results constitute a strong counter-evidence against the current practice of relying solely on the gradient Richardson number to describe the dynamic stability of stratified atmospheric slope flows. Constraint on the fifth force through perihelion precession of planets The equivalence principle is important in fundamental physics. The fifth force, as a describing formalism of the equivalence principle, may indicate the property of an unknown theory. Dark matter is one of the most mysterious objects in the current natural science. It is interesting to constrain the fifth force of dark matter. We propose a new method to use perihelion precession of planets to constrain the long-range fifth force of dark matter. Due to the high accuracy of perihelion precession observation, and the large difference of matter composition between the Sun and planets, we get one of the strongest constraints on the fifth force of dark matter. In the near future, the BepiColombo mission will be capable to improve the test by another factor of ten. Intertwined magnetic, structural, and electronic transitions in V$_2$O$_3$ We present a coordinated study of the paramagnetic-to-antiferromagnetic, rhombohedral-to-monoclinic, and metal-to-insulator transitions in thin-film specimens of the classic Mott insulator V$_2$O$_3$ using low-energy muon spin relaxation, x-ray diffraction, and nanoscale-resolved near-field infrared spectroscopic techniques. The measurements provide a detailed characterization of the thermal evolution of the magnetic, structural, and electronic phase transitions occurring in a wide temperature range, including quantitative measurements of the high- and low-temperature phase fractions for each transition. The results reveal a stable coexistence of the high- and low-temperature phases over a broad temperature range throughout the transition. Careful comparison of temperature dependence of the different measurements, calibrated by the resistance of the sample, demonstrates that the electronic, magnetic, and structural degrees of freedom remain tightly coupled to each other during the transition process. We also find evidence for antiferromagnetic fluctuations in the vicinity of the phase transition, highlighting the important role of the magnetic degree of freedom in the metal-insulator transition. Meta-Learning with Dynamic-Memory-Based Prototypical Network for Few-Shot Event Detection Event detection (ED), a sub-task of event extraction, involves identifying triggers and categorizing event mentions. Existing methods primarily rely upon supervised learning and require large-scale labeled event datasets which are unfortunately not readily available in many real-life applications. In this paper, we consider and reformulate the ED task with limited labeled data as a Few-Shot Learning problem. We propose a Dynamic-Memory-Based Prototypical Network (DMB-PN), which exploits Dynamic Memory Network (DMN) to not only learn better prototypes for event types, but also produce more robust sentence encodings for event mentions. Differing from vanilla prototypical networks simply computing event prototypes by averaging, which only consume event mentions once, our model is more robust and is capable of distilling contextual information from event mentions for multiple times due to the multi-hop mechanism of DMNs. The experiments show that DMB-PN not only deals with sample scarcity better than a series of baseline models but also performs more robustly when the variety of event types is relatively large and the instance quantity is extremely small. Tracking with wakefields in dielectric laser acceleration grating structures Due to the tiny apertures of dielectric laser acceleration grating structures within the range of the optical wavelength, wakefields limit the bunch charge for relativistic electrons to a few femtocoulomb. In this paper, we present a wakefield upgrade of our six-dimensional tracking scheme DLAtrack6D in order to analyze these limitations. Simulations with CST Studio Suite provide the wake functions to calculate the kicks within each tracking step. Scaling laws and the dependency of the wake on geometrical changes are calculated. The tracking with wakefields is applied to beam and structure parameters following recently performed and planned experiments. We compare the results to analytical models and identify intensity limits due to the transverse beam breakup and strong head-tail instability. Furthermore, we reconstruct phase advance spectrograms and use them to analyze possible stabilization mechanisms. Momentum transfer by linearised eddies in channel flows The presence and structure of an Orr-like inviscid mechanism is studied in fully developed, large-scale turbulent channel flow. Orr-like `bursts' are defined by the relation between the amplitude and local tilting angle of the wall-normal velocity perturbations, and extracted by means of wavelet-based filters. They span the shear-dominated region of the flow, and their sizes and lifespans are proportional to the distance from the wall in the logarithmic layer, forming a self-similar eddy hierarchy consistent with Townsend's attached-eddy model.
Except for their amplitude, which has to be determined nonlinearly, linearised transient growth represents their evolution reasonably well. Conditional analysis, based on wavelet-filtered and low-pass-filtered velocity fields, reveals that bursts of opposite sign pair side-by-side to form tilted quasi-streamwise rollers, which align along the streaks of the streamwise velocity with the right sign to reinforce them, and that they preferentially cluster along pre-existing streak inhomogeneities. On the other hand, temporal analysis shows that consecutive rollers do not form simultaneously, suggesting that they incrementally trigger each other. This picture is similar to that of the streak-vortex cycle of the buffer layer, and the properties of the bursts suggest that they are different manifestations of the well-known attached Q$_2$-Q$_4$ events of the Reynolds stress. AVOLAR. A high voltage generator for liquid argon time projection chambers Some of the main neutrino oscillation and dark matter experiments have chosen time projection chambers (TPC) filled with liquid argon (LAr) as their technology for the next generation of detectors. Because of its typical drift length of several meters, relatively large cathode voltages are desirable to provide a sizeable drift field. Current designs are based on feedthroughs with high voltages (HV) limited to several hundred kV. The present work proposes a novel method to produce higher voltages inside the detector. It is based on a Van de Graaff HV generator where the charge transporting belt is replaced by a cryogenic LAr flow. Negative charge is injected in liquid by means of a grounded sharp point facing a positive voltage electrode with a high speed LAr stream in between. The LAr flow transports the charge to the cathode through an electrically insulating pipe. In the cathode the charge is extracted with a metallic mesh. The LAr flux is driven by a cryogenic helium pump with unidirectional valves assuring a continuous flow. The LAr operational temperature is maintained by a pressurized liquid nitrogen deposit with automatic filling. The whole system is installed within a dewar container that will be filled with LAr reproducing the typical TPC conditions. This design has no mobile parts, so it is very robust and can be easily embedded within the structural support of a TPC cathode. A prototype of this HV generator has been constructed at CIEMAT (Madrid), and is currently being characterized. This R&D is presented and the preliminary results are discussed. Exploring crossmodal perceptual enhancement and integration in a sequence-reproducing task with cognitive priming Leveraging the perceptual phenomenon of crossmoal correspondence has been shown to facilitate peoples information processing and improves sensorimotor performance. However for goal-oriented interactive tasks, the question of how to enhance the perception of specific Crossmodal information, and how Crossmodal information integration takes place during interaction is still unclear. The present paper reports two experiments investigating these questions. In the first experiment, a cognitive priming technique was introduced as a way to enhance the perception of two Crossmodal stimuli, in two conditions respectively, and their effect on sensory-motor performance was observed. Based on the results, the second experiment combined the two Crossmodal stimuli in the same interfaces in a way that their correspondence congruency was mutually exclusive. The same priming techniques was applied as a manipulating factor to observe the Crossmodal integration process. Results showed that first, the Crossmodal integration during interaction can be enhanced by the priming technique, but the effect varies according to the combination of Crossmodal stimuli and the types of priming material. Moreover, peoples subjective evaluations towards priming types were in contradiction with their objective behavioural data. Second, when two Crossmodal sequences can be perceived simultaneously, results suggested different perceptual weights are possessed by different participants, and the perceptual enhancement effect was observed only on the dominant one, the pitch-elevation. Furthermore, the Crossmodal integration tended to be integrated in a selective manner without priming. These results contribute design implications for multisensory feedback and mindless computing. Energy Efficient Multicast Precoding for Multiuser Multibeam Satellite Communications Aiming at maximizing the energy efficiency (EE) of multicast multibeam satellite communications, we consider the precoding design under the total power and quality of service (QoS) constraints. Since the original EE maximization problem is nonconvex, it is sequentially converted into a concave-convex fractional programming problem by introducing some variables and using the first-order Taylor low bound approximation. Based on the Charnes-Cooper transformation, it is further converted into a convex problem. Then an iterative algorithm is presented to design the energy efficient precoding. To find feasible initialization points for the algorithm and ensure its convergence, another convex optimization problem with some nonnegative slack variables and a positive penalty parameter is iteratively solved. In particular, the algorithm is verified by the measured channel data of multibeam satellite communications. GarmentGAN: Photo-realistic Adversarial Fashion Transfer The garment transfer problem comprises two tasks: learning to separate a person's body (pose, shape, color) from their clothing (garment type, shape, style) and then generating new images of the wearer dressed in arbitrary garments. We present GarmentGAN, a new algorithm that performs image-based garment transfer through generative adversarial methods. The GarmentGAN framework allows users to virtually try-on items before purchase and generalizes to various apparel types. GarmentGAN requires as input only two images, namely, a picture of the target fashion item and an image containing the customer. The output is a synthetic image wherein the customer is wearing the target apparel. In order to make the generated image look photo-realistic, we employ the use of novel generative adversarial techniques. GarmentGAN improves on existing methods in the realism of generated imagery and solves various problems related to self-occlusions. Our proposed model incorporates additional information during training, utilizing both segmentation maps and body key-point information. We show qualitative and quantitative comparisons to several other networks to demonstrate the effectiveness of this technique. Photoluminescence dynamics in few-layer InSe We study the optical properties of thin flakes of InSe encapsulated in hBN. More specifically, we investigate the photoluminescence (PL) emission and its dependence on sample thickness and temperature. Through the analysis of the PL lineshape, we discuss the relative weights of the exciton and electron-hole contributions. Thereafter we investigate the PL dynamics. Two contributions are distinguishable at low temperature: direct bandgap electron-hole and defect-assisted recombination. The two recombination processes have lifetime of $\tau_1 \sim 8\;$ns and $\tau_2 \sim 100\;$ns, respectively. The relative weights of the direct bandgap and defect-assisted contributions show a strong layer dependence due to the direct-to-indirect bandgap crossover. Electron-hole PL lifetime is limited by population transfer to lower-energy states and no dependence on the number of layers was observed. The lifetime of the defect-assisted recombination gets longer for thinner samples. Finally, we show that the PL lifetime decreases at high temperatures as a consequence of more efficient non-radiative recombinations. TESS discovery of a super-Earth and three sub-Neptunes hosted by the bright, Sun-like star HD 108236 We report the discovery and validation of four extrasolar planets hosted by the nearby, bright, Sun-like (G3V) star HD~108236 using data from the Transiting Exoplanet Survey Satellite (TESS). We present transit photometry, reconnaissance and precise Doppler spectroscopy as well as high-resolution imaging, to validate the planetary nature of the objects transiting HD~108236, also known as the TESS Object of Interest (TOI) 1233. The innermost planet is a possibly-rocky super-Earth with a period of $3.79523_{-0.00044}^{+0.00047}$ days and has a radius of $1.586\pm0.098$ $R_\oplus$.
The outer planets are sub-Neptunes, with potential gaseous envelopes, having radii of $2.068_{-0.091}^{+0.10}$ $R_\oplus$, $2.72\pm0.11$ $R_\oplus$, and $3.12_{-0.12}^{+0.13}$ $R_\oplus$ and periods of $6.20370_{-0.00052}^{+0.00064}$ days, $14.17555_{-0.0011}^{+0.00099}$ days, and $19.5917_{-0.0020}^{+0.0022}$ days, respectively. With V and K$_{\rm s}$ magnitudes of 9.2 and 7.6, respectively, the bright host star makes the transiting planets favorable targets for mass measurements and, potentially, for atmospheric characterization via transmission spectroscopy. HD~108236 is the brightest Sun-like star in the visual (V) band known to host four or more transiting exoplanets. The discovered planets span a broad range of planetary radii and equilibrium temperatures, and share a common history of insolation from a Sun-like star ($R_\star = 0.888 \pm 0.017$ R$_\odot$, $T_{\rm eff} = 5730 \pm 50$ K), making HD 108236 an exciting, opportune cosmic laboratory for testing models of planet formation and evolution. Generating SOAP Notes from Doctor-Patient Conversations Using Modular Summarization Techniques Following each patient visit, physicians draft long semi-structured clinical summaries called SOAP notes. While invaluable to clinicians and researchers, creating digital SOAP notes is burdensome, contributing to physician burnout. In this paper, we introduce the first complete pipelines to leverage deep summarization models to generate these notes based on transcripts of conversations between physicians and patients. After exploring a spectrum of methods across the extractive-abstractive spectrum, we propose Cluster2Sent, an algorithm that (i) extracts important utterances relevant to each summary section; (ii) clusters together related utterances; and then (iii) generates one summary sentence per cluster. Cluster2Sent outperforms its purely abstractive counterpart by 8 ROUGE-1 points, and produces significantly more factual and coherent sentences as assessed by expert human evaluators. For reproducibility, we demonstrate similar benefits on the publicly available AMI dataset. Our results speak to the benefits of structuring summaries into sections and annotating supporting evidence when constructing summarization corpora. Focus Longer to See Better:Recursively Refined Attention for Fine-Grained Image Classification Deep Neural Network has shown great strides in the coarse-grained image classification task. It was in part due to its strong ability to extract discriminative feature representations from the images. However, the marginal visual difference between different classes in fine-grained images makes this very task harder. In this paper, we tried to focus on these marginal differences to extract more representative features. Similar to human vision, our network repetitively focuses on parts of images to spot small discriminative parts among the classes. Moreover, we show through interpretability techniques how our network focus changes from coarse to fine details. Through our experiments, we also show that a simple attention model can aggregate (weighted) these finer details to focus on the most dominant discriminative part of the image. Our network uses only image-level labels and does not need bounding box/part annotation information. Further, the simplicity of our network makes it an easy plug-n-play module. Apart from providing interpretability, our network boosts the performance (up to 2%) when compared to its baseline counterparts. Our codebase is available at https://github.com/TAMU-VITA/Focus-Longer-to-See-Better A Finite Element Method for Electrowetting on Dielectric We consider the problem of electrowetting on dielectric (EWoD). The system involves the dynamics of a conducting droplet, which is immersed in another dielectric fluid, on a dielectric substrate under an applied voltage. The fluid dynamics is modeled by the two-phase incompressible Navier-Stokes equations with the standard interface conditions, the Navier slip condition on the substrate, and a contact angle condition which relates the dynamic contact angle and the contact line velocity, as well as the kinematic condition for the evolution of the interface. The electric force acting on the fluid interface is modeled by Maxwell's equations in the domain occupied by the dielectric fluid and the dielectric substrate. We develop a numerical method for the model based on its weak form. This method combines the finite element method for the Navier-Stokes equations on a fixed bulk mesh with a parametric finite element method for the dynamics of the fluid interface, and the boundary integral method for the electric force along the fluid interface. Numerical examples are presented to demonstrate the accuracy and convergence of the numerical method, the effect of various physical parameters on the interface profile, and other interesting phenomena such as the transportation of droplet driven by the applied non-uniform electric potential difference. Simulating human interactions in supermarkets to measure the risk of COVID-19 contagion at scale Taking the context of simulating a retail environment using agent based modelling, a theoretical model is presented that describes the probability distribution of customer "collisions" using a novel space transformation to the Torus $Tor^2$. A method for generating the distribution of customer paths based on historical basket data is developed. Finally a calculation of the number of simulations required for statistical significance is developed. An implementation of this modelling approach to run simulations on multiple store geometries at industrial scale is being developed with current progress detailed in the technical appendix. Lower Bounds for Dynamic Distributed Task Allocation We study the problem of distributed task allocation in multi-agent systems. Suppose there is a collection of agents, a collection of tasks, and a demand vector, which specifies the number of agents required to perform each task. The goal of the agents is to cooperatively allocate themselves to the tasks to satisfy the demand vector. We study the dynamic version of the problem where the demand vector changes over time. Here, the goal is to minimize the switching cost, which is the number of agents that change tasks in response to a change in the demand vector. The switching cost is an important metric since changing tasks may incur significant overhead. We study a mathematical formalization of the above problem introduced by Su, Su, Dornhaus, and Lynch, which can be reformulated as a question of finding a low distortion embedding from symmetric difference to Hamming distance. In this model it is trivial to prove that the switching cost is at least 2. We present the first non-trivial lower bounds for the switching cost, by giving lower bounds of 3 and 4 for different ranges of the parameters. Cryptanalysis of Quantum Secure Direct Communication Protocol with Mutual Authentication Based on Single Photons and Bell States Recently, Yan et al. proposed a quantum secure direct communication (QSDC) protocol with authentication using single photons and Einstein-Podolsky-Rosen (EPR) pairs (Yan et al., CMC-Computers, Materials \& Continua, 63(3), 2020). In this work, we show that the QSDC protocol is not secure against intercept-and-resend attack and impersonation attack. An eavesdropper can get the full secret message by applying these attacks. We propose a modification of this protocol, which defeats the above attacks along with all the familiar attacks. Learning Part Boundaries from 3D Point Clouds We present a method that detects boundaries of parts in 3D shapes represented as point clouds. Our method is based on a graph convolutional network architecture that outputs a probability for a point to lie in an area that separates two or more parts in a 3D shape. Our boundary detector is quite generic: it can be trained to localize boundaries of semantic parts or geometric primitives commonly used in 3D modeling. Our experiments demonstrate that our method can extract more accurate boundaries that are closer to ground-truth ones compared to alternatives. We also demonstrate an application of our network to fine-grained semantic shape segmentation, where we also show improvements in terms of part labeling performance.
Understanding the dynamics emerging from infodemics: A call to action for interdisciplinary research Research on infodemics, i.e., the rapid spread of (mis)information related to a hazardous event, such as the COVID-19 pandemic, requires the integration of a multiplicity of scientific disciplines. The dynamics emerging from infodemics have the potential to generate complex behavioral patterns. In order to react appropriately, it is of ultimate importance for the fields of Business and Economics to understand the dynamics emerging from it. In the short run, dynamics might lead to an adaptation in household spending or to a shift in buying behavior towards online providers. In the long run, changes in investments, consumer behavior, and markets are to be expected. We argue that the dynamics emerge from complex interactions among multiple factors, such as information and misinformation accessible for individuals and the formation and revision of beliefs. (Mis)information accessible to individuals is, amongst others, affected by algorithms specifically designed to provide personalized information, while automated fact-checking algorithms can help reduce the amount of circulating misinformation. The formation and revision of individual (and probably false) beliefs and individual fact-checking and interpretation of information are heavily affected by linguistic patterns inherent to information during pandemics and infodemics and further factors, such as affect, intuition and motives. We argue that, in order to get a deep(er) understanding of the dynamics emerging from infodemics, the fields of Business and Economics should integrate the perspectives of Computer Science and Information Systems, (Computational) Linguistics, and Cognitive Science into the wider context of economic systems (e.g., organizations, markets or industries) and propose a way to do so. Broad Band Single Germanium Nanowire Photodetectors with Surface Oxide Controlled High Optical Gain We have investigated photoconductive properties of single Germanium Nanowires(NWs)of diameter less than 100 nm in the spectral range of 300 to 1100 nm showing ultra large peak Responsivity in excess of 10^{7}AW^{-1}.The NWs were grown by Vapor Liquid Solid method using Au nanoparticle as catalyst. In this report we discuss the likely origin of the ultra large responsivity that may arise from a combination of various physical effects which are a): Ge and GeO_{x} interface states which act as scavengers of electrons from the photo-generated pairs,leaving the holes free to reach the electrodes,b) Schottky barrier at the metal and NW interface which gets lowered substantially due to carrier diffusion in contact region and (c) photodetector length being small (approximately few {\mu}m), negligible loss of photogenerated carriers due to recombination at defect sites. We have observed from power dependence of the optical gain that the gain is controlled by trap states. We find that the surface of the nanowire has presence of a thin layer of GeO_{x} (as evidenced from HRTEM study) which provide interface states. It is observed that these state play a crucial role to provide a radial field for separation of photogenerated electron and hole pair which in turn leads to very high effective photoconductive gain that reaches a very high at low illumination density. On the Stampfli point of some operators and matrices The center of mass of an operator $A$ (denoted St($A$), and called in this paper as the {\em Stampfli point} of A) was introduced by Stampfli in his Pacific J. Math (1970) paper as the unique $\lambda\in\mathbb C$ delivering the minimum value of the norm of $A-\lambda I$. We derive some results concerning the location of St($A$) for several classes of operators, including 2-by-2 block operator matrices with scalar diagonal blocks and 3-by-3 matrices with repeated eigenvalues. We also show that for almost normal $A$ its Stampfli point lies in the convex hull of the spectrum, which is not the case in general. Some relations between the property St($A$)=0 and Roberts orthogonality of $A$ to the identity operator are established. Retrofitting Vector Representations of Adverse Event Reporting Data to Structured Knowledge to Improve Pharmacovigilance Signal Detection Adverse drug events (ADE) are prevalent and costly. Clinical trials are constrained in their ability to identify potential ADEs, motivating the development of spontaneous reporting systems for post-market surveillance. Statistical methods provide a convenient way to detect signals from these reports but have limitations in leveraging relationships between drugs and ADEs given their discrete count-based nature. A previously proposed method, aer2vec, generates distributed vector representations of ADE report entities that capture patterns of similarity but cannot utilize lexical knowledge. We address this limitation by retrofitting aer2vec drug embeddings to knowledge from RxNorm and developing a novel retrofitting variant using vector rescaling to preserve magnitude. When evaluated in the context of a pharmacovigilance signal detection task, aer2vec with retrofitting consistently outperforms disproportionality metrics when trained on minimally preprocessed data. Retrofitting with rescaling results in further improvements in the larger and more challenging of two pharmacovigilance reference sets used for evaluation. SENSEI: Aligning Video Streaming Quality with Dynamic User Sensitivity This paper aims to improve video streaming by leveraging a simple observation: users are more sensitive to low quality in certain parts of a video than in others. For instance, rebuffering during key moments of a sports video (e.g., before a goal is scored) is more annoying than rebuffering during normal gameplay. Such dynamic quality sensitivity, however, is rarely captured by current approaches, which predict QoE (quality-of-experience) using one-size-fits-all heuristics that are too simplistic to understand the nuances of video content. Instead of proposing yet another heuristic, we take a different approach: we run a separate crowdsourcing experiment for each video to derive users' quality sensitivity at different parts of the video. Of course, the cost of doing this at scale can be prohibitive, but we show that careful experiment design combined with a suite of pruning techniques can make the cost negligible compared to how much content providers invest in content generation and distribution. Our ability to accurately profile time-varying user sensitivity inspires a new approach: dynamically aligning higher (lower) quality with higher (lower) sensitivity periods. We present a new video streaming system called SENSEI that incorporates dynamic quality sensitivity into existing quality adaptation algorithms. We apply SENSEI to two state-of-the-art adaptation algorithms. SENSEI can take seemingly unusual actions: e.g., lowering bitrate (or initiating a rebuffering event) even when bandwidth is sufficient so that it can maintain a higher bitrate without rebuffering when quality sensitivity becomes higher in the near future. Compared to state-of-the-art approaches, SENSEI improves QoE by 15.1% or achieves the same QoE with 26.8% less bandwidth on average. Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS We prove that the reproducing kernel Hilbert spaces (RKHS) of a deep neural tangent kernel and the Laplace kernel include the same set of functions, when both kernels are restricted to the sphere $\mathbb{S}^{d-1}$. Additionally, we prove that the exponential power kernel with a smaller power (making the kernel less smooth) leads to a larger RKHS, when it is restricted to the sphere $\mathbb{S}^{d-1}$ and when it is defined on the entire $\mathbb{R}^d$. RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2 Visual Field Data based on Retinal Structure Glaucoma is the leading cause of irreversible blindness in the world, affecting over 70 million people. The cumbersome Standard Automated Perimetry (SAP) test is most frequently used to detect visual loss due to glaucoma. Due to the SAP test's innate difficulty and its high test-retest variability, we propose the RetiNerveNet, a deep convolutional recursive neural network for obtaining estimates of the SAP visual field.
RetiNerveNet uses information from the more objective Spectral-Domain Optical Coherence Tomography (SDOCT). RetiNerveNet attempts to trace-back the arcuate convergence of the retinal nerve fibers, starting from the Retinal Nerve Fiber Layer (RNFL) thickness around the optic disc, to estimate individual age-corrected 24-2 SAP values. Recursive passes through the proposed network sequentially yield estimates of the visual locations progressively farther from the optic disc. While all the methods used for our experiments exhibit lower performance for the advanced disease group, the proposed network is observed to be more accurate than all the baselines for estimating the individual visual field values. We further augment RetiNerveNet to additionally predict the SAP Mean Deviation values and also create an ensemble of RetiNerveNets that further improves the performance, by increasingly weighting-up underrepresented parts of the training data. Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration In this paper, we introduce Watch-And-Help (WAH), a challenge for testing social intelligence in agents. In WAH, an AI agent needs to help a human-like agent perform a complex household task efficiently. To succeed, the AI agent needs to i) understand the underlying goal of the task by watching a single demonstration of the human-like agent performing the same task (social perception), and ii) coordinate with the human-like agent to solve the task in an unseen environment as fast as possible (human-AI collaboration). For this challenge, we build VirtualHome-Social, a multi-agent household environment, and provide a benchmark including both planning and learning based baselines. We evaluate the performance of AI agents with the human-like agent as well as with real humans using objective metrics and subjective user ratings. Experimental results demonstrate that the proposed challenge and virtual environment enable a systematic evaluation on the important aspects of machine social intelligence at scale. Performance Analysis of Cell-Free Massive MIMO Systems: A Stochastic Geometry Approach Cell-free (CF) massive multiple-input-multiple-output (MIMO) has emerged as an alternative deployment for conventional cellular massive MIMO networks. Prior works relied on the strong assumption (quite idealized) that the APs are uniformly distributed, and actually, this randomness was considered during the simulation and not in the analysis. However, in practice, ongoing and future networks become denser and increasingly irregular. Having this in mind, we consider that the AP locations are modeled by means of a Poisson point process (PPP) which is a more realistic model for the spatial randomness than a grid or uniform deployment. In particular, by virtue of stochastic geometry tools, we derive both the downlink coverage probability and achievable rate. Notably, this is the only work providing the coverage probability and shedding light on this aspect of CF massive MIMO systems. Focusing on the extraction of interesting insights, we consider small-cells (SCs) as a benchmark for comparison. Among the findings, CF massive MIMO systems achieve both higher coverage and rate with comparison to SCs due to the properties of favorable propagation, channel hardening, and interference suppression. Especially, we showed for both architectures that increasing the AP density results in a higher coverage which saturates after a certain value and increasing the number of users decreases the achievable rate but CF massive MIMO systems take advantage of the aforementioned properties, and thus, outperform SCs. In general, the performance gap between CF massive MIMO systems and SCs is enhanced by increasing the AP density. Another interesting observation concerns that a higher path-loss exponent decreases the rate while the users closer to the APs affect more the performance in terms of the rate. A Bregman Method for Structure Learning on Sparse Directed Acyclic Graphs We develop a Bregman proximal gradient method for structure learning on linear structural causal models. While the problem is non-convex, has high curvature and is in fact NP-hard, Bregman gradient methods allow us to neutralize at least part of the impact of curvature by measuring smoothness against a highly nonlinear kernel. This allows the method to make longer steps and significantly improves convergence. Each iteration requires solving a Bregman proximal step which is convex and efficiently solvable for our particular choice of kernel. We test our method on various synthetic and real data sets. Dense matter equation of state of a massive neutron star with anti-kaon condensation Recent measurements of neutron star mass from several candidates (PSR J$1614-2230$, PSR J$0348+0432$, MSP J$0740+6620$) set the lower bound on the maximum possible mass for this class of compact objects $\sim 2$ M$_\odot$. Existence of stars with high mass brings the possibility of existence of exotic matter (hyperons, meson condensates) at the core region of the objects. In this work, we investigate the (anti)kaon ($K^-, \bar{K}^0$) condensation in $\beta-$equilibrated nuclear matter within the framework of covariant density functional theory. The functionals in the kaonic sector are constrained by the experimental studies on $K^-$ atomic, kaon-nucleon scattering data fits. We find that the equation of state softens with the inclusion of (anti)kaon condensates, which lowers the maximum mass of neutron star. In one of the density-independent coupling cases, the $K^-$ condensation is through a first-order phase transition type, which produces a $2$ M$_\odot$ neutron star. The first-order phase transition results in mixed phase region in the inner core of the stars. While $\bar{K}^0$ condensation appears via second-order phase transition for all the models we consider here. Theoretical Accuracy Analysis of RSS-Based Range Estimation for Visible Light Communication In this paper, an improved channel model of visible light communication (VLC) for ranging in presented. For indoor channel model of VLC, distance is estimated based on received signal strength. In this model, received shot noise as a distance-dependent parameter is considered in range estimation accuracy. Moreover, based on this model, the Cramer-Rao lower bound is computed as the theoretical limits on the performance and accuracy of any unbiased estimator. In this way, the effects of horizontal and vertical distances are investigated. In addition, the transmitted power effect on RSN and accordingly on CRLB is demonstrated. The combinatorics of normal subgroups in the unipotent upper triangular group Describing the conjugacy classes of the unipotent upper triangular groups $\mathrm{UT}_{n}(\mathbb{F}_{q})$ uniformly (for all or many values of $n$ and $q$) is a nearly impossible task. This paper takes on the related problem of describing the normal subgroups of $\mathrm{UT}_{n}(\mathbb{F}_{q})$. For $q$ a prime, a bijection will be established between these subgroups and pairs of combinatorial objects with labels from $\mathbb{F}_{q}^{\times}$. Each pair comprises a loopless binary matroid and a tight splice, an apparently new kind of combinatorial object which interpolates between nonnesting partitions and shortened polyominoes. For arbitrary $q$, the same approach describes a natural subset of normal subgroups: those which correspond to the ideals of the Lie algebra $\mathfrak{ut}_{n}(\mathbb{F}_{q})$ under an approximation of the exponential map. Domain Adaptation with Incomplete Target Domains Domain adaptation, as a task of reducing the annotation cost in a target domain by exploiting the existing labeled data in an auxiliary source domain, has received a lot of attention in the research community. However, the standard domain adaptation has assumed perfectly observed data in both domains, while in real world applications the existence of missing data can be prevalent. In this paper, we tackle a more challenging domain adaptation scenario where one has an incomplete target domain with partially observed data. We propose an Incomplete Data Imputation based Adversarial Network (IDIAN) model to address this new domain adaptation challenge. In the proposed model, we design a data imputation module to fill the missing feature values based on the partial observations in the target domain, while aligning the two domains via deep adversarial adaption. We conduct experiments on both cross-domain benchmark tasks and a real world adaptation task with imperfect target domains.
The experimental results demonstrate the effectiveness of the proposed method. Evolution of shape and volume fraction of superconducting domains with temperature and anion disorder in (TMTSF)$_2$ClO$_4$ In highly anisotropic organic superconductor (TMTSF)$_2$ClO$_4$, superconducting (SC) phase coexists with metallic and spin density wave phases in the form of domains. Using the Maxwell-Garnett approximation (MGA), we calculate the volume ratio and estimate the shape of these embedded SC domains from resistivity data at various temperature and anion disorder, controlled by the cooling rate or annealing time of (TMTSF)$_{2}$ClO$_{4}$ samples. We found that the variation of cooling rate and of annealing time affect differently the shape of SC domains. In all cases the SC domains have oblate shape, being the shortest along the interlayer $z$-axis. This contradicts the widely assumed filamentary superconductivity along $z$-axis, used to explain the anisotropic superconductivity onset. We show that anisotropic resistivity drop at the SC transition can be described by the analytical MGA theory with anisotropic background resistance, while the anisotropic $T_c$ can be explained by considering a finite size and flat shape of the samples. Due to a flat/needle sample shape, the probability of percolation via SC domains is the highest along the shortest sample dimension ($z$-axis), and the lowest along the sample length ($x$-axis). Our theory can be applied to other heterogeneous superconductors, where the size $d$ of SC domains is much larger than the SC coherence length $\xi$, e.g. cuprates, iron based or organic superconductors. It is also applicable when the spin/charge-density wave domains are embedded inside a metallic background, or vice versa. On a Conjecture of Bahri-Xu In order to study the Yamabe changing-sign problem, Bahri and Xu proposed a conjecture which is a universal inequality for $p$ points in $\mathbb R^m$. They have verified the conjecture for $p\leq3$. In this paper, we first simplify this conjecture by giving two sufficient and necessary conditions inductively. Then we prove the conjecture for the basic case $m=1$ with arbitrary $p$. In addition, for the cases when $p=4,5$ and $m\geq2$, we manage to reduce them to the basic case $m=1$ and thus prove them as well. Adversarial Vulnerability of Active Transfer Learning Two widely used techniques for training supervised machine learning models on small datasets are Active Learning and Transfer Learning. The former helps to optimally use a limited budget to label new data. The latter uses large pre-trained models as feature extractors and enables the design of complex, non-linear models even on tiny datasets. Combining these two approaches is an effective, state-of-the-art method when dealing with small datasets. In this paper, we share an intriguing observation: Namely, that the combination of these techniques is particularly susceptible to a new kind of data poisoning attack: By adding small adversarial noise on the input, it is possible to create a collision in the output space of the transfer learner. As a result, Active Learning algorithms no longer select the optimal instances, but almost exclusively the ones injected by the attacker. This allows an attacker to manipulate the active learner to select and include arbitrary images into the data set, even against an overwhelming majority of unpoisoned samples. We show that a model trained on such a poisoned dataset has a significantly deteriorated performance, dropping from 86\% to 34\% test accuracy. We evaluate this attack on both audio and image datasets and support our findings empirically. To the best of our knowledge, this weakness has not been described before in literature. Joint Design of Transmit Waveforms and Receive Filters for MIMO Radar via Manifold Optimization The problem of joint design of transmit waveforms and receive filters is desirable in many application scenarios of multiple-input multiple-output (MIMO) radar systems. In this paper, the joint design problem is investigated under the signal-to-interference-plus-noise ratio (SINR) performance metric, in which case the problem is formulated to maximize the SINR at the receiver side subject to some practical transmit waveform constraints. A numerical algorithm is proposed for problem resolution based on the manifold optimization method, which has been shown to be powerful and flexible to address nonconvex constrained optimization problems in many engineering applications. The proposed algorithm is able to efficiently solve the SINR maximization problem with different waveform constraints under a unified framework. Numerical experiments show that the proposed algorithm outperforms the existing benchmarks in terms of computation efficiency and achieves comparable SINR performance. Dislocation dynamics prediction of the strength of Al-Cu alloys containing shearable $\theta''$ precipitates The critical resolved shear stress of an Al 4 wt. \% Cu alloy containing a homogeneous distribution of $\theta''$ precipitates was determined by means of dislocation dynamics simulations. The size distribution, shape, orientation and volume fraction of the precipitates in the alloy were obtained from transmission electron microscopy observations while the parameters controlling the dislocation/precipitate interactions (elastic mismatch, transformation strains, dislocation mobility and cross-slip probability, etc.) were calculated from atomistic simulations. The precipitates were assumed to be either impenetrable or shearable by the dislocations, the latter characterized by a threshold shear stress that has to be overcome to shear the precipitate. The predictions of the simulations in terms of the critical resolved shear stress and of the dislocation/precipitate interaction mechanisms were in good agreement with the experimental results. It was concluded that the optimum strength of this alloy is attained with a homogeneous distribution of $\theta''$ precipitates whose average size ($\approx$ 40 nm) is at the transition between precipitate shearing and looping. Overall, the dislocation dynamics strategy presented in this paper is able to provide quantitative predictions of precipitate strengthening in metallic alloys. Motion of classical charged particles with magnetic moment in external plane-wave electromagnetic fields We study the motion of a charged particle with magnetic moment in external electromagnetic fields utilizing covariant unification of Gilbertian and Amperian descriptions of particle magnetic dipole moment. Considering the case of a current loop, our approach is verified by comparing classical dynamics with the classical limit of relativistic quantum dynamics. We obtain motion of a charged particle in the presence of an external linearly polarized EM (laser) plane wave field incorporating the effect of spin dynamics. For specific laser-particle initial configurations, we determine that the Stern-Gerlach force can have a cumulative effect on the trajectory of charged particles. First-principles derivation and properties of density-functional average-atom models Finite-temperature Kohn--Sham density-functional theory (KS-DFT) is a widely-used method in warm dense matter (WDM) simulations and diagnostics. Unfortunately, full KS-DFT-molecular dynamics models scale unfavourably with temperature and there remains uncertainty regarding the performance of existing approximate exchange-correlation (XC) functionals under WDM conditions. Of particular concern is the expected explicit dependence of the XC functional on temperature, which is absent from most approximations. Average-atom (AA) models, which significantly reduce the computational cost of KS-DFT calculations, have therefore become an integral part of WDM modelling. In this paper, we present a derivation of a first-principles AA model from the fully-interacting many-body Hamiltonian, carefully analysing the assumptions made and terms neglected in this reduction. We explore the impact of different choices within this model -- such as boundary conditions and XC functionals -- on common properties in WDM, for example equation-of-state data, ionization degree and the behaviour of the frontier energy levels. Furthermore, drawing upon insights from ground-state KS-DFT, we discuss the likely sources of error in KS-AA models and possible strategies for mitigating such errors. What Do We See: An Investigation Into the Representation of Disability in Video Games There has been a large body of research focused on the representation of gender in video games. Disproportionately, there has been very little research in respect to the representation of disability. This research was aimed at examining the representation of disabled characters through a method of content analysis of trailers combined with a survey of video gamers.
The overall results showed that disabled characters were under-represented in videogames trailers, and respondents to the survey viewed disabled characters as the least represented group. Both methods of research concluded that the representation of disabled characters was low. Additionally, the characters represented were predominantly secondary, non-playable characters not primary. However, the research found that the defined character type was a mixture of protagonists and antagonists, bucking the standard view of disabled characters in video games. Geodesic B-Score for Improved Assessment of Knee Osteoarthritis Three-dimensional medical imaging enables detailed understanding of osteoarthritis structural status. However, there remains a vast need for automatic, thus, reader-independent measures that provide reliable assessment of subject-specific clinical outcomes. To this end, we derive a consistent generalization of the recently proposed B-score to Riemannian shape spaces. We further present an algorithmic treatment yielding simple, yet efficient computations allowing for analysis of large shape populations with several thousand samples. Our intrinsic formulation exhibits improved discrimination ability over its Euclidean counterpart, which we demonstrate for predictive validity on assessing risks of total knee replacement. This result highlights the potential of the geodesic B-score to enable improved personalized assessment and stratification for interventions. Accessing slip activity in high purity tin with electron backscatter diffraction and measurement of slip strength Beta-tin has been used widely as an interconnect in modern electronics. To improve the understanding of the reliability of these components, we directly measure the critical resolved shear stress of individual slip systems in beta-tin using micropillar compression tests at room temperature with crystal orientations near-[100] and [001] in the loading direction within a large grain high purity tin (99.99%) sample. This activates the (110)[1-11]/2, (110)[1-1-1]/2, (010)[001] and (110)[001] slip systems. Analysis of the slip traces and load-displacement curves enables measurement of the critical resolved shear stress for epsilon=10^(-4) of tau_(CRSS)^({110}<1-11>/2)=10.4+/-0.4 and tau_(CRSS)^({010}<001>)=3.9+/-0.3 MPa. Probing the flavor-specific scalar mediator for the muon $(g-2)$ deviation, the proton radius puzzle and the light dark matter production Flavor-specific scalar bosons exist in various Standard Model extensions and couple to a single generation of fermions via a global flavor symmetry breaking mechanism. Given this strategy, we propose a MeV flavor-specific scalar model in dimension-$5$ operator series, which explains the muon g-2 anomaly and proton radius puzzle by coupling with the muon and down-quark at the same time. The framework is consistent with the null result of high-intensity searches. Specifically, the supernova constraints for muon couplings become weakened by including the contribution of down-quark interaction. The parameter space for explaining muon $g-2$ discrepancy is available when $10\%$ energy deposition is required in the energy explosion process in the supernova, but this is ruled out by the $1\%$ energy deposition requirement. We also investigate the searches for mediator and dark matter and the resulting constraints on viable parameter space such as nuclear physics constraints, direct detection for light boosted dark matter, and possible CMB constraints. When compared to conventional dark matter production, light dark matter production has two additional modifications: bound state formation and early kinetic equilibrium decoupling. We are now looking into the implications of these effects on the relic density of light dark matter. Small-scale Flux Emergence, Coronal Hole Heating, and Flux-tube Expansion: A Hybrid Solar Wind Model Extreme-ultraviolet images from the Solar Dynamics Observatory often show looplike fine structure to be present where no minority-polarity flux is visible in magnetograms, suggesting that the rate of ephemeral region (ER) emergence inside "unipolar" regions has been underestimated. Assuming that this rate is the same inside coronal holes as in the quiet Sun, we show that interchange reconnection between ERs and open field lines gives rise to a solar wind energy flux that exceeds 10$^5$ erg cm$^{-2}$ s$^{-1}$ and that scales as the field strength at the coronal base, consistent with observations. In addition to providing Ohmic heating in the low corona, these reconnection events may be a source of Alfv{\'e}n waves with periods ranging from the granular timescale of $\sim$10 minutes to the supergranular/plume timescale of many hours, with some of the longer-period waves being reflected and dissipated in the outer corona. The asymptotic wind speed depends on the radial distribution of the heating, which is largely controlled by the rate of flux-tube expansion. Along the rapidly diverging flux tubes associated with slow wind, heating is concentrated well inside the sonic point (1) because the outward conductive heat-flux density and thus the outer coronal temperatures are reduced, and (2) because the net wave energy flux is dissipated at a rate proportional to the local Alfv{\'e}n speed. In this "hybrid" solar wind model, reconnection heats the lower corona and drives the mass flux, whereas waves impart energy and momentum to the outflow at greater distances. Strichartz inequalities with white noise potential on compact surfaces We prove Strichatz inequalities for the Schr{\"o}dinger equation and the wave equation with multiplicative noise on a two-dimensional manifold. This relies on the Anderson Hamiltonian H described using high order paracontrolled calculus. As an application, it gives a low regularity solution theory for the associated nonlinear equations. On the Complexity of Fair Coin Flipping A two-party coin-flipping protocol is $\epsilon$-fair if no efficient adversary can bias the output of the honest party (who always outputs a bit, even if the other party aborts) by more than $\epsilon$. Cleve [STOC '86] showed that $r$-round $o(1/r)$-fair coin-flipping protocols do not exist. Awerbuch, Blum, Chor, Goldwasser, and Micali[Manuscript '85] constructed a $\Theta(1/\sqrt{r})$-fair coin-flipping protocol, assuming the existence of one-way functions. Moran, Naor, and Segev [Journal of Cryptology '16] constructed an $r$-round coin-flipping protocol that is $\Theta(1/r)$-fair (thus matching the aforementioned lower bound of Cleve [STOC '86]), assuming the existence of oblivious transfer. The above gives rise to the intriguing question of whether oblivious transfer, or more generally ``public-key primitives,'' is required for an $o(1/\sqrt r)$-fair coin flipping protocol. We make a different progress towards answering the question by showing that, for any constant $r\in \N$, the existence of an $1/(c\cdot \sqrt{r})$-fair, $r$-round coin-flipping protocol implies the existence of an infinitely-often key-agreement protocol, where $c$ denotes some universal constant (independent of $r$). Our reduction is \emph{non} black-box and makes a novel use of the recent dichotomy for two-party protocols of Haitner, Nissim, Omri, Shaltiel, and Silbak [FOCS '18] to facilitate a two-party variant of the recent attack of Beimel, Haitner, Makriyannis, and Omri [FOCS '18] on multi-party coin-flipping protocols. 3-D Deployment of UAV Swarm for Massive MIMO Communications We consider the uplink transmission between a multi-antenna ground station and an unmanned aerial vehicle (UAV) swarm. The UAVs are assumed as intelligent agents, which can explore their optimal three dimensional (3-D) deployment to maximize the channel capacity of the multiple input multiple output (MIMO) system.
Specifically, considering the limitations of each UAV in accessing the global information of the network, we focus on a decentralized control strategy by noting that each UAV in the swarm can only utilize the local information to achieve the optimal 3-D deployment. In this case, the optimization problem can be divided into several optimization sub-problems with respect to the rank function. Due to the non-convex nature of the rank function and the fact that the optimization sub-problems are coupled, the original problem is NP-hard and, thus, cannot be solved with standard convex optimization solvers. Interestingly, we can relax the constraint condition of each sub-problem and solve the optimization problem by a formulated UAVs channel capacity maximization game. We analyze such game according to the designed reward function and the potential function. Then, we discuss the existence of the pure Nash equilibrium in the game. To achieve the best Nash equilibrium of the MIMO system, we develop a decentralized learning algorithm, namely decentralized UAVs channel capacity learning. The details of the algorithm are provided, and then, the convergence, the effectiveness and the computational complexity are analyzed, respectively. Moreover, we give some insightful remarks based on the proofs and the theoretical analysis. Also, extensive simulations illustrate that the developed learning algorithm can achieve a high MIMO channel capacity by optimizing the 3-D UAV swarm deployment with the local information. Two-dimensional charge density wave TaX$_2$ (X=S, Se, Te) from first principles Transition metal dichalcogenides are rich in their structural phases, e.g. 1T-TaS2 and 1T-TaSe2 form charge density wave (CDW) under low temperature with interesting and exotic properties. Here, we present a systematic study of different structures in two-dimensional TaX2 (X=S, Se, Te) using density functional theory calculations with consideration of van der Waals interaction. All the normal phases present metal characteristics with various ground state and magnetic properties. The lattice reconstruction of CDW drastically affects the electronic and structural characteristics of 1T-TaS2 and 1T-TaSe2, leading to a transition from metal to insulator and an emergence of magnetic moment within periodic atomic clusters called the Star of David. The evaluated Heisenberg couplings indicate the weak ferromagnetic coupling between the clusters in monolayer. Furthermore, in bilayer commensurate CDW cases, we find intriguing phenomenon of the varying magnetic properties with different stacking orders. The magnetic moment in each layer disappears when two layers are coupled, but may sustain in certain stackings of interlayer antiferromagnetic configurations. Quantum Hall effect originated from helical edge states in Cd$_3$As$_2$ The recent experimental observations of the quantum Hall effect in 3D topological semimetals have attracted great attention, but there are still debates on its origin. We systematically study the dependence of the quantum Hall effect in topological semimetals on the thickness, Fermi energy, and growth direction, taking into account the contributions from the Fermi-arc surface states, confinement-induced bulk subbands, and helical side-surface edge states. In particular, we focus on the intensively studied Dirac semimetal Cd$_{3}$As$_{2}$ and its slabs grown along experimentally accessible directions, including [001], [110], and [112]. We reveal an ignored mechanism from the Zeeman splitting of the helical edge states, which along with Fermi-arc 3D quantum Hall effect, may give a non-monotonic dependence of the Hall conductance plateaus on the magnetic field in the most experimentally studied [112] direction slab. Our results will be insightful for exploring the quantum Hall effects beyond two dimensions. Attention-Based Keyword Localisation in Speech using Visual Grounding Visually grounded speech models learn from images paired with spoken captions. By tagging images with soft text labels using a trained visual classifier with a fixed vocabulary, previous work has shown that it is possible to train a model that can detect whether a particular text keyword occurs in speech utterances or not. Here we investigate whether visually grounded speech models can also do keyword localisation: predicting where, within an utterance, a given textual keyword occurs without any explicit text-based or alignment supervision. We specifically consider whether incorporating attention into a convolutional model is beneficial for localisation. Although absolute localisation performance with visually supervised models is still modest (compared to using unordered bag-of-word text labels for supervision), we show that attention provides a large gain in performance over previous visually grounded models. As in many other speech-image studies, we find that many of the incorrect localisations are due to semantic confusions, e.g. locating the word 'backstroke' for the query keyword 'swimming'. Long induced paths in a configuration model In an article published in 1987 in Combinatorica \cite{MR918397}, Frieze and Jackson established a lower bound on the length of the longest induced path (and cycle) in a sparse random graph. Their bound is obtained through a rough analysis of a greedy algorithm. In the present work, we provide a sharp asymptotic for the length of the induced path constructed by their algorithm. To this end, we introduce an alternative algorithm that builds the same induced path and whose analysis falls into the framework of a previous work by the authors on depth-first exploration of a configuration model \cite{EFMN}. We also analyze an extension of our algorithm that mixes depth-first and breadth-first explorations and generates $m$-induced paths. Crowding competes with trapping to enhance interfacial diffusion Diffusion in the crowded environments of the biological membranes or materials interfaces often involves intermittent binding to surface proteins or defects. To account for this situation we study a 2-dimensional lattice gas in a field of immobilized traps. Using kinetic Monte Carlo simulations, we calculate the effective diffusion coefficient in the long-time limit as a function of the traps and particle densities. We find a remarkable result - an increase of the diffusion coefficient with particle density, an effect that we coin as crowding-enhanced diffusion. We rationalize this result using scaling arguments and the master equation approach. Exploring Localization for Self-supervised Fine-grained Contrastive Learning Self-supervised contrastive learning has demonstrated great potential in learning visual representations. Despite their success in various downstream tasks such as image classification and object detection, self-supervised pre-training for fine-grained scenarios is not fully explored. We point out that current contrastive methods are prone to memorizing background/foreground texture and therefore have a limitation in localizing the foreground object. Analysis suggests that learning to extract discriminative texture information and localization are equally crucial for fine-grained self-supervised pre-training. Based on our findings, we introduce cross-view saliency alignment (CVSA), a contrastive learning framework that first crops and swaps saliency regions of images as a novel view generation and then guides the model to localize on foreground objects via a cross-view alignment loss. Extensive experiments on both small- and large-scale fine-grained classification benchmarks show that CVSA significantly improves the learned representation. Nanotube-based one-dimensional heterostructures coupled by van der Waals forces One-dimensional (1D) van der Waals heterostructures based on carbon nanotube templates are raising a lot of excitement due to the possibility of creating new optical and electronic properties, by either confining molecules inside their hollow core or by adding layers on the outside of the nanotube. In contrast to their 2D analogues, where the number of layers, atomic type and relative orientation of the constituting layers are the main parameters defining physical properties, 1D heterostructures provide an additional degree of freedom, i.e. their specific diameter and chiral structure, for engineering their characteristics. This review discusses the current state-of-the-art in synthesizing 1D heterostructures, in particular focusing on their resulting optical properties, and details the vast parameter space that can be used to design heterostructures with custom-built properties that can be integrated into a large variety of applications.
The review starts from describing the effects of van der Waals coupling on the properties of the simplest and best-studied 1D heterostructure, namely a double-wall carbon nanotube, then considers heterostructures built from the inside and the outside, which all use a nanotube as a template, and, finally, provides an outlook for the future of this research field. Temperature and Face Dependent Copper-Graphene Interactions The interaction between graphene and metals represents an important issue for the large-area preparation of graphene, graphene transfer and the contact quality in graphene devices. We demonstrate a simple method for estimating and manipulating the level of interaction between graphene and copper single crystals through heat treatment, at temperatures from 298K to 1073K. We performed an in-situ Raman spectroscopy showing Cu face-specific behavior of the overlying graphene during the heat treatment. On Cu(111) the interaction is consistent with theoretical predictions and remains stable, whereas on Cu(100) and Cu(110), the initially very weak interaction and charge transfer can be tuned by heating. Our results also suggest that graphene grown on Cu(100) and Cu(110) is detached from the copper substrate, thereby possibly enabling an easier graphene transfer process as compared to Cu (111). A Hybrid Vehicle Platoon for Connected and Automated Vehicles: Formulation, Stability Analysis, and Applications Vehicle platooning has the potential to significantly improve traffic throughput and reduce fuel consumption and emissions and thus has attracted extensive attention recently. In this study, we propose a hybrid vehicle platoon system for the connected and automated vehicles (CAVs). First, a hybrid spacing policy combining the constant time gap (CTG) and constant spacing (CS) is formulated for the proposed platoon system, where the leader adopts the CTG and the followers use the CS policy. Based on the h2-norm string stability criteria, the notions of exogenous-head-to-tail string stability and hybrid string stability are newly introduced, and the sufficient conditions of the hybrid string stability in the frequency domain are derived using the Laplace transform. Numerical experiments are conducted to validate the hybrid string stability. Moreover, two typical scenarios and several measurements of effectiveness (MOE) are adopted to verify the effectiveness of the proposed hybrid platoon system in various aspects. The results show that the hybrid platoon system performs better than the CS-based platoon system. It also indicates that the hybrid platoon system has obvious advantages over the CTG-based platoon system under the periodical fluctuation scenario and it is also comparable to the CTG-based platoon system under the large deceleration and acceleration scenario. The findings have demonstrated the merits of the combined implementation of CTG and CS policy in enhancing the performance and applicability of the platoon system for CAVs. Implicit Profiling Estimation for Semiparametric Models with Bundled Parameters Solving semiparametric models can be computationally challenging because the dimension of parameter space may grow large with increasing sample size. Classical Newton's method becomes quite slow and unstable with intensive calculation of the large Hessian matrix and its inverse. Iterative methods separately update parameters for finite dimensional component and infinite dimensional component have been developed to speed up single iteration, but they often take more steps until convergence or even sometimes sacrifice estimation precision due to sub-optimal update direction. We propose a computationally efficient implicit profiling algorithm that achieves simultaneously the fast iteration step in iterative methods and the optimal update direction in the Newton's method by profiling out the infinite dimensional component as the function of the finite dimensional component. We devise a first order approximation when the profiling function has no explicit analytical form. We show that our implicit profiling method always solve any local quadratic programming problem in two steps. In two numerical experiments under semiparametric transformation models and GARCH-M models, we demonstrated the computational efficiency and statistical precision of our implicit profiling method. Federated Learning Meets Fairness and Differential Privacy Deep learning's unprecedented success raises several ethical concerns ranging from biased predictions to data privacy. Researchers tackle these issues by introducing fairness metrics, or federated learning, or differential privacy. A first, this work presents an ethical federated learning model, incorporating all three measures simultaneously. Experiments on the Adult, Bank and Dutch datasets highlight the resulting ``empirical interplay" between accuracy, fairness, and privacy. Modeling of biomolecular machines in non-equilibrium steady states Numerical computations have become a pillar of all modern quantitative sciences. Any computation involves modeling--even if often this step is not made explicit--and any model has to neglect details while still being physically accurate. Equilibrium statistical mechanics guides both the development of models and numerical methods for dynamics obeying detailed balance. For systems driven away from thermal equilibrium such a universal theoretical framework is missing. For a restricted class of driven systems governed by Markov dynamics and local detailed balance, stochastic thermodynamics has evolved to fill this gap and to provide fundamental constraints and guiding principles. The next step is to advance stochastic thermodynamics from simple model systems to complex systems with ten thousands or even millions degrees of freedom. Biomolecules operating in the presence of chemical gradients and mechanical forces are a prime example for this challenge. In this Perspective, we give an introduction to isothermal stochastic thermodynamics geared towards the systematic multiscale modeling of the conformational dynamics of biomolecular and synthetic machines, and we outline some of the open challenges. Standard Errors for Calibrated Parameters Calibration, the practice of choosing the parameters of a structural model to match certain empirical moments, can be viewed as minimum distance estimation. Existing standard error formulas for such estimators require a consistent estimate of the correlation structure of the empirical moments, which is often unavailable in practice. Instead, the variances of the individual empirical moments are usually readily estimable. Using only these variances, we derive conservative standard errors and confidence intervals for the structural parameters that are valid even under the worst-case correlation structure. In the over-identified case, we show that the moment weighting scheme that minimizes the worst-case estimator variance amounts to a moment selection problem with a simple solution. Finally, we develop tests of over-identifying or parameter restrictions. We apply our methods empirically to a model of menu cost pricing for multi-product firms and to a heterogeneous agent New Keynesian model. Learning Visual Shape Control of Novel 3D Deformable Objects from Partial-View Point Clouds If robots could reliably manipulate the shape of 3D deformable objects, they could find applications in fields ranging from home care to warehouse fulfillment to surgical assistance. Analytic models of elastic, 3D deformable objects require numerous parameters to describe the potentially infinite degrees of freedom present in determining the object's shape. Previous attempts at performing 3D shape control rely on hand-crafted features to represent the object shape and require training of object-specific control models. We overcome these issues through the use of our novel DeformerNet neural network architecture, which operates on a partial-view point cloud of the object being manipulated and a point cloud of the goal shape to learn a low-dimensional representation of the object shape. This shape embedding enables the robot to learn to define a visual servo controller that provides Cartesian pose changes to the robot end-effector causing the object to deform towards its target shape. Crucially, we demonstrate both in simulation and on a physical robot that DeformerNet reliably generalizes to object shapes and material stiffness not seen during training and outperforms comparison methods for both the generic shape control and the surgical task of retraction. Spin chains, defects, and quantum wires for the quantum-double edge Non-Abelian defects that bind Majorana or parafermion zero modes are prominent in several topological quantum computation schemes. Underpinning their established understanding is the quantum Ising spin chain, which can be recast as a fermionic model or viewed as a standalone effective theory for the surface-code edge -- both of which harbor non-Abelian defects. We generalize these notions by deriving an effective Ising-like spin chain describing the edge of quantum-double topological order. Relating Majorana and parafermion modes to anyonic strings, we introduce quantum-double generalizations of non-Abelian defects.
We develop a way to embed finite-group valued qunits into those valued in continuous groups. Using this embedding, we provide a continuum description of the spin chain and recast its non-interacting part as a quantum wire via addition of a Wess-Zumino-Novikov-Witten term and non-Abelian bosonization. Streamlining Evaluation with ir-measures We present ir-measures, a new tool that makes it convenient to calculate a diverse set of evaluation measures used in information retrieval. Rather than implementing its own measure calculations, ir-measures provides a common interface to a handful of evaluation tools. The necessary tools are automatically invoked (potentially multiple times) to calculate all the desired metrics, simplifying the evaluation process for the user. The tool also makes it easier for researchers to use recently-proposed measures (such as those from the C/W/L framework) alongside traditional measures, potentially encouraging their adoption. On the stability of isothermal shocks in black hole accretion disks Most black holes possess accretion disks. Models of such disks inform observations and constrain the properties of the black holes and their surrounding medium. Here, we study isothermal shocks in a thin black hole accretion flow. Modelling infinitesimal molecular viscosity allows the use of multiple-scales matched asymptotic methods. We thus derive the first explicit calculations of isothermal shock stability. We find that the inner shock is always unstable, and the outer shock is always stable. The growth/decay rates of perturbations depend only on an effective potential and the incoming--outgoing flow difference at the shock location. We give a prescription of accretion regimes in terms of angular momentum and black hole radius. Accounting for angular momentum dissipation implies unstable outer shocks in much of parameter space, even for realistic viscous Reynolds numbers of the order $\approx 10^{20}$. Magnetic properties and pseudogap formation in infinite-layer nickelates: insights from the single-band Hubbard model We study the magnetic and spectral properties of a single-band Hubbard model for the infinite-layer nickelate compound LaNiO$_2$. As spatial correlations turn out to be the key ingredient for understanding its physics, we use two complementary extensions of the dynamical mean-field theory to take them into account: the cellular dynamical mean-field theory and the dynamical vertex approximation. Additionally to the systematic analysis of the doping dependence of the non-Curie-Weiss behavior of the uniform magnetic susceptibility, we provide insight into its relation to the formation of a pseudogap regime by the calculation of the one-particle spectral function and the magnetic correlation length. The latter is of the order of a few lattice spacings when the pseudogap opens, indicating a strong-coupling pseudogap formation in analogy to cuprates. Smooth torus quotients of Richardson varieties in the Grassmannian Let $k$ and $n$ be positive coprime integers with $k<n$. Let $T$ denote the subgroup of diagonal matrices in $SL(n,\mathbb{C})$. We study the GIT quotient of Richardson varieties $X^v_w$ in the Grassmannian $\mathrm{Gr}_{k,n}$ by $T$ with respect to a $T$-linearised line bundle $\cal{L}$ corresponding to the Pl\"{u}cker embedding. We give necessary and sufficient combinatorial conditions for the quotient variety $T \backslash\mkern-6mu\backslash (X_w^v)^{ss}_T({\cal L})$ to be smooth. A stellar stream remnant of a globular cluster below the metallicity floor Stellar ejecta gradually enrich the gas out of which subsequent stars form, making the least chemically enriched stellar systems direct fossils of structures formed in the early universe. Although a few hundred stars with metal content below one thousandth of the solar iron content are known in the Galaxy, none of them inhabit globular clusters, some of the oldest known stellar structures. These show metal content of at least ~0.2 percent of the solar metallicity ([Fe/H] > -2.7). This metallicity floor appears universal and it has been proposed that proto-galaxies that merge into the galaxies we observe today were simply not massive enough to form clusters that survived to the present day. Here, we report the discovery of a stellar stream, C-19, whose metallicity is less than 0.05 per cent the solar metallicity ([Fe/H]=-3.38 +/- 0.06 (stat.) +/- 0.20 (syst.)). The low metallicity dispersion and the chemical abundances of the C-19 stars show that this stream is the tidal remnant of the most metal-poor globular cluster ever discovered, and significantly below the purported metallicity floor: clusters with significantly lower metallicities than observed today existed in the past and contributed their stars to the Milky Way halo. Operating in a deep underground facility improves the locking of gradiometric fluxonium qubits at the sweet spots We demonstrate flux-bias locking and operation of a gradiometric fluxonium artificial atom using two symmetric granular aluminum (grAl) loops to implement the superinductor. The gradiometric fluxonium shows two orders of magnitude suppression of sensitivity to homogeneous magnetic fields, which can be an asset for hybrid quantum systems requiring strong magnetic field biasing. By cooling down the device in an external magnetic field while crossing the metal-to-superconductor transition, the gradiometric fluxonium can be locked either at $0$ or $\Phi_0/2$ effective flux bias, corresponding to an even or odd number of trapped fluxons, respectively. At mK temperatures, the fluxon parity prepared during initialization survives to magnetic field bias exceeding $100 \,\Phi_0$. However, even for states biased in the vicinity of $1 \,\Phi_0$, we observe unexpectedly short fluxon lifetimes of a few hours, which cannot be explained by thermal or quantum phase slips. When operating in a deep-underground cryostat of the Gran Sasso laboratory, the fluxon lifetimes increase to days, indicating that ionizing events activate phase slips in the grAl superinductor. Algorithmic nudge to make better choices: Evaluating effectiveness of XAI frameworks to reveal biases in algorithmic decision making to users In this position paper, we propose the use of existing XAI frameworks to design interventions in scenarios where algorithms expose users to problematic content (e.g. anti vaccine videos). Our intervention design includes facts (to indicate algorithmic justification of what happened) accompanied with either fore warnings or counterfactual explanations. While fore warnings indicate potential risks of an action to users, the counterfactual explanations will indicate what actions user should perform to change the algorithmic outcome. We envision the use of such interventions as `decision aids' to users which will help them make informed choices. Evaluation of Runtime Monitoring for UAV Emergency Landing To certify UAV operations in populated areas, risk mitigation strategies -- such as Emergency Landing (EL) -- must be in place to account for potential failures. EL aims at reducing ground risk by finding safe landing areas using on-board sensors. The first contribution of this paper is to present a new EL approach, in line with safety requirements introduced in recent research. In particular, the proposed EL pipeline includes mechanisms to monitor learning based components during execution. This way, another contribution is to study the behavior of Machine Learning Runtime Monitoring (MLRM) approaches within the context of a real-world critical system. A new evaluation methodology is introduced, and applied to assess the practical safety benefits of three MLRM mechanisms. The proposed approach is compared to a default mitigation strategy (open a parachute when a failure is detected), and appears to be much safer. Fault-tolerance in qudit circuit design The efficient decomposition of multi-controlled gates is a significant factor in quantum compiling, both in circuit depth and T-gate count. Recent work has demonstrated that qudits have the potential to reduce resource requirements from linear to logarithmic depth and to avoid fractional phase rotations. Here we argue, based on the scaling of decoherence in high-index states, that circuit depth is not the primary factor, and that both the choice of entangling gate and interaction network topology act together to determine the spread of errors and ultimate failure rate in a circuit.
We further show that for certain linear-depth circuits, additional error mitigation is possible via selective application of resources. Bayesian community detection for networks with covariates The increasing prevalence of network data in a vast variety of fields and the need to extract useful information out of them have spurred fast developments in related models and algorithms. Among the various learning tasks with network data, community detection, the discovery of node clusters or "communities," has arguably received the most attention in the scientific community. In many real-world applications, the network data often come with additional information in the form of node or edge covariates that should ideally be leveraged for inference. In this paper, we add to a limited literature on community detection for networks with covariates by proposing a Bayesian stochastic block model with a covariate-dependent random partition prior. Under our prior, the covariates are explicitly expressed in specifying the prior distribution on the cluster membership. Our model has the flexibility of modeling uncertainties of all the parameter estimates including the community membership. Importantly, and unlike the majority of existing methods, our model has the ability to learn the number of the communities via posterior inference without having to assume it to be known. Our model can be applied to community detection in both dense and sparse networks, with both categorical and continuous covariates, and our MCMC algorithm is very efficient with good mixing properties. We demonstrate the superior performance of our model over existing models in a comprehensive simulation study and an application to two real datasets. Query-Efficient Black-box Adversarial Attacks Guided by a Transfer-based Prior Adversarial attacks have been extensively studied in recent years since they can identify the vulnerability of deep learning models before deployed. In this paper, we consider the black-box adversarial setting, where the adversary needs to craft adversarial examples without access to the gradients of a target model. Previous methods attempted to approximate the true gradient either by using the transfer gradient of a surrogate white-box model or based on the feedback of model queries. However, the existing methods inevitably suffer from low attack success rates or poor query efficiency since it is difficult to estimate the gradient in a high-dimensional input space with limited information. To address these problems and improve black-box attacks, we propose two prior-guided random gradient-free (PRGF) algorithms based on biased sampling and gradient averaging, respectively. Our methods can take the advantage of a transfer-based prior given by the gradient of a surrogate model and the query information simultaneously. Through theoretical analyses, the transfer-based prior is appropriately integrated with model queries by an optimal coefficient in each method. Extensive experiments demonstrate that, in comparison with the alternative state-of-the-arts, both of our methods require much fewer queries to attack black-box models with higher success rates. Quantized and half-quantized Anomalous Hall effect induced by in-plane magnetic field In this paper we propose that, quantized and nearly half-quantized intrinsic anomalous Hall effect can be induced by in-plane external magnetic field through the Zeeman coupling in non-magnetic 2D systems with sizeable spin-orbital coupling but without two-fold rotational symmetry. An analytical result is derived for 2D electron gas model with $C_{3v}$ symmetry. Based on the $\boldsymbol{k\cdot p}$ Hamiltonian derived from first principle calculations, we find that quantized and nearly half-quantized conductance can be observed in $\mathrm{Sb_2Te_3}$ thin film in the clean limit with strong in-plane magnetic field $B>20\ \mathrm{T}$ and low temperature $T<100\ \mathrm{mK}$. On Convergence Lemma and Convergence Stability for Piecewise Analytic Functions In this work, a convergence lemma for function $f$ being finite compositions of analytic mappings and the maximum operator is proved. The lemma shows that the set of $\delta$-stationary points near an isolated local minimum point $x^*$ is shrinking to $x^*$ as $\delta\to 0$. It is a natural extension of the version for strongly convex $C^1$ functions. However, the correctness of the lemma is subtle. Analytic mappings are necessary for the lemma in the sense that replacing it with differentiable or $C^\infty$ mappings makes the lemma false. The proof is based on stratification theorems of semi-analytic sets by {\L}ojasiewicz. An extension of this proof presents a geometric characterization of the set of stationary points of $f$. Finally, a notion of stability on stationary points, called convergence stability, is proposed. It asks, under small numerical errors, whether a reasonable convergent optimization method started near a stationary point should eventually converge to the same stationary point. The concept of convergence stability becomes nontrivial qualitatively only when the objective function is both nonsmooth and nonconvex. Via the convergence lemma, an intuitive equivalent condition for convergence stability of $f$ is proved. These results together provide a new geometric perspective to study the problem of "where-to-converge" in nonsmooth nonconvex optimization. Reuse your features: unifying retrieval and feature-metric alignment We propose a compact pipeline to unify all the steps of Visual Localization: image retrieval, candidate re-ranking and initial pose estimation, and camera pose refinement. Our key assumption is that the deep features used for these individual tasks share common characteristics, so we should reuse them in all the procedures of the pipeline. Our DRAN (Deep Retrieval and image Alignment Network) is able to extract global descriptors for efficient image retrieval, use intermediate hierarchical features to re-rank the retrieval list and produce an initial pose guess, which is finally refined by means of a feature-metric optimization based on learned deep multi-scale dense features. DRAN is the first single network able to produce the features for the three steps of visual localization. DRAN achieves competitive performance in terms of robustness and accuracy under challenging conditions in public benchmarks, outperforming other unified approaches and consuming lower computational and memory cost than its counterparts using multiple networks. Code and models will be publicly available at https://github.com/jmorlana/DRAN. TuGeBiC: A Turkish German Bilingual Code-Switching Corpus In this paper we describe the process of collection, transcription, and annotation of recordings of spontaneous speech samples from Turkish-German bilinguals, and the compilation of a corpus called TuGeBiC. Participants in the study were adult Turkish-German bilinguals living in Germany or Turkey at the time of recording in the first half of the 1990s. The data were manually tokenised and normalised, and all proper names (names of participants and places mentioned in the conversations) were replaced with pseudonyms. Token-level automatic language identification was performed, which made it possible to establish the proportions of words from each language. The corpus is roughly balanced between both languages. We also present quantitative information about the number of code-switches, and give examples of different types of code-switching found in the data. The resulting corpus has been made freely available to the research community. Odor Descriptor Understanding through Prompting Embeddings from contemporary natural language processing (NLP) models are commonly used as numerical representations for words or sentences. However, odor descriptor words, like "leather" or "fruity", vary significantly between their commonplace usage and their olfactory usage, as a result traditional methods for generating these embeddings do not suffice. In this paper, we present two methods to generate embeddings for odor words that are more closely aligned with their olfactory meanings when compared to off-the-shelf embeddings. These generated embeddings outperform the previous state-of-the-art and contemporary fine-tuning/prompting methods on a pre-existing zero-shot odor-specific NLP benchmark. Probing WIMPs in space-based gravitational wave experiments Although searches for dark matter have lasted for decades, no convincing signal has been found without ambiguity in underground detections, cosmic ray observations, and collider experiments. We show by example that gravitational wave (GW) observations can be a supplement to dark matter detections if the production of dark matter follows a strong first-order cosmological phase transition. We explore this possibility in a complex singlet extension of the standard model with CP symmetry.
We demonstrate three benchmarks in which the GW signals from the first-order phase transition are loud enough for future space-based GW observations, for example, BBO, U-DECIGO, LISA, Taiji, and TianQin. While satisfying the constraints from the XENON1T experiment and the Fermi-LAT gamma-ray observations, the dark matter candidate with its mass around $\sim 1$~TeV in these scenarios has a correct relic abundance obtained by the Planck observations of the cosmic microwave background radiation. The development of the theory of automatic groups We describe the development of the theory of automatic groups. We begin with a historical introduction, define the concepts of automatic, biautomatic and combable groups, derive basic properties, then explain how hyperbolic groups and the groups of compact 3-manifolds based on six of Thurston's eight geometries can be proved automatic. We describe software developed in Warwick to compute automatic structures, as well as the development of practical algorithms that use those structures. We explain how actions of groups on spaces displaying various notions of negative curvature can be used to prove automaticity or biautomaticity, and show how these results have been used to derive these properties for groups in some infinite families (braid groups, mapping class groups, families of Artin groups, and Coxeter groups). Throughout the text we flag up open problems as well as problems that remained open for some time but have now been resolved. Recognition of Unseen Bird Species by Learning from Field Guides We exploit field guides to learn bird species recognition, in particular zero-shot recognition of unseen species. Illustrations contained in field guides deliberately focus on discriminative properties of each species, and can serve as side information to transfer knowledge from seen to unseen bird species. We study two approaches: (1) a contrastive encoding of illustrations, which can be fed into standard zero-shot learning schemes; and (2) a novel method that leverages the fact that illustrations are also images and as such structurally more similar to photographs than other kinds of side information. Our results show that illustrations from field guides, which are readily available for a wide range of species, are indeed a competitive source of side information for zero-shot learning. On a subset of the iNaturalist2021 dataset with 749 seen and 739 unseen species, we obtain a classification accuracy of unseen bird species of $12\%$ @top-1 and $38\%$ @top-10, which shows the potential of field guides for challenging real-world scenarios with many species. Our code is available at https://github.com/ac-rodriguez/zsl_billow Characterizing Properties and Trade-offs of Centralized Delegation Mechanisms in Liquid Democracy Liquid democracy is a form of transitive delegative democracy that has received a flurry of scholarly attention from the computer science community in recent years. In its simplest form, every agent starts with one vote and may have other votes assigned to them via delegation from other agents. They can choose to delegate all votes assigned to them to another agent or vote directly with all votes assigned to them. However, many proposed realizations of liquid democracy allow for agents to express their delegation/voting preferences in more complex ways (e.g., a ranked list of potential delegates) and employ a centralized delegation mechanism to compute the final vote tally. In doing so, centralized delegation mechanisms can make decisions that affect the outcome of a vote and where/whether agents are able to delegate their votes. Much of the analysis thus far has focused on the ability of these mechanisms to make a correct choice. We extend this analysis by introducing and formalizing other important properties of a centralized delegation mechanism in liquid democracy with respect to crucial features such as accountability, transparency, explainability, fairness, and user agency. In addition, we evaluate existing methods in terms of these properties, show how some prior work can be augmented to achieve desirable properties, prove impossibility results for achieving certain sets of properties simultaneously, and highlight directions for future work. Modern Distributed Data-Parallel Large-Scale Pre-training Strategies For NLP models Distributed deep learning is becoming increasingly popular due to the expanding demand for computing resources for deep learning models with a larger amount of parameters. Different from traditional training approaches, data-parallel training allows multiple compute nodes to train large deep learning models simultaneously in order to boost the training efficiency. In this paper, we present and compare six strategies for data-parallel training using PyTorch on the language model GPT-2 with 100M parameters using a qualitative approach. These strategies are Single GPU, Single Parameter Server, Distributed Parameter Server, Horovod, Distributed Parameter Server with Apex mixed-precision strategy, and Horovod with Apex mixed-precision strategy. We also analyze the quantitative experiment results from each strategy. In the end, we draw the conclusion that the Distributed Parameter Server with Apex mixedprecision strategy has the best performance on single node training, while Horovod with Apex is the most robust approach to use when we have single or multiple nodes. The Sparse-Grid-Based Adaptive Spectral Koopman Method The adaptive spectral Koopman (ASK) method was introduced to numerically solve autonomous dynamical systems that lay the foundation of numerous applications across different fields in science and engineering. Although ASK achieves high accuracy, it is computationally more expensive for multi-dimensional systems compared with conventional time integration schemes like Runge-Kutta. In this work, we combine the sparse grid and ASK to accelerate the computation for multi-dimensional systems. This sparse-grid-based ASK (SASK) method uses the Smolyak structure to construct multi-dimensional collocation points as well as associated polynomials that are used to approximate eigenfunctions of the Koopman operator of the system. In this way, the number of collocation points is reduced compared with using the tensor product rule. We demonstrate that SASK can be used to solve partial differential equations based-on their semi-discrete forms. Numerical experiments illustrate that SASK balances the accuracy with the computational cost, and hence accelerates ASK. Nonlinear Landau damping for the 2d Vlasov-Poisson system with massless electrons around Penrose-stable equilibria In this paper, we prove the nonlinear asymptotic stability of the Penrose-stable equilibria among solutions of the $2d$ Vlasov-Poisson system with massless electrons. Green's function and Pointwise Behavior of the One-Dimensional Vlasov-Maxwell-Boltzmann System The pointwise space-time behavior of the Green's function of the one-dimensional Vlasov-Maxwell-Boltzmann (VMB) system is studied in this paper. It is shown that the Green's function consists of the macroscopic diffusive waves and Huygens waves with the speed $\pm \sqrt{5/3}$ at low-frequency, the hyperbolic waves with the speed $\pm 1$ at high-frequency, the singular kinetic and leading short waves, and the remaining term decaying exponentially in space and time. Note that these high-frequency hyperbolic waves are completely new and can not be observed for the Boltzmann equation and the Vlasov-Poisson-Boltzmann system. In addition, we establish the pointwise space-time estimate of the global solution to the nonlinear VMB system based on the Green's function. Compared to the Boltzmann equation and the Vlasov-Poisson-Boltzmann system, some new ideas are introduced to overcome the difficulties caused by the coupling effects of the transport of particles and the rotating of electro-magnetic fields, and investigate the new hyperbolic waves and singular leading short waves. Realistic simulation of reflection high-energy electron diffraction patterns for two-dimensional lattices using Ewald construction Reflection high-energy electron diffraction (RHEED) is a powerful tool for characterizing crystal surface structures. However, the setup geometry leads to distorted and complicated patterns, which are not straightforward to link to the real-space structures. A program with a graphical user interface is provided here to simulate the RHEED patterns. Following the Ewald construction in the kinematic theory, we find out the exact geometric transformation in this model that determines the positions of diffraction spots. The program can deal with many forms of surface structures, including surface reconstructions or domains. The simulations exhibit great agreement with the experimental results in various cases. This program will benefit the structure analysis in thin film growth and surface science studies.
A Sublinear-Time Quantum Algorithm for Approximating Partition Functions We present a novel quantum algorithm for estimating Gibbs partition functions in sublinear time with respect to the logarithm of the size of the state space. This is the first speed-up of this type to be obtained over the seminal nearly-linear time algorithm of \v{S}tefankovi\v{c}, Vempala and Vigoda [JACM, 2009]. Our result also preserves the quadratic speed-up in precision and spectral gap achieved in previous work by exploiting the properties of quantum Markov chains. As an application, we obtain new polynomial improvements over the best-known algorithms for computing the partition function of the Ising model, counting the number of $k$-colorings, matchings or independent sets of a graph, and estimating the volume of a convex body. Our approach relies on developing new variants of the quantum phase and amplitude estimation algorithms that return nearly unbiased estimates with low variance and without destroying their initial quantum state. We extend these subroutines into a nearly unbiased quantum mean estimator that reduces the variance quadratically faster than the classical empirical mean. No such estimator was known to exist prior to our work. These properties, which are of general interest, lead to better convergence guarantees within the paradigm of simulated annealing for computing partition functions. Local Discontinuous Galerkin for the Functional Renormalisation Group We apply the Local Discontinuous Galerkin discretisation to flow equations of the O(N)-model in the Local Potential Approximation. The improved stability is directly observed by solving the flow equation for various $N$ and space-time dimensions $d$. A particular focus of this work is the numerical discretisation and its implementation. The code is publicly available, and is explained in detail here. It is realised as a module within the high performance PDE framework DUNE. Krylov Complexity in Open Quantum Systems Krylov complexity is a novel measure of operator complexity that exhibits universal behavior and bounds a large class of other measures. In this letter, we generalize Krylov complexity from a closed system to an open system coupled to a Markovian bath, where Lindbladian evolution replaces Hamiltonian evolution. We show that Krylov complexity in open systems can be mapped to a non-hermitian tight-binding model in a half-infinite chain. We discuss the properties of the non-hermitian terms and show that the strengths of the non-hermitian terms increase linearly with the increase of the Krylov basis index $n$. Such a non-hermitian tight-binding model can exhibit localized edge modes that determine the long-time behavior of Krylov complexity. Hence, the growth of Krylov complexity is suppressed by dissipation, and at long-time, Krylov complexity saturates at a finite value much smaller than that of a closed system with the same Hamitonian. Our conclusions are supported by numerical results on several models, such as the Sachdev-Ye-Kitaev model and the interacting fermion model. Our work provides insights for discussing complexity, chaos, and holography for open quantum systems. Rotating and Expanding Gas in Binary Post-AGB Stars There is a class of binary post-AGB stars (binary system including a post-AGB star) that are surrounded by Keplerian disks and outflows resulting from gas escaping from the disk. To date, there are seven sources that have been studied in detail through interferometric millimeter-wave maps of CO lines (ALMA/NOEMA). For the cases of the Red Rectangle, IW Carinae, IRAS 08544-4431, and AC Herculis, it is found that around greater than 85% of the total nebular mass is located in the disk with Keplerian dynamics. The remainder of the nebular mass is located in an expanding component. This outflow is probably a disk wind consisting of material escaping from the rotating disk. These sources are the disk-dominated nebulae. On the contrary, our maps and modeling of 89 Herculis, IRAS 19125+0343, and R Scuti, which allowed us to study their morphology, kinematics, and mass distribution, suggest that, in these sources, the outflow clearly is the dominant component of the nebula (around 75% of the total nebular mass), resulting in a new subclass of nebulae around binary post-AGB stars: the outflow-dominated sources.Besides CO, the chemistry of this type of source has been practically unknown thus far. We also present a very deep single-dish radio molecular survey in the 1.3, 2, 3, 7, and 13 mm bands (around 600 h of telescope time). Our results and detections allow us to classify our sources as O- or C-rich. We also conclude that the calculated abundances of the detected molecular species other than CO are particularly low, compared with AGB stars. This fact is very significant in those sources where the rotating disk is the dominant component of the nebula. Stochastic Compositional Optimization with Compositional Constraints Stochastic compositional optimization (SCO) has attracted considerable attention because of its broad applicability to important real-world problems. However, existing works on SCO assume that the projection within a solution update is simple, which fails to hold for problem instances where the constraints are in the form of expectations, such as empirical conditional value-at-risk constraints. We study a novel model that incorporates single-level expected value and two-level compositional constraints into the current SCO framework. Our model can be applied widely to data-driven optimization and risk management, including risk-averse optimization and high-moment portfolio selection, and can handle multiple constraints. We further propose a class of primal-dual algorithms that generates sequences converging to the optimal solution at the rate of $\cO(\frac{1}{\sqrt{N}})$under both single-level expected value and two-level compositional constraints, where $N$ is the iteration counter, establishing the benchmarks in expected value constrained SCO. In-situ animal behavior classification using knowledge distillation and fixed-point quantization We explore the use of knowledge distillation (KD) for learning compact and accurate models that enable classification of animal behavior from accelerometry data on wearable devices. To this end, we take a deep and complex convolutional neural network, known as residual neural network (ResNet), as the teacher model. ResNet is specifically designed for multivariate time-series classification. We use ResNet to distill the knowledge of animal behavior classification datasets into soft labels, which consist of the predicted pseudo-probabilities of every class for each datapoint. We then use the soft labels to train our significantly less complex student models, which are based on the gated recurrent unit (GRU) and multilayer perceptron (MLP). The evaluation results using two real-world animal behavior classification datasets show that the classification accuracy of the student GRU-MLP models improves appreciably through KD, approaching that of the teacher ResNet model. To further reduce the computational and memory requirements of performing inference using the student models trained via KD, we utilize dynamic fixed-point quantization (DQ) through an appropriate modification of the computational graph of the considered models. We implement both unquantized and quantized versions of the developed KD-based models on the embedded systems of our purpose-built collar and ear tag devices to classify animal behavior in situ and in real time. Our evaluations corroborate the effectiveness of KD and DQ in improving the accuracy and efficiency of in-situ animal behavior classification. Simultaneous Bright- and Dark-Field X-ray Microscopy at X-ray Free Electron Lasers The structures, strain fields, and defect distributions in solid materials underlie the mechanical and physical properties across numerous applications. Many modern microstructural microscopy tools characterize crystal grains, domains and defects required to map lattice distortions or deformation, but are limited to studies of the (near) surface. Generally speaking, such tools cannot probe the structural dynamics in a way that is representative of bulk behavior. Synchrotron X-ray diffraction based imaging has long mapped the deeply embedded structural elements, and with enhanced resolution, Dark Field X-ray Microscopy (DFXM) can now map those features with the requisite nm-resolution. However, these techniques still suffer from the required integration times due to limitations from the source and optics.
This work extends DFXM to X-ray free electron lasers, showing how the $10^{12}$ photons per pulse available at these sources offer structural characterization down to 100 fs resolution (orders of magnitude faster than current synchrotron images). We introduce the XFEL DFXM setup with simultaneous bright field microscopy to probe density changes within the same volume. This work presents a comprehensive guide to the multi-modal ultrafast high-resolution X-ray microscope that we constructed and tested at two XFELs, and shows initial data demonstrating two timing strategies to study associated reversible or irreversible lattice dynamics. Consistency pays off in science The exponentially growing number of scientific papers stimulates a discussion on the interplay between quantity and quality in science. In particular, one may wonder which publication strategy may offer more chances of success: publishing lots of papers, producing a few hit papers, or something in between. Here we tackle this question by studying the scientific portfolios of Nobel Prize laureates. A comparative analysis of different citation-based indicators of individual impact suggests that the best path to success may rely on consistently producing high-quality work. Such a pattern is especially rewarded by a new metric, the $E$-index, which identifies excellence better than state-of-the-art measures. Implicit Offline Reinforcement Learning via Supervised Learning Offline Reinforcement Learning (RL) via Supervised Learning is a simple and effective way to learn robotic skills from a dataset collected by policies of different expertise levels. It is as simple as supervised learning and Behavior Cloning (BC), but takes advantage of return information. On datasets collected by policies of similar expertise, implicit BC has been shown to match or outperform explicit BC. Despite the benefits of using implicit models to learn robotic skills via BC, offline RL via Supervised Learning algorithms have been limited to explicit models. We show how implicit models can leverage return information and match or outperform explicit algorithms to acquire robotic skills from fixed datasets. Furthermore, we show the close relationship between our implicit methods and other popular RL via Supervised Learning algorithms to provide a unified framework. Finally, we demonstrate the effectiveness of our method on high-dimension manipulation and locomotion tasks. Feedback Interacting Urn Models We introduce and discuss a special type of feedback interacting urn model with deterministic interaction. This is a generalisation of the very well known Eggenberger and Polya (1923) urn model. In our model, balls are added to a particular urn depending on the replacement matrix of that urn and the color of ball chosen from some other urn. This urn model can help in studying how various interacting models might behave in real life in the long run. We have also introduced a special type of interacting urn model with non-deterministic interaction and studied its behaviour. Furthermore, we have provided some nice examples to illustrate the various consequences of these interacting urn models. Follow the Wisdom of the Crowd: Effective Text Generation via Minimum Bayes Risk Decoding In open-ended natural-language generation, existing text decoding methods typically struggle to produce text which is both diverse and high-quality. Greedy and beam search are known to suffer from text degeneration and linguistic diversity issues, while temperature, top-k, and nucleus sampling often yield diverse but low-quality outputs. In this work, we present crowd sampling, a family of decoding methods based on Bayesian risk minimization, to address this diversity-quality trade-off. Inspired by the principle of "the wisdom of the crowd," crowd sampling seeks to select a candidate from a pool of candidates that has the least expected risk (i.e., highest expected reward) under a generative model according to a given utility function. Crowd sampling can be seen as a generalization of numerous existing methods, including majority voting, and in practice, it can be used as a drop-in replacement for existing sampling methods. Extensive experiments show that crowd sampling delivers improvements of 3-7 ROUGE and BLEU points across a wide range of tasks, including summarization, data-to-text, translation, and textual style transfer, while achieving new state-of-the-art results on WebNLG and WMT'16. Classification of Cellular Automata based on Statistical Mechanics Cellular automata are a set of computational models in discrete space that have a discrete time evolution defined by neighbourhood rules. They are used to simulate many complex systems in physics and science in general. In this work, statistical mechanics and thermodynamics are used to analyse a large set of outer totalistic two-dimensional cellular automata. Thermodynamic variables and potentials are derived and computed according to three different approaches to determine if a cellular automaton rule is representing a system akin to the ideal gas, in or out of the thermodynamical equilibrium. It is suggested that this classification is sufficiently robust and predictive of interesting properties for particular set of rules. Influence of Economic Decoupling in assessing carbon budget quotas for the European Union In the present study, for the first time, an effort sharing approach based on Inertia and Capability principles is proposed to assess European Union (EU27) carbon budget distribution among the Member States. This is done within the context of achieving the Green Deal objective and EU27 carbon neutrality by 2050. An in-depth analysis is carried out about the role of Economic Decoupling embedded in the Capability principle to evaluate the correlation between the expected increase of economic production and the level of carbon intensity in the Member States. As decarbonization is a dynamic process, the study proposes a simple mathematical model as a policy tool to assess and redistribute Member States carbon budgets as frequently as necessary to encourage progress or overcome the difficulties each Member State may face during the decarbonization pathways. Remarks on symmetric fusion categories of low rank in positive characteristic We give lower bounds for the rank of a symmetric fusion category in characteristic $p\geq 5$ in terms of $p$. We prove that the second Adams operation $\psi_2$ is not the identity for any non-trivial symmetric fusion category, and that symmetric fusion categories satisfying $\psi_2^a=\psi_2^{a-1}$ for some positive integer $a$ are super Tannakian. As an application, we classify all symmetric fusion categories of rank 3 and those of rank 4 with exactly two self dual simple objects. A Tractable Probability Distribution with Applications in Three-Dimensional Statistics This paper introduces and characterizes a new family of continuous probability distributions applicable to norm distributions in three-dimensional random spaces, specifically for the Euclidean norm of three random Gaussian variables with non-zero means. The distribution is specified over the semi-infinite range $[0,\infty)$ and is notable for its computational tractability. Building on this foundation, we also introduce a separate family of continuous probability distributions suitable for power distributions in three-dimensional random spaces. Despite being previously unknown, these distributions are attractive for numerous applications, some of which are discussed in this work. RIS-Assisted Green Secure Communications: Active RIS or Passive RIS? Reconfigurable Intelligent Surface (RIS) is one of the promising techniques for 6G wireless communications, and recently has also been shown to be able to improve secure communications. However, there is a "double fading" effect in the reflection link between base station and user, thus passive RIS only achieves a negligible secrecy gain in typical communications scenarios.In this letter, we propose an active RIS-aided multi-antenna physical layer secrecy transmission scheme, where the active RIS can amplify the signal actively. Our aim is to minimize the transmit power subject to the constraint of secrecy rate. To solve the non-convex optimization problem, a penalty-based alternating minimization (AltMin) algorithm is proposed to optimize both the beamformer at the transmitter and the reflection matrix at RIS. Simulation results show that active RIS can resist the impact of "double fading" effect effectively, and is more energy efficient than passive RIS. Diagonal property and weak point property of higher rank divisors and certain Hilbert schemes In this paper, we introduce the notion of the diagonal property and the weak point property for an ind-variety. We prove that the ind-varieties of higher rank divisors of integral slopes on a smooth projective curve have the weak point property. Moreover, we show that the ind-variety of $(1,n)$-divisors has the diagonal property. Furthermore, we obtain that the Hilbert schemes associated to the good partitions of a constant polynomial satisfy the diagonal property.
On the process of obtaining this, we provide an upper bound on the number of such Hilbert schemes up to isomorphism. Furthermore, we prove that the obtained upper bound is attained in case of genus zero curves and hence conclude that the bound is sharp. Projection hypothesis in the setting for the quantum Jarzynski equality Projective quantum measurement is a theoretically accepted process in modern quantum mechanics. However, its projection hypothesis is widely regarded as an experimentally established empirical law. In this paper, we combine a previous result regarding the realization of a Hamiltonian process of the projection hypothesis in projective quantum measurement, where the complete set of the orbital observables of the center of mass of a macroscopic quantum mechanical system is restricted to a set of mutually commuting classical observables, and a previous result regarding the work required for an event reading (i.e., the informatical process in projective quantum measurement). Then, a quantum thermodynamic scheme is proposed for experimentally testing these two mutually independent theoretical results of projective quantum measurement simultaneously. Probing spacetime and accretion model for the Galactic Center: Comparison of Kerr and dilaton black hole shadows In the vicinity of black holes, the influence of strong gravity, plasma physics, and emission processes govern the behavior of the system. Since observations such as those carried out by the EHT are not yet able to unambiguously constrain models for astrophysical and gravitational properties, it is imperative to explore the accretion models, particle distribution function, and description of the spacetime geometry. Our current understanding of these properties is often based on the assumption that the spacetime is well-described by by the Kerr solution to general relativity, combined with basic emission and accretion models. We explore alternative models for each property performing general relativistic magnetohydrodynamic and radiative transfer simulations. By choosing a Kerr solution to general relativity and a dilaton solution to Einstein-Maxwell-dilaton-axion gravity as exemplary black hole background spacetimes, we aim to investigate the influence of accretion and emission models on the ability to distinguish black holes in two theories of gravity. We carry out three-dimensional general relativistic magnetohydrodynamics simulations of both black holes, matched at their innermost stable circular orbit, in two distinct accretion scenarios. Using general-relativistic radiative transfer calculations, we model the thermal synchrotron emission and in the next step apply a non-thermal electron distribution function, exploring representative parameters to compare with multiwavelength observations. We further consider Kerr and dilaton black holes matched at their unstable circular photon orbits, as well as their event horizons. From multiwavelength emission and spectral index analysis, we find that accretion model and spacetime have only a small impact on the spectra compared to the choice of emission model. Self-Supervised Pre-Training for Deep Image Prior-Based Robust PET Image Denoising Deep image prior (DIP) has been successfully applied to positron emission tomography (PET) image restoration, enabling represent implicit prior using only convolutional neural network architecture without training dataset, whereas the general supervised approach requires massive low- and high-quality PET image pairs. To answer the increased need for PET imaging with DIP, it is indispensable to improve the performance of the underlying DIP itself. Here, we propose a self-supervised pre-training model to improve the DIP-based PET image denoising performance. Our proposed pre-training model acquires transferable and generalizable visual representations from only unlabeled PET images by restoring various degraded PET images in a self-supervised approach. We evaluated the proposed method using clinical brain PET data with various radioactive tracers ($^{18}$F-florbetapir, $^{11}$C-Pittsburgh compound-B, $^{18}$F-fluoro-2-deoxy-D-glucose, and $^{15}$O-CO$_{2}$) acquired from different PET scanners. The proposed method using the self-supervised pre-training model achieved robust and state-of-the-art denoising performance while retaining spatial details and quantification accuracy compared to other unsupervised methods and pre-training model. These results highlight the potential that the proposed method is particularly effective against rare diseases and probes and helps reduce the scan time or the radiotracer dose without affecting the patients. Klein-Gordon-Maxwell equations driven by mixed local-nonlocal operators Classical results concerning Klein-Gordon-Maxwell type systems are shortly reviewed and generalized to the setting of mixed local-nonlocal operators, where the nonlocal one is allowed to be nonpositive definite according to a real parameter. In this paper, we provide a range of parameter values to ensure the existence of solitary (standing) waves, obtained as Mountain Pass critical points for the associated energy functionals in two different settings, by considering two different classes of potentials: constant potentials and continuous, bounded from below, and coercive potentials. Optimal Trading in Automatic Market Makers with Deep Learning This article explores the optimisation of trading strategies in Constant Function Market Makers (CFMMs) and centralised exchanges. We develop a model that accounts for the interaction between these two markets, estimating the conditional dependence between variables using the concept of conditional elicitability. Furthermore, we pose an optimal execution problem where the agent hides their orders by controlling the rate at which they trade. We do so without approximating the market dynamics. The resulting dynamic programming equation is not analytically tractable, therefore, we employ the deep Galerkin method to solve it. Finally, we conduct numerical experiments and illustrate that the optimal strategy is not prone to price slippage and outperforms na\"ive strategies. Conductance oscillations of antiferromagnetic layer tunnel junctions We study the conductance oscillation of an antiferromagnetic layer tunnel junction composed of antiferromagnetic topological insulators (MTIs) such as MnBi$_{2}$Te$_{4}$. In presence of an in-plane magnetic field, we find that the two terminal differential conductance across the junction oscillates as a function of field strength. Notably, the quantum interference at weak fields for the odd-layer MTIs is distinctive from the even-layer MTIs due to the scattering phase difference. Consequently, the differential conductance is vanishing (maximized) at integer magnetic flux quanta for even-layer (odd-layer) junction. The conductance oscillations manifest the layer-dependent quantum interference in which symmetries and scattering phases play essential roles. In numerical calculations, we observe that the quantum interference undergoes an evolution from SQUID-like patterns to Fraunhofer-like oscillations as the junction length increases. HV Geometry for Signal Comparison In order to compare and interpolate signals, we investigate a Riemannian geometry on the space of signals. The metric allows discontinuous signals and measures both horizontal (thus providing many benefits of the Wasserstein metric) and vertical deformations. Moreover, it allows for signed signals, which overcomes the main deficiency of optimal transportation-based metrics in signal processing. We characterize the metric properties of the space of signals and establish the regularity and stability of geodesics. Furthermore, we introduce an efficient numerical scheme to compute the geodesics and present several experiments which highlight the nature of the metric. A posteriori error estimation for the optimal control of time-periodic eddy current problems This work presents the multiharmonic analysis and derivation of functional type a posteriori estimates of a distributed eddy current optimal control problem and its state equation in a time-periodic setting. The existence and uniqueness of the solution of a weak space-time variational formulation for the optimality system and the forward problem are proved by deriving inf-sup and sup-sup conditions. Using the inf-sup and sup-sup conditions, we derive guaranteed, sharp, and fully computable bounds of the approximation error for the optimal control problem and the forward problem in the functional type a posteriori estimation framework. We present here the first computational results on the derived estimates. Giant spin Nernst effect in a two-dimensional antiferromagnet due to magnetoelastic coupling-induced gaps and interband transitions between magnon-like bands We analyze theoretically the origin of the spin Nernst and thermal Hall effects in FePS3 as a realization of two-dimensional antiferromagnet (2D AFM). We find that a strong magnetoelastic coupling, hybridizing magnetic excitation (magnon) and elastic excitation (phonon), combined with time-reversal-symmetry-breaking, results in a Berry curvature hotspots in the region of anticrossing between the two distinct hybridized bands.
Furthermore, large spin Berry curvature emerges due to interband transitions between two magnon-like bands, where a small energy gap is induced by magnetoelastic coupling between such bands that are energetically distant from anticrossing of hybridized bands. These nonzero Berry curvatures generate topological transverse transport (i.e., the thermal Hall effect) of hybrid excitations, dubbed magnon-polaron, as well as of spin (i.e., the spin Nernst effect) carried by them, in response to applied longitudinal temperature gradient. We investigate the dependence of the spin Nernst and thermal Hall conductivities on the applied magnetic field and temperature, unveiling very large spin Nernst conductivity even at zero magnetic field. Our results suggest FePS3 AFM, which is already available in 2D form experimentally, as a promising platform to explore the topological transport of the magnon-polaron quasiparticles at THz frequencies. An efficient solver for ASP(Q) Answer Set Programming with Quantifiers ASP(Q) extends Answer Set Programming (ASP) to allow for declarative and modular modeling of problems from the entire polynomial hierarchy. The first implementation of ASP(Q), called qasp, was based on a translation to Quantified Boolean Formulae (QBF) with the aim of exploiting the well-developed and mature QBF-solving technology. However, the implementation of the QBF encoding employed in qasp is very general and might produce formulas that are hard to evaluate for existing QBF solvers because of the large number of symbols and sub-clauses. In this paper, we present a new implementation that builds on the ideas of qasp and features both a more efficient encoding procedure and new optimized encodings of ASP(Q) programs in QBF. The new encodings produce smaller formulas (in terms of the number of quantifiers, variables, and clauses) and result in a more efficient evaluation process. An algorithm selection strategy automatically combines several QBF-solving back-ends to further increase performance. An experimental analysis, conducted on known benchmarks, shows that the new system outperforms qasp. DRCFS: Doubly Robust Causal Feature Selection Knowing the features of a complex system that are highly relevant to a particular target variable is of fundamental interest in many areas of science. Existing approaches are often limited to linear settings, sometimes lack guarantees, and in most cases, do not scale to the problem at hand, in particular to images. We propose DRCFS, a doubly robust feature selection method for identifying the causal features even in nonlinear and high dimensional settings. We provide theoretical guarantees, illustrate necessary conditions for our assumptions, and perform extensive experiments across a wide range of simulated and semi-synthetic datasets. DRCFS significantly outperforms existing state-of-the-art methods, selecting robust features even in challenging highly non-linear and high-dimensional problems. Ultrafast switching of topological invariants by light-driven strain Reversible control of the topological invariants from nontrivial to trivial states has fundamental implications for quantum information processors and spintronics, by realizing of an on/off switch for robust and dissipationless spin-current. Although mechanical strain has typically advantageous for such control of topological invariants, it is often accompanied by in-plane fractures and is not suited for high-speed, time-dependent operations. Here, we use ultrafast optical and THz spectroscopy to investigate topological phase transitions by light-driven strain in Bi$_2$Se$_3$, a material that requires substantial strain for $\mathrm{Z}_2$ switching. We show that Bi$_2$Se$_3$ experiences ultrafast switching from being a topological insulator with spin-momentum-locked surfaces, to hybridized states and normal insulating phases at ambient conditions. Light-induced strong out-of-plane strain can suppress the surface-bulk coupling, enabling differentiation of surface and bulk conductance at room temperature, far above the Debye temperature. We illustrate various time-dependent sequences of transient hybridization, as well as the switching operation of topological invariants by adjusting the photoexcitation intensity. The abrupt alterations in both surface and bulk transport near the transition point allow for coherent conductance modulation at hyper-sound frequencies. Our findings regarding light-triggered ultrafast switching of topological invariants pave the way for high-speed topological switching and its associated applications. Reliable computation by large-alphabet formulas in the presence of noise We present two new positive results for reliable computation using formulas over physical alphabets of size $q > 2$. First, we show that for logical alphabets of size $\ell = q$ the threshold for denoising using gates subject to $q$-ary symmetric noise with error probability $\varepsilon$ is strictly larger than that for Boolean computation, and is possible as long as signals remain distinguishable, i.e. $\epsilon < (q - 1) / q$, in the limit of large fan-in $k \rightarrow \infty$. We also determine the point at which generalized majority gates with bounded fan-in fail, and show in particular that reliable computation is possible for $\epsilon < (q - 1) / (q (q + 1))$ in the case of $q$ prime and fan-in $k = 3$. Secondly, we provide an example where $\ell < q$, showing that reliable Boolean computation can be performed using $2$-input ternary logic gates subject to symmetric ternary noise of strength $\varepsilon < 1/6$ by using the additional alphabet element for error signaling. Orbit Classification of asteroids using implementation of radial Basis Function on Support Vector Machines This research paper focuses on the implementation of radial Basis Function (RBF) Support Vector Machines (SVM) for classifying asteroid orbits. Asteroids are important astronomical objects, and their orbits play a crucial role in understanding the dynamics of the solar system. The International Astronomical Union maintains data archives that provide a playground to experiment with various machine-learning techniques. In this study, we explore the application of RBF SVM algorithm to classify asteroids. The results show that the RBF SVM algorithm provides a good efficiency and accuracy to the dataset. We also analyze the impact of various parameters on the performance of the RBF SVM algorithm and present the optimal parameter settings. Our study highlights the importance of using machine learning techniques for classifying asteroid orbits and the effectiveness of the RBF SVM algorithm in this regard. Stellar properties of observed stars stripped in binaries in the Magellanic Clouds Massive stars (~8-25Msun) stripped of their hydrogen-rich envelopes via binary interaction are thought to be the main progenitors for merging neutron stars and stripped-envelope supernovae. We recently presented the discovery of the first set of such stripped stars in a companion paper. Here, we fit the spectra of ten stars with new atmosphere models in order to constrain their stellar properties precisely. We find that the stellar properties align well with the theoretical expectations from binary evolution models for helium-core burning envelope-stripped stars. The fits confirm that the stars have high effective temperatures (Teff~50-100kK), high surface gravities (log g ~5), and hydrogen-poor/helium-rich surfaces (X(H, surf)~0-0.4) while showing for the first time a range of bolometric luminosities (10^3-10^5 Lsun), small radii (~0.5-1Rsun), and low Eddington factors (Gamma_e~0.006-0.4). Using these properties, we derive intermediate current masses (~1-8Msun), which suggest that their progenitors were massive stars (~5-25Msun) and that a subset will reach core-collapse, leaving behind neutron stars or black holes. Using the model fits, we also estimate the emission rates of ionizing photons for these stars, which agree well with previous model expectations. Further, by computing models for a range of mass-loss rates, we find that the stellar winds are weaker than predicted by any existing scheme (Mdot(wind)<~ 1e-9 Msun/yr). The properties of this first sample of intermediate mass helium stars suggest they both contain progenitors of type Ib and IIb supernovae, and provide important benchmarks for binary evolution and population synthesis models.
Combinatorics of $m=1$ Grasstopes A Grasstope is the image of the totally nonnegative Grassmannian $\text{Gr}_{\geq 0}(k,n)$ under a linear map $\text{Gr}(k,n)\dashrightarrow \text{Gr}(k,k+m)$. This is a generalization of the amplituhedron, a geometric object of great importance to calculating scattering amplitudes in physics. The amplituhedron is a Grasstope arising from a totally positive linear map. While amplituhedra are relatively well-studied, much less is known about general Grasstopes. We study Grasstopes in the $m=1$ case and show that they can be characterized as unions of cells of a hyperplane arrangement satisfying a certain sign variation condition, extending work of Karp and Williams. Inspired by this characterization, we also suggest a notion of a Grasstope arising from an arbitrary oriented matroid. Discovery of Delta Scuti variables in eclipsing binary systems II.Southern TESS field search The presence of pulsating stars in eclipsing binary systems (EBs) makes these objects significant since they allow us to investigate the stellar interior structure and evolution. Different types of pulsating stars could be found in EBs such as Delta Scuti variables. Delta Scuti stars in EBs have been known for decades and the increasing number of such systems is important for understanding pulsational structure. Hence, in this study, a research was carried out on the southern TESS field to discover new Delta Scuti stars in EBs. We produced an algorithm to search for detached and semi-detached EBs considering three steps; the orbital period (P$_{orb}$)'s harmonics in the Fourier spectrum, skewness of the light curves, and classification of \textsc{UPSILON} program. If two of these steps classify a system as an EB, the algorithm also identifies it as an EB. The TESS pixel files of targets were also analyzed to see whether the fluxes are contaminated by other systems. No contamination was found. We researched the existence of pulsation through EBs with a visual inspection. To confirm Delta Scuti-type oscillations, the binary variation was removed from the light curve, and residuals were analyzed. Consequently, we identified 42 Delta Scuti candidates in EBs. The P$_{orb}$, $L$, and M$_{V}$ of systems were calculated. Their positions on the H-R diagram and the known orbital-pulsation period relationship were analyzed. We also examined our targets to find if any of them show frequency modulation with the orbital period and discovered one candidate of tidally tilted pulsators. Overtaking Moving Obstacles with Digit: Path Following for Bipedal Robots via Model Predictive Contouring Control Humanoid robots are expected to navigate in changing environments and perform a variety of tasks. Frequently, these tasks require the robot to make decisions online regarding the speed and precision of following a reference path. For example, a robot may want to decide to temporarily deviate from its path to overtake a slowly moving obstacle that shares the same path and is ahead. In this case, path following performance is compromised in favor of fast path traversal. Available global trajectory tracking approaches typically assume a given -- specified in advance -- time parametrization of the path and seek to minimize the norm of the Cartesian error. As a result, when the robot should be where on the path is fixed and temporary deviations from the path are strongly discouraged. Given a global path, this paper presents a Model Predictive Contouring Control (MPCC) approach to selecting footsteps that maximize path traversal while simultaneously allowing the robot to decide between faithful versus fast path following. The method is evaluated in high-fidelity simulations of the bipedal robot Digit in terms of tracking performance of curved paths under disturbances and is also applied to the case where Digit overtakes a moving obstacle. Enhancements on a saturated control for stabilizing a quadcopter: adaptive and robustness analysis in the flat output space This paper extends our previous study on an explicit saturated control for a quadcopter, which ensures both constraint satisfaction and stability thanks to the linear representation of the system in the flat output space. The novelty here resides in the adaptivity of the controller's gain to enhance the system's performance without exciting its parasitic dynamics and avoid lavishing the input actuation with excessively high gain parameters. Moreover, we provide a thorough robustness analysis of the proposed controller when additive disturbances are affecting the system behavior. Finally, simulation and experimental tests validate the proposed controller. ACNPU: A 4.75TOPS/W 1080P@30FPS Super Resolution Accelerator with Decoupled Asymmetric Convolution Deep learning-driven superresolution (SR) outperforms traditional techniques but also faces the challenge of high complexity and memory bandwidth. This challenge leads many accelerators to opt for simpler and shallow models like FSRCNN, compromising performance for real-time needs, especially for resource-limited edge devices. This paper proposes an energy-efficient SR accelerator, ACNPU, to tackle this challenge. The ACNPU enhances image quality by 0.34dB with a 27-layer model, but needs 36\% less complexity than FSRCNN, while maintaining a similar model size, with the \textit{decoupled asymmetric convolution and split-bypass structure}. The hardware-friendly 17K-parameter model enables \textit{holistic model fusion} instead of localized layer fusion to remove external DRAM access of intermediate feature maps. The on-chip memory bandwidth is further reduced with the \textit{input stationary flow} and \textit{parallel-layer execution} to reduce power consumption. Hardware is regular and easy to control to support different layers by \textit{processing elements (PEs) clusters with reconfigurable input and uniform data flow}. The implementation in the 40 nm CMOS process consumes 2333 K gate counts and 198KB SRAMs. The ACNPU achieves 31.7 FPS and 124.4 FPS for x2 and x4 scales Full-HD generation, respectively, which attains 4.75 TOPS/W energy efficiency. LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins Large language model (LLM) platforms, such as ChatGPT, have recently begun offering an app ecosystem to interface with third-party services on the internet. While these apps extend the capabilities of LLM platforms, they are developed by arbitrary third parties and thus cannot be implicitly trusted. Apps also interface with LLM platforms and users using natural language, which can have imprecise interpretations. In this paper, we propose a framework that lays a foundation for LLM platform designers to analyze and improve the security, privacy, and safety of current and future third-party integrated LLM platforms. Our framework is a formulation of an attack taxonomy that is developed by iteratively exploring how LLM platform stakeholders could leverage their capabilities and responsibilities to mount attacks against each other. As part of our iterative process, we apply our framework in the context of OpenAI's plugin (apps) ecosystem. We uncover plugins that concretely demonstrate the potential for the types of issues that we outline in our attack taxonomy. We conclude by discussing novel challenges and by providing recommendations to improve the security, privacy, and safety of present and future LLM-based computing platforms. A Hybrid Deep Learning-based Approach for Optimal Genotype by Environment Selection Precise crop yield prediction is essential for improving agricultural practices and ensuring crop resilience in varying climates. Integrating weather data across the growing season, especially for different crop varieties, is crucial for understanding their adaptability in the face of climate change. In the MLCAS2021 Crop Yield Prediction Challenge, we utilized a dataset comprising 93,028 training records to forecast yields for 10,337 test records, covering 159 locations across 28 U.S. states and Canadian provinces over 13 years (2003-2015). This dataset included details on 5,838 distinct genotypes and daily weather data for a 214-day growing season, enabling comprehensive analysis.
As one of the winning teams, we developed two novel convolutional neural network (CNN) architectures: the CNN-DNN model, combining CNN and fully-connected networks, and the CNN-LSTM-DNN model, with an added LSTM layer for weather variables. Leveraging the Generalized Ensemble Method (GEM), we determined optimal model weights, resulting in superior performance compared to baseline models. The GEM model achieved lower RMSE (5.55% to 39.88%), reduced MAE (5.34% to 43.76%), and higher correlation coefficients (1.1% to 10.79%) when evaluated on test data. We applied the CNN-DNN model to identify top-performing genotypes for various locations and weather conditions, aiding genotype selection based on weather variables. Our data-driven approach is valuable for scenarios with limited testing years. Additionally, a feature importance analysis using RMSE change highlighted the significance of location, MG, year, and genotype, along with the importance of weather variables MDNI and AP. Evaluating the Usability of Differential Privacy Tools with Data Practitioners Differential privacy (DP) has become the gold standard in privacy-preserving data analytics, but implementing it in real-world datasets and systems remains challenging. Recently developed DP tools aim to make DP implementation easier, but limited research has investigated these DP tools' usability. Through a usability study with 24 US data practitioners with varying prior DP knowledge, we evaluated the usability of four Python-based open-source DP tools: DiffPrivLib, Tumult Analytics, PipelineDP, and OpenDP. Our results suggest that using DP tools in this study may help DP novices better understand DP; that Application Programming Interface (API) design and documentation are vital for successful DP implementation; and that user satisfaction correlates with how well participants completed study tasks with these DP tools. We provide evidence-based recommendations to improve DP tools' usability to broaden DP adoption. Variational and Strong Variational Convexity in Infinite-Dimensional Variational Analysis This paper is devoted to a systematic study and characterizations of the fundamental notions of variational and strong variational convexity for lower semicontinuous functions. While these notions have been quite recently introduced by Rockafellar, the importance of them has been already recognized and documented in finite-dimensional variational analysis and optimization. Here we address general infinite-dimensional settings and derive comprehensive characterizations of both variational and strong variational convexity notions by developing novel techniques, which are essentially different from finite-dimensional counterparts. As a consequence of the obtained characterizations, we establish new quantitative and qualitative relationships between strong variational convexity and tilt stability of local minimizers in appropriate frameworks of Banach spaces. Accumulation points of normalized approximations Building on classical aspects of the theory of Diophantine approximation, we consider the collection of all accumulation points of normalized integer vector translates of points $q\alpha$ with $\alpha\in\mathbb{R}^d$ and $q\in\mathbb{Z}$. In the first part of the paper we derive measure theoretic and Hausdorff dimension results about the set of $\alpha$ whose accumulation points are all of $\mathbb{R}^d$. In the second part we focus primarily on the case when the coordinates of $\alpha$ together with $1$ form a basis for an algebraic number field $K$. Here we show that, under the correct normalization, the set of accumulation points displays an ordered geometric structure which reflects algebraic properties of the underlying number field. For example, when $d=2$, this collection of accumulation points can be described as a countable union of dilates (by norms of elements of an order in $K$) of a single ellipse, or of a pair of hyperbolas, depending on whether or not $K$ has a non-trivial embedding into $\mathbb{C}$. Patchy landscapes promote stability of small groups Group formation and coordination are fundamental characteristics of living systems, essential for performing tasks and ensuring survival. Interactions between individuals play a key role in group formation, and the impact of resource distributions is a vibrant area of research. Using active particles in a tuneable optical environment as a model system, we demonstrate that heterogeneous energy source distributions result in smaller, more stable groups with reduced individual exchange between clusters compared to homogeneous conditions. Reduced group sizes can be beneficial to optimise resources in heterogeneous environments and to control information flow within populations. Devoid of biological complications, our system provides insights into the importance of patchy landscapes in ecological dynamics and holds implications for refining swarm intelligence algorithms and enhancing crowd control techniques. Online Resource Sharing via Dynamic Max-Min Fairness: Efficiency, Robustness and Non-Stationarity We study the allocation of shared resources over multiple rounds among competing agents, via a dynamic max-min fair (DMMF) mechanism: the good in each round is allocated to the requesting agent with the least number of allocations received to date. Previous work has shown that when an agent has i.i.d. values across rounds, then in the worst case, she can never get more than a constant strictly less than $1$ fraction of her ideal utility -- her highest achievable utility given her nominal share of resources. Moreover, an agent can achieve at least half her utility under carefully designed `pseudo-market' mechanisms, even though other agents may act in an arbitrary (possibly adversarial and collusive) manner. We show that this robustness guarantee also holds under the much simpler DMMF mechanism. More significantly, under mild assumptions on the value distribution, we show that DMMF in fact allows each agent to realize a $1 - o(1)$ fraction of her ideal utility, despite arbitrary behavior by other agents. We achieve this by characterizing the utility achieved under a richer space of strategies, wherein an agent can tune how aggressive to be in requesting the item. Our new strategies also allow us to handle settings where an agent's values are correlated across rounds, thereby allowing an adversary to predict and block her future values. We prove that again by tuning one's aggressiveness, an agent can guarantee $\Omega(\gamma)$ fraction of her ideal utility, where $\gamma\in [0, 1]$ is a parameter that quantifies dependence across rounds (with $\gamma = 1$ indicating full independence and lower values indicating more correlation). Finally, we extend our efficiency results to the case of reusable resources, where an agent might need to hold the item over multiple rounds to receive utility. Improved bounds for the two-point logarithmic Chowla conjecture Let $\lambda$ be the Liouville function, defined as $\lambda(n) := (-1)^{\Omega(n)}$ where $\Omega(n)$ is the number of prime factors of $n$ with multiplicity. In 2021, Helfgott and Radziwi{\l}{\l} proved that $$\sum_{n\leq x} \frac{1}{n} \lambda(n) \lambda(n+1) \ll \frac{\log x}{(\log \log x)^{1/2}},$$improving earlier results by Tao and Ter\"av\"ainen. We prove that $$\sum_{n\leq x} \frac{1}{n} \lambda(n) \lambda(n+1) \ll (\log x)^{1-c}$$for some absolute constant $c>0$. This appears to be best possible with current methods. Intelligent Reflecting Surface-Aided Wireless Communication with Movable Elements Intelligent reflecting surface (IRS) has been recognized as a powerful technology for boosting communication performance. To reduce manufacturing and control costs, it is preferable to consider discrete phase shifts (DPSs) for IRS, which are set by default as uniformly distributed in the range of $[ - \pi,\pi )$ in the literature. Such setting, however, cannot achieve a desirable performance over the general Rician fading where the channel phase concentrates in a narrow range with a higher probability. Motivated by this drawback, we in this paper design optimal non-uniform DPSs for IRS to achieve a desirable performance level. The fundamental challenge is the \textit{possible offset in phase distribution across different cascaded source-element-destination channels}, if adopting conventional IRS where the position of each element is fixed.
Such phenomenon leads to different patterns of optimal non-uniform DPSs for each IRS element and thus causes huge manufacturing costs especially when the number of IRS elements is large. Driven by the recently emerging fluid antenna system (or movable antenna technology), we demonstrate that if the position of each IRS element can be flexibly adjusted, the above phase distribution offset can be surprisingly eliminated, leading to the same pattern of DPSs for each IRS element. Armed with this, we then determine the form of unified non-uniform DPSs based on a low-complexity iterative algorithm. Simulations show that our proposed design significantly improves the system performance compared to competitive benchmarks. Global H\"{o}lder solvability of linear and quasilinear Poisson equations We discuss the homogeneous Dirichlet problem for $p$-Poisson type equations with locally finite measure data. If there is a H\"{o}lder continuous solution, the corresponding data satisfies a local Morrey type condition. The main result of this paper provides existence of a global H\"{o}lder continuous solution under the same condition. The existence result gives a compact embedding theorem. Our results are also new even for the Poisson equation. Efficient Open-world Reinforcement Learning via Knowledge Distillation and Autonomous Rule Discovery Deep reinforcement learning suffers from catastrophic forgetting and sample inefficiency making it less applicable to the ever-changing real world. However, the ability to use previously learned knowledge is essential for AI agents to quickly adapt to novelties. Often, certain spatial information observed by the agent in the previous interactions can be leveraged to infer task-specific rules. Inferred rules can then help the agent to avoid potentially dangerous situations in the previously unseen states and guide the learning process increasing agent's novelty adaptation speed. In this work, we propose a general framework that is applicable to deep reinforcement learning agents. Our framework provides the agent with an autonomous way to discover the task-specific rules in the novel environments and self-supervise it's learning. We provide a rule-driven deep Q-learning agent (RDQ) as one possible implementation of that framework. We show that RDQ successfully extracts task-specific rules as it interacts with the world and uses them to drastically increase its learning efficiency. In our experiments, we show that the RDQ agent is significantly more resilient to the novelties than the baseline agents, and is able to detect and adapt to novel situations faster. Anomalous Josephson diode effect in superconducting multilayers In this study, we explore the Josephson current-phase relation within a planar diffuse tunneling superconducting multilayer junction subjected to a parallel magnetic field. Our investigation involves computing the supercurrent associated with a fixed jump in the phase of the order parameter at each of the two insulating interfaces, allowing us to derive the current-phase relation for the junction. Employing perturbation theory in junction conductance, we determine both the first and second harmonics of the current-phase relation under specific magnetic field conditions. Notably, the presence of a strong spin-orbit interaction in the middle region of the junction introduces an anomalous Josephson effect. The interplay between spin-orbit and Zeeman interactions results in the emergence of an effective vector potential. This specific characteristic induces a phase shift in each harmonic of the current-phase relation without altering the overall shape of the relation. The mechanism for the Josephson diode effect is discussed for disordered junctions of multiband superconductors. Traces of semi-invariants This article investigates the traces of certain modules over rings of invariants associated with finite groups. More precisely, we provide a formula for computing the traces of arbitrary semi-invariants, thereby contributing to the understanding of the non-Gorenstein locus of rings of invariants. Additionally, we discuss applications of this formula, including criteria for rings of invariants to be Gorenstein on the punctured spectrum and nearly Gorenstein, as well as criteria for semi-invariants to be locally free. Energy growth for systems of coupled oscillators with partial damping We consider two interacting particles on the circle. The particles are subject to stochastic forcing, which is modeled by white noise. In addition, one of the particles is subject to friction, which models energy dissipation due to the interaction with the environment. We show that, in the diffusive limit, the absolute value of the velocity of the other particle converges to the reflected Brownian motion. In other words, the interaction between the particles are asymptotically negligible in the scaling limit. The proof combines averaging for large energies with large deviation estimates for small energies. Rotation-Invariant Rapid TRISO-Fueled Pebble Identification Based on Feature Matching and Point Cloud Registration Pebble bed reactor (PBR) relying on TRISO-fueled pebbles is one of the most promising Gen-IV reactor designs because of intrinsic safety and thermal efficiency. Fuel pebbles flow through PBR's core and the identification of individual pebbles exiting the core will be beneficial to improve safeguards and fuel management. We propose a pebble identification method that is fast, accurate, robust, and applicable to PBRs containing hundreds of thousands of pebbles. The identification relies on the internal distribution of TRISO fuel particles, which is a unique feature of each pebble. We experimentally demonstrated that X-ray CT can extract the particle distribution with high accuracy. We then applied the algorithm to identify a single pebble in a data set of 100,000 pebbles achieving 100% identification accuracy in 90,000 tests with the presence of arbitrary rotations and measurement noises. The average time to identify one pebble is below 50 s, compatible with PBR operation. HD 110067 is a wide hierarchical triple system We report that HD 110067, the recently announced host star of a resonant sextuplet of transiting sub-Neptunes, is not a single star as claimed in the discovery paper, but a wide hierarchical triple. The K0 V planet hosting star (V = 8.4 mag, d = 32 pc) has a companion at a wide projected separation of 13400 au. This companion, namely HD 110106, is a slightly fainter (V = 8.8 mag) K3 V type 8-year period double-lined spectroscopic binary. The secondary in this spectroscopic binary is contributing a significant amount of flux and has a measured high mass ratio. Irreducible modules of modular Lie superalgebras and super version of the first Kac-Weisfeiler conjecture Suppose $g=g_0+g_1$ is a finite-dimensional restricted Lie superalgebra over an algebraically closed field $k$ of characteristic $p>2$. In this article, we propose a conjecture for maximal dimensions of irreducible modules over the universal enveloping algebra $U(g)$ of $g$, as a super generalization of the celebrated first Kac-Weisfeiler conjecture. It is demonstrated that the conjecture holds for all basic classical Lie superalgebras and all completely solvable restricted Lie superalgebras. In this process, we investigate irreducible representations of solvable Lie superalgebras. Flip Graphs on Self-Complementary Ideals of Chain Products In this paper, we introduce a flip operation on self-complementary ideals of chain product posets and study the resulting flip graphs. We give asymptotics for the number of vertices in these graphs, compute their diameters, and give bounds for their radii. We also define similar flip operations on self-complementary ideals of the chain product $[2r]\times [2r]\times [2r]$ satisfying additional symmetries, and we achieve similar results for the resulting flip graphs. Graph-based Algorithms for Linear Computation Coding We revisit existing linear computation coding (LCC) algorithms, and introduce a new framework that measures the computational cost of computing multidimensional linear functions, not only in terms of the number of additions, but also with respect to their suitability for parallel processing. Utilizing directed acyclic graphs, which correspond to signal flow graphs in hardware, we propose a novel LCC algorithm that controls the trade-off between the total number of operations and their parallel executability. Numerical evaluations show that the proposed algorithm, constrained to a fully parallel structure, outperforms existing schemes.
Cross-Task Affinity Learning for Multitask Dense Scene Predictions Multitask learning (MTL) has become prominent for its ability to predict multiple tasks jointly, achieving better per-task performance with fewer parameters than single-task learning. Recently, decoder-focused architectures have significantly improved multitask performance by refining task predictions using features from related tasks. However, most refinement methods struggle to efficiently capture both local and long-range dependencies between task-specific representations and cross-task patterns. In this paper, we introduce the Cross-Task Affinity Learning (CTAL) module, a lightweight framework that enhances task refinement in multitask networks. CTAL effectively captures local and long-range cross-task interactions by optimizing task affinity matrices for parameter-efficient grouped convolutions without concern for information loss. Our results demonstrate state-of-the-art MTL performance for both CNN and transformer backbones, using significantly fewer parameters than single-task learning. Our code is publicly available at https://github.com/Armanfard-Lab/EMA-Net. Unraveling Generalized Parton Distributions Through Lorentz Symmetry and Partial DGLAP Knowledge Relying on the polynomiality property of generalized parton distributions, which roots on Lorentz covariance, we prove that it is enough to know them at vanishing- and low-skewness within the DGLAP region to obtain a unique extension to their entire support up to a D-term. We put this idea in practice using two methods: Reconstruction using artificial neural networks and finite-elements methods. We benchmark our results against standard models for generalized parton distributions. In agreement with the formal expectation, we obtain a very accurate reconstructions for a maximal value of the skewness as low as 20% of the longitudinal momentum fraction. This result might be relevant for reconstruction of generalized parton distribution from experimental and lattice QCD data, where computations are for now, restricted in skewness. Excitonic thermalization bottleneck in twisted TMD heterostructures Twisted van der Waals heterostructures show an intriguing interface exciton physics including hybridization effects and emergence of moir\'e potentials. Recent experiments have revealed that moir\'e-trapped excitons exhibit a remarkable dynamics, where excited states show lifetimes that are several orders of magnitude longer than those in monolayers. The origin of this behaviour is still under debate. Based on a microscopic many-particle approach, we investigate the phonon-driven relaxation cascade of non-equilibrium moir\'e excitons in the exemplary MoSe$_2$-WSe$_2$ heterostructure. We track the exciton relaxation pathway across different moir\'e mini-bands and identify the phonon-scattering channels assisting the spatial redistribution of excitons into low-energy pockets of the moir\'e potential. We unravel a phonon bottleneck in the flat band structure at low twist angles preventing excitons to fully thermalize into the lowest state explaining the measured enhanced emission intensity of excited moir\'e excitons. Overall, our work provides important insights into exciton relaxation dynamics in flatband exciton materials. On multicolor Tur\'an numbers We address a problem which is a generalization of Tur\'an-type problems recently introduced by Imolay, Karl, Nagy and V\'ali. Let $F$ be a fixed graph and let $G$ be the union of $k$ edge-disjoint copies of $F$, namely $G = \mathbin{\dot{\cup}}_{i=1}^{k} F_i$, where each $F_i$ is isomorphic to a fixed graph $F$ and $E(F_i)\cap E(F_j)=\emptyset$ for all $i \neq j$. We call a subgraph $H\subseteq G$ multicolored if $H$ and $F_i$ share at most one edge for all $i$. Define $\text{ex}_F(H,n)$ to be the maximum value $k$ such that there exists $G = \mathbin{\dot{\cup}}_{i=1}^{k} F_i$ on $n$ vertices without a multicolored copy of $H$. We show that $\text{ex}_{C_5}(C_3,n) \le n^2/25 + 3n/25+o(n)$ and that all extremal graphs are close to a blow-up of the 5-cycle. This bound is tight up to the linear error term. Automated Classification of Body MRI Sequence Type Using Convolutional Neural Networks Multi-parametric MRI of the body is routinely acquired for the identification of abnormalities and diagnosis of diseases. However, a standard naming convention for the MRI protocols and associated sequences does not exist due to wide variations in imaging practice at institutions and myriad MRI scanners from various manufacturers being used for imaging. The intensity distributions of MRI sequences differ widely as a result, and there also exists information conflicts related to the sequence type in the DICOM headers. At present, clinician oversight is necessary to ensure that the correct sequence is being read and used for diagnosis. This poses a challenge when specific series need to be considered for building a cohort for a large clinical study or for developing AI algorithms. In order to reduce clinician oversight and ensure the validity of the DICOM headers, we propose an automated method to classify the 3D MRI sequence acquired at the levels of the chest, abdomen, and pelvis. In our pilot work, our 3D DenseNet-121 model achieved an F1 score of 99.5% at differentiating 5 common MRI sequences obtained by three Siemens scanners (Aera, Verio, Biograph mMR). To the best of our knowledge, we are the first to develop an automated method for the 3D classification of MRI sequences in the chest, abdomen, and pelvis, and our work has outperformed the previous state-of-the-art MRI series classifiers. What Large-Scale Publication and Citation Data Tell Us About International Research Collaboration in Europe: Changing National Patterns in Global Contexts This study analyzes the unprecedented growth of international research collaboration (IRC) in Europe during the period 2009-2018 in terms of coauthorship and citation distribution of globally indexed publications. The results reveal the dynamics of this change, as growing IRC moves European systems away from institutional collaboration, with stable and strong national collaboration. Domestic output has remained flat. The growth in publications in major European systems is almost entirely attributable to internationally coauthored papers. A comparison of trends within the four complementary collaboration modes clearly reveals that the growth of European science is driven solely by internationally co-authored papers. With the emergence of global network science, which diminishes the role of national policies in IRC and foregrounds the role of scientists, the individual scientists willingness to collaborate internationally is central to advancing IRC in Europe. Scientists collaborate internationally when it enhances their academic prestige, scientific recognition, and access to research funding, as indicated by the credibility cycle, prestige maximization, and global science models. The study encompassed 5.5 million Scopus-indexed articles, including 2.2 million involving international collaboration. Cobra Effect in Reference-Free Image Captioning Metrics Evaluating the compatibility between textual descriptions and corresponding images represents a core endeavor within multi-modal research. In recent years, a proliferation of reference-free methods, leveraging visual-language pre-trained models (VLMs), has emerged. Empirical evidence has substantiated that these innovative approaches exhibit a higher correlation with human judgment, marking a significant advancement in the field. However, does a higher correlation with human evaluations alone sufficiently denote the complete of a metric? In response to this question, in this paper, we study if there are any deficiencies in reference-free metrics. Specifically, inspired by the Cobra Effect, we utilize metric scores as rewards to direct the captioning model toward generating descriptions that closely align with the metric's criteria. If a certain metric has flaws, it will be exploited by the model and reflected in the generated sentences. Our findings reveal that descriptions guided by these metrics contain significant flaws, e.g. incoherent statements and excessive repetition.
Subsequently, we propose a novel method termed Self-Improving to rectify the identified shortcomings within these metrics. We employ GPT-4V as an evaluative tool to assess generated sentences and the result reveals that our approach achieves state-of-the-art (SOTA) performance. In addition, we also introduce a challenging evaluation benchmark called Flaws Caption to evaluate reference-free image captioning metrics comprehensively. Our code is available at https://github.com/aaronma2020/robust_captioning_metric Comparing Mass Mapping Reconstruction Methods with Minkowski Functionals Using higher-order statistics to capture cosmological information from weak lensing surveys often requires a transformation of observed shear to a measurement of the convergence signal. This inverse problem is complicated by noise and boundary effects, and various reconstruction methods have been developed to implement the process. Here we evaluate the retention of signal information of four such methods: Kaiser-Squires, Wiener filter, $\texttt{DarkMappy}$, and $\texttt{DeepMass}$. We use the higher order statistics $\textit{Minkowski functionals}$ to determine which method best reconstructs the original convergence with efficiency and precision. We find $\texttt{DeepMass}$ produces the tightest constraints on cosmological parameters, while Kaiser-Squires, Wiener filter, and $\texttt{DarkMappy}$ are similar at a smoothing scale of 3.5 arcmin. We also study the MF inaccuracy caused by inappropriate training sets in the $\texttt{DeepMass}$ method and find it to be large compared to the errors, underlining the importance of selecting appropriate training cosmologies. Voltage Regulation in Polymer Electrolyte Fuel Cell Systems Using Gaussian Process Model Predictive Control This study introduces a novel approach utilizing Gaussian process model predictive control (MPC) to stabilize the output voltage of a polymer electrolyte fuel cell (PEFC) system by simultaneously regulating hydrogen and airflow rates. Two Gaussian process models are developed to capture PEFC dynamics, taking into account constraints including hydrogen pressure and input change rates, thereby aiding in mitigating errors inherent to PEFC predictive control. The dynamic performance of the physical model and Gaussian process MPC in constraint handling and system inputs is compared and analyzed. Simulation outcomes demonstrate that the proposed Gaussian process MPC effectively maintains the voltage at the target 48 V while adhering to safety constraints, even amidst workload disturbances ranging from 110-120 A. In comparison to traditional MPC using detailed system models, Gaussian process MPC exhibits a 43\% higher overshoot and 25\% slower response time. Nonetheless, it offers the advantage of not requiring the underlying true system model and needing less system information. Zooming in on the Circumgalactic Medium with GIBLE: the Topology and Draping of Magnetic Fields around Cold Clouds We use a cosmological zoom-in simulation of a Milky Way-like galaxy to study and quantify the topology of magnetic field lines around cold gas clouds in the circumgalactic medium (CGM). This simulation is a new addition to Project GIBLE, a suite of cosmological magnetohydrodynamical simulations of galaxy formation with preferential super-Lagrangian refinement in the CGM, reaching an unprecedented (CGM) gas mass resolution of $\sim$ $225$ M$_\odot$. To maximize statistics and resolution, we focus on a sample of $\sim$ $200$ clouds with masses of $\sim$ $10^6$ M$_\odot$. The topology of magnetic field lines around clouds is diverse, from threading to draping, and there is large variation in the magnetic curvature ($\kappa$) within cloud-background interfaces. We typically find little variation of $\kappa$ between upstream and downstream cloud faces, implying that strongly draped configurations are rare. In addition, $\kappa$ correlates strongly with multiple properties of the interface and the ambient background, including cloud overdensity and relative velocity, suggesting that cloud properties impact the topology of interface magnetic fields. What Makes Multimodal In-Context Learning Work? Large Language Models have demonstrated remarkable performance across various tasks, exhibiting the capacity to swiftly acquire new skills, such as through In-Context Learning (ICL) with minimal demonstration examples. In this work, we present a comprehensive framework for investigating Multimodal ICL (M-ICL) in the context of Large Multimodal Models. We consider the best open-source multimodal models (e.g., IDEFICS, OpenFlamingo) and a wide range of multimodal tasks. Our study unveils several noteworthy findings: (1) M-ICL primarily relies on text-driven mechanisms, showing little to no influence from the image modality. (2) When used with advanced-ICL strategy (like RICES), M-ICL is not better than a simple strategy based on majority voting over context examples. Moreover, we identify several biases and limitations of M-ICL that warrant consideration prior to deployment. Code available at https://gitlab.com/folbaeni/multimodal-icl Revealing the regularities of electron correlation energies associated with valence electrons in atoms in the first three rows of the periodic table Electronic correlation is a complex many-body effect and the correlation energy depends on the specific electronic structure and spatial distribution of electrons in each atom and molecule. Although the total correlation energy in an atom can be decomposed into different components such as inter-orbital and intra-orbital pair-correlation energies (PCE), it is generally believed that the PCEs in different atoms cannot be the same. In this work, we investigate the correlation energies of the atoms in the first three rows of the periodic table (He to Ar). It is found that when the correlation energy is defined as the difference between the exact ground-state energy and the unrestricted Hartree-Fock (UHF) energy, the inter- and intra-orbital PECs associated with the valence electrons of the atoms in the same row of the periodic table have the same values. These PCEs are not entangled and their values depend only on the electron orbitals. For two specific orbitals, the inter-orbital correlation energy is the same between two electrons of parallel spins or anti-parallel spins. We also show that the effects of orbital relaxation on the correlation energy are surprisingly small. Statistical inference for a stochastic generalized logistic differential equation This research aims to estimate three parameters in a stochastic generalized logistic differential equation. We assume the intrinsic growth rate and shape parameters are constant but unknown. To estimate these two parameters, we use the maximum likelihood method and establish that the estimators for these two parameters are strongly consistent. We estimate the diffusion parameter by using the quadratic variation processes. To test our results, we evaluate two data scenarios, complete and incomplete, with fixed values assigned to the three parameters. In the incomplete data scenario, we apply an Expectation Maximization algorithm. Identifying stable communities in Hi-C data using a multifractal null model Chromosome capture techniques like Hi-C have expanded our understanding of mammalian genome 3D architecture and how it influences gene activity. To analyze Hi-C data sets, researchers increasingly treat them as DNA-contact networks and use standard community detection techniques to identify mesoscale 3D communities. However, there are considerable challenges in finding significant communities because the Hi-C networks have cross-scale interactions and are almost fully connected. This paper presents a pipeline to distil 3D communities that remain intact under experimental noise. To this end, we bootstrap an ensemble of Hi-C datasets representing noisy data and extract 3D communities that we compare with the unperturbed dataset. Notably, we extract the communities by maximizing local modularity (using the Generalized Louvain method), which considers the multifractal spectrum recently discovered in Hi-C maps. Our pipeline finds that stable communities (under noise) typically have above-average internal contact frequencies and tend to be enriched in active chromatin marks. We also find they fold into more nested cross-scale hierarchies than less stable ones. Apart from presenting how to systematically extract robust communities in Hi-C data, our paper offers new ways to generate null models that take advantage of the network's multifractal properties. We anticipate this has a broad applicability to several network applications.
Learning the local density of states of a bilayer moir\'e material in one dimension Recent work of three of the authors showed that the operator which maps the local density of states of a one-dimensional untwisted bilayer material to the local density of states of the same bilayer material at non-zero twist, known as the twist operator, can be learned by a neural network. In this work, we first provide a mathematical formulation of that work, making the relevant models and operator learning problem precise. We then prove that the operator learning problem is well-posed for a family of one-dimensional models. To do this, we first prove existence and regularity of the twist operator by solving an inverse problem. We then invoke the universal approximation theorem for operators to prove existence of a neural network capable of approximating the twist operator. Automatic Segmentation of the Kidneys and Cystic Renal Lesions on Non-Contrast CT Using a Convolutional Neural Network Objective: Automated segmentation tools are useful for calculating kidney volumes rapidly and accurately. Furthermore, these tools have the power to facilitate large-scale image-based artificial intelligence projects by generating input labels, such as for image registration algorithms. Prior automated segmentation models have largely ignored non-contrast computed tomography (CT) imaging. This work aims to implement and train a deep learning (DL) model to segment the kidneys and cystic renal lesions (CRLs) from non-contrast CT scans. Methods: Manual segmentation of the kidneys and CRLs was performed on 150 non-contrast abdominal CT scans. The data were divided into an 80/20 train/test split and a deep learning (DL) model was trained to segment the kidneys and CRLs. Various scoring metrics were used to assess model performance, including the Dice Similarity Coefficient (DSC), Jaccard Index (JI), and absolute and percent error kidney volume and lesion volume. Bland-Altman (B-A) analysis was performed to compare manual versus DL-based kidney volumes. Results: The DL model achieved a median kidney DSC of 0.934, median CRL DSC of 0.711, and total median study DSC of 0.823. Average volume errors were 0.9% for renal parenchyma, 37.0% for CRLs, and 2.2% overall. B-A analysis demonstrated that DL-based volumes tended to be greater than manual volumes, with a mean bias of +3.0 ml (+/- 2 SD of +/- 50.2 ml). Conclusion: A deep learning model trained to segment kidneys and cystic renal lesions on non-contrast CT examinations was able to provide highly accurate segmentations, with a median kidney Dice Similarity Coefficient of 0.934. Keywords: deep learning; kidney segmentation; artificial intelligence; convolutional neural networks. Precarious Experiences: Citizens' Frustrations, Anxieties and Burdens of an Online Welfare Benefit System There is a significant overlap between people who are supported by income-related social welfare benefits, often in precarious situations, and those who experience greater digital exclusion. We report on a study of claimants using the UK's Universal Credit online welfare benefit system designed as, and still, "digital by default". Through data collection involving remote interviews (n=11) and online surveys (n=66), we expose claimants' own lived experiences interacting with this system. The claimants explain how digital channels can contribute to an imbalance of power and agency, at a time when their own circumstances mean they have reduced abilities, resources and capacities, and where design choices can adversely affect people's utility to leverage help from their own wider socio-technical ecosystems. We contribute eight recommendations from these accounts to inform the future design and development of digital welfare benefit systems for this population, to reduce digital barriers and harms. On the positivity of MSbar distributions We discuss the positivity of parton distribution functions using the common $\overline{MS}$ factorization scheme. We find that in the perturbative regime $\overline{MS}$ PDFs inherit the strict positivity of physical PDFs. We explicitly discuss the scheme transformation by using suitable physical observables and find that $\overline{MS}$ PDFs are positive above the scale $Q^2$ > 5 GeV^2. Finally, we comment on the direct counterpart of longitudinally polarized PDFs, finding agreement with the unpolarized counterpart. Fisher's Legacy of Directional Statistics, and Beyond to Statistics on Manifolds It will not be an exaggeration to say that R A Fisher is the Albert Einstein of Statistics. He pioneered almost all the main branches of statistics, but it is not as well known that he opened the area of Directional Statistics with his 1953 paper introducing a distribution on the sphere which is now known as the Fisher distribution. He stressed that for spherical data one should take into account that the data is on a manifold. We will describe this Fisher distribution and reanalyse his geological data. We also comment on the two goals he set himself in that paper, and how he reinvented the von Mises distribution on the circle. Since then, many extensions of this distribution have appeared bearing Fisher's name such as the von Mises Fisher distribution and the matrix Fisher distribution. In fact, the subject of Directional Statistics has grown tremendously in the last two decades with new applications emerging in Life Sciences, Image Analysis, Machine Learning and so on. We give a recent new method of constructing the Fisher type distribution which has been motivated by some problems in Machine Learning. The subject related to his distribution has evolved since then more broadly as Statistics on Manifolds which also includes the new field of Shape Analysis. We end with a historical note pointing out some correspondence between D'Arcy Thompson and R A Fisher related to Shape Analysis. WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild We introduce WildBench, an automated evaluation framework designed to benchmark large language models (LLMs) using challenging, real-world user queries. WildBench consists of 1,024 tasks carefully selected from over one million human-chatbot conversation logs. For automated evaluation with WildBench, we have developed two metrics, WB-Reward and WB-Score, which are computable using advanced LLMs such as GPT-4-turbo. WildBench evaluation uses task-specific checklists to evaluate model outputs systematically and provides structured explanations that justify the scores and comparisons, resulting in more reliable and interpretable automatic judgments. WB-Reward employs fine-grained pairwise comparisons between model responses, generating five potential outcomes: much better, slightly better, slightly worse, much worse, or a tie. Unlike previous evaluations that employed a single baseline model, we selected three baseline models at varying performance levels to ensure a comprehensive pairwise evaluation. Additionally, we propose a simple method to mitigate length bias, by converting outcomes of ``slightly better/worse'' to ``tie'' if the winner response exceeds the loser one by more than $K$ characters. WB-Score evaluates the quality of model outputs individually, making it a fast and cost-efficient evaluation metric. WildBench results demonstrate a strong correlation with the human-voted Elo ratings from Chatbot Arena on hard tasks. Specifically, WB-Reward achieves a Pearson correlation of 0.98 with top-ranking models. Additionally, WB-Score reaches 0.95, surpassing both ArenaHard's 0.91 and AlpacaEval2.0's 0.89 for length-controlled win rates, as well as the 0.87 for regular win rates. Vacuum polarization and Wichmann-Kroll correction in the finite basis set approximation The finite basis set method is commonly used to calculate atomic spectra, including QED contributions such as bound-electron self-energy. Still, it remains problematic and underexplored for vacuum-polarization calculations. We fill this gap by trying this approach in its application to the calculation of the vacuum-polarization charge density and the Wichmann-Kroll correction to the electron binding energy in a hydrogen-like ion. We study the convergence of the method with different types and sizes of basis sets. We cross-check our results for the Wichmann-Kroll correction by direct integration of the Green's function.
As a relevant example, we consider several heavy hydrogen-like ions and evaluate the vacuum polarization correction for $S$ and $P$ electron orbitals. Information Aggregation with Costly Information Acquisition We study information aggregation in a dynamic trading model with partially informed traders. Ostrovsky [2012] showed that 'separable' securities aggregate information in all equilibria, however, separability is not robust to small changes in the traders' private information. To remedy this problem, we enhance the model by allowing traders to acquire signals with cost $\kappa$, in every period. We show that '$\kappa$ separable securities' aggregate information and, as the cost decreases, nearly all securities become $\kappa$ separable, irrespective of the traders' initial private information. Moreover, the switch to $\kappa$ separability happens not gradually but discontinuously, hence even a small decrease in costs can result in a security aggregating information. Finally, even with myopic traders, cheaper information may accelerate or decelerate information aggregation for all but Arrow-Debreu securities. Wilf's question in numerical semigroups $S_3$ revisited and inequalities for rescaled genera We consider numerical semigroups $S_3 = \langle d_1,d_2,d_3\rangle$, minimally generated by three positive integers. We revisit the Wilf question in $S_3$ and, making use of identities for degrees of syzygies of such semigroups, give a short proof of existence of an affirmative answer. We find also the lower bound for Frobenius numbers of $S_3$ and upper and lower bounds for rescaled genera. Fully-Adaptive Dynamic Connectivity of Square Intersection Graphs A classical problem in computational geometry and graph algorithms is: given a dynamic set S of geometric shapes in the plane, efficiently maintain the connectivity of the intersection graph of S. Previous papers studied the setting where, before the updates, the data structure receives some parameter P. Then, updates could insert and delete disks as long as at all times the disks have a diameter that lies in a fixed range [1/P, 1]. The state-of-the-art for storing disks in a dynamic connectivity data structure is a data structure that uses O(Pn) space and that has amortized O(P log^4 n) expected amortized update time. Connectivity queries between disks are supported in O( log n / loglog n) time. The state-of-the-art for Euclidean disks immediately implies a data structure for connectivity between axis-aligned squares that have their diameter in the fixed range [1/P, 1], with an improved update time of O(P log^4 n) amortized time. We restrict our attention to axis-aligned squares, and study fully-dynamic square intersection graph connectivity. Our result is fully-adaptive to the aspect ratio, spending time proportional to the current aspect ratio {\psi}, as opposed to some previously given maximum P. Our focus on squares allows us to simplify and streamline the connectivity pipeline from previous work. When $n$ is the number of squares and {\psi} is the aspect ratio after insertion (or before deletion), our data structure answers connectivity queries in O(log n / loglog n) time. We can update connectivity information in O({\psi} log^4 n + log^6 n) amortized time. We also improve space usage from O(P n log n) to O(n log^3 n log {\psi}) -- while generalizing to a fully-adaptive aspect ratio -- which yields a space usage that is near-linear in n for any polynomially bounded {\psi}. A definition of the SI second based on several optical transitions A new definition of the SI second based on optical transitions is expected to be adopted within the next 10 years. Several options for this redefinition are currently under consideration. Among them, a definition based on several transitions would take advantage of the variety of high performance optical frequency standards. In this paper, we review practical aspects such a definition entails, and propose a detailed analysis of its strengths and weaknesses. Sharp stability of the Brunn-Minkowski inequality via optimal mass transportation The Brunn-Minkowski inequality, applicable to bounded measurable sets $A$ and $B$ in $\mathbb{R}^d$, states that $|A+B|^{1/d} \geq |A|^{1/d}+|B|^{1/d}$. Equality is achieved if and only if $A$ and $B$ are convex and homothetic sets in $\mathbb{R}^d$. The concept of stability in this context concerns how, when approaching equality, sets $A$ and $B$ are close to homothetic convex sets. In a recent breakthrough [FvHT23], the authors of this paper proved the following folklore conjectures on the sharp stability for the Brunn-Minkowski inequality: (1) A linear stability result concerning the distance from $A$ and $B$ to their respective convex hulls. (2) A quadratic stability result concerning the distance from $A$ and $B$ to their common convex hull. As announced in [FvHT23], in the present paper, we leverage (1) in conjunction with a novel optimal transportation approach to offer an alternative proof for (2). Spectral Eigen-subspace and Tree Structure for a Cantor Measure In this work we investigate the question of constructions of the possible Fourier bases $E(\Lambda)=\{e^{2\pi i \lambda x}:\lambda\in\Lambda\}$ for the Hilbert space $L^2(\mu_4)$, where $\mu_4$ is the standard middle-fourth Cantor measure and $\Lambda$ is a countable discrete set. We show that the set $$\mathop \bigcap_{p\in 2\Z+1}\left\{\Lambda\subset \R: \text{$E(\Lambda)$ and $E(p\Lambda)$ are Fourier bases for $L^2(\mu_4)$}\right\}$$ has the cardinality of the continuum. We also give other characterizations on the orthonormal set of exponential functions being a basis for the space $L^2(\mu_4)$ from the viewpoint of measure and dimension. Moreover, we provide a method of constructing explicit discrete set $\Lambda$ such that $E(\Lambda)$ and its all odd scaling sets $E(\Lambda),p\in2\Z+1,$ are still Fourier bases for $L^2(\mu_4)$. MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents There has been significant recent interest in harnessing LLMs to control software systems through multi-step reasoning, planning and tool-usage. While some promising results have been obtained, application to specific domains raises several general issues including the control of specialized domain tools, the lack of existing datasets for training and evaluation, and the non-triviality of automated system evaluation and improvement. In this paper, we present a case-study where we examine these issues in the context of a specific domain. Specifically, we present an automated math visualizer and solver system for mathematical pedagogy. The system orchestrates mathematical solvers and math graphing tools to produce accurate visualizations from simple natural language commands. We describe the creation of specialized data-sets, and also develop an auto-evaluator to easily evaluate the outputs of our system by comparing them to ground-truth expressions. We have open sourced the data-sets and code for the proposed system. Machine Learning for Dynamic Management Zone in Smart Farming Digital agriculture is growing in popularity among professionals and brings together new opportunities along with pervasive use of modern data-driven technologies. Digital agriculture approaches can be used to replace all traditional agricultural system at very reasonable costs. It is very effective in optimising large-scale management of resources, while traditional techniques cannot even tackle the problem. In this paper, we proposed a dynamic management zone delineation approach based on Machine Learning clustering algorithms using crop yield data, elevation and soil texture maps and available NDVI data. Our proposed dynamic management zone delineation approach is useful for analysing the spatial variation of yield zones. Delineation of yield regions based on historical yield data augmented with topography and soil physical properties helps farmers to economically and sustainably deploy site-specific management practices identifying persistent issues in a field.
The use of frequency maps is capable of capturing dynamically changing incidental issues within a growing season. The proposed zone management approach can help farmers/agronomists to apply variable-rate N fertilisation more effectively by analysing yield potential and stability zones with satellite-based NDVI monitoring. Proceedings of the 21st International Conference on Quantum Physics and Logic This volume contains the proceedings of the 21st International Conference on Quantum Physics and Logic (QPL 2024), which was held from July 15th to 19th, 2024, in Buenos Aires, Argentina, organized jointly by Universidad de Buenos Aires and Universidad Nacional de Quilmes. QPL is an annual conference that brings together academic and industry researchers working on the mathematical foundations of quantum computation, quantum physics, and related areas. The main focus is on the use of algebraic and categorical structures, formal languages, semantic methods, as well as other mathematical and computer scientific techniques applicable to the study of physical systems, physical processes, and their composition. Emergence of global receptive fields capturing multipartite quantum correlations In quantum physics, even simple data with a well-defined structure at the wave function level can be characterized by extremely complex correlations between its constituent elements. The inherent non-locality of the quantum correlations generally prevents one from providing their simple and transparent interpretation, which also remains a challenging problem for advanced classical techniques that approximate quantum states with neural networks. Here we show that monitoring the neural network weight space while learning quantum statistics from measurements allows to develop physical intuition about complex multipartite patterns and thus helps to construct more effective classical representations of the wave functions. Particularly, we observe the formation of distinct global convolutional structures, receptive fields in the hidden layer of the Restricted Boltzmann Machine (RBM) within the neural quantum tomography of the highly-entangled Dicke states. On this basis we propose an exact two-parameter classical representation not only for a specific quantum wave function, but for the whole family of the N-qubit Dicke states of different entanglement. Our findings suggest a fresh look at constructing convolutional neural networks for processing data with non-local patterns and pave the way for developing exact learning-based representations of entangled quantum states. 3D{\pi}: Three-Dimensional Positron Imaging, A Novel Total-Body PET Scanner Using Xenon-Doped Liquid Argon Scintillator Objective: This paper introduces a novel PET imaging methodology called 3-dimensional positron imaging (3D{\pi}), which integrates total-body (TB) coverage, time-of-flight (TOF) technology, ultra-low dose imaging capabilities, and ultra-fast readout electronics inspired by emerging technology from the DarkSide collaboration. Approach: The study evaluates the performance of 3D{\pi} using Monte Carlo simulations based on NEMA NU 2-2018 protocols. The methodology employs a homogenous, monolithic scintillator composed of liquid argon (LAr) doped with xenon (Xe) with silicon photomultipliers (SiPM) operating at cryogenic temperatures. Main results: Significant enhancements in system performance are observed, with the 3D{\pi} system achieving a noise equivalent count rate (NECR) of 3.2 Mcps which is approximately two times higher than uEXPLORER's peak NECR (1.5 Mcps) at 17.3 (kBq/mL). Spatial resolution measurements show an average FWHM of 2.7 mm across both axial positions. The system exhibits superior sensitivity, with values reaching 373 kcps/MBq with a line source at the center of the field of view. Additionally, 3D{\pi} achieves a TOF resolution of 151 ps at 5.3 kBq/mL, highlighting its potential to produce high-quality images with reduced noise levels. Significance: The study underscores the potential of 3D{\pi} in improving PET imaging performance, offering the potential for shorter scan times and reduced radiation exposure for patients. The Xe-doped LAr offers advantages such as fast scintillation, enhanced light yield, and cost-effectiveness. Future research will focus on optimizing system geometry and further refining reconstruction algorithms to exploit the strengths of 3D{\pi} for clinical applications. Map-level baryonification: Efficient modelling of higher-order correlations in the weak lensing and thermal Sunyaev-Zeldovich fields Semi-analytic methods can generate baryon-corrected fields from N-body simulations (``baryonification'') and are rapidly becoming a ubiquitous tool in modeling structure formation on non-linear scales. We extend this formalism to consistently model the weak lensing and thermal Sunyaev-Zeldovich (tSZ) fields directly on the full-sky, with an emphasis on higher-order correlations. We use the auto- and cross- $N$th-order moments, with $N \in \{2, 3, 4\}$, as a summary statistic of the lensing and tSZ fields, and show that our model can jointly fit these statistics measured in IllustrisTNG to within measurement uncertainties, for scales above $\gtrsim 1 {\rm Mpc}$ and across multiple redshifts. The model predictions change only minimally when including additional information from secondary halo properties, such as halo concentration and ellipticity. Each individual moment is dependent on halos of different mass ranges and has different sensitivities to the model parameters. A simulation-based forecast on the ULAGAM simulation suite shows that the combination of all moments, measured from current and upcoming lensing and tSZ surveys, can jointly constrain cosmology and baryons to high precision. The lensing and tSZ field are sensitive to different combinations of the baryonification parameters, with degeneracy directions that are often orthogonal, and the combination of the two fields leads to significantly better constraints on both cosmology and astrophysics. Our pipeline for map-level baryonification is publicly available at https://github.com/DhayaaAnbajagane/BaryonForge. A procedure to characterize the performance of Energy-Resolved Detectors (EDX) The detector group of Synchrotron SOLEIL is monitoring the performance of Energy-Resolved Detectors (EDX) and their associated electronics since last five years. A characterization procedure has been developed for this purpose and for Site Acceptance Tests (SATs) of new EDXs installed at beamlines. This manuscript presents the procedure, illustrating it with an example. Decoupling DNS Update Timing from TTL Values A relatively simple safety-belt mechanism for improving DNS system availability and efficiency is proposed here. While it may seem ambitious, a careful examination shows it is both feasible and beneficial for the DNS system. The mechanism called "DNS Real-time Update" (DNSRU), a service that facilitates real-time and secure updates of cached domain records in DNS resolvers worldwide, even before the expiration of the corresponding Time To Live (TTL) values. This service allows Internet domain owners to quickly rectify any erroneous global IP address distribution, even if a long TTL value is associated with it. By addressing this critical DNS high availability issue, DNSRU eliminates the need for short TTL values and their associated drawbacks. Therefore, DNSRU DNSRU reduces the traffic load on authoritative servers while enhancing the system's fault tolerance. In this paper we show that our DNSRU design is backward compatible, supports gradual deployment, secure, efficient, and feasible. Multiparticle azimuthal correlations in isobaric $^{96}$Ru+$^{96}$Ru and $^{96}$Zr+$^{96}$Zr collisions at $\sqrt{s_{NN}} =$ 200 GeV Correlations between event-by-event fluctuations in the amplitudes of flow harmonics offer a novel way to access initial state properties in heavy-ion collisions. We have extensively predicted correlations in different flow harmonics based on multiparticle cumulants in $^{96}$Ru+$^{96}$Ru and $^{96}$Zr+$^{96}$Zr collisions at $\sqrt{s_{NN}} =$ 200 GeV from a multiphase transport model.
The state-of-the-art correlated nuclear distributions for the isobars were used to show the difference in nuclear deformations and neutron skin thickness, which have distinct characteristics seen in multiparticle azimuthal correlation. We also found a minimal effect of the shear viscosity effect on these multiparticle azimuthal correlations. Therefore, these studies could also serve as an additional tool for understanding the nature of the initial state fluctuations and nuclear structure, as well as input for possible in-depth dynamical studies for experimental measurement. Explainable AI: Definition and attributes of a good explanation for health AI Proposals of artificial intelligence (AI) solutions based on increasingly complex and accurate predictive models are becoming ubiquitous across many disciplines. As the complexity of these models grows, transparency and users' understanding often diminish. This suggests that accurate prediction alone is insufficient for making an AI-based solution truly useful. In the development of healthcare systems, this introduces new issues related to accountability and safety. Understanding how and why an AI system makes a recommendation may require complex explanations of its inner workings and reasoning processes. Although research on explainable AI (XAI) has significantly increased in recent years and there is high demand for XAI in medicine, defining what constitutes a good explanation remains ad hoc, and providing adequate explanations continues to be challenging. To fully realize the potential of AI, it is critical to address two fundamental questions about explanations for safety-critical AI applications, such as health-AI: (1) What is an explanation in health-AI? and (2) What are the attributes of a good explanation in health-AI? In this study, we examined published literature and gathered expert opinions through a two-round Delphi study. The research outputs include (1) a definition of what constitutes an explanation in health-AI and (2) a comprehensive list of attributes that characterize a good explanation in health-AI. Commutation of transfer and Aubert-Zelevinski involution for metaplectic groups A result of K. Hiraga says endoscopic transfer is compatible with Aubert-Zelevinski involution. In this short note, we generalize Hiraga's result to metaplectic group setting. Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation Liver tumor ablation procedures require accurate placement of the needle applicator at the tumor centroid. The lower-cost and real-time nature of ultrasound (US) has advantages over computed tomography (CT) for applicator guidance, however, in some patients, liver tumors may be occult on US and tumor mimics can make lesion identification challenging. Image registration techniques can aid in interpreting anatomical details and identifying tumors, but their clinical application has been hindered by the tradeoff between alignment accuracy and runtime performance, particularly when compensating for liver motion due to patient breathing or movement. Therefore, we propose a 2D-3D US registration approach to enable intra-procedural alignment that mitigates errors caused by liver motion. Specifically, our approach can correlate imbalanced 2D and 3D US image features and use continuous 6D rotation representations to enhance the model's training stability. The dataset was divided into 2388, 196 and 193 image pairs for training, validation and testing, respectively. Our approach achieved a mean Euclidean distance error of 2.28 mm $\pm$ 1.81 mm and a mean geodesic angular error of 2.99$^{\circ}$ $\pm$ 1.95$^{\circ}$, with a runtime of 0.22 seconds per 2D-3D US image pair. These results demonstrate that our approach can achieve accurate alignment and clinically acceptable runtime, indicating potential for clinical translation. Multinomial Catalan Numbers and Lucas Analogues We define a new generalization of Catalan numbers to multinomial coefficients. With arithmetic methods, we study their integrality and the integrality of their Lucasnomial generalization. We give a complete characterization of regular Lucas sequences for which they yield integers up to finitely many cases. First experimental study of multiple orientation muon tomography, with image optimization in sparse data environments Due to the high penetrating power of cosmic ray muons, they can be used to probe very thick and dense objects. As charged particles, they can be tracked by ionization detectors, determining the position and direction of the muons. With detectors on either side of an object, particle direction changes can be used to extract scattering information within an object. This can be used to produce a scattering intensity image within the object related to density and atomic number. Such imaging is typically performed with a single detector-object orientation, taking advantage of the more intense downward flux of muons, producing planar imaging with some depth-of-field information in the third dimension. Several simulation studies have been published with multi-orientation tomography, which can form a three-dimensional representation faster than a single orientation view. In this work we present the first experimental multiple orientation muon tomography study. Experimental muon-scatter based tomography was performed using a concrete filled steel drum with several different metal wedges inside, between detector planes. Data was collected from different detector-object orientations by rotating the steel drum. The data collected from each orientation were then combined using two different tomographic methods. Results showed that using a combination of multiple depth-of-field reconstructions, rather than a traditional inverse Radon transform approach used for CT, resulted in more useful images for sparser data. As cosmic ray muon flux imaging is rate limited, the imaging techniques were compared for sparse data. Using the combined depth-of-field reconstruction technique, fewer detector-object orientations were needed to reconstruct images that could be used to differentiate the metal wedge compositions. NaVIP: An Image-Centric Indoor Navigation Solution for Visually Impaired People Indoor navigation is challenging due to the absence of satellite positioning. This challenge is manifold greater for Visually Impaired People (VIPs) who lack the ability to get information from wayfinding signage. Other sensor signals (e.g., Bluetooth and LiDAR) can be used to create turn-by-turn navigation solutions with position updates for users. Unfortunately, these solutions require tags to be installed all around the environment or the use of fairly expensive hardware. Moreover, these solutions require a high degree of manual involvement that raises costs, thus hampering scalability. We propose an image dataset and associated image-centric solution called NaVIP towards visual intelligence that is infrastructure-free and task-scalable, and can assist VIPs in understanding their surroundings. Specifically, we start by curating large-scale phone camera data in a four-floor research building, with 300K images, to lay the foundation for creating an image-centric indoor navigation and exploration solution for inclusiveness. Every image is labelled with precise 6DoF camera poses, details of indoor PoIs, and descriptive captions to assist VIPs. We benchmark on two main aspects: 1) positioning system and 2) exploration support, prioritizing training scalability and real-time inference, to validate the prospect of image-based solution towards indoor navigation. The dataset, code, and model checkpoints are made publicly available at https://github.com/junfish/VIP_Navi. Testing Identity of Distributions under Kolmogorov Distance in Polylogarithmic Space Suppose we have a sample from a distribution $D$ and we want to test whether $D = D^*$ for a fixed distribution $D^*$. Specifically, we want to reject with constant probability, if the distance of $D$ from $D^*$ is $\geq \varepsilon$ in a given metric. In the case of continuous distributions, this has been studied thoroughly in the statistics literature. Namely, for the well-studied Kolmogorov metric a test is known that uses the optimal $O(1/\varepsilon^2)$ samples. However, this test naively uses also space $O(1/\varepsilon^2)$, and previous work improved this to $O(1/\varepsilon)$. In this paper, we show that much less space suffices -- we give an algorithm that uses space $O(\log^4 \varepsilon^{-1})$ in the streaming setting while also using an asymptotically optimal number of samples. This is in contrast with the standard total variation distance on discrete distributions for which such space reduction is known to be impossible.
Finally, we state 9 related open problems that we hope will spark interest in this and related problems. Uniform stability of ranks Chen and Ye recently proved that the analytic rank of tensors is stable under field extensions, assuming a fixed base field. Using a more careful analysis, we show that this assumption is unnecessary. First Integrals of Homogeneous Vector Fields and the Eigenmirror Problem of Geometric Optics The eigenmirror problem asks: ``When does the reflection of a surface in a curved mirror appear undistorted to an observer?'' We call such a surface an {\em eigensurface} and the corresponding mirror an {\em eigenmirror}. The data for an eigenmirror problem consists of a homogeneous transformation ${\bf H}:\mathbb{R}^3 \to \mathbb{R}^3$ that encodes what it means for two observers to see a surface in the ``same way.'' A solution to this problem is a differentiable 2-manifold that (1) satisfies a first-order partial differential equation called the {\bf anti-eikonal equation}, and (2) satisfies certain side inequalities that ensure that a ray reflecting off the mirror behaves in a physically meaningful way. Although these side inequalities initially seem like an ad hoc global restriction, we show that under reasonable conditions, an integral curve of the characteristic flow of the anti-eikonal equation may not intersect the boundary of an eigenmirror. Thus, in those cases, the eigenmirror is invariant under the characteristic flow. We give several examples exhibiting our results. Integrated Ising Model with global inhibition for decision making Humans and other organisms make decisions choosing between different options, with the aim to maximize the reward and minimize the cost. The main theoretical framework for modeling the decision-making process has been based on the highly successful drift-diffusion model, which is a simple tool for explaining many aspects of this process. However, new observations challenge this model. Recently, it was found that inhibitory tone increases during high cognitive load and situations of uncertainty, but the origin of this phenomenon is not understood. Motivated by this observation, we extend a recently developed model for decision making while animals move towards targets in real space. We introduce an integrated Ising-type model, that includes global inhibition, and use it to explore its role in decision-making. This model can explain how the brain may utilize inhibition to improve its decision-making accuracy. Compared to experimental results, this model suggests that the regime of the brain's decision-making activity is in proximity to a critical transition line between the ordered and disordered. Within the model, the critical region near the transition line has the advantageous property of enabling a significant decrease in error with a small increase in inhibition and also exhibits unique properties with respect to learning and memory decay. Interval Multiplicities of Persistence Modules For any persistence module $M$ over a finite poset $\mathbf{P}$, and any interval $I$ in $\mathbf{P}$, we give a formula of the multiplicity $d_M(V_I)$ of the interval module $V_I$ in the indecomposable decomposition of $M$ in terms of structure linear maps of the module $M$. This makes it possible to compute the maximal interval-decomposable direct summand of $M$, which gives us a way to decide whether $M$ is interval-decomposable or not. Moreover, the formula tells us essential morphisms of $\mathbf{P}$ that are necessary to compute the multiplicity $d_M(V_I)$. This suggests us some poset morphism $\zeta \colon Z \to \mathbf{P}$ such that the induced restriction functor $R \colon \operatorname{mod} \mathbf{P} \to \operatorname{mod} Z$ has the property that the multiplicity $d:= d_{R(M)}(R(V_I))$ is equal to $d_M(V_I)$. If $Z$ can be taken as a poset of Dynkin type $\mathbb{A}$ as in the bipath case, then the calculation of the multiplicity $d$ can be done more efficiently, starting from the filtration level of topological spaces. Thus this even makes it unnecessary to compute the structure linear maps of $M$. Optimal transport maps, majorization, and log-subharmonic measures Caffarelli's contraction theorem bounds the derivative of the optimal transport map between a log-convex measure and a strongly log-concave measure. We show that an analogous phenomenon holds on the level of the trace: The trace of the derivative of the optimal transport map between a log-subharmonic measure and a strongly log-concave measure is bounded. We show that this trace bound has a number of consequences pertaining to volume-contracting transport maps, majorization and its monotonicity along Wasserstein geodesics, growth estimates of log-subharmonic functions, the Wehrl conjecture for Glauber states, and two-dimensional Coulomb gases. We also discuss volume-contraction properties for the Kim-Milman transport map Universal and Context-Independent Triggers for Precise Control of LLM Outputs Large language models (LLMs) have been widely adopted in applications such as automated content generation and even critical decision-making systems. However, the risk of prompt injection allows for potential manipulation of LLM outputs. While numerous attack methods have been documented, achieving full control over these outputs remains challenging, often requiring experienced attackers to make multiple attempts and depending heavily on the prompt context. Recent advancements in gradient-based white-box attack techniques have shown promise in tasks like jailbreaks and system prompt leaks. Our research generalizes gradient-based attacks to find a trigger that is (1) Universal: effective irrespective of the target output; (2) Context-Independent: robust across diverse prompt contexts; and (3) Precise Output: capable of manipulating LLM inputs to yield any specified output with high accuracy. We propose a novel method to efficiently discover such triggers and assess the effectiveness of the proposed attack. Furthermore, we discuss the substantial threats posed by such attacks to LLM-based applications, highlighting the potential for adversaries to taking over the decisions and actions made by AI agents. UVLLM: An Automated Universal RTL Verification Framework using LLMs Verifying hardware designs in embedded systems is crucial but often labor-intensive and time-consuming. While existing solutions have improved automation, they frequently rely on unrealistic assumptions. To address these challenges, we introduce a novel framework, UVLLM, which combines Large Language Models (LLMs) with the Universal Verification Methodology (UVM) to relax these assumptions. UVLLM significantly enhances the automation of testing and repairing error-prone Register Transfer Level (RTL) codes, a critical aspect of verification development. Unlike existing methods, UVLLM ensures that all errors are triggered during verification, achieving a syntax error fix rate of 86.99% and a functional error fix rate of 71.92% on our proposed benchmark. These results demonstrate a substantial improvement in verification efficiency. Additionally, our study highlights the current limitations of LLM applications, particularly their reliance on extensive training data. We emphasize the transformative potential of LLMs in hardware design verification and suggest promising directions for future research in AI-driven hardware design methodologies. The Repo. of dataset and code: https://anonymous.4open.science/r/UVLLM/. Magnifier: Detecting Network Access via Lightweight Traffic-based Fingerprints Network access detection plays a crucial role in global network management, enabling efficient network monitoring and topology measurement by identifying unauthorized network access and gathering detailed information about mobile devices. Existing methods for endpoint-based detection primarily rely on deploying monitoring software to recognize network connections. However, the challenges associated with developing and maintaining such systems have limited their universality and coverage in practical deployments, especially given the cost implications of covering a wide array of devices with heterogeneous operating systems. To tackle the issues, we propose Magnifier for mobile device network access detection that, for the first time, passively infers access patterns from backbone traffic at the gateway level. Magnifier's foundation is the creation of device-specific access patterns using the innovative Domain Name Forest (dnForest) fingerprints. We then employ a two-stage distillation algorithm to fine-tune the weights of individual Domain Name Trees (dnTree) within each dnForest, emphasizing the unique device fingerprints.
With these meticulously crafted fingerprints, Magnifier efficiently infers network access from backbone traffic using a lightweight fingerprint matching algorithm. Our experimental results, conducted in real-world scenarios, demonstrate that Magnifier exhibits exceptional universality and coverage in both initial and repetitive network access detection in real-time. To facilitate further research, we have thoughtfully curated the NetCess2023 dataset, comprising network access data from 26 different models across 7 brands, covering the majority of mainstream mobile devices. We have also made both the Magnifier prototype and the NetCess2023 dataset publicly available\footnote{https://github.com/SecTeamPolaris/Magnifier}. An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models In vitro fertilization (IVF) is a widely utilized assisted reproductive technology, yet predicting its success remains challenging due to the multifaceted interplay of clinical, demographic, and procedural factors. This study develops a robust artificial intelligence (AI) pipeline aimed at predicting live birth outcomes in IVF treatments. The pipeline uses anonymized data from 2010 to 2018, obtained from the Human Fertilization and Embryology Authority (HFEA). We evaluated the prediction performance of live birth success as a binary outcome (success/failure) by integrating different feature selection methods, such as principal component analysis (PCA) and particle swarm optimization (PSO), with different traditional machine learning-based classifiers including random forest (RF) and decision tree, as well as deep learning-based classifiers including custom transformer-based model and a tab transformer model with an attention mechanism. Our research demonstrated that the best performance was achieved by combining PSO for feature selection with the TabTransformer-based deep learning model, yielding an accuracy of 99.50% and an AUC of 99.96%, highlighting its significant performance to predict live births. This study establishes a highly accurate AI pipeline for predicting live birth outcomes in IVF, demonstrating its potential to enhance personalized fertility treatments. Object-level Visual Prompts for Compositional Image Generation We introduce a method for composing object-level visual prompts within a text-to-image diffusion model. Our approach addresses the task of generating semantically coherent compositions across diverse scenes and styles, similar to the versatility and expressiveness offered by text prompts. A key challenge in this task is to preserve the identity of the objects depicted in the input visual prompts, while also generating diverse compositions across different images. To address this challenge, we introduce a new KV-mixed cross-attention mechanism, in which keys and values are learned from distinct visual representations. The keys are derived from an encoder with a small bottleneck for layout control, whereas the values come from a larger bottleneck encoder that captures fine-grained appearance details. By mixing keys and values from these complementary sources, our model preserves the identity of the visual prompts while supporting flexible variations in object arrangement, pose, and composition. During inference, we further propose object-level compositional guidance to improve the method's identity preservation and layout correctness. Results show that our technique produces diverse scene compositions that preserve the unique characteristics of each visual prompt, expanding the creative potential of text-to-image generation. Nondipole interaction between two uniformly magnetized spheres and its relation to superconducting levitation Analytically solving the magnetostatic Maxwell equations in the bispherical coordinates, we calculate the magnetic field around two uniformly magnetized spheres oriented so that their magnetic moments are parallel to the axis passing through the centers of the spheres. We demonstrate that, contrary to what is often claimed in the literature, the magnetic interaction between such spheres is not equivalent to the interaction between two point magnetic dipoles placed in the centers of the spheres. The nonzero levitation force acting on a uniformly magnetized sphere or a point magnetic dipole above a superconducting sphere in the ideal Meissner state is a clear manifestation of the non-equivalence. Weakly almost-Fuchsian manifolds are nearly-Fuchsian We show that a hyperbolic three-manifold $M$ containing a closed minimal surface with principal curvatures in $[-1,1]$ also contains nearby (non-minimal) surfaces with principal curvatures in $(-1,1)$. When $M$ is complete and homeomorphic to $S\times\mathbb{R}$, for $S$ a closed surface, this implies that $M$ is quasi-Fuchsian, answering a question left open from Uhlenbeck's 1983 seminal paper. Additionally, our result implies that there exist (many) quasi-Fuchsian manifolds that contain a closed surface with principal curvatures in $(-1,1)$, but no closed minimal surface with principal curvatures in $(-1,1)$, disproving a conjecture from the 2000s. SMT-Boosted Security Types for Low-Level MPC Secure Multi-Party Computation (MPC) is an important enabling technology for data privacy in modern distributed applications. We develop a new type theory to automatically enforce correctness,confidentiality, and integrity properties of protocols written in the \emph{Prelude/Overture} language framework. Judgements in the type theory are predicated on SMT verifications in a theory of finite fields, which supports precise and efficient analysis. Our approach is automated, compositional, scalable, and generalizes to arbitrary prime fields for data and key sizes. Bias-variance decompositions: the exclusive privilege of Bregman divergences Bias-variance decompositions are widely used to understand the generalization performance of machine learning models. While the squared error loss permits a straightforward decomposition, other loss functions - such as zero-one loss or $L_1$ loss - either fail to sum bias and variance to the expected loss or rely on definitions that lack the essential properties of meaningful bias and variance. Recent research has shown that clean decompositions can be achieved for the broader class of Bregman divergences, with the cross-entropy loss as a special case. However, the necessary and sufficient conditions for these decompositions remain an open question. In this paper, we address this question by studying continuous, nonnegative loss functions that satisfy the identity of indiscernibles under mild regularity conditions. We prove that so-called $g$-Bregman divergences are the only such loss functions that have a clean bias-variance decomposition. A $g$-Bregman divergence can be transformed into a standard Bregman divergence through an invertible change of variables. This makes the squared Mahalanobis distance, up to such a variable transformation, the only symmetric loss function with a clean bias-variance decomposition. We also examine the impact of relaxing the restrictions on the loss functions and how this affects our results. RUN: Reversible Unfolding Network for Concealed Object Segmentation Existing concealed object segmentation (COS) methods frequently utilize reversible strategies to address uncertain regions. However, these approaches are typically restricted to the mask domain, leaving the potential of the RGB domain underexplored. To address this, we propose the Reversible Unfolding Network (RUN), which applies reversible strategies across both mask and RGB domains through a theoretically grounded framework, enabling accurate segmentation. RUN first formulates a novel COS model by incorporating an extra residual sparsity constraint to minimize segmentation uncertainties. The iterative optimization steps of the proposed model are then unfolded into a multistage network, with each step corresponding to a stage. Each stage of RUN consists of two reversible modules: the Segmentation-Oriented Foreground Separation (SOFS) module and the Reconstruction-Oriented Background Extraction (ROBE) module. SOFS applies the reversible strategy at the mask level and introduces Reversible State Space to capture non-local information. ROBE extends this to the RGB domain, employing a reconstruction network to address conflicting foreground and background regions identified as distortion-prone areas, which arise from their separate estimation by independent modules. As the stages progress, RUN gradually facilitates reversible modeling of foreground and background in both the mask and RGB domains, directing the network's attention to uncertain regions and mitigating false-positive and false-negative results.
Extensive experiments demonstrate the superior performance of RUN and highlight the potential of unfolding-based frameworks for COS and other high-level vision tasks. We will release the code and models. Marginal Price Optimization We introduce a new framework for optimal routing and arbitrage in AMM driven markets. This framework improves on the original best-practice convex optimization by restricting the search to the boundary of the optimal space. We can parameterize this boundary using a set of prices, and a potentially very high dimensional optimization problem (2 optimization variables per curve) gets reduced to a much lower dimensional root finding problem (1 optimization variable per token, regardless of the number of the curves). Our reformulation is similar to the dual problem of a reformulation of the original convex problem. We show our reformulation of the problem is equivalent to the original formulation except in the case of infinitely concentrated liquidity, where we provide a suitable approximation. Our formulation performs far better than the original one in terms of speed - we obtain an improvement of up to 200x against Clarabel, the new CVXPY default solver - and robustness, especially on levered curves. RAMer: Reconstruction-based Adversarial Model for Multi-party Multi-modal Multi-label Emotion Recognition Conventional multi-modal multi-label emotion recognition (MMER) from videos typically assumes full availability of visual, textual, and acoustic modalities. However, real-world multi-party settings often violate this assumption, as non-speakers frequently lack acoustic and textual inputs, leading to a significant degradation in model performance. Existing approaches also tend to unify heterogeneous modalities into a single representation, overlooking each modality's unique characteristics. To address these challenges, we propose RAMer (Reconstruction-based Adversarial Model for Emotion Recognition), which leverages adversarial learning to refine multi-modal representations by exploring both modality commonality and specificity through reconstructed features enhanced by contrastive learning. RAMer also introduces a personality auxiliary task to complement missing modalities using modality-level attention, improving emotion reasoning. To further strengthen the model's ability to capture label and modality interdependency, we propose a stack shuffle strategy to enrich correlations between labels and modality-specific features. Experiments on three benchmarks, i.e., MEmoR, CMU-MOSEI, and $M^3$ED, demonstrate that RAMer achieves state-of-the-art performance in dyadic and multi-party MMER scenarios. A First Look at the Performance Enhancement Potential of Fluid Reconfigurable Intelligent Surface The fluid antenna concept represents shape-flexible and position-flexible antenna technologies designed to enhance wireless communication applications. In this paper, we apply this concept to reconfigurable intelligent surfaces (RISs), introducing fluid RIS (FRIS), where each tunably reflecting element becomes a fluid element with additional position reconfigurability. This new paradigm is referred to as fluid RIS (FRIS). We investigate an FRIS-programmable wireless channel, where the fluid meta-surface is divided into non-overlapping subareas, each acting as a fluid element that can dynamically adjust both its position and phase shift of the reflected signal. We first analyze the single-user, single-input single-output (SU-SISO) channel, in which a single-antenna transmitter communicates with a single-antenna receiver via an FRIS. The achievable rate is maximized by optimizing the fluid elements using a particle swarm optimization (PSO)- based approach. Next, we extend our analysis to the multi-user, multiple-input single-output (MU-MISO) case, where a multi-antenna base station (BS) transmits individual data streams to multiple single-antenna users via an FRIS. In this case, the joint optimization of the positions and phase shifts of the FRIS element, as well as the BS precoding to maximize the sum-rate is studied. To solve the problem, a combination of techniques including PSO, semi-definite relaxation (SDR), and minimum mean square error (MMSE) is proposed. Numerical results demonstrate that the proposed FRIS approach significantly outperforms conventional RIS configurations in terms of achievable rate performance. Forecasting Monthly Residential Natural Gas Demand Using Just-In-Time-Learning Modeling Natural gas (NG) is relatively a clean source of energy, particularly compared to fossil fuels, and worldwide consumption of NG has been increasing almost linearly in the last two decades. A similar trend can also be seen in Turkey, while another similarity is the high dependence on imports for the continuous NG supply. It is crucial to accurately forecast future NG demand (NGD) in Turkey, especially, for import contracts; in this respect, forecasts of monthly NGD for the following year are of utmost importance. In the current study, the historical monthly NG consumption data between 2014 and 2024 provided by SOCAR, the local residential NG distribution company for two cities in Turkey, Bursa and Kayseri, was used to determine out-of-sample monthly NGD forecasts for a period of one year and nine months using various time series models, including SARIMA and ETS models, and a novel proposed machine learning method. The proposed method, named Just-in-Time-Learning-Gaussian Process Regression (JITL-GPR), uses a novel feature representation for the past NG demand values; instead of using past demand values as column-wise separate features, they are placed on a two-dimensional (2-D) grid of year-month values. For each test point, a kernel function, tailored for the NGD predictions, is used in GPR to predict the query point. Since a model is constructed separately for each test point, the proposed method is, indeed, an example of JITL. The JITL-GPR method is easy to use and optimize, and offers a reduction in forecast errors compared to traditional time series methods and a state-of-the-art combination model; therefore, it is a promising tool for NGD forecasting in similar settings. Compact and fully functional high-frequency sine wave gating InGaAs/InP single-photon detector module High-frequency sine wave gating (SWG) InGaAs/InP single-photon detectors (SPDs) are widely used for synchronous near-infrared single-photon detection. For practical use, the size of SPD is one of the most concerning features for system integration. Here we present, to the best of our knowledge, the most compact and fully functional high-frequency SWG InGaAs/InP SPD. We develop a sine wave gating integrated circuit (SWGIC) using system-in-package technology that supports functions including large amplitude sine wave gate generation, coincidence gate generation, phase regulation, amplitude monitoring, and amplitude modulation. Moreover, we design and fabricate a high-performance multi-mode fiber coupled InGaAs/InP single-photon avalanche diode (SPAD) with a compact butterfly package. Furthermore, we implement a monolithically integrated readout circuit (MIRC) to extract the weak avalanche signal from large capacitance response of SWG. Finally, the SWGIC, SPAD, MIRC, and the affiliated circuits are integrated into a single module with a size of 6 cm x 5.7 cm x 1.7 cm. After characterization, the SPD module exhibits a photon detection efficiency of 40%, a dark count rate of 9 kcps, and an afterpulse probability of 4.6% at an operation temperature of 238 K and a hold-off time of 160 ns. Our work provides a practical solution for applications necessitating highly integrated near-infrared single-photon detection. Removing Averaging: Personalized Lip-Sync Driven Characters Based on Identity Adapter Recent advances in diffusion-based lip-syncing generative models have demonstrated their ability to produce highly synchronized talking face videos for visual dubbing. Although these models excel at lip synchronization, they often struggle to maintain fine-grained control over facial details in generated images. In this work, we identify "lip averaging" phenomenon where the model fails to preserve subtle facial details when dubbing unseen in-the-wild videos.
This issue arises because the commonly used UNet backbone primarily integrates audio features into visual representations in the latent space via cross-attention mechanisms and multi-scale fusion, but it struggles to retain fine-grained lip details in the generated faces. To address this issue, we propose UnAvgLip, which extracts identity embeddings from reference videos to generate highly faithful facial sequences while maintaining accurate lip synchronization. Specifically, our method comprises two primary components: (1) an Identity Perceiver module that encodes facial embeddings to align with conditioned audio features; and (2) an ID-CrossAttn module that injects facial embeddings into the generation process, enhancing model's capability of identity retention. Extensive experiments demonstrate that, at a modest training and inference cost, UnAvgLip effectively mitigates the "averaging" phenomenon in lip inpainting, significantly preserving unique facial characteristics while maintaining precise lip synchronization. Compared with the original approach, our method demonstrates significant improvements of 5% on the identity consistency metric and 2% on the SSIM metric across two benchmark datasets (HDTF and LRW). Wasserstein-based Kernels for Clustering: Application to Power Distribution Graphs Many data clustering applications must handle objects that cannot be represented as vector data. In this context, the bag-of-vectors representation can be leveraged to describe complex objects through discrete distributions, and the Wasserstein distance can effectively measure the dissimilarity between them. Additionally, kernel methods can be used to embed data into feature spaces that are easier to analyze. Despite significant progress in data clustering, a method that simultaneously accounts for distributional and vectorial dissimilarity measures is still lacking. To tackle this gap, this work explores kernel methods and Wasserstein distance metrics to develop a computationally tractable clustering framework. The compositional properties of kernels allow the simultaneous handling of different metrics, enabling the integration of both vectors and discrete distributions for object representation. This approach is flexible enough to be applied in various domains, such as graph analysis and image processing. The framework consists of three main components. First, we efficiently approximate pairwise Wasserstein distances using multiple reference distributions. Second, we employ kernel functions based on Wasserstein distances and present ways of composing kernels to express different types of information. Finally, we use the kernels to cluster data and evaluate the quality of the results using scalable and distance-agnostic validity indices. A case study involving two datasets of 879 and 34,920 power distribution graphs demonstrates the framework's effectiveness and efficiency. BLR velocities in optically and X-ray selected AGN samples We have analyzed optical spectra of 473 X-ray and 235 optically selected AGNs, to study their emission line properties. We present results of an analysis of the H-beta linewidths. We find that the linewidth distribution of quasars is shifted towards higher velocities (<v>=4300 km s-1) compared to the distribution of Sy 1s (<v>=3000 km s-1). There are no Narrow Line Quasars, i.e. there are no AGNs with quasar luminosities and FWHM(H-beta) < 2000 km s-1. NLSy1s comprise 20-30 per cent of the AGN population at faint absolute magnitudes (MB>-22), irrespective of the selection method. In the RASS sample we find Gamma [0.1-2.4 keV] < 3.3. The Gamma vs. FWHM(H-beta) distribution for Sy 1 galaxies is consistent with previous work. For QSOs the spectral index also flattens with increasing FWHM(H-beta), but they have larger linewidths than Seyfert 1s. An inhomogeneous fractal cosmological model We present a cosmological model in which the metric allows for an inhomogeneous Universe with no intrinsic symmetries (Stephani models), providing the ideal features to describe a fractal distribution of matter. Constraints on the metric functions are derived using the expansion and redshift relations and allowing for scaling number counts, as expected in a fractal set. The main characteristics of such a cosmological model are discussed. The HELLAS2XMM survey: II. Multiwavelength observations of P3: an X-ray bright, optically inactive galaxy Recent X-ray surveys have clearly demonstrated that a population of optically dull, X-ray bright galaxies is emerging at 2-10 keV fluxes of the order of 10^{-14} erg cm^{-2} s^{-1}. Although they might constitute an important fraction of the sources responsible for the hard X-ray background, their nature is still unknown. With the aim to better understand the physical mechanisms responsible for the observed properties, we have started an extensive program of multiwavelength follow-up observations of hard X-ray, optically quiet galaxies discovered with XMM-Newton. Here we report the results of what can be considered the first example of this class of objects: CXOUJ031238.9-765134, originally discovered by Chandra, and optically identified by Fiore et al. (2000) with an apparently normal early-type galaxy at z=0.159, usually known as "FIORE P3". The analysis of the broad-band energy distribution suggests the presence of a heavily obscured active nucleus. Constraints on Models for TeV Gamma Rays from Gamma-Ray Bursts We explore several models which might be proposed to explain recent possible detections of high-energy (TeV) gamma rays in association with low-energy gamma-ray bursts (GRBs). Likely values (and/or upper limits) for the source energies in low- and high-energy gamma rays and hadrons are deduced for the burst sources associated with possible TeV gamma-ray detections by the Project GRAND array. Possible spectra for energetic gammas are deduced for three models: 1) inverse-Compton scattering of ambient photons from relativistic electrons; 2) proton-synchrotron emission; and 3) inelastic scattering of relativistic protons from ambient photons creating high-energy neutral pions, which decay into high-energy photons. These models rely on some basic assumptions about the GRB properties, e.g. that: the low- and high-energy gamma rays are produced at the same location; the time variability of the high-energy component can be estimated from the FWHM of the highest peak in the low-energy gamma ray light curve; and the variability-luminosity relation of Fenimore & Ramirez-Ruiz (2000) gives a reliable estimate of the redshifts of these bursts. We also explore the impact of each of these assumptions upon our models. We conclude that the energetic requirements are difficult to satisfy for any of these models unless, perhaps, either the photon beaming angle is much narrower for the high-energy component than for the low-energy GRB or the bursts occur at very low redshifts (z<0.01). Nevertheless, we find that the energetic requirements are most easily satisfied if TeV gamma rays are produced predominantly by inverse-Compton scattering with a magnetic field strength well below equipartition or by proton-synchrotron emission with a magnetic field strength near equipartition. Metallicity in the Galactic Center: The Arches cluster We present a quantitative spectral analysis of five very massive stars in the Arches cluster, located near the Galactic center, to determine stellar parameters, stellar wind properties and, most importantly, metallicity content. The analysis uses a new technique, presented here for the first time, and uses line-blanketed NLTE wind/atmosphere models fit to high-resolution near-infrared spectra of late-type nitrogen-rich Wolf-Rayet stars and OfI+ stars in the cluster. It relies on the fact that massive stars reach a maximum nitrogen abundance that is related to initial metallicity when they are in the WNL phase. We determine the present-day nitrogen abundance of the WNL stars in the Arches cluster to be 1.6% (mass fraction) and constrain the stellar metallicity in the cluster to be solar. This result is invariant to assumptions about the mass-luminosity relationship, the mass-loss rates, and rotation speeds. In addition, from this analysis, we find the age of the Arches cluster to be 2-2.5Myr, assuming coeval formation.
The GALEX-VVDS Measurement of the Evolution of the Far-Ultraviolet Luminosity Density and the Cosmic Star Formation Rate In a companion paper (Arnouts et al. 2004) we presented new measurements of the galaxy luminosity function at 1500 Angstroms out to z~1 using GALEX-VVDS observations (1039 galaxies with NUV<24.5 and z>0.2) and at higher z using existing data sets. In this paper we use the same sample to study evolution of the FUV luminosity density. We detect evolution consistent with a (1+z)^{2.5+/-0.7} rise to z~1 and (1+z)^{0.5+/-0.4} for z>1. The luminosity density from the most UV-luminous galaxies (UVLG) is undergoing dramatic evolution (x30) between 0<z<1. UVLGs are responsible for a significant fraction (>25%) of the total FUV luminosity density at z<1. We measure dust attenuation and star formation rates of our sample galaxies and determine the star formation rate density as a function of redshift, both uncorrected and corrected for dust. We find good agreement with other measures of the SFR density in the rest ultraviolet and Halpha given the still significant uncertainties in the attenuation correction. Stellar disk truncations at high-z: probing inside-out galaxy formation We have conducted a systematic search for stellar disk truncations in disk-like galaxies at intermediate redshift (z<1.1) using the Hubble Ultra Deep Field (UDF) data. We use the position of the truncation as a direct estimator of the size of the stellar disk. After accounting for the surface brightness evolution of the galaxies, our results suggest that the radial position of the truncations has increased with cosmic time by ~1-3 kpc in the last ~8 Gyr. This result indicates a small to moderate (~25%) inside-out growth of the disk galaxies since z~1. New Bounds on Omega Baryons from Observational Big Bang Nucleosynthesis We re-examine the systematic errors in the determination of the primordial helium abundance, $Y_{\rm P}$. We find that the systematics are significantly larger than the statistical errors. The uncertainty in (the determination of) $Y_{\rm P}$, is thus, larger than is currently claimed. Furthermore, most of the systematics lead to underestimate of $Y_{\rm P}$. The new upper bound allows cosmological models with no non-baryonic dark matter in which $\Omega_{baryons} = \Omega_{BBN} = \Omega_{dyn}$. The Radio-to-Submm Spectral Index as a Redshift Indicator We present models of the 1.4 GHz to 350 GHz spectral index, alpha(350/1.4), for starburst galaxies as a function of redshift. The models include a semi-analytic formulation, based on the well quantified radio-to-far infrared correlation for low redshift star forming galaxies, and an empirical formulation, based on the observed spectrum of the starburst galaxies M82 and Arp 220. We compare the models to the observed values of alpha(350/1.4) for starburst galaxies at low and high redshift. We find reasonable agreement between the models and the observations, and in particular, that an observed spectral index of alpha(350/1.4) > +0.5 indicates that the target source is likely to be at high redshift, z > 1. The evolution of alpha(350/1.4) with redshift is mainly due to the very steep rise in the Raleigh-Jeans portion of the thermal dust spectrum shifting into the 350 GHz band with increasing redshift. We also discuss situations where this relationship could be violated. We then apply our models to examine the putative identifications of submm sources in the Hubble Deep Field, and conclude that the submm sources reported by Hughes et al. are likely to be at high redshifts, z > 1.5. Search for optical microvariability in a large sample of Seyfert I galaxies We present results of an optical (I band) monitoring of a sample of 22 Seyfert I galaxies. We aimed to detect microvariability with time resolution from ~ 6 minutes down to 30 seconds for the most luminous one. It is the largest survey ever done in the search of rapid optical variations in Seyfert galaxies. We used differential photometry and a new method of analysis between galaxy and comparison stars light curves in order to minimize the influence of the intrinsic variabilities of the latter. We thus obtain precision on standard deviation measurements less than 1% and generally of the order of 0.5%. We obtain no clear detection of microvariability in any of these objects. In the hypothesis where optical microvariability could be due to synchrotron emission of a non thermal electrons population, we discuss the physical constraints imposed by these results. A determination of H_0 with the CLASS gravitational lens B1608+656: II. Mass models and the Hubble constant from lensing EDITED FROM PAPER: We present mass models of the four-image gravitational lens system B1608+656. A mass model for the lens galaxies has been determined that reproduces the image positions, two out of three flux-density ratios and the model time delays. Using the time delays determined by Fassnacht et al. (1999a), we find that the best isothermal mass model gives H_0=59^{+7}_{-6} km/s/Mpc for Omega_m=1 and Omega_l=0.0, or H_0=(65-63)^{+7}_{-6} km/s/Mpc for Omega_m=0.3 and Omega_l = 0.0-0.7 (95.4% statistical confidence). A systematic error of +/-15 km/s/Mpc is estimated. This cosmological determination of H_0 agrees well with determinations from three other gravitational lens systems (i.e. B0218+357, Q0957+561 and PKS1830-211), SNe Ia, the S-Z effect and local determinations. The current agreement on H_0 from four out of five gravitational lens systems (i) emphasizes the reliability of its determination from isolated gravitational lens systems and (ii) suggests that a close-to-isothermal mass profile can describe disk galaxies, ellipticals and central cluster ellipticals. The average of H_0 from B0218+357, Q0957+561, B1608+656 and PKS1830-211, gives H_0(GL)=69 +/-7 km/s/Mpc for a flat universe with Omega_m=1 or H_0(GL)=74 +/-8 km/s/Mpc for Omega_m=0.3 and Omega_l=0.0-0.7. When including PG1115+080, these values decrease to 64 +/-11 km/s/Mpc and 68 +/-13 km/s/Mpc (2-sigma errors), respectively. Protein dynamics with off-lattice Monte Carlo moves A Monte Carlo method for dynamics simulation of all-atom protein models is introduced, to reach long times not accessible to conventional molecular dynamics. The considered degrees of freedom are the dihedrals at C$_\alpha$-atoms. Two Monte Carlo moves are used: single rotations about torsion axes, and cooperative rotations in windows of amide planes, changing the conformation globally and locally, respectively. For local moves Jacobians are used to obtain an unbiased distribution of dihedrals. A molecular dynamics energy function adapted to the protein model is employed. A polypeptide is folded into native-like structures by local but not by global moves. Response Generation in Collaborative Negotiation In collaborative planning activities, since the agents are autonomous and heterogeneous, it is inevitable that conflicts arise in their beliefs during the planning process. In cases where such conflicts are relevant to the task at hand, the agents should engage in collaborative negotiation as an attempt to square away the discrepancies in their beliefs.
This paper presents a computational strategy for detecting conflicts regarding proposed beliefs and for engaging in collaborative negotiation to resolve the conflicts that warrant resolution. Our model is capable of selecting the most effective aspect to address in its pursuit of conflict resolution in cases where multiple conflicts arise, and of selecting appropriate evidence to justify the need for such modification. Furthermore, by capturing the negotiation process in a recursive Propose-Evaluate-Modify cycle of actions, our model can successfully handle embedded negotiation subdialogues. Lattice dynamics effects on small polaron properties This study details the conditions under which strong-coupling perturbation theory can be applied to the molecular crystal model, a fundamental theoretical tool for analysis of the polaron properties. I show that lattice dimensionality and intermolecular forces play a key role in imposing constraints on the applicability of the perturbative approach. The polaron effective mass has been computed in different regimes ranging from the fully antiadiabatic to the fully adiabatic. The polaron masses become essentially dimension independent for sufficiently strong intermolecular coupling strengths and converge to much lower values than those tradition-ally obtained in small-polaron theory. I find evidence for a self-trapping transition in a moderately adiabatic regime at an electron-phonon coupling value of .3. Our results point to a substantial independence of the self-trapping event on dimensionality. Static overscreening and nonlinear response in the Hubbard Model We investigate the static charge response for the Hubbard model. Using the Slave-Boson method in the saddle-point approximation we calculate the charge susceptibility. We find that RPA works quite well close to half-filling, breaking, of course, down close to the Mott transition. Away from half filling RPA is much less reliable: Already for very small values of the Hubbard interaction U, the linear response becomes much more efficient than RPA, eventually leading to overscreening already beyond quite moderate values of U. To understand this behavior we give a simple argument, which implies that the response to an external perturbation at large U should actually be strongly non-linear. This prediction is confirmed by the results of exact diagonalization. Quantum Phenomena in Low-Dimensional Systems A brief summary of the physics of low-dimensional quantum systems is given. The material should be accessible to advanced physics undergraduate students. References to recent review articles and books are provided when possible. Modified Thouless-Anderson-Palmer equations for the Sherrington-Kirkpatrick spin glass: Numerical solutions For large but finite systems the static properties of the infinite ranged Sherrington-Kirkpatrick model are numerically investigated in the entire the glass regime. The approach is based on the modified Thouless-Anderson-Palmer equations in combination with a phenomenological relaxational dynamics used as a numerical tool. For all temperatures and all bond configurations stable and meta stable states are found. Following a discussion of the finite size effects, the static properties of the state of lowest free energy are presented in the presence of a homogeneous magnetic field for all temperatures below the spin glass temperature. Moreover some characteristic features of the meta stable states are presented. These states exist in finite temperature intervals and disappear via local saddle node bifurcations. Numerical evidence is found that the excess free energy of the meta stable states remains finite in the thermodynamic limit. This implies a the `multi-valley' structure of the free energy on a sub-extensive scale. Symmetry Properties of Anisotropic Superfluids A system of equations is developed for a fluid with non-abelian local gauge symmetry. Anisotropy is introduced by requiring that the symmetry breaking preserves a restricted local gauge symmetry about a given direction in the gauge parameter space. A set of equations is proposed for the 3He-A system. Topological quantization conditions are discussed. Formation of fermionic molecules via interisotope Feshbach resonances We perform an analysis of recent experimental measurements and improve the lithium interaction potentials. For $^6$Li a consistent description can be given. We discuss theoretical uncertainties for the position of the wide $^6$Li Feshbach resonance, and we present an analytic scattering model for this resonance, based on the inclusion of a field-dependent virtual open-channel state. We predict new Feshbach resonances for the $^6$Li-$^7$Li system, and their importance for different types of crossover superfluidity models is discussed. Magnetism and Transport in YbMn2Sb2 A new ternary intermetallic compound, namely, YbMn2Sb2, has been synthesized and its magnetic and electrical transport properties have been studied in the temperature range of 2 to 300 K. This compound crystallizes in a trigonal, La2O2S type structure (space group P3bm1, No. 164) and is found to be ferromagnetically ordered at room temperature. The magnetism is attributed to the ordering of Mn sublattice. M5 xray absorption spectrum of YbMn2Sb2 obtained at room temperature suggests that the valency of Yb in this compound is close to 2. Electrical resistivity of this compound is metal like and a positive magnetoresistance of 13 percent is observed at 5 K in an applied field of 9T. Key words Rare earth intermetallics and alloys, Magnetic properties, Xray absorption spectroscopy, Electrical transport. Molecular motor traffic in a half-open tube The traffic of molecular motors which interact through mutual exclusion is studied theoretically for half-open tube-like compartments. These half-open tubes mimic the shapes of axons. The mutual exclusion leads to traffic jams or density plateaus on the filaments. A phase transition is obtained when the motor velocity changes sign. We identify the relevant length scales and characterize the jamming behavior using both analytical approximations and Monte Carlo simulations of lattice models. Critical domain size in a driven diffusive system The homogeneous ordered state transforms into a polydomain state via a nucleation mechanism in two-dimensional lattice gas if the particle jumps are biased by an external field $E$. A simple phenomenological model is used to describe the time evolution of a circular interface separating the ordered regions. It is shown that the area of a domain increases if its radius exceeds a critical value proportional to $1/E$ which agrees qualitatively with Monte Carlo simulations. Connection between Calogero-Marchioro-Wolfes type few-body models and free oscillators We establish the exact correspondence of the Calogero-Marchioro-Wolfes model and several of its generalizations with free oscillators. This connection yields the eigenstates and leads to a proof of the quantum integrability. The usefulness of our method for finding new solvable models is then demonstrated by an example. Optimum ground states for spin-3/2 ladders with two legs We construct the exact ground state for an antiferromagnetic spin-3/2 model on the two-leg ladder as an optimum ground state. The ground state contains a discrete parameter "sigma"=+/-1 and a continuous parameter "a" which controls z-axis anisotropy. For most values of "a" the global ground state is unique. It has vanishing sublattice magnetization and exponentially decaying correlation functions. By using the transfer matrix technique, we calculate exactly the fluctuations of the magnetization, the nearest-neighbour correlation, and the longitudinal correlation length as functions of the parameters. Charge dynamics and optical conductivity of the t-J model The dynamic charge susceptibility and the optical conductivity are calculated in the planar t-J model within the memory function method, working directly in terms of Hubbard operators. The density fluctuation spectrum consists of a damped sound-like mode for small wave vectors and a broad high energy peak ($\sim t$) for large momenta. The study of the optical conductivity shows that electron scattering from spin fluctuations leads to the Drude-frequency dependent relaxation rate which exhibits a crossover from $\omega^{3/2}$ behavior at low frequencies ($\omega <2|\mu|$), to a linear $\omega$-dependence for frequencies larger than $2|\mu|$. Due to the spin-polaron nature of charge carriers, extra absorbtions arise starting at a frequency $\omega \agt J$. The obtained results are in a good agreement with exact diagonalization studies. Crossover from Luttinger- to Fermi-liquid behavior in strongly anisotropic systems in large dimensions We consider the low-energy region of an array of Luttinger liquids coupled by a weak interchain hopping.
The leading logarithmic divergences can be re-summed to all orders within a self-consistent perturbative expansion in the hopping, in the large-dimension limit. The anomalous exponent scales to zero below the one-particle crossover temperature. As a consequence, coherent quasiparticles with finite weight appear along the whole Fermi surface. Extending the expansion self-consistently to all orders turns out to be crucial in order to restore the correct Fermi-liquid behavior. Long-range spin-pairing order and spin defects in quantum spin-1/2 ladders For w-legged antiferromagnetic spin-1/2 Heisenberg ladders, a long-range spin-pairing order can be identified which enables the separation of the space spanned by finite-range (covalent) valence-bond configurations into w+1 subspaces. Since every subspace has an equivalent counter subspace connected by translational symmetry, twofold degeneracy, breaking traslational symmetry is found except for the subspace where the ground state of w=even belongs to. In terms of energy ordering, (non)degeneracy and the discontinuities introduced in the long-range spin-pairing order by topological spin defects, the differences between even and odd ladders are explained in a general and systematic way. Evaluation of Coreference Rules on Complex Narrative Texts This article studies the problem of assessing relevance to each of the rules of a reference resolution system. The reference solver described here stems from a formal model of reference and is integrated in a reference processing workbench. Evaluation of the reference resolution is essential, as it enables differential evaluation of individual rules. Numerical values of these measures are given, and discussed, for simple selection rules and other processing rules; such measures are then studied for numerical parameters. Partial fillup and search time in LC tries Andersson and Nilsson introduced in 1993 a level-compressed trie (in short: LC trie) in which a full subtree of a node is compressed to a single node of degree being the size of the subtree. Recent experimental results indicated a 'dramatic improvement' when full subtrees are replaced by partially filled subtrees. In this paper, we provide a theoretical justification of these experimental results showing, among others, a rather moderate improvement of the search time over the original LC tries. For such an analysis, we assume that n strings are generated independently by a binary memoryless source with p denoting the probability of emitting a 1. We first prove that the so called alpha-fillup level (i.e., the largest level in a trie with alpha fraction of nodes present at this level) is concentrated on two values with high probability. We give these values explicitly up to O(1), and observe that the value of alpha (strictly between 0 and 1) does not affect the leading term. This result directly yields the typical depth (search time) in the alpha-LC tries with p not equal to 1/2, which turns out to be C loglog n for an explicitly given constant C (depending on p but not on alpha). This should be compared with recently found typical depth in the original LC tries which is C' loglog n for a larger constant C'. The search time in alpha-LC tries is thus smaller but of the same order as in the original LC tries. minimUML: A Minimalist Approach to UML Diagraming for Early Computer Science Education The Unified Modeling Language (UML) is commonly used in introductory Computer Science to teach basic object-oriented design. However, there appears to be a lack of suitable software to support this task. Many of the available programs that support UML focus on developing code and not on enhancing learning. Those that were designed for educational use sometimes have poor interfaces or are missing common and important features, such as multiple selection and undo/redo. There is a need for software that is tailored to an instructional environment and has all the useful and needed functionality for that specific task. This is the purpose of minimUML. minimUML provides a minimum amount of UML, just what is commonly used in beginning programming classes, while providing a simple, usable interface. In particular, minimUML was designed to support abstract design while supplying features for exploratory learning and error avoidance. In addition, it allows for the annotation of diagrams, through text or freeform drawings, so students can receive feedback on their work. minimUML was developed with the goal of supporting ease of use, supporting novice students, and a requirement of no prior-training for its use. An effective model of the spacetime foam An approximate model of the spacetime foam is offered in which each quantum handle (wormhole) is a 5D wormhole-like solution. A spinor field is introduced for an effective description of this foam. The topological handles of the spacetime foam can be attached either to one space or connect two different spaces. In the first case we have a wormhole with the quantum throat and such object can demonstrate a model of preventing the formation the naked singularity with relation $e > m$. In the second case the spacetime foam looks as a dielectric with quantum handles as dipoles. It is supposed that supergravity theories with a nonminimal interaction between spinor and electromagnetic fields can be considered as an effective model approximately describing the spacetime foam. The Dynamics of Inhomogeneous Cosmologies In this thesis we investigate cosmological models more general than the isotropic and homogeneous Friedmann-Lemaitre models. We focus on cosmologies with one spatial degree of freedom, whose matter content consists of a perfect fluid and the cosmological constant. We formulate the Einstein field equations as a system of quasilinear first order partial differential equations, using scale-invariant variables. The primary goal is to study the dynamics in the two asymptotic regimes, i.e. near the initial singularity and at late times. We highlight the role of spatially homogeneous dynamics as the background dynamics, and analyze the inhomogeneous aspect of the dynamics. We perform a variety of numerical simulations to support our analysis and to explore new phenomena. Redshifts and Killing Vectors Courses in introductory special and general relativity have increasingly become part of the curriculum for upper-level undergraduate physics majors and master's degree candidates. One of the topics rarely discussed is symmetry, particularly in the theory of general relativity. The principal tool for its study is the Killing vector. We provide an elementary introduction to the concept of a Killing vector field, its properties, and as an example of its utility apply these ideas to the rigorous determination of gravitational and cosmological redshifts. Comment on 'Model-dependence of Shapiro time delay and the "speed of gravity/speed of light" controversy' In a recent paper published in Classical and Quantum Gravity, 2004, vol. 21, p. 3803 Carlip used a vector-tensor theory of gravity to calculate the Shapiro time delay by a moving gravitational lens. He claimed that the relativistic correction of the order of v/c beyond the static part of the Shapiro delay depends on the speed of light c and, hence, the Fomalont-Kopeikin experiment is not sensitive to the speed of gravity c_g. In this letter we analyze Carlip's calculation and demonstrate that it implies a gravitodynamic (non-metric) system of units based on the principle of the constancy of the speed of gravity but it is disconnected from the practical method of measurement of astronomical distances based on the principle of the constancy of the speed of light and the SI metric (electrodynamic) system of units. Re-adjustment of theoretically-admissible but practically unmeasurable Carlip's coordinates to the SI metric system of units used in JPL ephemeris, reveals that the velocity-dependent correction to the static part of the Shapiro time delay does depend on the speed of gravity c_g as shown by Kopeikin in Classical and Quantum Gravity, 2004, vol. 21, p. 1. This analysis elucidates the importance of employing the metric system of units for physically meaningful interpretation of gravitational experiments. Lattice QCD - A guide for people who want results Lattice QCD was invented thirty years ago but only in the last few years has it finally fulfilled its promise as a precision tool for calculations in hadron physics. This review will cover the fundamentals of discretising QCD onto a space-time lattice and how to reduce the errors associated with the discretisation.
This 'improvement' is the key that has made the enormous computational task of a lattice QCD calculation tractable and enabled us to reach the recent milestone of precision calculations of simple 'gold-plated' hadron masses. Accurate decay matrix elements, such as those for leptonic and semileptonic decays of heavy mesons needed by the B factory experimental programme, are now within sight. I will describe what goes into such calculations and what the future prospects and limitations are. Exploring the spectrum of QCD using a space-time lattice Some past and ongoing explorations of the spectrum of QCD using Monte Carlo simulations on a space-time lattice are described. Glueball masses in the pure-gauge theory are reviewed, and the energies of gluonic excitations in the presence of a static quark-antiquark pair are discussed. Current efforts to compute the baryon spectrum using extended three-quark operators are also presented, emphasizing the need to use irreducible representations of the cubic point group to identify spin quantum numbers in the continuum limit. Three-Dimensional 3-State Potts Model Revisited With New Techniques We report a fairly detailed finite-size scaling analysis of the first-order phase transition in the three-dimensional 3-state Potts model on cubic lattices with emphasis on recently introduced quantities whose infinite-volume extrapolations are governed `only' by exponentially small terms. In these quantities no asymptotic power series in the inverse volume are involved which complicate the finite-size scaling behaviour of standard observables related to the specific-heat maxima or Binder-parameter minima. Introduced initially for strong first-order phase transitions in q-state Potts models with ``large enough'' q, the new techniques prove to be surprisingly accurate for a q value as small as 3. On the basis of the high-precision Monte Carlo data of Alves `et al.' [Phys. Rev. B43 (1991) 5846], this leads to a refined estimate of $\beta_t = 0.550,565(10)$ for the infinite-volume transition point. The spin content of the proton in full QCD We present preliminary results on the proton spin structure function in full QCD. The measurement has been done using 4 flavours of staggered fermions and an improved definition of the lattice topological charge density. Extension of the Nielsen-Ninomiya theorem The index theorem is employed to extend the no-go theorem for lattice chiral Dirac fermions to translation non-invariant and non-local formulations. Strange sea asymmetry in nucleons We evaluate the medium effects in nucleon which can induce an asymmetry of the strange sea. The short-distance effects determined by the weak interaction can give rise to $\delta m\equiv \Delta m_s-\Delta m_{\bar s}$ where $\Delta m_{s(\bar s)}$ is the medium-induced mass of strange quark by a few KeV at most, but the long-distance effects by strong interaction could be sizable. NNLO coefficient functions of Higgs and Drell--Yan cross sections in Mellin space We calculate the Mellin moments of next-to-next-to-leading order coefficient functions of the Drell-Yan and Higgs production cross sections. The results can be expressed in term of finite harmonic sums which are maximally threefold up to weight four. Various algebraic relations among these finite sums reduce the complexity of the results suitable for fast numerical evaluations. It is shown that only five non--trivial functions occur besides Euler's $\psi$--function in the representation of these Wilson coefficients. Kink modes and effective four dimensional fermion and Higgs brane models In the construction of a classical smoothed out brane world model in five dimensions, one uses a dynamically generated domain wall (a kink) to localise an effective four dimensional theory. At the level of the Euler-Lagrange equations the kink sets up a potential well, a mechanism which has been employed extensively to obtain localised, four dimensional, massless chiral fermions. We present the generalisation of this kink trapping mechanism for both scalar and fermionic fields, and retain all degrees of freedom that were present in the higher dimensional theory. We show that a kink background induces a symmetric modified Poschl-Teller potential well, and give explicit analytic forms for all the bound modes and a restricted set of the continuum modes. We demonstrate that it is possible to confine an effective four dimensional scalar field with a quartic potential of arbitrary shape. This can be used to place the standard model electroweak Higgs field on the brane, and also generate nested kink solutions. We also consider the limits of the parameters in the theory which give thin kinks and localised and de-localised scalar and fermionic fields. Bubble Wall Velocity at the Electroweak Phase Transition We calculate the velocity and thickness of a bubble wall at the electroweak phase transition in the Minimal Standard Model. We model the wall with semiclassical equations of motion and show that friction arises from the deviation of massive particle populations from thermal equilibrium. We treat these with Boltzmann equations in a fluid approximation in the background of the wall. Our analysis improves on the previous work by using the two loop effective potential, accounting for particle transport, and determining the wall thickness dynamically. We find that the wall is significantly thicker than at phase equilibrium, and that the velocity is fairly high, $v_w \simeq 0.7c$, and quite weakly dependent on the Higgs mass. Possible Nonstandard Effects in Z+Gamma Events at LEP2 We point out that the so--called 'radiative return' events at LEP2 are suited to the study of nonstandard physics, particularly if the vector bosons are emitted into the central detector region. An effective vertex is constructed which contains the most general gauge invariant eeZGamma interaction and its phenomenological consequences are examined. Low Energy Constraints on the effective vertex are discussed as well. Various Modified Solutions of the Randall-Sundrum Model with the Gauss-Bonnet Interaction The Gauss-Bonnet interaction is the only consistent quadratic interaction below the Planck scale in the Randall-Sundrum compactification. We study various static and inflationary solutions including this Gauss-Bonnet interaction. Remarks on the canonical quantization of noncommutative theories Free noncommutative fields constitute a natural and interesting example of constrained theories with higher derivatives. The quantization methods involving constraints in the higher derivative formalism can be nicely applied to these systems. We study real and complex free noncommutative scalar fields where momenta have an infinite number of terms. We show that these expressions can be summed in a closed way and lead to a set of Dirac brackets which matches the usual corresponding brackets of the commutative case. Improved BFT embedding having chain-structure We newly revisit the gauge non-invariant chiral Schwinger model with a=1 in view of the chain structure. As a result, we show that the Dirac brackets can be easily read off from the exact symplectic algebra of second-class constraints. Furthermore, by using an improved BFT embedding preserving the chain structure, we obtain the desired gauge invariant action including a new type of Wess-Zumino term. Non-Geometric Magnetic Flux and Crossed Modules It is shown that the BRST operator of twisted N=4 Yang-Mills theory in four dimensions is locally the same as the BRST operator of a fully decomposed non-Abelian gerbe. Using locally defined Yang-Mills theories we describe non-perturbative backgrounds that carry a novel magnetic flux. Given by elements of the crossed module G x Aut G, these non-geometric fluxes can be classified in terms of the cohomology class of the underlying non-Abelian gerbe, and generalise the centre ZG valued magnetic flux found by 't Hooft. These results shed light also on the description of non-local dynamics of the chiral five-brane in terms of non-Abelian gerbes. Tunneling in two dimensional QCD The spectral density for two dimensional continuum QCD has a non-analytic behavior for a critical area. Apparently this is not reflected in the Wilson loops. However, we show that the existence of a critical area is encoded in the winding Wilson loops: Although there is no non-analyticity or phase transition in these Wilson loops, the dynamics of these loops consists of two smoothly connected domains separated by the critical area, one domain with a confining behavior for large winding Wilson loops, and one (below the critical size) where the string tension disappears. We show that this can be interpreted in terms of a simple tunneling process between an ordered and a disordered state.
In view of recent results by Narayanan and Neuberger this tunneling may also be relevant for four dimensional QCD. Lattice W algebras and quantum groups We represent Feigin's construction [11] of lattice W algebras and give some simple results: lattice Virasoro and $W_3$ algebras. For simplest case $g=sl(2)$ we introduce whole $U_q(sl(2))$ quantum group on this lattice. We find simplest two-dimensional module as well as exchange relations and define lattice Virasoro algebra as algebra of invariants of $U_q(sl(2))$. Another generalization is connected with lattice integrals of motion as the invariants of quantum affine group $U_q(\hat{n}_{+})$. We show that Volkov's scheme leads to the system of difference equations for the function from non-commutative variables.Continium limit of this lattice algebras are considered. Interaction of non-parallel D1-branes We find the potential per unit length between two non-intersecting D1-branes as a function of their relative angle. Semi-infinite throats at finite temperature and static solutions in exactly solvable models of 2d dilaton gravity Found is a general form of static solutions in exactly solvable models of 2d dilaton gravity at finite temperature. We reveal a possibility for the existence of everywhere regular solutions including black holes, semi-infinite throats and star-like configurations. In particular, we consider the Bose-Parker-Peleg (BPP) model which possesses a semi-infinite throat and analyze it at finite temperature. We also suggest generalization of the BPP model in which the appearance of semi-infinite throat has a generic character and does not need special fine tuning between parameters of the solution. Bose-Einstein condensation and superfluidity of a weakly-interacting photon gas in a nonlinear Fabry-Perot cavity A field theoretical framework for the recently proposed photon condensation effect in a nonlinear Fabry-Perot cavity is discussed. The dynamics of the photon gas turns out to be described by an effective 2D Hamiltonian of a complex massive scalar field. Finite size effects are shown to be relevant for the existence of the photon condensate. On Holomorphic Effective Actions of Hypermultiplets Coupled to External Gauge Superfields We study the structure of holomorphic effective action for hypermultiplet models interacting with background super Yang-Mills fields. A general form of holomorphic effective action is found for hypermultiplet belonging to arbitrary representation of any semisimple compact Lie group spontaneously broken to its maximal abelian subgroup. The applications of obtained results to hypermultiplets in fundamental and adjoint representations of the SU(n), SO(n), Sp(n) groups are considered. Monotone Solutions of a Nonautonomous Differential Equation for a Sedimenting Sphere We study a class of integrodifferential equations and related ordinary differential equations for the initial value problem of a rigid sphere falling through an infinite fluid medium. We prove that for creeping Newtonian flow, the motion of the sphere is monotone in its approach to the steady state solution given by the Stokes drag. We discuss this property in terms of a general nonautonomous second order differential equation, focusing on a decaying nonautonomous term motivated by the sedimenting sphere problem. A rigid body dynamics derived from a class of extended Gaudin models : an integrable discretization We consider a hierarchy of classical Liouville completely integrable models sharing the same (linear) $r$--matrix structure obtained through an $N$--th jet--extension of $\mathfrak{su}(2)$ rational Gaudin models. The main goal of the present paper is the study of the integrable model corresponding to N=3, since the case N=2 has been considered by the authors in separate papers, both in the one--body case (Lagrange top) and in the $n$--body one (Lagrange chain). We now obtain a rigid body associated with a Lie--Poisson algebra which is an extension of the Lie--Poisson structure for the two--field top, thus breaking its semidirect product structure. In the second part of the paper we construct an integrable discretization of a suitable continuous Hamiltonian flow for the system. The map is constructed following the theory of B\"acklund transformations for finite--dimensional integrable systems developed by V.B. Kuznetsov and E.K. Sklyanin. Stable reduction of modular curves We determine the stable reduction at $p$ of all three point covers of the projective line with Galois group ${\rm SL}_2(p)$. As a special case, we recover the results of Deligne and Rapoport on the reduction of the modular curves $X_0(p)$ and $X_1(p)$. Our method does not use the fact that modular curves are moduli spaces. Instead, we rely on results of Raynaud and the authors which describe the stable reduction of three point covers whose Galois group is strictly divisible by $p$. A recursive bijective approach to counting permutations containing 3-letter patterns We present a method, illustrated by several examples, to find explicit counts of permutations containing a given multiset of three letter patterns. The method is recursive, depending on bijections to reduce to the case of a smaller multiset, and involves a consideration of separate cases according to how the patterns overlap. Specifically, we use the method (i) to provide combinatorial proofs of Bona's formula {2n-3}choose{n-3} for the number of n-permutations containing one 132 pattern and Noonan's formula 3/n {2n}choose{n+3} for one 123 pattern, (ii) to express the number of n-permutations containing exactly k 123 patterns in terms of ballot numbers for k<=4, and (iii) to express the number of 123-avoiding n-permutations containing exactly k 132 patterns as a linear combination of powers of 2, also for k<=4. The results strengthen the conjecture that the counts are algebraic for all k. Martin Boundary and Integral Representation for Harmonic Functions of Symmetric Stable Processes Martin boundaries and integral representations of positive functions which are harmonic in a bounded domain $D$ with respect to Brownian motion are well understood. Unlike the Brownian case, there are two different kinds of harmonicity with respect to a discontinuous symmetric stable process. One kind are functions harmonic in $D$ with respect to the whole process $X$, and the other are functions harmonic in $D$ with respect to the process $X^D$ killed upon leaving $D$. In this paper we show that for bounded Lipschitz domains, the Martin boundary with respect to the killed stable process $X^D$ can be identified with the Euclidean boundary. We further give integral representations for both kinds of positive harmonic functions. Also given is the conditional gauge theorem conditioned according to Martin kernels and the limiting behaviors of the $h$-conditional stable process, where $h$ is a positive harmonic function of $X^D$. In the case when $D$ is a bounded $C^{1, 1}$ domain, sharp estimate on the Martin kernel of $D$ is obtained. Theoretical description of the double beta decay of 160Gd The half-life of the 2 neutrino double-beta-decay of 160Gd, a process which was previously reported as theoretically forbidden, is estimated by including the pairing interaction, which mixes different occupations and opens channels for the decay. Explicit expressions are presented for the pairing mixing, and for the 2 nu and 0 nu double-beta-decay nuclear matrix elements in the present pseudo SU(3) approach. The estimated double-beta-decay half-lives suggest that the planned experiments would succeed in detecting the 2 nu double-beta-decay in 160Gd, and in putting competitive limits for the zero neutrino mode. Pattern Recognition and Data Compression for the ALICE High Level Trigger The central detectors of the ALICE experiment at LHC will produce a data size of up to 75 MByte/event at an event rate <200 Hz resulting in a data rate of \~15 GByte/sec. This exceeds the foreseen mass storage bandwidth of 1.25 GByte/sec by one order of magnitude. Online processing of the data is necessary in order to select interesting (sub)events ("High Level Trigger"), or to compress data efficiently by modeling techniques. The largest computing challenge is imposed by the TPC, requiring realtime pattern recognition.
The work carried out investigates the performance of various pattern recognition schemes applicable for online track reconstruction within the ALICE HLT system. Furthermore, as an application for reducing the data rate, very efficient TPC data compression algorithms based on track and cluster modeling have been evaluated. Heavy atom tunneling in chemical reactions: study of H + LiF collisions The H+LiF(X 1Sigma+,v=0-2,j=0)-->HF(X 1Sigma+,v',j')+Li(2S) bimolecular process is investigated by means of quantum scattering calculations on the chemically accurate X 2A' LiHF potential energy surface of Aguado et al. [J. Chem. Phys. 119, 10088 (2003)]. Calculations have been performed for zero total angular momentum for translational energies from 10-7 to 10-1 eV. Initial-state selected reaction probabilities and cross sections are characterized by resonances originating from the decay of metastable states of the H...F-Li and Li...F-H van der Waals complexes. Extensive assignment of the resonances has been carried out by performing quasibound states calculations in the entrance and exit channel wells. Chemical reactivity is found to be significantly enhanced by vibrational excitation at low temperatures, although reactivity appears much less favorable than non-reactive processes due to the inefficient tunneling of the relatively heavy fluorine atom strongly bound in van der Waals complexes. Role of network connectivity in intercellular calcium oscillations It is important to understand the coordinated performance of cells in tissue. One possible mechanism in this coordination involves intracellular calcium signaling. The topology of intercellular connections in tissue should also play an important role in this process. It is most relevant for plane tissues, in which the interaction between cells is due to gap junctions (epithelium, blood vessels). We demonstrate the importance of the topology of intercellular connectivity by investigating the properties of a model of calcium signaling for a small number of connected cells. Local-field effect in atom optics of two-component Bose-Einstein condensates Starting from the first principles of nonrelativistic QED we have developed the quantum theory of the interaction of a two-component ultracold atomic ensemble with the electromagnetic field of vacuum and laser photons. The main attention has been paid to the consistent consideration of dynamical dipole-dipole interactions in the radiation field. Taking into account local-field effects we have derived the system of Maxwell-Bloch equations. Optical properties of the two-component Bose gas are investigated. It is shown that the refractive index of the gas is given by the Maxwell-Garnett formula. All equations which are used up to now for the description of the behavior of an ultracold atomic ensemble in a radiation field can be obtained from our general system of equations in the low-density limit. Raman-Nath diffraction of the two-component atomic beam is investigated on the basis of our general system of equations. What's wrong with this rebuttal? A recent rebuttal to criticism of Bell's analysis is shown to be defective by fault of failure to consider all hypothetical conditions input into the derivation of Bell Inequalitites. On the problem of interactions in quantum theory The structure of representations describing systems of free particles in the theory with the invariance group SO(1,4) is investigated. The property of the particles to be free means as usual that the representation describing a many-particle system is the tensor product of the corresponding single-particle representations (i.e. no interaction is introduced). It is shown that the mass operator contains only continuous spectrum in the interval $(-\infty,\infty)$ and such representations are unitarily equivalent to ones describing interactions (gravitational, electromagnetic etc.). This means that there are no bound states in the theory and the Hilbert space of the many-particle system contains a subspace of states with the following property: the action of free representation operators on these states is manifested in the form of different interactions. Possible consequences of the results are discussed.
