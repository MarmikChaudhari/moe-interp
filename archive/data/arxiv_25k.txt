\title{\bf Decentralized adaptation in interconnected uncertain systems with nonlinear parametrization}

\begin{abstract}
We propose a technique for the design and analysis of decentralized adaptation algorithms in interconnected dynamical systems. Our technique does not require Lyapunov stability of the target dynamics and allows nonlinearly parameterized uncertainties. We show that for the considered class of systems,
conditions for reaching the control goals can be formulated in terms of the nonlinear $L_2$-gains of target dynamics of each interconnected subsystem. Equations for decentralized controllers and corresponding adaptation algorithms are also explicitly provided.

{\it Keywords:} nonlinear parametrization; unstable,
non-equilibrium dynamics; decentralized adaptive control; monotone functions
\end{abstract}

\section*{Notation}

According to the standard convention, $\mathbb{R}$ defines the field of real numbers and $\mathbb{R}_{\geq c}=\{x\in\mathbb{R}|x\geq c\}$,
$\mathbb{R}_{+}=\mathbb{R}_{\geq 0}$; symbol $\mathbb{R}^n$ stands for a linear space $\mathcal{L}(\mathbb{R})$ over the field of reals with
$\mathrm{dim}\{\mathcal{L}(\mathbb{R})\}=n$; $\|\mathbf{x}\|$ denotes the Euclidian norm of $\mathbf{x}\in\mathbb{R}^n$; $\mathcal{C}^k$ denotes the space of functions that are at least $k$ times differentiable;
$\mathcal{K}$ denotes the class of all strictly increasing functions $\kappa: \mathbb{R}_+\rightarrow \mathbb{R}_+$ such that
$\kappa(0)=0$. By ${L}_{p}^n[t_0,T]$, where $T>0$, $p\geq 1$ we denote the space of all functions $\mathbf{f}:\mathbb{R}_+\rightarrow\mathbb{R}^n$
such that
$\|\mathbf{f}\|_{p,[t_0,T]}=\left(\int_{0}^T\|\mathbf{f}(\tau)\|^{p}d\tau\right)^{1/p}<\infty$;
$\|\mathbf{f}\|_{p,[t_0,T]}$ denotes the ${L}_{p}^n[t_0,T]$-norm of
$\mathbf{f}(t)$. By ${L}^n_\infty[t_0,T]$ we denote the space of all functions $\mathbf{f}:\mathbb{R}_+\rightarrow\mathbb{R}^n$ such that
$\|\mathbf{f}\|_{\infty,[t_0,T]}={\mathrm{ess}} \sup\{\|\mathbf{f}(t)\|,t \in
[t_0,T]\}<\infty$, and $\|\mathbf{f}\|_{\infty,[t_0,T]}$ stands for the
${L}^n_\infty[t_0,T]$ norm of $\mathbf{f}(t)$.

A function $\mathbf{f}(\mathbf{x}): \mathbb{R}^{n}\rightarrow \mathbb{R}^m$ is said to be locally bounded if for any $\|\mathbf{x}\|<\delta$ there exists a constant $D(\delta)>0$ such that the following inequality holds:
$\|\mathbf{f}(\mathbf{x})\|\leq D(\delta)$. Let $\Gamma$ be an $n\times n$
square matrix, then $\Gamma>0$ denotes a positive definite
(symmetric) matrix, and $\Gamma^{-1}$ is the inverse of $\Gamma$.
By $\Gamma\geq 0$ we denote a positive semi-definite matrix,
$\|\mathbf{x}\|_{\Gamma}^2$ to denotes the quadratic form:
$\mathbf{x}^{T}\Gamma\mathbf{x}$, $\mathbf{x}\in\mathbb{R}^n$. The notation $|\cdot|$
stands for the modulus of a scalar. The solution of a system of differential equations $\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},t,{\boldsymbol{\theta}},\mathbf{u}), \
\mathbf{x}(t_0)=\mathbf{x}_0$, $\mathbf{u}:\mathbb{R}_+\rightarrow\mathbb{R}^m$,
${\boldsymbol{\theta}}\in\mathbb{R}^d$ for $t\geq t_0$ will be denoted as
$\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},\mathbf{u})$, or simply as $\mathbf{x}(t)$ if it is clear from the context what the values of $\mathbf{x}_0,{\boldsymbol{\theta}}$
are and how the function $\mathbf{u}(t)$ is defined.

Let $\mathbf{u}:\mathbb{R}^n\times\mathbb{R}^d\times\mathbb{R}_+\rightarrow\mathbb{R}^m$ be a function of state $\mathbf{x}$, parameters $\hat{{\boldsymbol{\theta}}}$, and time
$t$. Let in addition both $\mathbf{x}$ and $\hat{{\boldsymbol{\theta}}}$ be functions of $t$. Then in case the arguments of $\mathbf{u}$ are clearly defined by the context, we will simply write $\mathbf{u}(t)$ instead of
$\mathbf{u}(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)$.

The (forward complete) system
$\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},t,{\boldsymbol{\theta}},\mathbf{u}(t))$, is said to have an
$L_{p}^m [t_0,T]\mapsto L_{q}^n[t_0,T]$, gain ($T\geq t_0$,
$p,q\in\mathbb{R}_{\geq 1}\cup\infty$) with respect to its input
$\mathbf{u}(t)$ if and only if $\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},\mathbf{u}(t))\in L_{q}^n [t_0,T]$ for any $\mathbf{u}(t)\in L_{p}^m [t_0,T]$ and there exists a function
$\gamma_{q,p}:\mathbb{R}^n\times\mathbb{R}^d\times\mathbb{R}_+\rightarrow\mathbb{R}_+$
such that the following inequality holds:
$\|\mathbf{x}(t)\|_{q,[t_0,T]}\leq
\gamma_{q,p}(\mathbf{x}_0,{\boldsymbol{\theta}},\|\mathbf{u}(t)\|_{p,[t_0,T]})$. The function $\gamma_{q,p}(\mathbf{x}_0,{\boldsymbol{\theta}},\|\mathbf{u}(t)\|_{p,[t_0,T]})$
is assumed to be non-decreasing in $\|\mathbf{u}(t)\|_{p,[t_0,T]}$, and locally bounded in its arguments.

For notational convenience when dealing with vector fields and partial derivatives we will use the following extended notion of the Lie derivative of a function. Let $\mathbf{x}\in\mathbb{R}^n$ and assume
$\mathbf{x}$ can be partitioned as follows $\mathbf{x}=\mathbf{x}_1\oplus\mathbf{x}_2$,
where $\mathbf{x}_1\in\mathbb{R}^q$, $\mathbf{x}_1=(x_{11},\dots,x_{1q})^T$,
$\mathbf{x}_2\in\mathbb{R}^p$, $\mathbf{x}_2=(x_{21},\dots,x_{2p})^T$, $q+p=n$, and
$\oplus$ denotes the concatenation of two vectors. Define
$\mathbf{f}:\mathbb{R}^{n}\rightarrow\mathbb{R}^n$ such that
$\mathbf{f}(\mathbf{x})=\mathbf{f}_1(\mathbf{x})\oplus\mathbf{f}_2(\mathbf{x})$, where
$\mathbf{f}_1:\mathbb{R}^n\rightarrow\mathbb{R}^q$,
$\mathbf{f}_1(\cdot)=(f_{11}(\cdot),\dots,f_{1q}(\cdot))^T$,
$\mathbf{f}_2:\mathbb{R}^n\rightarrow\mathbb{R}^p$,
$\mathbf{f}_2(\cdot)=(f_{21}(\cdot),\dots,f_{2p}(\cdot))^T$. Then
$L_{\mathbf{f}_i(\mathbf{x})}\psi(\mathbf{x},t)$, $i\in\{1,2\}$ denotes the Lie derivative of the function $\psi(\mathbf{x},t)$ with respect to the vector field $\mathbf{f}_i(\mathbf{x},{\boldsymbol{\theta}})$:
$L_{\mathbf{f}_i(\mathbf{x})}\psi(\mathbf{x},t)=\sum_{j}^{\dim{\mathbf{x}_i}}\frac{{\partial}
\psi(\mathbf{x},t) }{{\partial} x_{ij}}f_{ij}(\mathbf{x},{\boldsymbol{\theta}})$.

\section{Introduction}

We consider the problem how to control the behavior of complex dynamical systems composed of interconnected lower-dimensional subsystems. Centralized control of these systems is practically inefficient because of high demands for computational power,
measurements and prohibitive communication cost. On the other hand, standard decentralized solutions often face severe limitations due to the deficiency of information about the interconnected subsystems. In addition, the nature of their their interconnections may vary depending on conditions in the environment. In order to address these problems in their most general setup, decentralized adaptive control is needed.

Currently there is a large literature on decentralized adaptive control which contains successful solutions to problems of adaptive stabilization \cite{Gavel_1989,Jain_1997}, tracking
\cite{Ioannou86,Jain_1997,Shi_1992,Passino96}, and output regulation \cite{Jiang_2000,Huang_2003} of linear and nonlinear systems. In most of these cases the problem of decentralized control is solved within the conventional framework of adaptive stabilization/tracking/regulation by a family of linearly parameterized controllers. While these results may be successfully implemented in a large variety of technical and artificial systems, there is room for further improvements. In particular,
when the target dynamics of the systems is not stable in the Lyapunov sense but intermittent, meta-stable, or multi-stable
\cite{Arecchi_2004,Raffone_2003,Tsuda_2004} or when the uncertainties are nonlinearly parameterized
\cite{Armstrong_1993,Boskovic_1995,Canudas_1999,Kitching_2000},
and no domination of the uncertainties by feedback is allowed.

In the present article we address these issues at once for a class of nonlinear dynamical systems. Our contribution is that we provide conditions ensuring forward-completeness, boundedness and asymptotic reaching of the goal for a pair of interconnected systems with uncertain coupling and parameters. Our method does not require availability of a Lyapunov function for the desired motions in each subsystem, nor linear parametrization of the controllers. Our results can straightforwardly be extended to interconnection of arbitrary many (but still, a finite number of)
subsystems. Explicit equations for corresponding decentralized adaptive controllers are also provided.

The paper is organized as follows. In Section 2 we provide a formal statement of the problem, Section 3 contains necessary preliminaries and auxiliary results. In Section 4 we present the main results of our current contribution, and in Section 5 we provide concluding remarks to our approach.

\section{Problem Formulation}

Let us consider two interconnected systems $\mathcal{S}_x$ and
$\mathcal{S}_y$:
\begin{eqnarray}
&\mathcal{S}_x: & \
\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}}_x)+\gamma_y(\mathbf{y},t)+
\mathbf{g}(\mathbf{x})u_x \label{eq:system:s1} \\
&\mathcal{S}_y: & \
\dot{\mathbf{y}}=\mathbf{q}(\mathbf{y},{\boldsymbol{\theta}}_y)+\gamma_x(\mathbf{x},t)+\mathbf{z}(\mathbf{y})u_y\label{eq:system:s2}
\end{eqnarray}
where $\mathbf{x}\in\mathbb{R}^{n_x}$, $\mathbf{y}\in\mathbb{R}^{n_y}$ are the state vectors of systems $\mathcal{S}_x$ and $\mathcal{S}_y$, vectors
${\boldsymbol{\theta}}_x\in\mathbb{R}^{n_{\theta_x}}$,
${\boldsymbol{\theta}}_y\in\mathbb{R}^{n_{\theta_y}}$ are unknown parameters,
functions
$\mathbf{f}:\mathbb{R}^{n_x}\times\mathbb{R}^{n_{\theta_x}}\rightarrow\mathbb{R}^{n_x}$,
$\mathbf{q}:\mathbb{R}^{n_y}\times\mathbb{R}^{n_{\theta_y}}\rightarrow\mathbb{R}^{n_y}$,
$\mathbf{g}:\mathbb{R}^{n_x}\rightarrow\mathbb{R}^{n_x}$,
$\mathbf{z}:\mathbb{R}^{n_y}\rightarrow\mathbb{R}^{n_y}$ are continuous and locally bounded. Functions
$\gamma_y:\mathbb{R}^{n_y}\times\mathbb{R}_+\rightarrow\mathbb{R}_n$,
$\gamma_x:\mathbb{R}^{n_x}\times\mathbb{R}_+\rightarrow\mathbb{R}^{n_y}$, stand for nonlinear, non-stationary and, in general, unknown couplings between systems $\mathcal{S}_x$ and $\mathcal{S}_y$, and
$u_x\in\mathbb{R}$, $u_y\in\mathbb{R}$ are the control inputs.

In the present paper we are interested in the following problem

\begin{problem}\label{problem:decentralized}\normalfont Let $\psi_x:\mathbb{R}^{n_x}\times\mathbb{R}_+\rightarrow\mathbb{R}$,
$\psi_y:\mathbb{R}^{n_y}\times\mathbb{R}_+\rightarrow\mathbb{R}$ be the goal functions for systems $\mathcal{S}_x$, $\mathcal{S}_y$
respectively. In the other words, for some values
$\varepsilon_x\in\mathbb{R}_{+}$, $\varepsilon_y\in\mathbb{R}_+$ and time instant $t^\ast\in\mathbb{R}_+$, inequalities
\begin{equation}\label{eq:goal_functionals}
\|\psi_x(\mathbf{x}(t),t)\|_{\infty,[t^\ast,\infty]}\leq\varepsilon_x, \
\|\psi_y(\mathbf{y}(t),t)\|_{\infty,[t^\ast,\infty]}\leq\varepsilon_y
\end{equation}
specify the desired state of interconnection (\ref{eq:system:s1}),
(\ref{eq:system:s2}). Derive functions $u_x(\mathbf{x},t)$, $u_y(\mathbf{y},t)$
such that for all ${\boldsymbol{\theta}}_x\in\mathbb{R}^{n_{\theta_x}}$,
${\boldsymbol{\theta}}_y\in\mathbb{R}^{n_{\theta_y}}$

1) interconnection (\ref{eq:system:s1}), (\ref{eq:system:s2}) is forward-complete;

2) the trajectories $\mathbf{x}(t)$, $\mathbf{y}(t)$ are bounded;

3) for given values of $\varepsilon_x$, $\varepsilon_y$, some
$t^\ast\in\mathbb{R}_+$ exists such that inequalities
(\ref{eq:goal_functionals}) are satisfied or, possibly, both functions $\psi_x(\mathbf{x}(t),t)$, $\psi_y(\mathbf{y}(t),t)$ converge to zero as $t\rightarrow\infty$.

Function $u_x(\cdot)$ should not depend explicitly on $\mathbf{y}$ and,
symmetrically, function $u_y(\cdot)$ should not depend explicitly on $\mathbf{x}$. The general structure of the desired configuration of the control scheme is provided in Figure 1.
\end{problem}

\begin{figure}
\begin{center}
\includegraphics[width=110pt]{decentralized.eps}
\end{center}
\begin{center}
\caption{General structure of interconnection}\label{fig:decentralized:singularity}
\end{center}
\end{figure}

In the next sections we provide sufficient conditions, ensuring solvability of Problem \ref{problem:decentralized} and we also explicitly derive functions $u_x(\mathbf{x},t)$ and $u_y(\mathbf{y},t)$ which satisfy requirements 1) -- 3) of Problem
\ref{problem:decentralized}. We start with the introduction of a new class of adaptive control schemes and continue by providing the input-output characterizations of the controlled systems.
These results are given in Section \ref{sec:preliminary}. Then,
using these characterizations, in Section \ref{sec:main} we provide the main results of our study.

\section{Assumptions and properties of the decoupled systems}\label{sec:preliminary}

Let the following system be given:
\begin{equation}\label{system1}
\begin{split}
\dot{\mathbf{x}}_1=&\mathbf{f}_1(\mathbf{x})+\mathbf{g}_1(\mathbf{x})u, \\
\dot{\mathbf{x}}_2=&\mathbf{f}_2(\mathbf{x},{\boldsymbol{\theta}})+\mathbf{g}_2(\mathbf{x})u,
\end{split}
\end{equation}
where
\[
\mathbf{x}_1=(x_{11},\dots,x_{1 q})^T\in \mathbb{R}^q; \
\mathbf{x}_2=(x_{21},\dots,x_{2 p})^T\in \mathbb{R}^p;
\]
\[
\mathbf{x}=(x_{11},\dots,x_{1 q},x_{21},\dots,x_{2 p})^T\in \mathbb{R}^{n}
\]
${\boldsymbol{\theta}}\in \Omega_\theta\in \mathbb{R}^d$ is a vector of unknown parameters, and $\Omega_\theta$ is a closed bounded subset of
$\mathbb{R}^d$; $u\in\mathbb{R}$ is the control input, and functions
$\mathbf{f}_1:\mathbb{R}^{n}\rightarrow \mathbb{R}^{q}$,
$\mathbf{f}_2:\mathbb{R}^{n}\times\mathbb{R}^d\rightarrow \mathbb{R}^{p}$,
$\mathbf{g}_1:\mathbb{R}^{n}\rightarrow \mathbb{R}^q$,
$\mathbf{g}_2:\mathbb{R}^{n}\rightarrow\mathbb{R}^{p}$ are continuous and locally bounded. The vector $\mathbf{x}\in\mathbb{R}^n$ is the state vector, and vectors $\mathbf{x}_1$, $\mathbf{x}_2$ are referred to as {\it uncertainty-independent} and {\it uncertainty-dependent} partition of $\mathbf{x}$, respectively. For the sake of compactness we will also use the following description of (\ref{system1}):
\begin{equation}\label{system}
\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})+\mathbf{g}(\mathbf{x})u,
\end{equation}
where
\[
\mathbf{g}(\mathbf{x})=(g_{11}(\mathbf{x}),\dots,g_{1q}(\mathbf{x}),g_{21}(\mathbf{x}),\dots,g_{2 p}(\mathbf{x}))^{T},
\]
\[
\mathbf{f}(\mathbf{x})=(f_{11}(\mathbf{x}),\dots,f_{1q}(\mathbf{x}),f_{21}(\mathbf{x},{\boldsymbol{\theta}}),\dots,f_{2 p}(\mathbf{x},{\boldsymbol{\theta}}))^{T}.
\]

As a measure of closeness of trajectories $\mathbf{x}(t)$ to the desired state we introduce the error or goal function $\psi:\mathbb{R}^n\times
\mathbb{R}_+\rightarrow \mathbb{R}, \ \psi\in \mathcal{C}^1$.
We suppose also that for the chosen function $\psi(\mathbf{x},t)$
satisfies the following:
\begin{assume}[Target operator]\label{assume:psi} For the given function $\psi(\mathbf{x},t)\in \mathcal{C}^1$ the following property holds:
\begin{equation}\label{eq:assume_psi}
\|\mathbf{x}(t)\|_{\infty,[t_0,T]}\leq
\tilde{\gamma}\left(\mathbf{x}_0,{\boldsymbol{\theta}},\|\psi(\mathbf{x}(t),t)\|_{\infty,[t_0,T]}\right)
\end{equation}
where
$\tilde{\gamma}\left(\mathbf{x}_0,{\boldsymbol{\theta}},\|\psi(\mathbf{x}(t),t)\|_{\infty,[t_0,T]}\right)$
is a locally bounded and non-negative function of its arguments.
\end{assume}
Assumption \ref{assume:psi} can be interpreted as a sort of {\it unboundedness observability} property \cite{Jiang_1994} of system
(\ref{system1}) with respect to the ``output" function
$\psi(\mathbf{x},t)$. It can also be viewed as a {\it bounded input -
bounded state} assumption for system (\ref{system1}) along the constraint
$\psi(\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},u(\mathbf{x}(t),t)),t)=\upsilon(t)$,
where the signal $\upsilon(t)$ serves as a new input. If, however,
boundedness of the state is not explicitly required (i.e. it is guaranteed by additional control or follows from the physical properties of the system itself), Assumption \ref{assume:psi} can be removed from the statements of our results.

Let us specify a class of control inputs $u$ which can ensure boundedness of $\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},u)$ for every
${\boldsymbol{\theta}}\in \Omega_\theta$ and $\mathbf{x}_0\in\mathbb{R}^n$. According to
(\ref{eq:assume_psi}), boundedness of
$\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},u)$ is ensured if we find a control input $u$ such that $\psi(\mathbf{x}(t),t)\in L_\infty^1[t_0,\infty]$.
For this objective consider the dynamics of system (\ref{system})
with respect to $\psi(\mathbf{x},t)$:
\begin{equation}\label{dpsi}
\dot{\psi}=L_{\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})}\psi(\mathbf{x},t)+L_{\mathbf{g}(\mathbf{x})}\psi(\mathbf{x},t)u+\frac{{\partial}
\psi(\mathbf{x},t)}{{\partial} t},
\end{equation}
Assuming that the inverse
$\left(L_{\mathbf{g}(\mathbf{x})}\psi(\mathbf{x},t)\right)^{-1}$ exists everywhere,
we may choose the control input $u$ in the following class of functions:
\begin{equation}\label{control}
\begin{split}
u(\mathbf{x},\hat{\boldsymbol{\theta}},{\boldsymbol{\omega}},t)&=\frac{1}{L_{\mathbf{g}(\mathbf{x})}\psi(\mathbf{x},t)}\left(-L_{\mathbf{f}(\mathbf{x},\hat{{\boldsymbol{\theta}}})}\psi(\mathbf{x},t)-\varphi(\psi,{\boldsymbol{\omega}},t)-\frac{{\partial}\psi(\mathbf{x},t)}{{\partial} t}\right) \\
& \ \varphi: \ \mathbb{R}\times\mathbb{R}^w\times\mathbb{R}_+\rightarrow\mathbb{R}
\end{split}
\end{equation}
where ${\boldsymbol{\omega}}\in\Omega_\omega\subset\mathbb{R}^w$ is a vector of
{\it known} parameters of the function
$\varphi(\psi,{\boldsymbol{\omega}},t)$. Denoting
$L_{\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})}\psi(\mathbf{x},t)=f(\mathbf{x},{\boldsymbol{\theta}},t)$ and taking into account (\ref{control}) we may rewrite equation
(\ref{dpsi}) in the following manner:
\begin{equation}\label{error_model}
{\dot\psi}=f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-\varphi(\psi,{\boldsymbol{\omega}},t)
\end{equation}

For the purpose of the present article, instead of
(\ref{error_model}) it is worthwhile to consider the extended equation:
\begin{equation}\label{error_model_d}
{\dot\psi}=f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-\varphi(\psi,{\boldsymbol{\omega}},t)+\varepsilon(t),
\end{equation}
where, if not stated overwise, the function
$\varepsilon:\mathbb{R}_+\rightarrow\mathbb{R}$, $\varepsilon\in L_{2}^1
[t_0,\infty]\cap C^0$. One of the immediate advantages of equation
(\ref{error_model_d}) in comparison with (\ref{error_model}) is that it allows us to take the presence of coupling between interconnected systems into consideration.

Let us now specify the desired properties of the function
$\varphi(\psi,{\boldsymbol{\omega}},t)$ in (\ref{control}),
(\ref{error_model_d}). The majority of known algorithms for parameter estimation and adaptive control
\cite{Kokotovich95,Fradkov99,Narendra89,Sastry89} assume global
(Lyapunov) stability of system
(\ref{error_model_d}) for ${\boldsymbol{\theta}}\equiv\hat{{\boldsymbol{\theta}}}$. In our study, however, we refrain from this standard, restrictive requirement. Instead we propose that finite energy of the signal
$f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)$, defined for example by its $L_{2}^1[t_0,\infty]$ norm with respect to the variable $t$, results in finite deviation from the target set given by the equality $\psi(\mathbf{x},t)=0$. Formally this requirement is introduced in Assumption \ref{assume:gain}:
\begin{assume}[Target dynamics operator]\label{assume:gain} Consider the following system:
\begin{equation}\label{eq:target_dynamics}
{\dot\psi}=-\varphi(\psi,{\boldsymbol{\omega}},t)+\zeta(t),
\end{equation}
where $\zeta:\mathbb{R}_+\rightarrow\mathbb{R}$ and
$\varphi(\psi,{\boldsymbol{\omega}},t)$ is defined in (\ref{error_model_d}).
Then for every ${\boldsymbol{\omega}}\in\Omega_\omega$ system
(\ref{eq:target_dynamics}) has $L_{2}^1 [t_0,\infty]\mapsto L_\infty^1[t_0,\infty]$ gain with respect to input $\zeta(t)$. In other words, there exists a function $\gamma_{\infty,2}$ such that
\begin{equation}\label{eq:gain_psi_L2}
\|\psi(t)\|_{\infty,[t_0,T]}\leq
\gamma_{\infty,2}(\psi_0,{\boldsymbol{\omega}},\|\zeta(t)\|_{2,[t_0,T]}), \ \
\forall \ \zeta(t)\in L_{2}^1[t_0,T]
\end{equation}
\end{assume}
In contrast to conventional approaches, Assumption
\ref{assume:gain} does not require global {\it asymptotic stability} of the origin of the unperturbed (i.e for $\zeta(t)=0$)
system (\ref{eq:target_dynamics}). When the stability of the target dynamics ${\dot\psi}=-\varphi(\psi,{\boldsymbol{\omega}},t)$ is known a-priori, one of the benefits of Assumption \ref{assume:gain} is that there is no need to know a {\it particular Lyapunov function}
of the unperturbed system.

So far we have introduced basic assumptions on system
(\ref{system1}) and the class of feedback considered in this article. Let us now specify the class of functions
$f(\mathbf{x},{\boldsymbol{\theta}},t)$ in (\ref{error_model_d}). Since general parametrization of function $f(\mathbf{x},{\boldsymbol{\theta}},t)$ is methodologically difficult to deal with, but solutions provided for nonlinearities with convenient linear re-parametrization often yield physically implausible models and large number of unknown parameters, we have opted for a new class of parameterizations.
As a candidate for such a parametrization we suggest nonlinear functions that satisfy the following assumption:
\begin{assume}[Monotonicity and Growth Rate in Parameters]\label{assume:alpha}For the given function
$f(\mathbf{x},{\boldsymbol{\theta}},t)$ in (\ref{error_model_d}) there exists function $\boldsymbol{\alpha}(\mathbf{x},t): \mathbb{R}^{n}\times \mathbb{R}_+\rightarrow
\mathbb{R}^d, \ \boldsymbol{\alpha}(\mathbf{x},t)\in \mathcal{C}^1$ and positive constant $D>0$ such that
\begin{equation}\label{eq:assume_alpha}
(f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-f(\mathbf{x},{\boldsymbol{\theta}},t))(\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}}))\geq0
\end{equation}
\begin{equation}\label{eq:assume_gamma}
|f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-f(\mathbf{x},{\boldsymbol{\theta}},t)|\leq D
|\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}})|
\end{equation}
\end{assume}
This set of conditions naturally extends from systems that are linear in parameters to those with nonlinear parametrization.
Examples and models of physical and artificial systems which satisfy Assumption \ref{assume:alpha} (at least for bounded
${\boldsymbol{\theta}},\hat{{\boldsymbol{\theta}}}\in \Omega_\theta$) can be found in the following references
\cite{Armstrong_1993,Boskovic_1995,Canudas_1999,Abbott_2001,Kitching_2000}.
Assumption \ref{assume:alpha} bounds the growth rate of the difference $|f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)|$ by the functional
$D|\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}})|$.
In addition, it might also be useful to have an estimate of
$|f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)|$ from below, as specified in Assumption \ref{assume:alpha_upper}:
\begin{assume}\label{assume:alpha_upper} For the given function
$f(\mathbf{x},{\boldsymbol{\theta}},t)$ in (\ref{error_model_d}) and function
$\boldsymbol{\alpha}(\mathbf{x},t)$, satisfying Assumption \ref{assume:alpha},
there exists a positive constant $D_1>0$ such that
\begin{equation}\label{eq:assume_alpha_upper}
|f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-f(\mathbf{x},{\boldsymbol{\theta}},t)|\geq D_1
|\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}})|
\end{equation}
\end{assume}

\noindent In problems of adaptation, parameter and optimization estimation, effectiveness of the algorithms often depends on how
"good" the nonlinearity $f(\mathbf{x},{\boldsymbol{\theta}},t)$ is, and how predictable is the system's behavior. As a measure of goodness and predictability usually the substitutes as smoothness and boundedness are considered. In our study, we distinguish several of such specific properties of the functions $f(\mathbf{x},{\boldsymbol{\theta}},t)$
and $\varphi(\psi,{\boldsymbol{\omega}},t)$. These properties are provided below.

\begin{hyp}\label{hyp:locally_bound_uniform_f} The function $f(\mathbf{x},{\boldsymbol{\theta}},t)$ is locally bounded with respect to $\mathbf{x}$, ${{\boldsymbol{\theta}}}$ uniformly in $t$.
\end{hyp}

\begin{hyp}\label{hyp:locally_bound_uniform_df} The function $f(\mathbf{x},{\boldsymbol{\theta}},t)\in \mathcal{C}^1$, and $ {\partial}
{f(\mathbf{x},{\boldsymbol{\theta}},t)}/{{\partial} t}$ is locally bounded with respect to
$\mathbf{x}$, ${{\boldsymbol{\theta}}}$ uniformly in $t$.
\end{hyp}

\begin{hyp}\label{hyp:locally_bound_uniform_phi} The function $\varphi(\psi,{\boldsymbol{\omega}},t)$ is locally bounded in $\psi$,
${\boldsymbol{\omega}}$ uniformly in $t$.
\end{hyp}

Let us show that under an additional structural requirement, which relates properties of the function $\boldsymbol{\alpha}(\mathbf{x},t)$ and vector-field
$\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})=\mathbf{f}_1(\mathbf{x},{\boldsymbol{\theta}})\oplus\mathbf{f}_2(\mathbf{x},{\boldsymbol{\theta}})$
in (\ref{system1}), (\ref{system}), there exist adaptive algorithms ensuring that the following desired property holds:
\begin{equation}\label{eq:desired_prop}
\mathbf{x}(t)\in L_\infty^n[t_0,\infty]; \
f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}}(t),t)\in L_{2}^1[t_0,\infty]
\end{equation}

Consider the following adaptation algorithms:
\begin{equation}\label{fin_forms_ours_tr1}
\begin{split}
\hat{{\boldsymbol{\theta}}}(\mathbf{x},t)&=\Gamma(\hat{{\boldsymbol{\theta}}}_P(\mathbf{x},t)+\hat{{\boldsymbol{\theta}}}_I(t));
\ \Gamma\in\mathbb{R}^{d\times d}, \ \Gamma>0
\\ \hat{{\boldsymbol{\theta}}}_P(\mathbf{x},t)&=
\psi(\mathbf{x},t)\boldsymbol{\alpha}(\mathbf{x},t)-\Psi(\mathbf{x},t) \\
\dot{\hat{{\boldsymbol{\theta}}}}_I&=\varphi(\psi(\mathbf{x},t),{\boldsymbol{\omega}},t)\boldsymbol{\alpha}(\mathbf{x},t)+\mathcal{R}(\mathbf{x},\hat{{\boldsymbol{\theta}}},u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t),t),
\end{split}
\end{equation}
where the function
$\mathcal{R}(\mathbf{x},\hat{{\boldsymbol{\theta}}},u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t),t):\mathbb{R}^n\times\mathbb{R}^d\times\mathbb{R}\times\mathbb{R}_+\rightarrow\mathbb{R}^d$
in (\ref{fin_forms_ours_tr1}) is given as follows:
\begin{equation}\label{fin_forms_ours_tr11}
\begin{split}
&\mathcal{R}(\mathbf{x},u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t),t)={{\partial}
\Psi(\mathbf{x},t)}/{{\partial} t}-\psi(\mathbf{x},t)({{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}/{{\partial} t}+L_{\mathbf{f}_1}\boldsymbol{\alpha}(\mathbf{x},t))\\
& + L_{\mathbf{f}_1}
\Psi(\mathbf{x},t)-(\psi(\mathbf{x},t)L_{\mathbf{g}_1}\boldsymbol{\alpha}(\mathbf{x},t)-L_{\mathbf{g}_1}
\Psi(\mathbf{x},t))u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)
\end{split}
\end{equation}
and function
$\Psi(\mathbf{x},t):\mathbb{R}^{n}\times\mathbb{R}_+\rightarrow\mathbb{R}_d$,
$\Psi(\mathbf{x},t)\in \mathcal{C}^1$ satisfies Assumption
\ref{assume:explicit_realizability}.
\begin{assume}\label{assume:explicit_realizability} There exists a function $\Psi(\mathbf{x},t)$ such that
\begin{equation}\label{eq:assume_explicit}
\frac{{\partial} \Psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}-\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} \mathbf{x}_2}=0
\end{equation}
\end{assume}
Additional restrictions imposed by this assumption will be discussed in some details after we summarize the properties of system (\ref{system1}), (\ref{control}),
(\ref{fin_forms_ours_tr1}), (\ref{fin_forms_ours_tr11}) in the following theorem.

\begin{theorem}[Properties of the decoupled systems]\label{stability_theorem}
Let system (\ref{system1}), (\ref{error_model_d}),
(\ref{fin_forms_ours_tr1}), (\ref{fin_forms_ours_tr11}) be given and Assumptions \ref{assume:alpha}, \ref{assume:alpha_upper},
\ref{assume:explicit_realizability} be satisfied. Then the following properties hold

P1) Let for the given initial conditions $\mathbf{x}(t_0)$,
$\hat{{\boldsymbol{\theta}}}_I(t_0)$ and parameters vector ${\boldsymbol{\theta}}$,
interval $[t_0,T^\ast]$ be the (maximal) time-interval of existence of solutions of the closed loop system (\ref{system1}),
(\ref{error_model_d}), (\ref{fin_forms_ours_tr1}),
(\ref{fin_forms_ours_tr11}). Then
\begin{equation}\label{eq:f_diff_L2}
\|f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t))\|_{2,[t_0,T^\ast]}\leq D_f({\boldsymbol{\theta}},t_0,\Gamma,\|\varepsilon(t)\|_{2,[t_0,T^\ast]});
\end{equation}
\[
D_f({\boldsymbol{\theta}},t_0,\Gamma,\|\varepsilon(t)\|_{2,[t_0,T^\ast]})=\left(\frac{D}{2}\|{\boldsymbol{\theta}}-\hat{{\boldsymbol{\theta}}}(t_0)\|^{2}_{\Gamma^{-1}}\right)^{0.5}
+ \frac{D}{D_1}\|\varepsilon(t)\|_{2,[t_0,T^\ast]}
\]
\[
\|{\boldsymbol{\theta}}-\hat{\boldsymbol{\theta}}(t)\|^{2}_{\Gamma^{-1}}\leq
\|\hat{{\boldsymbol{\theta}}}(t_0)-{\boldsymbol{\theta}}\|^{2}_{\Gamma^{-1}}+\frac{D}{2 D_1^2}\|\varepsilon(t)\|^{2}_{2,[t_0,T^\ast]}
\]

\noindent In addition, if Assumptions \ref{assume:psi} and
\ref{assume:gain} are satisfied then

P2) $\psi(\mathbf{x}(t),t)\in L_\infty^1[t_0,\infty]$, $\mathbf{x}(t)\in L_{\infty}^n[t_0,\infty]$ and
\begin{equation}\label{eq:psi_gain}
\|\psi(\mathbf{x}(t),t)\|_{\infty,[t_0,\infty]}\leq
\gamma_{\infty,2}\left(\psi(\mathbf{x}_0,t_0),{\boldsymbol{\omega}},\mathcal{D}\right)
\end{equation}
\[
\mathcal{D}=D_f({\boldsymbol{\theta}},t_0,\Gamma,\|\varepsilon(t)\|_{2,[t_0,\infty]})+\|\varepsilon(t)\|_{2,[t_0,\infty]}
\]

P3) if properties H\ref{hyp:locally_bound_uniform_f},
H\ref{hyp:locally_bound_uniform_phi} hold, and system
(\ref{eq:target_dynamics}) has $L_{2}^1 [t_0,\infty]\mapsto L_{p}^1 [t_0,\infty]$, $p>1$ gain with respect to input $\zeta(t)$
and output $\psi$ then
\begin{equation}\label{eq:convergence_psi_theorem}
\varepsilon(t)\in L_{2}^1 [t_0,\infty]\cap L_{\infty}^1[t_0,\infty]\Rightarrow
\lim_{t\rightarrow\infty}\psi(\mathbf{x}(t),t)=0
\end{equation}

If, in addition, property H\ref{hyp:locally_bound_uniform_df}
holds, and the functions $\boldsymbol{\alpha}(\mathbf{x},t)$, ${\partial}
\psi(\mathbf{x},t)/{\partial} t$ are locally bounded with respect to $\mathbf{x}$
uniformly in $t$, then

P4) the following holds
\begin{equation}\label{eq:convergence_f_theorem}
\lim_{t\rightarrow\infty}f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)=0
\end{equation}

\end{theorem}
The proof of Theorem \ref{stability_theorem} and subsequent results are given in Section 6.

Let us briefly comment on Assumption
\ref{assume:explicit_realizability}.
Let $\boldsymbol{\alpha}(\mathbf{x},t)\in
\mathcal{C}^2$,
$\boldsymbol{\alpha}(\mathbf{x},t)=\mathrm{col}(\alpha_1(\mathbf{x},t),\dots,\alpha_d(\mathbf{x},t))$,
then necessary and sufficient conditions for existence of the function $\Psi(\mathbf{x},t)$ follow from the Poincar$\acute{\mathrm{e}}$ lemma:
\begin{equation}\label{eq:poincare}
\frac{{\partial}}{{\partial} \mathbf{x}_2}\left(\psi(\mathbf{x},t)\frac{{\partial}
\alpha_i(\mathbf{x},t)}{{\partial}
\mathbf{x}_2}
\right)=\left(\frac{{\partial}}{{\partial}
\mathbf{x}_2}\left(\psi(\mathbf{x},t)\frac{{\partial} \alpha_i(\mathbf{x},t)}{{\partial}
\mathbf{x}_2}
\right)
\right)^T
\end{equation}
This relation, in the form of conditions of existence of the solutions for function $\Psi(\mathbf{x},t)$ in
(\ref{eq:assume_explicit}), takes into account structural properties of system (\ref{system1}), (\ref{error_model_d}).
Indeed,
consider partial derivatives ${\partial} \alpha_i(\mathbf{x},t)/{\partial} \mathbf{x}_2$,
${\partial} \psi(\mathbf{x},t)/{\partial} \mathbf{x}_2$ with respect to the vector
$\mathbf{x}_2=(x_{21},\dots,x_{2p})^T$. Let
\begin{equation}\label{eq:single_dim}
\begin{split}
\frac{{\partial} \psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}=\left(\begin{array}{cccccccc}
0& 0
& \cdots & 0& \ast & 0&\cdots&0
\end{array}\right), \
\frac{{\partial}
\alpha_i(\mathbf{x},t)}{{\partial}\mathbf{x}_2}=\left(\begin{array}{cccccccc}
0 & 0
& \cdots & 0&
\ast &
0&\cdots&0
\end{array}\right)
\end{split}
\end{equation}
where the symbol $\ast$ denotes a function of $\mathbf{x}$ and $t$. Then condition (\ref{eq:single_dim}) guarantees that equality
(\ref{eq:poincare}) (and, subsequently, Assumption
\ref{assume:explicit_realizability}) holds. In case ${\partial}
\alpha(\mathbf{x}_1\oplus \mathbf{x}_2,t)/{\partial} \mathbf{x}_2=0$, Assumption
\ref{assume:explicit_realizability} holds for arbitrary
$\psi(\mathbf{x},t)\in \mathcal{C}^1$. If $\psi(\mathbf{x},t)$,
$\boldsymbol{\alpha}(\mathbf{x},t)$ depend on a single component of $\mathbf{x}_2$, for instance $x_{2k}, \ k\in\{0,\dots,p\}$, then conditions
(\ref{eq:single_dim}) hold and the function $\Psi(\mathbf{x},t)$ can be derived explicitly by integration
\begin{equation}\label{eq:single_dim_int}
\Psi(\mathbf{x},t)=\int\psi(\mathbf{x},t)\frac{\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} x_{2k}}d x_{2k}
\end{equation}
In all other cases, existence of the required function
$\Psi(\mathbf{x},t)$ follows from (\ref{eq:poincare}).

In the general case, when $\dim\{\mathbf{x}_2\}>1$, the problems of finding a function $\Psi(\mathbf{x},t)$ satisfying condition
(\ref{eq:assume_explicit}) can be avoided (or converted into one with an already known solutions such as (\ref{eq:poincare}),
(\ref{eq:single_dim_int})) by the {\it embedding} technique proposed in \cite{ECC_2003}. The main idea of the method is to introduce an auxiliary system that is forward-complete with respect to input $\mathbf{x}(t)$
\begin{equation}\label{eq:embed}
\begin{split}
\dot{{\boldsymbol{\xi}}}&=\mathbf{f}_{\boldsymbol{\xi}}(\mathbf{x},{\boldsymbol{\xi}},t), \ {\boldsymbol{\xi}}\in\mathbb{R}^z \\
\mathbf{h}_\xi&=\mathbf{h}_\xi({\boldsymbol{\xi}},t), \
\mathbb{R}^z\times\mathbb{R}_+\rightarrow\mathbb{R}^h
\end{split}
\end{equation}
such that
\begin{equation}\label{eq:embed_L2}
\|f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}_1(t)\oplus\mathbf{h}_\xi(t)\oplus\mathbf{x}_2'(t),{\boldsymbol{\theta}},t)\|_{2,[t_0,T]}
\leq C_\xi\in\mathbb{R}_+
\end{equation}
for all $T\geq t_0$, and $\dim\{{\mathbf{h}_\xi}\}+\dim{\{\mathbf{x}_2'\}}=p$.
Then (\ref{error_model_d}) can be rewritten as follows:
\begin{equation}\label{error_model_d1}
{\dot\psi}=f(\mathbf{x}_1\oplus\mathbf{h}_\xi\oplus\mathbf{x}_2',{\boldsymbol{\theta}},t)-f(\mathbf{x}_1\oplus\mathbf{h}_\xi\oplus\mathbf{x}_2',\hat{\boldsymbol{\theta}},t)-\varphi(\psi,{\boldsymbol{\omega}},t)+\varepsilon_\xi(t),
\end{equation}
where $\varepsilon_\xi(t)\in L_{2}^1 [t_0,\infty]$, and
$\dim\{\mathbf{x}_2'\}=p-h<p$. In principle, the dimension of $\mathbf{x}_2'$
could be reduced to $1$ or $0$. As soon as this is ensured,
Assumption \ref{assume:explicit_realizability} will be satisfied and the results of Theorem \ref{stability_theorem} follow.
Sufficient conditions ensuring the existence of such an embedding in the general case are provided in \cite{ECC_2003}. For systems in which the parametric uncertainty can be reduced to vector fields with low-triangular structure the embedding is given in
\cite{ALCOSP_2004}.

\section{Main Results}\label{sec:main}

Without loss of generality let us rewrite interconnection
(\ref{eq:system:s1}), (\ref{eq:system:s2}) as follows
:
\begin{equation}\label{eq:system:s11}
\begin{split}
\dot{\mathbf{x}}_1&=\mathbf{f}_1(\mathbf{x})+\mathbf{g}_1(\mathbf{x})u_x\\
\dot{\mathbf{x}}_2 &=\mathbf{f}_2(\mathbf{x},{\boldsymbol{\theta}}_x)+\gamma_y(\mathbf{y},t)+
\mathbf{g}_2(\mathbf{x})u_x
\end{split}
\end{equation}

\begin{equation}\label{eq:system:s21}
\begin{split}
\dot{\mathbf{y}}_1&=\mathbf{q}_1(\mathbf{y})+\mathbf{z}_1(\mathbf{y})u_y\\
\dot{\mathbf{y}}_2&=\mathbf{q}_2(\mathbf{y},{\boldsymbol{\theta}}_y)+\gamma_x(\mathbf{x},t)+\mathbf{z}_2(\mathbf{y})u_y
\end{split}
\end{equation}

Let us now consider the following control functions
\begin{equation}\label{control_s1}
\begin{split}
u_x(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x,{\boldsymbol{\omega}}_x,t)&=(L_{\mathbf{g}(\mathbf{x})}\psi_x(\mathbf{x},t))^{-1}\left(-L_{\mathbf{f}(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x)}\psi_x(\mathbf{x},t)-\varphi_x(\psi_x,{\boldsymbol{\omega}}_x,t)\right.\\
& \left.-\frac{{\partial}\psi_x(\mathbf{x},t)}{{\partial} t}\right), \ \ \varphi_x: \
\mathbb{R}\times\mathbb{R}^w\times\mathbb{R}_+\rightarrow\mathbb{R}
\end{split}
\end{equation}
\begin{equation}\label{control_s2}
\begin{split}
u_y(\mathbf{y},\hat{{\boldsymbol{\theta}}}_y,{\boldsymbol{\omega}}_y,t)&=(L_{\mathbf{z}(\mathbf{y})}\psi_y(\mathbf{y},t))^{-1}\left(-L_{\mathbf{q}(\mathbf{y},\hat{{\boldsymbol{\theta}}}_y)}\psi_y(\mathbf{y},t)-\varphi_y(\psi_y,{\boldsymbol{\omega}}_y,t)\right.\\
&\left.-\frac{{\partial}\psi_y(\mathbf{y},t)}{{\partial} t}\right), \ \ \varphi_y: \
\mathbb{R}\times\mathbb{R}^w\times\mathbb{R}_+\rightarrow\mathbb{R}
\end{split}
\end{equation}
These functions transform the original equations
(\ref{eq:system:s11}), (\ref{eq:system:s21}) into the following form
\begin{equation}\label{eq:error_coupled}
\begin{split}
{\dot\psi}_x&=-\varphi_x(\psi_x,{\boldsymbol{\omega}}_x,t)+f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)-f_x(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x,t)+h_y(\mathbf{x},\mathbf{y},t)\\
{\dot\psi}_y&=-\varphi_y(\psi_x,{\boldsymbol{\omega}}_y,t)+f_y(\mathbf{y},{\boldsymbol{\theta}}_y,t)-f_y(\mathbf{y},\hat{{\boldsymbol{\theta}}}_y,t)+h_x(\mathbf{x},\mathbf{y},t),
\end{split}
\end{equation}
where
\[
h_x(\mathbf{x},\mathbf{y},t)=L_{\gamma_y(\mathbf{y},t)}\psi_x(\mathbf{x},t), \
h_y(\mathbf{x},\mathbf{y},t)=L_{\gamma_x(\mathbf{x},t)}\psi_y(\mathbf{y},t)
\]
\[
f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)=L_{\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}}_x)}\psi_x(\mathbf{x},t), \
f_y(\mathbf{x},{\boldsymbol{\theta}}_y,t)=L_{\mathbf{q}(\mathbf{y},{\boldsymbol{\theta}}_y)}\psi_y(\mathbf{y},t)
\]

Consider the following adaptation algorithms
\begin{equation}\label{fin_forms_ours_tr1x}
\begin{split}
\hat{{\boldsymbol{\theta}}}_x(\mathbf{x},t)&=\Gamma_x(\hat{{\boldsymbol{\theta}}}_{P,x}(\mathbf{x},t)+\hat{{\boldsymbol{\theta}}}_{I,x}(t));
\ \Gamma_x\in\mathbb{R}^{d\times d}, \ \Gamma_x>0
\\ \hat{{\boldsymbol{\theta}}}_{P,x}(\mathbf{x},t)&=
\psi_x(\mathbf{x},t)\boldsymbol{\alpha}_x(\mathbf{x},t)-\Psi_x(\mathbf{x},t) \\
\dot{\hat{{\boldsymbol{\theta}}}}_{I,x}&=\varphi_x(\psi_x(\mathbf{x},t),{\boldsymbol{\omega}}_x,t)\boldsymbol{\alpha}_x(\mathbf{x},t)+\mathcal{R}_x(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x,u_x(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x,t),t),
\end{split}
\end{equation}

\begin{equation}\label{fin_forms_ours_tr1y}
\begin{split}
\hat{{\boldsymbol{\theta}}}_y(\mathbf{x},t)&=\Gamma_y(\hat{{\boldsymbol{\theta}}}_{P,y}(\mathbf{y},t)+\hat{{\boldsymbol{\theta}}}_{I,y}(t));
\ \Gamma_y\in\mathbb{R}^{d\times d}, \ \Gamma_y>0
\\ \hat{{\boldsymbol{\theta}}}_{P,y}(\mathbf{y},t)&=
\psi_y(\mathbf{y},t)\boldsymbol{\alpha}_y(\mathbf{y},t)-\Psi_y(\mathbf{y},t) \\
\dot{\hat{{\boldsymbol{\theta}}}}_{I,y}&=\varphi_y(\psi_y(\mathbf{y},t),{\boldsymbol{\omega}}_y,t)\boldsymbol{\alpha}_y(\mathbf{y},t)+\mathcal{R}_y(\mathbf{x},\hat{{\boldsymbol{\theta}}}_y,u_y(\mathbf{y},\hat{{\boldsymbol{\theta}}}_y,t),t),
\end{split}
\end{equation}
where $\mathcal{R}_x(\cdot)$, $\mathcal{R}_y(\cdot)$ are defined as in (\ref{fin_forms_ours_tr11}), and the functions
$\Psi_x(\cdot)$, $\Psi_y(\cdot)$ will be specified later. Now we are ready to formulate the following result

\begin{theorem}[Properties of the interconnected systems]\label{theorem:interconnection} Let systems (\ref{eq:system:s11}), (\ref{eq:system:s21}) be given. Furthermore, suppose that the following conditions hold:

1) The functions $\psi_x(\mathbf{x},t)$, $\psi_y(\mathbf{y},t)$ satisfy Assumption \ref{assume:psi} for systems (\ref{eq:system:s11}),
(\ref{eq:system:s21}) respectively;

2) The systems
\begin{equation}\label{eq:target_dynamics_connected}
\dot{\psi}_x=-\varphi_x(\psi_x,{\boldsymbol{\omega}}_x,t)+\zeta_x(t), \ \
\dot{\psi}_y=-\varphi_y(\psi_y,{\boldsymbol{\omega}}_y,t)+\zeta_y(t)
\end{equation}
satisfy Assumption \ref{assume:gain} with corresponding mappings
\[
\gamma_{x_{\infty,2}}(\psi_{x_0},{\boldsymbol{\omega}}_x,\|\zeta_x(t)\|_{2,[t_0,T]}),
\ \
\gamma_{y_{\infty,2}}(\psi_{y_0},{\boldsymbol{\omega}}_y,\|\zeta_y(t)\|_{2,[t_0,T]}),
\]

3) The systems (\ref{eq:target_dynamics_connected}) have
$L_2^1[t_0,\infty]\mapsto L_2^1[t_0,\infty]$ gains, that is
\begin{equation}\label{eq:L_2_2_gains}
\begin{split}
\|\psi_x(\mathbf{x}(t),t)\|_{2,[t_0,T]}&\leq C_{\gamma_x}+\gamma_{x_{2,2}}(\|\zeta_x(t)\|_{2,[t_0,T]}),\\
\|\psi_y(\mathbf{y}(t),t)\|_{2,[t_0,T]}&\leq C_{\gamma_y}+\gamma_{y_{2,2}}(\|\zeta_y(t)\|_{2,[t_0,T]}),\\
C_{\gamma_x}, \ C_{\gamma_y}\in\mathbb{R}_+& \gamma_{x_{2,2}}, \
\gamma_{y_{2,2}}\in\mathcal{K}_\infty
\end{split}
\end{equation}

4) The functions $f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)$,
$f_y(\mathbf{y},{\boldsymbol{\theta}}_y,t)$ satisfy Assumptions \ref{assume:alpha},
\ref{assume:alpha_upper} with corresponding constants $D_x$,
$D_{x_1}$, $D_y$, $D_{y_1}$ and functions $\boldsymbol{\alpha}_x(\mathbf{x},t)$,
$\boldsymbol{\alpha}_y(\mathbf{y},t)$;

5) The functions $h_x(\mathbf{x},\mathbf{y},t)$, $h_y(\mathbf{x},\mathbf{y},t)$ satisfy the following inequalities:
\begin{equation}\label{eq:disturbance_gain}
\|h_x(\mathbf{x},\mathbf{y},t)\|\leq \beta_x \|\psi_x(\mathbf{x},t)\|, \
\|h_y(\mathbf{x},\mathbf{y},t)\|\leq \beta_y \|\psi_y(\mathbf{y},t)\|, \ \beta_x,
\beta_y\in \mathbb{R}_+
\end{equation}

Finally, let the functions $\Psi_x(\mathbf{x},t)$, $\Psi_y(\mathbf{y},t)$ in
(\ref{fin_forms_ours_tr1x}), (\ref{fin_forms_ours_tr1y}) satisfy Assumption \ref{assume:explicit_realizability}
for systems (\ref{eq:system:s11}), (\ref{eq:system:s21})
respectively, and there exist functions $\rho_1(\cdot), \
\rho_2(\cdot), \ \rho_3(\cdot)>Id(\cdot)\in\mathcal{K}_\infty$ and constant $\bar{\Delta}\in\mathbb{R}_+$ such the following inequality holds:
\begin{equation}\label{eq:small_gain_adapt}
\beta_y\circ\gamma_{y_{2,2}}\circ\rho_1\circ\left(\frac{D_y}{D_{y,1}}+1\right)\circ\rho_3\circ
\beta_x\circ
\gamma_{x_{2,2}}\circ\rho_2\circ\left(\frac{D_x}{D_{x,1}}+1\right)(\Delta)<
\Delta
\end{equation}
for all $\Delta\geq \bar{\Delta}$. Then

C1) The interconnection (\ref{eq:system:s11}),
(\ref{eq:system:s21}) with controls (\ref{control_s1}),
(\ref{control_s2}) is forward-complete and trajectories $\mathbf{x}(t)$,
$\mathbf{y}(t)$ are bounded

Furthermore,

C2) if properties H\ref{hyp:locally_bound_uniform_f},
H\ref{hyp:locally_bound_uniform_phi} hold for
$f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)$, $f_y(\mathbf{y},{\boldsymbol{\theta}}_y,t)$,
$h_x(\mathbf{x},\mathbf{y},t)$, $h_y(\mathbf{x},\mathbf{y},t)$, and also functions
$\varphi_x(\psi_x,{\boldsymbol{\omega}}_x,t)$,
$\varphi_y(\psi_y,{\boldsymbol{\omega}}_y,t)$, then
\begin{equation}\label{eq:convergence_psi_xy}
\lim_{t\rightarrow\infty}\psi_x(\mathbf{x}(t),t)=0, \
\lim_{t\rightarrow\infty}\psi_y(\mathbf{y}(t),t)=0
\end{equation}

Moreover,

C3) if property H\ref{hyp:locally_bound_uniform_df} holds for
$f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)$, $f_y(\mathbf{y},{\boldsymbol{\theta}}_y,t)$, and the functions
\[
\boldsymbol{\alpha}_x(\mathbf{x},t), \ {\partial} \psi_x(\mathbf{x},t)/{\partial} t, \
\boldsymbol{\alpha}_y(\mathbf{y},t), \ {\partial} \psi_y(\mathbf{y},t)/{\partial} t
\]
are locally bounded with respect to $\mathbf{x}$, $\mathbf{y}$ uniformly in $t$,
then
\begin{equation}\label{eq:convergence_f_xy}
\begin{split}
\lim_{t\rightarrow\infty}f_x(\mathbf{x}(t),{\boldsymbol{\theta}}_x,t)-f_x(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}_x(t),t)&=0,
\\
\lim_{t\rightarrow\infty}f_y(\mathbf{y}(t),{\boldsymbol{\theta}}_y,t)-f_y(\mathbf{y}(t),\hat{{\boldsymbol{\theta}}}_y(t),t)&=0
\end{split}
\end{equation}
\end{theorem}

Let us briefly comment on the conditions and assumptions of Theorem \ref{theorem:interconnection}. Conditions 1), 2) specify restrictions on the goal functionals, similar to those of Theorem
\ref{stability_theorem}. Condition 3) is analogous to requirement to P3) in Theorem \ref{stability_theorem}, condition 5) specifies uncertainties in the coupling functions $h_x(\cdot)$, $h_y(\cdot)$
in terms of their growth rates w.r.t. $\psi_x(\cdot)$,
$\psi_y(\cdot)$. We observe here that this property is needed in order to characterize the $L_2$ norms of functions
$h_x(\mathbf{x}(t),\mathbf{y}(t),t)$, $h_y(\mathbf{x}(t),\mathbf{y}(t),t)$ in terms of the
$L_2$ norms of functions $\psi_x(\mathbf{x}(t),t)$, $\psi_y(\mathbf{y}(t),t)$.
Therefore, it is possible to replace requirement
(\ref{eq:disturbance_gain}) with the following set of conditions:
\begin{equation}\label{eq:disturbance_gain_1}
\begin{split}
\|h_x(\mathbf{x}(t),\mathbf{y}(t),t)\|_{2,[t_0,T]}&\leq \beta_x
\|\psi_x(\mathbf{x}(t),t)\|_{2,[t_0,T]}+C_x, \\
\|h_y(\mathbf{x}(t),\mathbf{y}(t),t)\|_{2,[t_0,T]}&\leq \beta_y
\|\psi_y(\mathbf{y}(t),t)\|_{2,[t_0,T]}+C_y
\end{split}
\end{equation}
The replacement will allow us to extend results of Theorem
\ref{theorem:interconnection} to interconnections of systems where the coupling functions do not depend explicitly on
$\psi_x(\mathbf{x}(t),t)$, $\psi_y(\mathbf{y}(t),t)$. We illustrate this possibility later with an example.

Condition (\ref{eq:small_gain_adapt}) is the small-gain condition with respect to the $L_2^1[t_0,T]$ norms for interconnection
(\ref{eq:system:s11}), (\ref{eq:system:s21}) with control
(\ref{control_s1}), (\ref{control_s2}). In the case that mappings
$\gamma_{x_{2,2}}(\cdot)$, $\gamma_{y_{2,2}}(\cdot)$ in
(\ref{eq:target_dynamics_connected}) are majorated by linear functions
\[
\gamma_{x_{2,2}}(\Delta)\leq g_{x_{2,2}} \Delta, \
\gamma_{y_{2,2}}(\Delta)\leq g_{y_{2,2}} \Delta, \ \Delta\geq 0,
\]
condition (\ref{eq:small_gain_adapt}) reduces to the much simpler
\[
\beta_y \beta_x g_{x_{2,2}} g_{y_{2,2}}
\left(\frac{D_y}{D_{y,1}}+1\right)\left(\frac{D_x}{D_{x,1}}+1\right)<
1
\]
Notice also that the mappings $\gamma_{x_{2,2}}(\cdot)$,
$\gamma_{y_{2,2}}(\cdot)$ are defined by properties of the target dynamics (\ref{eq:target_dynamics_connected}), and, in principle,
these can be made arbitrarily small. This eventually leads to the following conclusion: the smaller the $L_2$-gains of the target dynamics of systems $\mathcal{S}_1$, $\mathcal{S}_2$, the wider the class of nonlinearities (bounds for $\beta_x$, $\beta_y$, domains of $D_x$, $D_{1,x}$, $D_y$, $D_{1,y}$) which admit a solution to Problem \ref{problem:decentralized}.

\paragraph{Example}

Let us illustrate application of Theorem
\ref{theorem:interconnection} to the problem of decentralized control of two coupled oscillators with nonlinear damping.
Consider the following interconnected systems:
\begin{equation}\label{eq:example_dec_model}
\left\{\begin{array}{ll}
\dot{x}_{1}&=x_{2}\\
\dot{x}_{2}&=f_x(x_{1},\theta_x)+k_1 y_{1} + u_x,
\end{array} \right. \ \
\left\{
\begin{array}{ll}
\dot{y}_{1}&=y_{2}\\
\dot{y}_{22}&=f_y(y_{1},\theta_y)+k_2 x_{1}+ u_y,
\end{array}\right.
\end{equation}
where $k_1$, $k_2\in\mathbb{R}$ are uncertain parameters of coupling,
functions $f(x_{1},\theta_x)$, $f(y_{1},\theta_y)$
stand for the nonlinear damping terms, and
$\theta_{x}$, $\theta_y$ are unknown parameters. For illustrative purpose we assume the following mathematical model for functions
$f_x(\cdot)$, $f_y(\cdot)$ in (\ref{eq:example_dec_model}):
\begin{equation}\label{eq:example_dec_uncertainty}
\begin{split}
f_x(x_{1},\theta_x)&= \theta_x (x_{1}-x_0)+0.5\sin
(\theta_x(x_{1}-x_0)),\\
\ f_y(y_{1},\theta_y)&= \theta_y (y_{1}-y_0)+0.6\sin
(\theta_y(y_{1}-y_0))
\end{split}
\end{equation}
where $x_0$, $y_0$ are known. Let the control goal be to steer states $\mathbf{x}$ and $\mathbf{y}$ to the origin. Consider the following goal functions
\begin{equation}\label{eq:example_psi}
\psi_x(\mathbf{x},t)=x_1+x_2, \ \psi_y(\mathbf{y},t)= y_1+y_2
\end{equation}
Taking into account equations (\ref{eq:example_dec_model}) and
(\ref{eq:example_psi}) we can derive that
\begin{equation}\label{eq:example_relative_dynamics}
\dot{x}_1=-x_1+\psi_x(\mathbf{x}(t),t), \ \dot{y}_1=-y_1+\psi_y(\mathbf{y},t)
\end{equation}
This automatically implies that
\[
\begin{split}
\|x_1(t)\|_{\infty,[t_0,T]}&\leq
\|x_1(t_0)\|+\|\psi_x(\mathbf{x}(t),t)\|_{\infty,[t_0,T]}\\
\|y_1(t)\|_{\infty,[t_0,T]}&\leq
\|y_1(t_0)\|+\|\psi_y(\mathbf{y}(t),t)\|_{\infty,[t_0,T]}
\end{split}
\]
Hence, Assumption \ref{assume:psi} is satisfied for chosen goal functions $\psi_x(\cdot)$ and $\psi_y(\cdot)$. Notice also that equalities (\ref{eq:example_relative_dynamics}) imply that
\begin{equation}\label{eq:example_L2_gains}
\begin{split}
\|x_1(t)\|_{2,[t_0,T]}&\leq 2^{-1/2}\|x_1(t_0)\|+
\|\psi_x(\mathbf{x},t)\|_{2,[t_0,T]}\\
\|y_1(t)\|_{2,[t_0,T]}&\leq 2^{-1/2}\|y_1(t_0)\|+
\|\psi_y(\mathbf{y},t)\|_{2,[t_0,T]}
\end{split}
\end{equation}
Moreover, according to (\ref{eq:example_relative_dynamics})
limiting relations
\begin{equation}\label{eq:example_control_goal_limit}
\begin{split}
&
\lim_{t\rightarrow\infty}\psi_x(\mathbf{x}(t),t)=\lim_{t\rightarrow\infty}x_1(t)+x_2(t)=0,\\
&
\lim_{t\rightarrow\infty}\psi_y(\mathbf{y}(t),t)=\lim_{t\rightarrow\infty}y_1(t)+y_2(t)=0
\end{split}
\end{equation}
guarantee that
\[
\lim_{t\rightarrow\infty} x_1(t)=0, \
\lim_{t\rightarrow\infty}x_2(t)=0, \ \lim_{t\rightarrow\infty}
y_1(t)=0, \ \lim_{t\rightarrow\infty}y_2(t)=0
\]
Hence, property (\ref{eq:example_control_goal_limit}) ensures asymptotic reaching of the control goal.

According to equations (\ref{control_s1}), (\ref{control_s2})
control functions
\begin{equation}\label{eq:example_control}
\begin{split}
u_x&=-\lambda_x\psi_x-x_2-f_x(x_1,\hat{\theta}_x)\\
u_y&=-\lambda_y\psi_y-y_2-f_y(y_1,\hat{\theta}_y), \ \lambda_x, \
\lambda_y>0
\end{split}
\end{equation}
transform system (\ref{eq:example_dec_model}) into the following form
\begin{equation}\label{eq:example_error_model}
\begin{split}
\dot{\psi}_x&=-\lambda_x \psi_x +
f_x(x_1,\theta_x)-f_x(x_1,\hat{\theta}_x)+k_1 y_1\\
\dot{\psi}_x&=-\lambda_x \psi_x +
f_x(x_1,\theta_x)-f_x(x_1,\hat{\theta}_x)+k_2 x_1
\end{split}
\end{equation}
Notice that systems
\[
\dot{\psi}_x=-\lambda_x \psi_x +\xi_x(t), \
\dot{\psi}_y=-\lambda_y \psi_t +\xi_y(t)
\]
satisfy Assumption \ref{assume:gain} with
\[
\gamma_{x_{2,2}}=\frac{1}{\lambda_x}\|\psi_x(\mathbf{x}(t),t)\|_{2,[t_0,T]},
\
\gamma_{y_{2,2}}=\frac{1}{\lambda_y}\|\psi_y(\mathbf{y}(t),t)\|_{2,[t_0,T]}
\]
respectively, and functions $f_x(\cdot)$, $f_y(\cdot)$ satisfy Assumptions \ref{assume:alpha}, \ref{assume:alpha_upper} with
\[
\begin{split}
&D_{x}=1.5, \ D_{x,1}=0.5, \ \alpha_x(\mathbf{x},t)= x_1-x_0, \\
&D_{y}=1.6, \ D_{y,1}=0.4, \ \alpha_y(\mathbf{y},t)= y_1-y_0
\end{split}
\]
Hence conditions 1)-4) of Theorem \ref{theorem:interconnection}
are satisfied. Furthermore, according to the remarks regarding condition 5) of the theorem, requirements
(\ref{eq:disturbance_gain}) can be replaced with implicit constraints (\ref{eq:disturbance_gain_1}). These, however,
according to (\ref{eq:example_L2_gains}) also hold with
$\beta_x=k_1$, $\beta_y=k_2$.

Given that $\alpha_x(\mathbf{x},t)=x_1-x_0$, $\alpha_y(\mathbf{y},t)=y_1-y_0$,
Assumption \ref{assume:explicit_realizability} will be satisfied for functions $\alpha_x(\mathbf{x},t)$, $\alpha_y(\mathbf{y},t)$ with
$\Psi_x(\cdot)=0$, $\Psi_y(\cdot)=0$. Therefore, adaptation algorithms (\ref{fin_forms_ours_tr1x}),
(\ref{fin_forms_ours_tr1y}) will have the following form:
\begin{eqnarray}\label{eq:example_adaptation}
\hat{\theta}_x&=& \Gamma_x((x_1+x_2) (x_1-x_0) +
\hat{\theta}_{x,I}),\nonumber \\
\dot{\hat\theta}_{x,I}&=& \lambda_x (x_1+x_2)(x_1-x_0) - (x_1+x_2)x_2\nonumber \\
\hat{\theta}_y&=& \Gamma_y((y_1+y_2) (y_1-y_0) +
\hat{\theta}_{y,I}),\\
\dot{\hat\theta}_{y,I}&=& \lambda_y (y_1+y_2)(y_1-y_0) -
(y_1+y_2)y_2\nonumber
\end{eqnarray}
Hence, according to Theorem \ref{theorem:interconnection}
boundedness of the solutions in the closed loop system
(\ref{eq:example_error_model}), (\ref{eq:example_adaptation}) is ensured upon the following condition
\begin{equation}\label{eq:example_condition_boundedness}
\frac{k_1 k_2}{\lambda_x
\lambda_y}\left(1+\frac{D_x}{D_{x,1}}\right)\left(1+\frac{D_y}{D_{y,1}}\right)<1
\Rightarrow k_1 k_2 < \frac{\lambda_x\lambda_y}{20}
\end{equation}
Moreover, given that properties H\ref{hyp:locally_bound_uniform_f}--
H\ref{hyp:locally_bound_uniform_phi} hold for the chosen functions
$\psi_x(\mathbf{x},t)$, $\psi_y(\mathbf{y},t)$, condition
(\ref{eq:example_condition_boundedness}) guarantees that limiting relations (\ref{eq:convergence_psi_xy}),
(\ref{eq:convergence_f_xy}) hold.

Trajectories of the closed loop system
(\ref{eq:example_dec_model}), (\ref{eq:example_control}),
(\ref{eq:example_adaptation}) with the following values of parameters $\Gamma_x=\Gamma_y=1$, $\lambda_x=\lambda_y=2$,
$x_0=y_0=1$, $\theta_x=\theta_y=1$ and initial conditions
$x_1(0)=-1$, $x_2(0)=0$, $y_1(0)=1$, $y_2(0)=0$,
$\hat{\theta}_{x,I}(0)=-1$, $\hat{\theta}_{y,I}(0)=-2$ are provided in Fig. \ref{fig:decentralized:example}.

\begin{figure}
\begin{center}
\includegraphics[width=300pt]{example_decentralized.eps}
\end{center}
\begin{center}
\caption{Plots of trajectories $x_1(t)$ (panel a), $x_2(t)$ (panel b), $y_1(t)$ (panel c), $y_2(t)$ (panel d) as functions of $t$ in closed loop system (\ref{eq:example_dec_model}),
(\ref{eq:example_control}), (\ref{eq:example_adaptation}). Dotted lines correspond to the case when $k_1=k_2=0.4$, and solid lines stand for solutions obtained with the following values of coupling
$k_1=1$, $k_2=0.1$}\label{fig:decentralized:example}
\end{center}
\end{figure}

\section{Conclusion}

We provided new tools for the design and analysis of adaptive decentralized control schemes. Our method allows the desired dynamics to be Lyapunov unstable and the parametrization of the uncertainties to be nonlinear. The results are based on a formulation of the problem for adaptive control as a problem of regulation in functional spaces (in particular, $L_2^1[t_0,T]$
spaces) rather than of simply reaching of the control goal in
$\mathbb{R}^n$. This allows us to introduce adaptation algorithms with new properties and apply a small-gain argument to establish applicability of these schemes to the problem of decentralized control.

In order to avoid unnecessary complications, state feedback was assumed in the main-loop controllers which transform original equation into the error coupled model. Extension of the results to output-feedback main loop controllers is a topic for future study.

\section{Proofs of the theorems}

\subsection{Proof of Theorem \ref{stability_theorem}}

Let us first show that property P1) holds. Consider solutions of system (\ref{system1}), (\ref{error_model_d}),
(\ref{fin_forms_ours_tr1}), (\ref{fin_forms_ours_tr11}) passing through the point $\mathbf{x}(t_0)$, $\hat{{\boldsymbol{\theta}}}_I(t_0)$ for
$t\in[t_0,T^\ast]$
. Let us calculate the time-derivative of function
$\hat{{\boldsymbol{\theta}}}(\mathbf{x},t)$:
$\dot{\hat{{\boldsymbol{\theta}}}}(\mathbf{x},t)=\Gamma({\dot{\hat{{\boldsymbol{\theta}}}}_{P}}+\dot{\hat{\boldsymbol{\theta}}}_I)=\Gamma({\dot\psi}\boldsymbol{\alpha}(\mathbf{x},t)+\psi\dot{\boldsymbol{\alpha}}(\mathbf{x},t)-\dot{\Psi}(\mathbf{x},t)+\dot{\hat{\boldsymbol{\theta}}}_I)$.
Notice that
\begin{equation}\label{t2_1}
\begin{split}
&\psi\dot{\boldsymbol{\alpha}}(\mathbf{x},t)-\dot{\Psi}(\mathbf{x},t)+\dot{\hat{{\boldsymbol{\theta}}}}_I=\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} \mathbf{x}_1}\dot{\mathbf{x}}_1+\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x})}{{\partial} \mathbf{x}_2}\dot{\mathbf{x}}_2 +\\
& \psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} t}-
\frac{{\partial} \Psi(\mathbf{x},t)}{{\partial} \mathbf{x}_1}\dot{\mathbf{x}}_1-\frac{{\partial}
\Psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}\dot{\mathbf{x}}_2-\frac{{\partial} \Psi(\mathbf{x},t)}{{\partial} t}+\dot{\hat{\boldsymbol{\theta}}}_I
\end{split}
\end{equation}
According to Assumption \ref{assume:explicit_realizability},
$\frac{{\partial} \Psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}=\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} \mathbf{x}_2}
$. Then taking into account (\ref{t2_1}), we obtain
\begin{equation}\label{t2_2}
\begin{split}
&
\psi\dot{\boldsymbol{\alpha}}(\mathbf{x},t)-\dot{\Psi}(\mathbf{x},t)+\dot{\hat{{\boldsymbol{\theta}}}}_I=\left(\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} \mathbf{x}_1}-\frac{{\partial} \Psi}{{\partial} \mathbf{x}_1
}\right)\dot{\mathbf{x}}_1\\
&+\psi(\mathbf{x},t)\frac{{\partial} \boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} t}-\frac{\Psi(\mathbf{x},t)}{{\partial} t}
\end{split}
\end{equation}
Notice that according to the proposed notation we can rewrite the term $\left(\psi(\mathbf{x},t)\frac{{\partial} \boldsymbol{\alpha}(\mathbf{x},t)}{{\partial}
\mathbf{x}_1}-\frac{{\partial} \Psi}{{\partial} \mathbf{x}_1 }\right)\dot{\mathbf{x}}_1$ in the following form: $\psi(\mathbf{x},t)L_{\mathbf{f}_1}
\boldsymbol{\alpha}(\mathbf{x},t)-L_{\mathbf{f}_1} \Psi(\mathbf{x},t)+
\left(\psi(\mathbf{x},t)L_{\mathbf{g}_1} \boldsymbol{\alpha}(\mathbf{x},t)-L_{\mathbf{g}_1}
\Psi(\mathbf{x},t)\right)u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)$. Hence, it follows from (\ref{fin_forms_ours_tr1}) and (\ref{t2_2}) that
$\psi\dot{\boldsymbol{\alpha}}(\mathbf{x},t)-\dot{\Psi}(\mathbf{x},t)+\dot{\hat{{\boldsymbol{\theta}}}}_I=\varphi(\psi)\boldsymbol{\alpha}(\mathbf{x},t)
$. Therefore, the derivative $\dot{\hat{\boldsymbol{\theta}}}(\mathbf{x},t)$ can be written in the following way:
\begin{equation}\label{algorithm_dpsi}
\dot{\hat{{\boldsymbol{\theta}}}}=\Gamma({\dot\psi}+\varphi(\psi))\boldsymbol{\alpha}(\mathbf{x},t)
\end{equation}
Asymptotic properties of nonlinear parameterized control systems with adaptation algorithm (\ref{algorithm_dpsi}) under assumption of Lyapunov stability of the target dynamics were investigated in
\cite{tpt2003_tac}. In the present contribution we aim to provide characterizations of the closed loop system in terms of functional mappings between functions $\psi(\mathbf{x}(t),t)$, $\varepsilon(t)$,
and $f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)$ and without requiring Lyapunov stability of the target dynamics
(\ref{eq:target_dynamics}).


Categories: physics.gen-ph
Abstract: The evolution of Earth-Moon system is described by the dark matter field
fluid model proposed in the Meeting of Division of Particle and Field 2004,
American Physical Society. The current behavior of the Earth-Moon system agrees
with this model very well and the general pattern of the evolution of the
Moon-Earth system described by this model agrees with geological and fossil
evidence. The closest distance of the Moon to Earth was about 259000 km at 4.5
billion years ago, which is far beyond the Roche's limit. The result suggests
that the tidal friction may not be the primary cause for the evolution of the
Earth-Moon system. The average dark matter field fluid constant derived from
Earth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts
that the Mars's rotation is also slowing with the angular acceleration rate
about -4.38 x 10^(-22) rad s^(-2).

Categories: nlin.PS, physics.chem-ph, q-bio.MN
Abstract: Spatiotemporal pattern formation in a product-activated enzymic reaction at
high enzyme concentrations is investigated. Stochastic simulations show that
catalytic turnover cycles of individual enzymes can become coherent and that
complex wave patterns of molecular synchronization can develop. The analysis
based on the mean-field approximation indicates that the observed patterns
result from the presence of Hopf and wave bifurcations in the considered
system.

Categories: physics.optics, physics.comp-ph
Abstract: We performed a rigorous theoretical convergence analysis of the discrete
dipole approximation (DDA). We prove that errors in any measured quantity are
bounded by a sum of a linear and quadratic term in the size of a dipole d, when
the latter is in the range of DDA applicability. Moreover, the linear term is
significantly smaller for cubically than for non-cubically shaped scatterers.
Therefore, for small d errors for cubically shaped particles are much smaller
than for non-cubically shaped. The relative importance of the linear term
decreases with increasing size, hence convergence of DDA for large enough
scatterers is quadratic in the common range of d. Extensive numerical
simulations were carried out for a wide range of d. Finally we discuss a number
of new developments in DDA and their consequences for convergence.

Categories: physics.optics, physics.comp-ph
Abstract: We propose an extrapolation technique that allows accuracy improvement of the
discrete dipole approximation computations. The performance of this technique
was studied empirically based on extensive simulations for 5 test cases using
many different discretizations. The quality of the extrapolation improves with
refining discretization reaching extraordinary performance especially for
cubically shaped particles. A two order of magnitude decrease of error was
demonstrated. We also propose estimates of the extrapolation error, which were
proven to be reliable. Finally we propose a simple method to directly separate
shape and discretization errors and illustrated this for one test case.

Categories: physics.optics, physics.comp-ph
Abstract: In this manuscript we investigate the capabilities of the Discrete Dipole
Approximation (DDA) to simulate scattering from particles that are much larger
than the wavelength of the incident light, and describe an optimized publicly
available DDA computer program that processes the large number of dipoles
required for such simulations. Numerical simulations of light scattering by
spheres with size parameters x up to 160 and 40 for refractive index m=1.05 and
2 respectively are presented and compared with exact results of the Mie theory.
Errors of both integral and angle-resolved scattering quantities generally
increase with m and show no systematic dependence on x. Computational times
increase steeply with both x and m, reaching values of more than 2 weeks on a
cluster of 64 processors. The main distinctive feature of the computer program
is the ability to parallelize a single DDA simulation over a cluster of
computers, which allows it to simulate light scattering by very large
particles, like the ones that are considered in this manuscript. Current
limitations and possible ways for improvement are discussed.

Categories: physics.optics, physics.comp-ph
Abstract: We present a review of the discrete dipole approximation (DDA), which is a
general method to simulate light scattering by arbitrarily shaped particles. We
put the method in historical context and discuss recent developments, taking
the viewpoint of a general framework based on the integral equations for the
electric field. We review both the theory of the DDA and its numerical aspects,
the latter being of critical importance for any practical application of the
method. Finally, the position of the DDA among other methods of light
scattering simulation is shown and possible future developments are discussed.

Categories: physics.gen-ph, quant-ph
Abstract: It is outlined the possibility to extend the quantum formalism in relation to
the requirements of the general systems theory. It can be done by using a
quantum semantics arising from the deep logical structure of quantum theory. It
is so possible taking into account the logical openness relationship between
observer and system. We are going to show how considering the truth-values of
quantum propositions within the context of the fuzzy sets is here more useful
for systemics . In conclusion we propose an example of formal quantum
coherence.

Categories: astro-ph, nlin.CD, physics.plasm-ph, physics.space-ph
Abstract: We present a theoretical framework for plasma turbulence in astrophysical
plasmas (solar wind, interstellar medium, galaxy clusters, accretion disks).
The key assumptions are that the turbulence is anisotropic with respect to the
mean magnetic field and frequencies are low compared to the ion cyclotron
frequency. The energy injected at the outer scale scale has to be converted
into heat, which ultimately cannot be done without collisions. A KINETIC
CASCADE develops that brings the energy to collisional scales both in space and
velocity. Its nature depends on the physics of plasma fluctuations. In each of
the physically distinct scale ranges, the kinetic problem is systematically
reduced to a more tractable set of equations. In the "inertial range" above the
ion gyroscale, the kinetic cascade splits into a cascade of Alfvenic
fluctuations, which are governed by the RMHD equations at both the collisional
and collisionless scales, and a passive cascade of compressive fluctuations,
which obey a linear kinetic equation along the moving field lines associated
with the Alfvenic component. In the "dissipation range" between the ion and
electron gyroscales, there are again two cascades: the kinetic-Alfven-wave
(KAW) cascade governed by two fluid-like Electron RMHD equations and a passive
phase-space cascade of ion entropy fluctuations. The latter cascade brings the
energy of the inertial-range fluctuations that was damped by collisionless
wave-particle interaction at the ion gyroscale to collisional scales in the
phase space and leads to ion heating. The KAW energy is similarly damped at the
electron gyroscale and converted into electron heat. Kolmogorov-style scaling
relations are derived for these cascades. Astrophysical and space-physical
applications are discussed in detail.

Categories: physics.ed-ph, quant-ph
Abstract: A novel way of picturing the processing of quantum information is described,
allowing a direct visualization of teleportation of quantum states and
providing a simple and intuitive understanding of this fascinating phenomenon.
The discussion is aimed at providing physicists a method of explaining
teleportation to non-scientists. The basic ideas of quantum physics are first
explained in lay terms, after which these ideas are used with a graphical
description, out of which teleportation arises naturally.

Categories: physics.pop-ph
Abstract: I shall present three arguments for the proposition that intelligent life is
very rare in the universe. First, I shall summarize the consensus opinion of
the founders of the Modern Synthesis (Simpson, Dobzhanski, and Mayr) that the
evolution of intelligent life is exceedingly improbable. Second, I shall
develop the Fermi Paradox: if they existed they'd be here. Third, I shall show
that if intelligent life were too common, it would use up all available
resources and die out. But I shall show that the quantum mechanical principle
of unitarity (actually a form of teleology!) requires intelligent life to
survive to the end of time. Finally, I shall argue that, if the universe is
indeed accelerating, then survival to the end of time requires that intelligent
life, though rare, to have evolved several times in the visible universe. I
shall argue that the acceleration is a consequence of the excess of matter over
antimatter in the universe. I shall suggest experiments to test these claims.

Categories: physics.soc-ph
Abstract: No abstract given; compares pairs of languages from World Atlas of Language
Structures.

Categories: physics.gen-ph
Abstract: The Dark Energy problem is forcing us to re-examine our models and our
understanding of relativity and space-time. Here a novel idea of Fundamental
Forces is introduced. This allows us to perceive the General Theory of
Relativity and Einstein's Equation from a new pesrpective. In addition to
providing us with an improved understanding of space and time, it will be shown
how it leads to a resolution of the Dark Energy problem.

Categories: cond-mat.soft, nlin.PS, physics.flu-dyn
Abstract: We employ granular hydrodynamics to investigate a paradigmatic problem of
clustering of particles in a freely cooling dilute granular gas. We consider
large-scale hydrodynamic motions where the viscosity and heat conduction can be
neglected, and one arrives at the equations of ideal gas dynamics with an
additional term describing bulk energy losses due to inelastic collisions. We
employ Lagrangian coordinates and derive a broad family of exact non-stationary
analytical solutions that depend only on one spatial coordinate. These
solutions exhibit a new type of singularity, where the gas density blows up in
a finite time when starting from smooth initial conditions. The density blowups
signal formation of close-packed clusters of particles. As the density blow-up
time $t_c$ is approached, the maximum density exhibits a power law $\sim
(t_c-t)^{-2}$. The velocity gradient blows up as $\sim - (t_c-t)^{-1}$ while
the velocity itself remains continuous and develops a cusp (rather than a shock
discontinuity) at the singularity. The gas temperature vanishes at the
singularity, and the singularity follows the isobaric scenario: the gas
pressure remains finite and approximately uniform in space and constant in time
close to the singularity. An additional exact solution shows that the density
blowup, of the same type, may coexist with an "ordinary" shock, at which the
hydrodynamic fields are discontinuous but finite. We confirm stability of the
exact solutions with respect to small one-dimensional perturbations by solving
the ideal hydrodynamic equations numerically. Furthermore, numerical solutions
show that the local features of the density blowup hold universally,
independently of details of the initial and boundary conditions.

Categories: physics.optics
Abstract: The results of the spectral, energetical and temporal characteristics of
radiation in the presence of the photonic flame effect are presented.
Artificial opal posed on Cu plate at the temperature of liquid nitrogen boiling
point (77 K) being irradiated by nanosecond ruby laser pulse produces long-
term luminiscence with a duration till ten seconds with a finely structured
spectrum in the the antistocks part of the spectrum. Analogous visible
luminescence manifesting time delay appeared in other samples of the artificial
opals posed on the same plate. In the case of the opal infiltrated with
different nonlinear liquids the threshold of the luminiscence is reduced and
the spatial disribution of the bright emmiting area on the opal surface is
being changed. In the case of the putting the frozen nonlinear liquids on the
Cu plate long-term blue bright luminiscence took place in the frozen species of
the liquids. Temporal characteristics of this luminiscence are nearly the same
as in opal matrixes.

Categories: physics.data-an, physics.gen-ph
Abstract: Statistical modeling of experimental physical laws is based on the
probability density function of measured variables. It is expressed by
experimental data via a kernel estimator. The kernel is determined objectively
by the scattering of data during calibration of experimental setup. A physical
law, which relates measured variables, is optimally extracted from experimental
data by the conditional average estimator. It is derived directly from the
kernel estimator and corresponds to a general nonparametric regression. The
proposed method is demonstrated by the modeling of a return map of noisy
chaotic data. In this example, the nonparametric regression is used to predict
a future value of chaotic time series from the present one. The mean predictor
error is used in the definition of predictor quality, while the redundancy is
expressed by the mean square distance between data points. Both statistics are
used in a new definition of predictor cost function. From the minimum of the
predictor cost function, a proper number of data in the model is estimated.

Categories: cs.CE, cond-mat.stat-mech, cs.MS, cs.NA, physics.data-an
Abstract: Real Options for Project Schedules (ROPS) has three recursive
sampling/optimization shells. An outer Adaptive Simulated Annealing (ASA)
optimization shell optimizes parameters of strategic Plans containing multiple
Projects containing ordered Tasks. A middle shell samples probability
distributions of durations of Tasks. An inner shell samples probability
distributions of costs of Tasks. PATHTREE is used to develop options on
schedules.. Algorithms used for Trading in Risk Dimensions (TRD) are applied to
develop a relative risk analysis among projects.

Categories: physics.data-an
Abstract: A physical law is represented by the probability distribution of a measured
variable. The probability density is described by measured data using an
estimator whose kernel is the instrument scattering function. The experimental
information and data redundancy are defined in terms of information entropy.
The model cost function, comprised of data redundancy and estimation error, is
minimized by the creation-annihilation process.

Categories: nlin.CD, cond-mat.other, physics.optics
Abstract: The microwave phonon stimulated emission (SE) has been experimentally and
numerically investigated in a nonautonomous microwave acoustic quantum
generator, called also microwave phonon laser or phaser (see previous works
arXiv:cond-mat/0303188 ; arXiv:cond-mat/0402640 ; arXiv:nlin.CG/0703050)
Phenomena of branching and long-time refractority (absence of the reaction on
the external pulses) for deterministic chaotic and regular processes of SE were
observed in experiments with various levels of electromagnetic pumping. At the
pumping level growth, the clearly depined increasing of the number of
coexisting SE states has been observed both in real physical experiments and in
computer simulations. This confirms the analytical estimations of the branching
density in the phase space. The nature of the refractority of SE pulses is
closely connected with the pointed branching and reflects the crises of strange
attractors, i.e. their collisions with unstable periodic components of the
higher branches of SE states in the nonautonomous microwave phonon laser.

Categories: physics.gen-ph
Abstract: Based on overall experimental observations, especially the pair processes, I
developed a model structure of the vacuum along with a basic-particle formation
scheme begun in 2000 (with collaborator P-I Johansson). The model consists in
that the vacuum is, briefly, filled of neutral but polarizable vacuuons,
consisting each of a p-vaculeon and n- vaculeon of charges $+e$ and $-e$ of
zero rest masses but with spin motions, assumed interacting each other with a
Coulomb force. The model has been introduced in full in a book (Nova Sci, 2005)
and referred to in a number of journal/E-print papers. I outline in this easier
accessible paper the detailed derivation of the model and a corresponding
quantitative determination of the vacuuon size.

Categories: physics.gen-ph
Abstract: The 32-dimensional compounding fields and their quantum interplays in the
trigintaduonion space can be presented by analogy with octonion and sedenion
electromagnetic, gravitational, strong and weak interactions. In the
trigintaduonion fields which are associated with the electromagnetic,
gravitational, strong and weak interactions, the study deduces some conclusions
of field source particles (quarks and leptons) and intermediate particles which
are consistent with current some sorts of interaction theories. In the
trigintaduonion fields which are associated with the hyper-strong and
strong-weak fields, the paper draws some predicts and conclusions of the field
source particles (sub-quarks) and intermediate particles. The research results
show that there may exist some new particles in the nature.

Categories: physics.optics, physics.class-ph, quant-ph
Abstract: Statistical ensemble formalism of Kim, Mandel and Wolf (J. Opt. Soc. Am. A 4,
433 (1987)) offers a realistic model for characterizing the effect of
stochastic non-image forming optical media on the state of polarization of
transmittedlight. With suitable choice of the Jones ensemble, various Mueller
transformations - some of which have been unknown so far - are deduced. It is
observed that the ensemble approach is formally identical to the positive
operator valued measures (POVM) on the quantum density matrix. This
observation, in combination with the recent suggestion by Ahnert and Payne
(Phys. Rev. A 71, 012330, (2005)) - in the context of generalized quantum
measurement on single photon polarization states - that linear optics elements
can be employed in setting up all possible POVMs, enables us to propose a way
of realizing different types of Mueller devices.

Categories: physics.data-an, physics.comp-ph
Abstract: The extraction of a physical law y=yo(x) from joint experimental data about x
and y is treated. The joint, the marginal and the conditional probability
density functions (PDF) are expressed by given data over an estimator whose
kernel is the instrument scattering function. As an optimal estimator of yo(x)
the conditional average is proposed. The analysis of its properties is based
upon a new definition of prediction quality. The joint experimental information
and the redundancy of joint measurements are expressed by the relative entropy.
With the number of experiments the redundancy on average increases, while the
experimental information converges to a certain limit value. The difference
between this limit value and the experimental information at a finite number of
data represents the discrepancy between the experimentally determined and the
true properties of the phenomenon. The sum of the discrepancy measure and the
redundancy is utilized as a cost function. By its minimum a reasonable number
of data for the extraction of the law yo(x) is specified. The mutual
information is defined by the marginal and the conditional PDFs of the
variables. The ratio between mutual information and marginal information is
used to indicate which variable is the independent one. The properties of the
introduced statistics are demonstrated on deterministically and randomly
related variables.

Categories: physics.gen-ph
Abstract: Classical oscillator differential equation is replaced by the corresponding
(finite time) difference equation. The equation is, then, symmetrized so that
it remains invariant under the change d going to -d, where d is the smallest
span of time. This symmetric equation has solutions, which come in reciprocally
related pairs. One member of a pair agrees with the classical solution and the
other is an oscillating solution and does not converge to a limit as d goes to
0. This solution contributes to oscillator energy a term which is a multiple of
half-integers.

Categories: cond-mat.stat-mech, cond-mat.soft, physics.chem-ph
Abstract: An overview of some analytical approaches to the computation of the
structural and thermodynamic properties of single component and multicomponent
hard-sphere fluids is provided. For the structural properties, they yield a
thermodynamically consistent formulation, thus improving and extending the
known analytical results of the Percus-Yevick theory. Approximate expressions
for the contact values of the radial distribution functions and the
corresponding analytical equations of state are also discussed. Extensions of
this methodology to related systems, such as sticky hard spheres and
square-well fluids, as well as its use in connection with the perturbation
theory of fluids are briefly addressed.
