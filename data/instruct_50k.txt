\title{\bf Decentralized adaptation in interconnected uncertain systems with nonlinear parametrization}

\begin{abstract}
We propose a technique for the design and analysis of decentralized adaptation algorithms in interconnected dynamical systems. Our technique does not require Lyapunov stability of the target dynamics and allows nonlinearly parameterized uncertainties. We show that for the considered class of systems,
conditions for reaching the control goals can be formulated in terms of the nonlinear $L_2$-gains of target dynamics of each interconnected subsystem. Equations for decentralized controllers and corresponding adaptation algorithms are also explicitly provided.

{\it Keywords:} nonlinear parametrization; unstable,
non-equilibrium dynamics; decentralized adaptive control; monotone functions
\end{abstract}

\section*{Notation}

According to the standard convention, $\mathbb{R}$ defines the field of real numbers and $\mathbb{R}_{\geq c}=\{x\in\mathbb{R}|x\geq c\}$,
$\mathbb{R}_{+}=\mathbb{R}_{\geq 0}$; symbol $\mathbb{R}^n$ stands for a linear space $\mathcal{L}(\mathbb{R})$ over the field of reals with
$\mathrm{dim}\{\mathcal{L}(\mathbb{R})\}=n$; $\|\mathbf{x}\|$ denotes the Euclidian norm of $\mathbf{x}\in\mathbb{R}^n$; $\mathcal{C}^k$ denotes the space of functions that are at least $k$ times differentiable;
$\mathcal{K}$ denotes the class of all strictly increasing functions $\kappa: \mathbb{R}_+\rightarrow \mathbb{R}_+$ such that
$\kappa(0)=0$. By ${L}_{p}^n[t_0,T]$, where $T>0$, $p\geq 1$ we denote the space of all functions $\mathbf{f}:\mathbb{R}_+\rightarrow\mathbb{R}^n$
such that
$\|\mathbf{f}\|_{p,[t_0,T]}=\left(\int_{0}^T\|\mathbf{f}(\tau)\|^{p}d\tau\right)^{1/p}<\infty$;
$\|\mathbf{f}\|_{p,[t_0,T]}$ denotes the ${L}_{p}^n[t_0,T]$-norm of
$\mathbf{f}(t)$. By ${L}^n_\infty[t_0,T]$ we denote the space of all functions $\mathbf{f}:\mathbb{R}_+\rightarrow\mathbb{R}^n$ such that
$\|\mathbf{f}\|_{\infty,[t_0,T]}={\mathrm{ess}} \sup\{\|\mathbf{f}(t)\|,t \in
[t_0,T]\}<\infty$, and $\|\mathbf{f}\|_{\infty,[t_0,T]}$ stands for the
${L}^n_\infty[t_0,T]$ norm of $\mathbf{f}(t)$.

A function $\mathbf{f}(\mathbf{x}): \mathbb{R}^{n}\rightarrow \mathbb{R}^m$ is said to be locally bounded if for any $\|\mathbf{x}\|<\delta$ there exists a constant $D(\delta)>0$ such that the following inequality holds:
$\|\mathbf{f}(\mathbf{x})\|\leq D(\delta)$. Let $\Gamma$ be an $n\times n$
square matrix, then $\Gamma>0$ denotes a positive definite
(symmetric) matrix, and $\Gamma^{-1}$ is the inverse of $\Gamma$.
By $\Gamma\geq 0$ we denote a positive semi-definite matrix,
$\|\mathbf{x}\|_{\Gamma}^2$ to denotes the quadratic form:
$\mathbf{x}^{T}\Gamma\mathbf{x}$, $\mathbf{x}\in\mathbb{R}^n$. The notation $|\cdot|$
stands for the modulus of a scalar. The solution of a system of differential equations $\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},t,{\boldsymbol{\theta}},\mathbf{u}), \
\mathbf{x}(t_0)=\mathbf{x}_0$, $\mathbf{u}:\mathbb{R}_+\rightarrow\mathbb{R}^m$,
${\boldsymbol{\theta}}\in\mathbb{R}^d$ for $t\geq t_0$ will be denoted as
$\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},\mathbf{u})$, or simply as $\mathbf{x}(t)$ if it is clear from the context what the values of $\mathbf{x}_0,{\boldsymbol{\theta}}$
are and how the function $\mathbf{u}(t)$ is defined.

Let $\mathbf{u}:\mathbb{R}^n\times\mathbb{R}^d\times\mathbb{R}_+\rightarrow\mathbb{R}^m$ be a function of state $\mathbf{x}$, parameters $\hat{{\boldsymbol{\theta}}}$, and time
$t$. Let in addition both $\mathbf{x}$ and $\hat{{\boldsymbol{\theta}}}$ be functions of $t$. Then in case the arguments of $\mathbf{u}$ are clearly defined by the context, we will simply write $\mathbf{u}(t)$ instead of
$\mathbf{u}(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)$.

The (forward complete) system
$\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},t,{\boldsymbol{\theta}},\mathbf{u}(t))$, is said to have an
$L_{p}^m [t_0,T]\mapsto L_{q}^n[t_0,T]$, gain ($T\geq t_0$,
$p,q\in\mathbb{R}_{\geq 1}\cup\infty$) with respect to its input
$\mathbf{u}(t)$ if and only if $\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},\mathbf{u}(t))\in L_{q}^n [t_0,T]$ for any $\mathbf{u}(t)\in L_{p}^m [t_0,T]$ and there exists a function
$\gamma_{q,p}:\mathbb{R}^n\times\mathbb{R}^d\times\mathbb{R}_+\rightarrow\mathbb{R}_+$
such that the following inequality holds:
$\|\mathbf{x}(t)\|_{q,[t_0,T]}\leq
\gamma_{q,p}(\mathbf{x}_0,{\boldsymbol{\theta}},\|\mathbf{u}(t)\|_{p,[t_0,T]})$. The function $\gamma_{q,p}(\mathbf{x}_0,{\boldsymbol{\theta}},\|\mathbf{u}(t)\|_{p,[t_0,T]})$
is assumed to be non-decreasing in $\|\mathbf{u}(t)\|_{p,[t_0,T]}$, and locally bounded in its arguments.

For notational convenience when dealing with vector fields and partial derivatives we will use the following extended notion of the Lie derivative of a function. Let $\mathbf{x}\in\mathbb{R}^n$ and assume
$\mathbf{x}$ can be partitioned as follows $\mathbf{x}=\mathbf{x}_1\oplus\mathbf{x}_2$,
where $\mathbf{x}_1\in\mathbb{R}^q$, $\mathbf{x}_1=(x_{11},\dots,x_{1q})^T$,
$\mathbf{x}_2\in\mathbb{R}^p$, $\mathbf{x}_2=(x_{21},\dots,x_{2p})^T$, $q+p=n$, and
$\oplus$ denotes the concatenation of two vectors. Define
$\mathbf{f}:\mathbb{R}^{n}\rightarrow\mathbb{R}^n$ such that
$\mathbf{f}(\mathbf{x})=\mathbf{f}_1(\mathbf{x})\oplus\mathbf{f}_2(\mathbf{x})$, where
$\mathbf{f}_1:\mathbb{R}^n\rightarrow\mathbb{R}^q$,
$\mathbf{f}_1(\cdot)=(f_{11}(\cdot),\dots,f_{1q}(\cdot))^T$,
$\mathbf{f}_2:\mathbb{R}^n\rightarrow\mathbb{R}^p$,
$\mathbf{f}_2(\cdot)=(f_{21}(\cdot),\dots,f_{2p}(\cdot))^T$. Then
$L_{\mathbf{f}_i(\mathbf{x})}\psi(\mathbf{x},t)$, $i\in\{1,2\}$ denotes the Lie derivative of the function $\psi(\mathbf{x},t)$ with respect to the vector field $\mathbf{f}_i(\mathbf{x},{\boldsymbol{\theta}})$:
$L_{\mathbf{f}_i(\mathbf{x})}\psi(\mathbf{x},t)=\sum_{j}^{\dim{\mathbf{x}_i}}\frac{{\partial}
\psi(\mathbf{x},t) }{{\partial} x_{ij}}f_{ij}(\mathbf{x},{\boldsymbol{\theta}})$.

\section{Introduction}

We consider the problem how to control the behavior of complex dynamical systems composed of interconnected lower-dimensional subsystems. Centralized control of these systems is practically inefficient because of high demands for computational power,
measurements and prohibitive communication cost. On the other hand, standard decentralized solutions often face severe limitations due to the deficiency of information about the interconnected subsystems. In addition, the nature of their their interconnections may vary depending on conditions in the environment. In order to address these problems in their most general setup, decentralized adaptive control is needed.

Currently there is a large literature on decentralized adaptive control which contains successful solutions to problems of adaptive stabilization \cite{Gavel_1989,Jain_1997}, tracking
\cite{Ioannou86,Jain_1997,Shi_1992,Passino96}, and output regulation \cite{Jiang_2000,Huang_2003} of linear and nonlinear systems. In most of these cases the problem of decentralized control is solved within the conventional framework of adaptive stabilization/tracking/regulation by a family of linearly parameterized controllers. While these results may be successfully implemented in a large variety of technical and artificial systems, there is room for further improvements. In particular,
when the target dynamics of the systems is not stable in the Lyapunov sense but intermittent, meta-stable, or multi-stable
\cite{Arecchi_2004,Raffone_2003,Tsuda_2004} or when the uncertainties are nonlinearly parameterized
\cite{Armstrong_1993,Boskovic_1995,Canudas_1999,Kitching_2000},
and no domination of the uncertainties by feedback is allowed.

In the present article we address these issues at once for a class of nonlinear dynamical systems. Our contribution is that we provide conditions ensuring forward-completeness, boundedness and asymptotic reaching of the goal for a pair of interconnected systems with uncertain coupling and parameters. Our method does not require availability of a Lyapunov function for the desired motions in each subsystem, nor linear parametrization of the controllers. Our results can straightforwardly be extended to interconnection of arbitrary many (but still, a finite number of)
subsystems. Explicit equations for corresponding decentralized adaptive controllers are also provided.

The paper is organized as follows. In Section 2 we provide a formal statement of the problem, Section 3 contains necessary preliminaries and auxiliary results. In Section 4 we present the main results of our current contribution, and in Section 5 we provide concluding remarks to our approach.

\section{Problem Formulation}

Let us consider two interconnected systems $\mathcal{S}_x$ and
$\mathcal{S}_y$:
\begin{eqnarray}
&\mathcal{S}_x: & \
\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}}_x)+\gamma_y(\mathbf{y},t)+
\mathbf{g}(\mathbf{x})u_x \label{eq:system:s1} \\
&\mathcal{S}_y: & \
\dot{\mathbf{y}}=\mathbf{q}(\mathbf{y},{\boldsymbol{\theta}}_y)+\gamma_x(\mathbf{x},t)+\mathbf{z}(\mathbf{y})u_y\label{eq:system:s2}
\end{eqnarray}
where $\mathbf{x}\in\mathbb{R}^{n_x}$, $\mathbf{y}\in\mathbb{R}^{n_y}$ are the state vectors of systems $\mathcal{S}_x$ and $\mathcal{S}_y$, vectors
${\boldsymbol{\theta}}_x\in\mathbb{R}^{n_{\theta_x}}$,
${\boldsymbol{\theta}}_y\in\mathbb{R}^{n_{\theta_y}}$ are unknown parameters,
functions
$\mathbf{f}:\mathbb{R}^{n_x}\times\mathbb{R}^{n_{\theta_x}}\rightarrow\mathbb{R}^{n_x}$,
$\mathbf{q}:\mathbb{R}^{n_y}\times\mathbb{R}^{n_{\theta_y}}\rightarrow\mathbb{R}^{n_y}$,
$\mathbf{g}:\mathbb{R}^{n_x}\rightarrow\mathbb{R}^{n_x}$,
$\mathbf{z}:\mathbb{R}^{n_y}\rightarrow\mathbb{R}^{n_y}$ are continuous and locally bounded. Functions
$\gamma_y:\mathbb{R}^{n_y}\times\mathbb{R}_+\rightarrow\mathbb{R}_n$,
$\gamma_x:\mathbb{R}^{n_x}\times\mathbb{R}_+\rightarrow\mathbb{R}^{n_y}$, stand for nonlinear, non-stationary and, in general, unknown couplings between systems $\mathcal{S}_x$ and $\mathcal{S}_y$, and
$u_x\in\mathbb{R}$, $u_y\in\mathbb{R}$ are the control inputs.

In the present paper we are interested in the following problem

\begin{problem}\label{problem:decentralized}\normalfont Let $\psi_x:\mathbb{R}^{n_x}\times\mathbb{R}_+\rightarrow\mathbb{R}$,
$\psi_y:\mathbb{R}^{n_y}\times\mathbb{R}_+\rightarrow\mathbb{R}$ be the goal functions for systems $\mathcal{S}_x$, $\mathcal{S}_y$
respectively. In the other words, for some values
$\varepsilon_x\in\mathbb{R}_{+}$, $\varepsilon_y\in\mathbb{R}_+$ and time instant $t^\ast\in\mathbb{R}_+$, inequalities
\begin{equation}\label{eq:goal_functionals}
\|\psi_x(\mathbf{x}(t),t)\|_{\infty,[t^\ast,\infty]}\leq\varepsilon_x, \
\|\psi_y(\mathbf{y}(t),t)\|_{\infty,[t^\ast,\infty]}\leq\varepsilon_y
\end{equation}
specify the desired state of interconnection (\ref{eq:system:s1}),
(\ref{eq:system:s2}). Derive functions $u_x(\mathbf{x},t)$, $u_y(\mathbf{y},t)$
such that for all ${\boldsymbol{\theta}}_x\in\mathbb{R}^{n_{\theta_x}}$,
${\boldsymbol{\theta}}_y\in\mathbb{R}^{n_{\theta_y}}$

1) interconnection (\ref{eq:system:s1}), (\ref{eq:system:s2}) is forward-complete;

2) the trajectories $\mathbf{x}(t)$, $\mathbf{y}(t)$ are bounded;

3) for given values of $\varepsilon_x$, $\varepsilon_y$, some
$t^\ast\in\mathbb{R}_+$ exists such that inequalities
(\ref{eq:goal_functionals}) are satisfied or, possibly, both functions $\psi_x(\mathbf{x}(t),t)$, $\psi_y(\mathbf{y}(t),t)$ converge to zero as $t\rightarrow\infty$.

Function $u_x(\cdot)$ should not depend explicitly on $\mathbf{y}$ and,
symmetrically, function $u_y(\cdot)$ should not depend explicitly on $\mathbf{x}$. The general structure of the desired configuration of the control scheme is provided in Figure 1.
\end{problem}

\begin{figure}
\begin{center}
\includegraphics[width=110pt]{decentralized.eps}
\end{center}
\begin{center}
\caption{General structure of interconnection}\label{fig:decentralized:singularity}
\end{center}
\end{figure}

In the next sections we provide sufficient conditions, ensuring solvability of Problem \ref{problem:decentralized} and we also explicitly derive functions $u_x(\mathbf{x},t)$ and $u_y(\mathbf{y},t)$ which satisfy requirements 1) -- 3) of Problem
\ref{problem:decentralized}. We start with the introduction of a new class of adaptive control schemes and continue by providing the input-output characterizations of the controlled systems.
These results are given in Section \ref{sec:preliminary}. Then,
using these characterizations, in Section \ref{sec:main} we provide the main results of our study.

\section{Assumptions and properties of the decoupled systems}\label{sec:preliminary}

Let the following system be given:
\begin{equation}\label{system1}
\begin{split}
\dot{\mathbf{x}}_1=&\mathbf{f}_1(\mathbf{x})+\mathbf{g}_1(\mathbf{x})u, \\
\dot{\mathbf{x}}_2=&\mathbf{f}_2(\mathbf{x},{\boldsymbol{\theta}})+\mathbf{g}_2(\mathbf{x})u,
\end{split}
\end{equation}
where
\[
\mathbf{x}_1=(x_{11},\dots,x_{1 q})^T\in \mathbb{R}^q; \
\mathbf{x}_2=(x_{21},\dots,x_{2 p})^T\in \mathbb{R}^p;
\]
\[
\mathbf{x}=(x_{11},\dots,x_{1 q},x_{21},\dots,x_{2 p})^T\in \mathbb{R}^{n}
\]
${\boldsymbol{\theta}}\in \Omega_\theta\in \mathbb{R}^d$ is a vector of unknown parameters, and $\Omega_\theta$ is a closed bounded subset of
$\mathbb{R}^d$; $u\in\mathbb{R}$ is the control input, and functions
$\mathbf{f}_1:\mathbb{R}^{n}\rightarrow \mathbb{R}^{q}$,
$\mathbf{f}_2:\mathbb{R}^{n}\times\mathbb{R}^d\rightarrow \mathbb{R}^{p}$,
$\mathbf{g}_1:\mathbb{R}^{n}\rightarrow \mathbb{R}^q$,
$\mathbf{g}_2:\mathbb{R}^{n}\rightarrow\mathbb{R}^{p}$ are continuous and locally bounded. The vector $\mathbf{x}\in\mathbb{R}^n$ is the state vector, and vectors $\mathbf{x}_1$, $\mathbf{x}_2$ are referred to as {\it uncertainty-independent} and {\it uncertainty-dependent} partition of $\mathbf{x}$, respectively. For the sake of compactness we will also use the following description of (\ref{system1}):
\begin{equation}\label{system}
\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})+\mathbf{g}(\mathbf{x})u,
\end{equation}
where
\[
\mathbf{g}(\mathbf{x})=(g_{11}(\mathbf{x}),\dots,g_{1q}(\mathbf{x}),g_{21}(\mathbf{x}),\dots,g_{2 p}(\mathbf{x}))^{T},
\]
\[
\mathbf{f}(\mathbf{x})=(f_{11}(\mathbf{x}),\dots,f_{1q}(\mathbf{x}),f_{21}(\mathbf{x},{\boldsymbol{\theta}}),\dots,f_{2 p}(\mathbf{x},{\boldsymbol{\theta}}))^{T}.
\]

As a measure of closeness of trajectories $\mathbf{x}(t)$ to the desired state we introduce the error or goal function $\psi:\mathbb{R}^n\times
\mathbb{R}_+\rightarrow \mathbb{R}, \ \psi\in \mathcal{C}^1$.
We suppose also that for the chosen function $\psi(\mathbf{x},t)$
satisfies the following:
\begin{assume}[Target operator]\label{assume:psi} For the given function $\psi(\mathbf{x},t)\in \mathcal{C}^1$ the following property holds:
\begin{equation}\label{eq:assume_psi}
\|\mathbf{x}(t)\|_{\infty,[t_0,T]}\leq
\tilde{\gamma}\left(\mathbf{x}_0,{\boldsymbol{\theta}},\|\psi(\mathbf{x}(t),t)\|_{\infty,[t_0,T]}\right)
\end{equation}
where
$\tilde{\gamma}\left(\mathbf{x}_0,{\boldsymbol{\theta}},\|\psi(\mathbf{x}(t),t)\|_{\infty,[t_0,T]}\right)$
is a locally bounded and non-negative function of its arguments.
\end{assume}
Assumption \ref{assume:psi} can be interpreted as a sort of {\it unboundedness observability} property \cite{Jiang_1994} of system
(\ref{system1}) with respect to the ``output" function
$\psi(\mathbf{x},t)$. It can also be viewed as a {\it bounded input -
bounded state} assumption for system (\ref{system1}) along the constraint
$\psi(\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},u(\mathbf{x}(t),t)),t)=\upsilon(t)$,
where the signal $\upsilon(t)$ serves as a new input. If, however,
boundedness of the state is not explicitly required (i.e. it is guaranteed by additional control or follows from the physical properties of the system itself), Assumption \ref{assume:psi} can be removed from the statements of our results.

Let us specify a class of control inputs $u$ which can ensure boundedness of $\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},u)$ for every
${\boldsymbol{\theta}}\in \Omega_\theta$ and $\mathbf{x}_0\in\mathbb{R}^n$. According to
(\ref{eq:assume_psi}), boundedness of
$\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},u)$ is ensured if we find a control input $u$ such that $\psi(\mathbf{x}(t),t)\in L_\infty^1[t_0,\infty]$.
For this objective consider the dynamics of system (\ref{system})
with respect to $\psi(\mathbf{x},t)$:
\begin{equation}\label{dpsi}
\dot{\psi}=L_{\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})}\psi(\mathbf{x},t)+L_{\mathbf{g}(\mathbf{x})}\psi(\mathbf{x},t)u+\frac{{\partial}
\psi(\mathbf{x},t)}{{\partial} t},
\end{equation}
Assuming that the inverse
$\left(L_{\mathbf{g}(\mathbf{x})}\psi(\mathbf{x},t)\right)^{-1}$ exists everywhere,
we may choose the control input $u$ in the following class of functions:
\begin{equation}\label{control}
\begin{split}
u(\mathbf{x},\hat{\boldsymbol{\theta}},{\boldsymbol{\omega}},t)&=\frac{1}{L_{\mathbf{g}(\mathbf{x})}\psi(\mathbf{x},t)}\left(-L_{\mathbf{f}(\mathbf{x},\hat{{\boldsymbol{\theta}}})}\psi(\mathbf{x},t)-\varphi(\psi,{\boldsymbol{\omega}},t)-\frac{{\partial}\psi(\mathbf{x},t)}{{\partial} t}\right) \\
& \ \varphi: \ \mathbb{R}\times\mathbb{R}^w\times\mathbb{R}_+\rightarrow\mathbb{R}
\end{split}
\end{equation}
where ${\boldsymbol{\omega}}\in\Omega_\omega\subset\mathbb{R}^w$ is a vector of
{\it known} parameters of the function
$\varphi(\psi,{\boldsymbol{\omega}},t)$. Denoting
$L_{\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})}\psi(\mathbf{x},t)=f(\mathbf{x},{\boldsymbol{\theta}},t)$ and taking into account (\ref{control}) we may rewrite equation
(\ref{dpsi}) in the following manner:
\begin{equation}\label{error_model}
{\dot\psi}=f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-\varphi(\psi,{\boldsymbol{\omega}},t)
\end{equation}

For the purpose of the present article, instead of
(\ref{error_model}) it is worthwhile to consider the extended equation:
\begin{equation}\label{error_model_d}
{\dot\psi}=f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-\varphi(\psi,{\boldsymbol{\omega}},t)+\varepsilon(t),
\end{equation}
where, if not stated overwise, the function
$\varepsilon:\mathbb{R}_+\rightarrow\mathbb{R}$, $\varepsilon\in L_{2}^1
[t_0,\infty]\cap C^0$. One of the immediate advantages of equation
(\ref{error_model_d}) in comparison with (\ref{error_model}) is that it allows us to take the presence of coupling between interconnected systems into consideration.

Let us now specify the desired properties of the function
$\varphi(\psi,{\boldsymbol{\omega}},t)$ in (\ref{control}),
(\ref{error_model_d}). The majority of known algorithms for parameter estimation and adaptive control
\cite{Kokotovich95,Fradkov99,Narendra89,Sastry89} assume global
(Lyapunov) stability of system
(\ref{error_model_d}) for ${\boldsymbol{\theta}}\equiv\hat{{\boldsymbol{\theta}}}$. In our study, however, we refrain from this standard, restrictive requirement. Instead we propose that finite energy of the signal
$f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)$, defined for example by its $L_{2}^1[t_0,\infty]$ norm with respect to the variable $t$, results in finite deviation from the target set given by the equality $\psi(\mathbf{x},t)=0$. Formally this requirement is introduced in Assumption \ref{assume:gain}:
\begin{assume}[Target dynamics operator]\label{assume:gain} Consider the following system:
\begin{equation}\label{eq:target_dynamics}
{\dot\psi}=-\varphi(\psi,{\boldsymbol{\omega}},t)+\zeta(t),
\end{equation}
where $\zeta:\mathbb{R}_+\rightarrow\mathbb{R}$ and
$\varphi(\psi,{\boldsymbol{\omega}},t)$ is defined in (\ref{error_model_d}).
Then for every ${\boldsymbol{\omega}}\in\Omega_\omega$ system
(\ref{eq:target_dynamics}) has $L_{2}^1 [t_0,\infty]\mapsto L_\infty^1[t_0,\infty]$ gain with respect to input $\zeta(t)$. In other words, there exists a function $\gamma_{\infty,2}$ such that
\begin{equation}\label{eq:gain_psi_L2}
\|\psi(t)\|_{\infty,[t_0,T]}\leq
\gamma_{\infty,2}(\psi_0,{\boldsymbol{\omega}},\|\zeta(t)\|_{2,[t_0,T]}), \ \
\forall \ \zeta(t)\in L_{2}^1[t_0,T]
\end{equation}
\end{assume}
In contrast to conventional approaches, Assumption
\ref{assume:gain} does not require global {\it asymptotic stability} of the origin of the unperturbed (i.e for $\zeta(t)=0$)
system (\ref{eq:target_dynamics}). When the stability of the target dynamics ${\dot\psi}=-\varphi(\psi,{\boldsymbol{\omega}},t)$ is known a-priori, one of the benefits of Assumption \ref{assume:gain} is that there is no need to know a {\it particular Lyapunov function}
of the unperturbed system.

So far we have introduced basic assumptions on system
(\ref{system1}) and the class of feedback considered in this article. Let us now specify the class of functions
$f(\mathbf{x},{\boldsymbol{\theta}},t)$ in (\ref{error_model_d}). Since general parametrization of function $f(\mathbf{x},{\boldsymbol{\theta}},t)$ is methodologically difficult to deal with, but solutions provided for nonlinearities with convenient linear re-parametrization often yield physically implausible models and large number of unknown parameters, we have opted for a new class of parameterizations.
As a candidate for such a parametrization we suggest nonlinear functions that satisfy the following assumption:
\begin{assume}[Monotonicity and Growth Rate in Parameters]\label{assume:alpha}For the given function
$f(\mathbf{x},{\boldsymbol{\theta}},t)$ in (\ref{error_model_d}) there exists function $\boldsymbol{\alpha}(\mathbf{x},t): \mathbb{R}^{n}\times \mathbb{R}_+\rightarrow
\mathbb{R}^d, \ \boldsymbol{\alpha}(\mathbf{x},t)\in \mathcal{C}^1$ and positive constant $D>0$ such that
\begin{equation}\label{eq:assume_alpha}
(f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-f(\mathbf{x},{\boldsymbol{\theta}},t))(\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}}))\geq0
\end{equation}
\begin{equation}\label{eq:assume_gamma}
|f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-f(\mathbf{x},{\boldsymbol{\theta}},t)|\leq D
|\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}})|
\end{equation}
\end{assume}
This set of conditions naturally extends from systems that are linear in parameters to those with nonlinear parametrization.
Examples and models of physical and artificial systems which satisfy Assumption \ref{assume:alpha} (at least for bounded
${\boldsymbol{\theta}},\hat{{\boldsymbol{\theta}}}\in \Omega_\theta$) can be found in the following references
\cite{Armstrong_1993,Boskovic_1995,Canudas_1999,Abbott_2001,Kitching_2000}.
Assumption \ref{assume:alpha} bounds the growth rate of the difference $|f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)|$ by the functional
$D|\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}})|$.
In addition, it might also be useful to have an estimate of
$|f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)|$ from below, as specified in Assumption \ref{assume:alpha_upper}:
\begin{assume}\label{assume:alpha_upper} For the given function
$f(\mathbf{x},{\boldsymbol{\theta}},t)$ in (\ref{error_model_d}) and function
$\boldsymbol{\alpha}(\mathbf{x},t)$, satisfying Assumption \ref{assume:alpha},
there exists a positive constant $D_1>0$ such that
\begin{equation}\label{eq:assume_alpha_upper}
|f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-f(\mathbf{x},{\boldsymbol{\theta}},t)|\geq D_1
|\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}})|
\end{equation}
\end{assume}

\noindent In problems of adaptation, parameter and optimization estimation, effectiveness of the algorithms often depends on how
"good" the nonlinearity $f(\mathbf{x},{\boldsymbol{\theta}},t)$ is, and how predictable is the system's behavior. As a measure of goodness and predictability usually the substitutes as smoothness and boundedness are considered. In our study, we distinguish several of such specific properties of the functions $f(\mathbf{x},{\boldsymbol{\theta}},t)$
and $\varphi(\psi,{\boldsymbol{\omega}},t)$. These properties are provided below.

\begin{hyp}\label{hyp:locally_bound_uniform_f} The function $f(\mathbf{x},{\boldsymbol{\theta}},t)$ is locally bounded with respect to $\mathbf{x}$, ${{\boldsymbol{\theta}}}$ uniformly in $t$.
\end{hyp}

\begin{hyp}\label{hyp:locally_bound_uniform_df} The function $f(\mathbf{x},{\boldsymbol{\theta}},t)\in \mathcal{C}^1$, and $ {\partial}
{f(\mathbf{x},{\boldsymbol{\theta}},t)}/{{\partial} t}$ is locally bounded with respect to
$\mathbf{x}$, ${{\boldsymbol{\theta}}}$ uniformly in $t$.
\end{hyp}

\begin{hyp}\label{hyp:locally_bound_uniform_phi} The function $\varphi(\psi,{\boldsymbol{\omega}},t)$ is locally bounded in $\psi$,
${\boldsymbol{\omega}}$ uniformly in $t$.
\end{hyp}

Let us show that under an additional structural requirement, which relates properties of the function $\boldsymbol{\alpha}(\mathbf{x},t)$ and vector-field
$\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})=\mathbf{f}_1(\mathbf{x},{\boldsymbol{\theta}})\oplus\mathbf{f}_2(\mathbf{x},{\boldsymbol{\theta}})$
in (\ref{system1}), (\ref{system}), there exist adaptive algorithms ensuring that the following desired property holds:
\begin{equation}\label{eq:desired_prop}
\mathbf{x}(t)\in L_\infty^n[t_0,\infty]; \
f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}}(t),t)\in L_{2}^1[t_0,\infty]
\end{equation}

Consider the following adaptation algorithms:
\begin{equation}\label{fin_forms_ours_tr1}
\begin{split}
\hat{{\boldsymbol{\theta}}}(\mathbf{x},t)&=\Gamma(\hat{{\boldsymbol{\theta}}}_P(\mathbf{x},t)+\hat{{\boldsymbol{\theta}}}_I(t));
\ \Gamma\in\mathbb{R}^{d\times d}, \ \Gamma>0
\\ \hat{{\boldsymbol{\theta}}}_P(\mathbf{x},t)&=
\psi(\mathbf{x},t)\boldsymbol{\alpha}(\mathbf{x},t)-\Psi(\mathbf{x},t) \\
\dot{\hat{{\boldsymbol{\theta}}}}_I&=\varphi(\psi(\mathbf{x},t),{\boldsymbol{\omega}},t)\boldsymbol{\alpha}(\mathbf{x},t)+\mathcal{R}(\mathbf{x},\hat{{\boldsymbol{\theta}}},u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t),t),
\end{split}
\end{equation}
where the function
$\mathcal{R}(\mathbf{x},\hat{{\boldsymbol{\theta}}},u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t),t):\mathbb{R}^n\times\mathbb{R}^d\times\mathbb{R}\times\mathbb{R}_+\rightarrow\mathbb{R}^d$
in (\ref{fin_forms_ours_tr1}) is given as follows:
\begin{equation}\label{fin_forms_ours_tr11}
\begin{split}
&\mathcal{R}(\mathbf{x},u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t),t)={{\partial}
\Psi(\mathbf{x},t)}/{{\partial} t}-\psi(\mathbf{x},t)({{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}/{{\partial} t}+L_{\mathbf{f}_1}\boldsymbol{\alpha}(\mathbf{x},t))\\
& + L_{\mathbf{f}_1}
\Psi(\mathbf{x},t)-(\psi(\mathbf{x},t)L_{\mathbf{g}_1}\boldsymbol{\alpha}(\mathbf{x},t)-L_{\mathbf{g}_1}
\Psi(\mathbf{x},t))u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)
\end{split}
\end{equation}
and function
$\Psi(\mathbf{x},t):\mathbb{R}^{n}\times\mathbb{R}_+\rightarrow\mathbb{R}_d$,
$\Psi(\mathbf{x},t)\in \mathcal{C}^1$ satisfies Assumption
\ref{assume:explicit_realizability}.
\begin{assume}\label{assume:explicit_realizability} There exists a function $\Psi(\mathbf{x},t)$ such that
\begin{equation}\label{eq:assume_explicit}
\frac{{\partial} \Psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}-\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} \mathbf{x}_2}=0
\end{equation}
\end{assume}
Additional restrictions imposed by this assumption will be discussed in some details after we summarize the properties of system (\ref{system1}), (\ref{control}),
(\ref{fin_forms_ours_tr1}), (\ref{fin_forms_ours_tr11}) in the following theorem.

\begin{theorem}[Properties of the decoupled systems]\label{stability_theorem}
Let system (\ref{system1}), (\ref{error_model_d}),
(\ref{fin_forms_ours_tr1}), (\ref{fin_forms_ours_tr11}) be given and Assumptions \ref{assume:alpha}, \ref{assume:alpha_upper},
\ref{assume:explicit_realizability} be satisfied. Then the following properties hold

P1) Let for the given initial conditions $\mathbf{x}(t_0)$,
$\hat{{\boldsymbol{\theta}}}_I(t_0)$ and parameters vector ${\boldsymbol{\theta}}$,
interval $[t_0,T^\ast]$ be the (maximal) time-interval of existence of solutions of the closed loop system (\ref{system1}),
(\ref{error_model_d}), (\ref{fin_forms_ours_tr1}),
(\ref{fin_forms_ours_tr11}). Then
\begin{equation}\label{eq:f_diff_L2}
\|f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t))\|_{2,[t_0,T^\ast]}\leq D_f({\boldsymbol{\theta}},t_0,\Gamma,\|\varepsilon(t)\|_{2,[t_0,T^\ast]});
\end{equation}
\[
D_f({\boldsymbol{\theta}},t_0,\Gamma,\|\varepsilon(t)\|_{2,[t_0,T^\ast]})=\left(\frac{D}{2}\|{\boldsymbol{\theta}}-\hat{{\boldsymbol{\theta}}}(t_0)\|^{2}_{\Gamma^{-1}}\right)^{0.5}
+ \frac{D}{D_1}\|\varepsilon(t)\|_{2,[t_0,T^\ast]}
\]
\[
\|{\boldsymbol{\theta}}-\hat{\boldsymbol{\theta}}(t)\|^{2}_{\Gamma^{-1}}\leq
\|\hat{{\boldsymbol{\theta}}}(t_0)-{\boldsymbol{\theta}}\|^{2}_{\Gamma^{-1}}+\frac{D}{2 D_1^2}\|\varepsilon(t)\|^{2}_{2,[t_0,T^\ast]}
\]

\noindent In addition, if Assumptions \ref{assume:psi} and
\ref{assume:gain} are satisfied then

P2) $\psi(\mathbf{x}(t),t)\in L_\infty^1[t_0,\infty]$, $\mathbf{x}(t)\in L_{\infty}^n[t_0,\infty]$ and
\begin{equation}\label{eq:psi_gain}
\|\psi(\mathbf{x}(t),t)\|_{\infty,[t_0,\infty]}\leq
\gamma_{\infty,2}\left(\psi(\mathbf{x}_0,t_0),{\boldsymbol{\omega}},\mathcal{D}\right)
\end{equation}
\[
\mathcal{D}=D_f({\boldsymbol{\theta}},t_0,\Gamma,\|\varepsilon(t)\|_{2,[t_0,\infty]})+\|\varepsilon(t)\|_{2,[t_0,\infty]}
\]

P3) if properties H\ref{hyp:locally_bound_uniform_f},
H\ref{hyp:locally_bound_uniform_phi} hold, and system
(\ref{eq:target_dynamics}) has $L_{2}^1 [t_0,\infty]\mapsto L_{p}^1 [t_0,\infty]$, $p>1$ gain with respect to input $\zeta(t)$
and output $\psi$ then
\begin{equation}\label{eq:convergence_psi_theorem}
\varepsilon(t)\in L_{2}^1 [t_0,\infty]\cap L_{\infty}^1[t_0,\infty]\Rightarrow
\lim_{t\rightarrow\infty}\psi(\mathbf{x}(t),t)=0
\end{equation}

If, in addition, property H\ref{hyp:locally_bound_uniform_df}
holds, and the functions $\boldsymbol{\alpha}(\mathbf{x},t)$, ${\partial}
\psi(\mathbf{x},t)/{\partial} t$ are locally bounded with respect to $\mathbf{x}$
uniformly in $t$, then

P4) the following holds
\begin{equation}\label{eq:convergence_f_theorem}
\lim_{t\rightarrow\infty}f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)=0
\end{equation}

\end{theorem}
The proof of Theorem \ref{stability_theorem} and subsequent results are given in Section 6.

Let us briefly comment on Assumption
\ref{assume:explicit_realizability}.
Let $\boldsymbol{\alpha}(\mathbf{x},t)\in
\mathcal{C}^2$,
$\boldsymbol{\alpha}(\mathbf{x},t)=\mathrm{col}(\alpha_1(\mathbf{x},t),\dots,\alpha_d(\mathbf{x},t))$,
then necessary and sufficient conditions for existence of the function $\Psi(\mathbf{x},t)$ follow from the Poincar$\acute{\mathrm{e}}$ lemma:
\begin{equation}\label{eq:poincare}
\frac{{\partial}}{{\partial} \mathbf{x}_2}\left(\psi(\mathbf{x},t)\frac{{\partial}
\alpha_i(\mathbf{x},t)}{{\partial}
\mathbf{x}_2}
\right)=\left(\frac{{\partial}}{{\partial}
\mathbf{x}_2}\left(\psi(\mathbf{x},t)\frac{{\partial} \alpha_i(\mathbf{x},t)}{{\partial}
\mathbf{x}_2}
\right)
\right)^T
\end{equation}
This relation, in the form of conditions of existence of the solutions for function $\Psi(\mathbf{x},t)$ in
(\ref{eq:assume_explicit}), takes into account structural properties of system (\ref{system1}), (\ref{error_model_d}).
Indeed,
consider partial derivatives ${\partial} \alpha_i(\mathbf{x},t)/{\partial} \mathbf{x}_2$,
${\partial} \psi(\mathbf{x},t)/{\partial} \mathbf{x}_2$ with respect to the vector
$\mathbf{x}_2=(x_{21},\dots,x_{2p})^T$. Let
\begin{equation}\label{eq:single_dim}
\begin{split}
\frac{{\partial} \psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}=\left(\begin{array}{cccccccc}
0& 0
& \cdots & 0& \ast & 0&\cdots&0
\end{array}\right), \
\frac{{\partial}
\alpha_i(\mathbf{x},t)}{{\partial}\mathbf{x}_2}=\left(\begin{array}{cccccccc}
0 & 0
& \cdots & 0&
\ast &
0&\cdots&0
\end{array}\right)
\end{split}
\end{equation}
where the symbol $\ast$ denotes a function of $\mathbf{x}$ and $t$. Then condition (\ref{eq:single_dim}) guarantees that equality
(\ref{eq:poincare}) (and, subsequently, Assumption
\ref{assume:explicit_realizability}) holds. In case ${\partial}
\alpha(\mathbf{x}_1\oplus \mathbf{x}_2,t)/{\partial} \mathbf{x}_2=0$, Assumption
\ref{assume:explicit_realizability} holds for arbitrary
$\psi(\mathbf{x},t)\in \mathcal{C}^1$. If $\psi(\mathbf{x},t)$,
$\boldsymbol{\alpha}(\mathbf{x},t)$ depend on a single component of $\mathbf{x}_2$, for instance $x_{2k}, \ k\in\{0,\dots,p\}$, then conditions
(\ref{eq:single_dim}) hold and the function $\Psi(\mathbf{x},t)$ can be derived explicitly by integration
\begin{equation}\label{eq:single_dim_int}
\Psi(\mathbf{x},t)=\int\psi(\mathbf{x},t)\frac{\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} x_{2k}}d x_{2k}
\end{equation}
In all other cases, existence of the required function
$\Psi(\mathbf{x},t)$ follows from (\ref{eq:poincare}).

In the general case, when $\dim\{\mathbf{x}_2\}>1$, the problems of finding a function $\Psi(\mathbf{x},t)$ satisfying condition
(\ref{eq:assume_explicit}) can be avoided (or converted into one with an already known solutions such as (\ref{eq:poincare}),
(\ref{eq:single_dim_int})) by the {\it embedding} technique proposed in \cite{ECC_2003}. The main idea of the method is to introduce an auxiliary system that is forward-complete with respect to input $\mathbf{x}(t)$
\begin{equation}\label{eq:embed}
\begin{split}
\dot{{\boldsymbol{\xi}}}&=\mathbf{f}_{\boldsymbol{\xi}}(\mathbf{x},{\boldsymbol{\xi}},t), \ {\boldsymbol{\xi}}\in\mathbb{R}^z \\
\mathbf{h}_\xi&=\mathbf{h}_\xi({\boldsymbol{\xi}},t), \
\mathbb{R}^z\times\mathbb{R}_+\rightarrow\mathbb{R}^h
\end{split}
\end{equation}
such that
\begin{equation}\label{eq:embed_L2}
\|f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}_1(t)\oplus\mathbf{h}_\xi(t)\oplus\mathbf{x}_2'(t),{\boldsymbol{\theta}},t)\|_{2,[t_0,T]}
\leq C_\xi\in\mathbb{R}_+
\end{equation}
for all $T\geq t_0$, and $\dim\{{\mathbf{h}_\xi}\}+\dim{\{\mathbf{x}_2'\}}=p$.
Then (\ref{error_model_d}) can be rewritten as follows:
\begin{equation}\label{error_model_d1}
{\dot\psi}=f(\mathbf{x}_1\oplus\mathbf{h}_\xi\oplus\mathbf{x}_2',{\boldsymbol{\theta}},t)-f(\mathbf{x}_1\oplus\mathbf{h}_\xi\oplus\mathbf{x}_2',\hat{\boldsymbol{\theta}},t)-\varphi(\psi,{\boldsymbol{\omega}},t)+\varepsilon_\xi(t),
\end{equation}
where $\varepsilon_\xi(t)\in L_{2}^1 [t_0,\infty]$, and
$\dim\{\mathbf{x}_2'\}=p-h<p$. In principle, the dimension of $\mathbf{x}_2'$
could be reduced to $1$ or $0$. As soon as this is ensured,
Assumption \ref{assume:explicit_realizability} will be satisfied and the results of Theorem \ref{stability_theorem} follow.
Sufficient conditions ensuring the existence of such an embedding in the general case are provided in \cite{ECC_2003}. For systems in which the parametric uncertainty can be reduced to vector fields with low-triangular structure the embedding is given in
\cite{ALCOSP_2004}.

\section{Main Results}\label{sec:main}

Without loss of generality let us rewrite interconnection
(\ref{eq:system:s1}), (\ref{eq:system:s2}) as follows
:
\begin{equation}\label{eq:system:s11}
\begin{split}
\dot{\mathbf{x}}_1&=\mathbf{f}_1(\mathbf{x})+\mathbf{g}_1(\mathbf{x})u_x\\
\dot{\mathbf{x}}_2 &=\mathbf{f}_2(\mathbf{x},{\boldsymbol{\theta}}_x)+\gamma_y(\mathbf{y},t)+
\mathbf{g}_2(\mathbf{x})u_x
\end{split}
\end{equation}

\begin{equation}\label{eq:system:s21}
\begin{split}
\dot{\mathbf{y}}_1&=\mathbf{q}_1(\mathbf{y})+\mathbf{z}_1(\mathbf{y})u_y\\
\dot{\mathbf{y}}_2&=\mathbf{q}_2(\mathbf{y},{\boldsymbol{\theta}}_y)+\gamma_x(\mathbf{x},t)+\mathbf{z}_2(\mathbf{y})u_y
\end{split}
\end{equation}

Let us now consider the following control functions
\begin{equation}\label{control_s1}
\begin{split}
u_x(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x,{\boldsymbol{\omega}}_x,t)&=(L_{\mathbf{g}(\mathbf{x})}\psi_x(\mathbf{x},t))^{-1}\left(-L_{\mathbf{f}(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x)}\psi_x(\mathbf{x},t)-\varphi_x(\psi_x,{\boldsymbol{\omega}}_x,t)\right.\\
& \left.-\frac{{\partial}\psi_x(\mathbf{x},t)}{{\partial} t}\right), \ \ \varphi_x: \
\mathbb{R}\times\mathbb{R}^w\times\mathbb{R}_+\rightarrow\mathbb{R}
\end{split}
\end{equation}
\begin{equation}\label{control_s2}
\begin{split}
u_y(\mathbf{y},\hat{{\boldsymbol{\theta}}}_y,{\boldsymbol{\omega}}_y,t)&=(L_{\mathbf{z}(\mathbf{y})}\psi_y(\mathbf{y},t))^{-1}\left(-L_{\mathbf{q}(\mathbf{y},\hat{{\boldsymbol{\theta}}}_y)}\psi_y(\mathbf{y},t)-\varphi_y(\psi_y,{\boldsymbol{\omega}}_y,t)\right.\\
&\left.-\frac{{\partial}\psi_y(\mathbf{y},t)}{{\partial} t}\right), \ \ \varphi_y: \
\mathbb{R}\times\mathbb{R}^w\times\mathbb{R}_+\rightarrow\mathbb{R}
\end{split}
\end{equation}
These functions transform the original equations
(\ref{eq:system:s11}), (\ref{eq:system:s21}) into the following form
\begin{equation}\label{eq:error_coupled}
\begin{split}
{\dot\psi}_x&=-\varphi_x(\psi_x,{\boldsymbol{\omega}}_x,t)+f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)-f_x(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x,t)+h_y(\mathbf{x},\mathbf{y},t)\\
{\dot\psi}_y&=-\varphi_y(\psi_x,{\boldsymbol{\omega}}_y,t)+f_y(\mathbf{y},{\boldsymbol{\theta}}_y,t)-f_y(\mathbf{y},\hat{{\boldsymbol{\theta}}}_y,t)+h_x(\mathbf{x},\mathbf{y},t),
\end{split}
\end{equation}
where
\[
h_x(\mathbf{x},\mathbf{y},t)=L_{\gamma_y(\mathbf{y},t)}\psi_x(\mathbf{x},t), \
h_y(\mathbf{x},\mathbf{y},t)=L_{\gamma_x(\mathbf{x},t)}\psi_y(\mathbf{y},t)
\]
\[
f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)=L_{\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}}_x)}\psi_x(\mathbf{x},t), \
f_y(\mathbf{x},{\boldsymbol{\theta}}_y,t)=L_{\mathbf{q}(\mathbf{y},{\boldsymbol{\theta}}_y)}\psi_y(\mathbf{y},t)
\]

Consider the following adaptation algorithms
\begin{equation}\label{fin_forms_ours_tr1x}
\begin{split}
\hat{{\boldsymbol{\theta}}}_x(\mathbf{x},t)&=\Gamma_x(\hat{{\boldsymbol{\theta}}}_{P,x}(\mathbf{x},t)+\hat{{\boldsymbol{\theta}}}_{I,x}(t));
\ \Gamma_x\in\mathbb{R}^{d\times d}, \ \Gamma_x>0
\\ \hat{{\boldsymbol{\theta}}}_{P,x}(\mathbf{x},t)&=
\psi_x(\mathbf{x},t)\boldsymbol{\alpha}_x(\mathbf{x},t)-\Psi_x(\mathbf{x},t) \\
\dot{\hat{{\boldsymbol{\theta}}}}_{I,x}&=\varphi_x(\psi_x(\mathbf{x},t),{\boldsymbol{\omega}}_x,t)\boldsymbol{\alpha}_x(\mathbf{x},t)+\mathcal{R}_x(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x,u_x(\mathbf{x},\hat{{\boldsymbol{\theta}}}_x,t),t),
\end{split}
\end{equation}

\begin{equation}\label{fin_forms_ours_tr1y}
\begin{split}
\hat{{\boldsymbol{\theta}}}_y(\mathbf{x},t)&=\Gamma_y(\hat{{\boldsymbol{\theta}}}_{P,y}(\mathbf{y},t)+\hat{{\boldsymbol{\theta}}}_{I,y}(t));
\ \Gamma_y\in\mathbb{R}^{d\times d}, \ \Gamma_y>0
\\ \hat{{\boldsymbol{\theta}}}_{P,y}(\mathbf{y},t)&=
\psi_y(\mathbf{y},t)\boldsymbol{\alpha}_y(\mathbf{y},t)-\Psi_y(\mathbf{y},t) \\
\dot{\hat{{\boldsymbol{\theta}}}}_{I,y}&=\varphi_y(\psi_y(\mathbf{y},t),{\boldsymbol{\omega}}_y,t)\boldsymbol{\alpha}_y(\mathbf{y},t)+\mathcal{R}_y(\mathbf{x},\hat{{\boldsymbol{\theta}}}_y,u_y(\mathbf{y},\hat{{\boldsymbol{\theta}}}_y,t),t),
\end{split}
\end{equation}
where $\mathcal{R}_x(\cdot)$, $\mathcal{R}_y(\cdot)$ are defined as in (\ref{fin_forms_ours_tr11}), and the functions
$\Psi_x(\cdot)$, $\Psi_y(\cdot)$ will be specified later. Now we are ready to formulate the following result

\begin{theorem}[Properties of the interconnected systems]\label{theorem:interconnection} Let systems (\ref{eq:system:s11}), (\ref{eq:system:s21}) be given. Furthermore, suppose that the following conditions hold:

1) The functions $\psi_x(\mathbf{x},t)$, $\psi_y(\mathbf{y},t)$ satisfy Assumption \ref{assume:psi} for systems (\ref{eq:system:s11}),
(\ref{eq:system:s21}) respectively;

2) The systems
\begin{equation}\label{eq:target_dynamics_connected}
\dot{\psi}_x=-\varphi_x(\psi_x,{\boldsymbol{\omega}}_x,t)+\zeta_x(t), \ \
\dot{\psi}_y=-\varphi_y(\psi_y,{\boldsymbol{\omega}}_y,t)+\zeta_y(t)
\end{equation}
satisfy Assumption \ref{assume:gain} with corresponding mappings
\[
\gamma_{x_{\infty,2}}(\psi_{x_0},{\boldsymbol{\omega}}_x,\|\zeta_x(t)\|_{2,[t_0,T]}),
\ \
\gamma_{y_{\infty,2}}(\psi_{y_0},{\boldsymbol{\omega}}_y,\|\zeta_y(t)\|_{2,[t_0,T]}),
\]

3) The systems (\ref{eq:target_dynamics_connected}) have
$L_2^1[t_0,\infty]\mapsto L_2^1[t_0,\infty]$ gains, that is
\begin{equation}\label{eq:L_2_2_gains}
\begin{split}
\|\psi_x(\mathbf{x}(t),t)\|_{2,[t_0,T]}&\leq C_{\gamma_x}+\gamma_{x_{2,2}}(\|\zeta_x(t)\|_{2,[t_0,T]}),\\
\|\psi_y(\mathbf{y}(t),t)\|_{2,[t_0,T]}&\leq C_{\gamma_y}+\gamma_{y_{2,2}}(\|\zeta_y(t)\|_{2,[t_0,T]}),\\
C_{\gamma_x}, \ C_{\gamma_y}\in\mathbb{R}_+& \gamma_{x_{2,2}}, \
\gamma_{y_{2,2}}\in\mathcal{K}_\infty
\end{split}
\end{equation}

4) The functions $f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)$,
$f_y(\mathbf{y},{\boldsymbol{\theta}}_y,t)$ satisfy Assumptions \ref{assume:alpha},
\ref{assume:alpha_upper} with corresponding constants $D_x$,
$D_{x_1}$, $D_y$, $D_{y_1}$ and functions $\boldsymbol{\alpha}_x(\mathbf{x},t)$,
$\boldsymbol{\alpha}_y(\mathbf{y},t)$;

5) The functions $h_x(\mathbf{x},\mathbf{y},t)$, $h_y(\mathbf{x},\mathbf{y},t)$ satisfy the following inequalities:
\begin{equation}\label{eq:disturbance_gain}
\|h_x(\mathbf{x},\mathbf{y},t)\|\leq \beta_x \|\psi_x(\mathbf{x},t)\|, \
\|h_y(\mathbf{x},\mathbf{y},t)\|\leq \beta_y \|\psi_y(\mathbf{y},t)\|, \ \beta_x,
\beta_y\in \mathbb{R}_+
\end{equation}

Finally, let the functions $\Psi_x(\mathbf{x},t)$, $\Psi_y(\mathbf{y},t)$ in
(\ref{fin_forms_ours_tr1x}), (\ref{fin_forms_ours_tr1y}) satisfy Assumption \ref{assume:explicit_realizability}
for systems (\ref{eq:system:s11}), (\ref{eq:system:s21})
respectively, and there exist functions $\rho_1(\cdot), \
\rho_2(\cdot), \ \rho_3(\cdot)>Id(\cdot)\in\mathcal{K}_\infty$ and constant $\bar{\Delta}\in\mathbb{R}_+$ such the following inequality holds:
\begin{equation}\label{eq:small_gain_adapt}
\beta_y\circ\gamma_{y_{2,2}}\circ\rho_1\circ\left(\frac{D_y}{D_{y,1}}+1\right)\circ\rho_3\circ
\beta_x\circ
\gamma_{x_{2,2}}\circ\rho_2\circ\left(\frac{D_x}{D_{x,1}}+1\right)(\Delta)<
\Delta
\end{equation}
for all $\Delta\geq \bar{\Delta}$. Then

C1) The interconnection (\ref{eq:system:s11}),
(\ref{eq:system:s21}) with controls (\ref{control_s1}),
(\ref{control_s2}) is forward-complete and trajectories $\mathbf{x}(t)$,
$\mathbf{y}(t)$ are bounded

Furthermore,

C2) if properties H\ref{hyp:locally_bound_uniform_f},
H\ref{hyp:locally_bound_uniform_phi} hold for
$f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)$, $f_y(\mathbf{y},{\boldsymbol{\theta}}_y,t)$,
$h_x(\mathbf{x},\mathbf{y},t)$, $h_y(\mathbf{x},\mathbf{y},t)$, and also functions
$\varphi_x(\psi_x,{\boldsymbol{\omega}}_x,t)$,
$\varphi_y(\psi_y,{\boldsymbol{\omega}}_y,t)$, then
\begin{equation}\label{eq:convergence_psi_xy}
\lim_{t\rightarrow\infty}\psi_x(\mathbf{x}(t),t)=0, \
\lim_{t\rightarrow\infty}\psi_y(\mathbf{y}(t),t)=0
\end{equation}

Moreover,

C3) if property H\ref{hyp:locally_bound_uniform_df} holds for
$f_x(\mathbf{x},{\boldsymbol{\theta}}_x,t)$, $f_y(\mathbf{y},{\boldsymbol{\theta}}_y,t)$, and the functions
\[
\boldsymbol{\alpha}_x(\mathbf{x},t), \ {\partial} \psi_x(\mathbf{x},t)/{\partial} t, \
\boldsymbol{\alpha}_y(\mathbf{y},t), \ {\partial} \psi_y(\mathbf{y},t)/{\partial} t
\]
are locally bounded with respect to $\mathbf{x}$, $\mathbf{y}$ uniformly in $t$,
then
\begin{equation}\label{eq:convergence_f_xy}
\begin{split}
\lim_{t\rightarrow\infty}f_x(\mathbf{x}(t),{\boldsymbol{\theta}}_x,t)-f_x(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}_x(t),t)&=0,
\\
\lim_{t\rightarrow\infty}f_y(\mathbf{y}(t),{\boldsymbol{\theta}}_y,t)-f_y(\mathbf{y}(t),\hat{{\boldsymbol{\theta}}}_y(t),t)&=0
\end{split}
\end{equation}
\end{theorem}

Let us briefly comment on the conditions and assumptions of Theorem \ref{theorem:interconnection}. Conditions 1), 2) specify restrictions on the goal functionals, similar to those of Theorem
\ref{stability_theorem}. Condition 3) is analogous to requirement to P3) in Theorem \ref{stability_theorem}, condition 5) specifies uncertainties in the coupling functions $h_x(\cdot)$, $h_y(\cdot)$
in terms of their growth rates w.r.t. $\psi_x(\cdot)$,
$\psi_y(\cdot)$. We observe here that this property is needed in order to characterize the $L_2$ norms of functions
$h_x(\mathbf{x}(t),\mathbf{y}(t),t)$, $h_y(\mathbf{x}(t),\mathbf{y}(t),t)$ in terms of the
$L_2$ norms of functions $\psi_x(\mathbf{x}(t),t)$, $\psi_y(\mathbf{y}(t),t)$.
Therefore, it is possible to replace requirement
(\ref{eq:disturbance_gain}) with the following set of conditions:
\begin{equation}\label{eq:disturbance_gain_1}
\begin{split}
\|h_x(\mathbf{x}(t),\mathbf{y}(t),t)\|_{2,[t_0,T]}&\leq \beta_x
\|\psi_x(\mathbf{x}(t),t)\|_{2,[t_0,T]}+C_x, \\
\|h_y(\mathbf{x}(t),\mathbf{y}(t),t)\|_{2,[t_0,T]}&\leq \beta_y
\|\psi_y(\mathbf{y}(t),t)\|_{2,[t_0,T]}+C_y
\end{split}
\end{equation}
The replacement will allow us to extend results of Theorem
\ref{theorem:interconnection} to interconnections of systems where the coupling functions do not depend explicitly on
$\psi_x(\mathbf{x}(t),t)$, $\psi_y(\mathbf{y}(t),t)$. We illustrate this possibility later with an example.

Condition (\ref{eq:small_gain_adapt}) is the small-gain condition with respect to the $L_2^1[t_0,T]$ norms for interconnection
(\ref{eq:system:s11}), (\ref{eq:system:s21}) with control
(\ref{control_s1}), (\ref{control_s2}). In the case that mappings
$\gamma_{x_{2,2}}(\cdot)$, $\gamma_{y_{2,2}}(\cdot)$ in
(\ref{eq:target_dynamics_connected}) are majorated by linear functions
\[
\gamma_{x_{2,2}}(\Delta)\leq g_{x_{2,2}} \Delta, \
\gamma_{y_{2,2}}(\Delta)\leq g_{y_{2,2}} \Delta, \ \Delta\geq 0,
\]
condition (\ref{eq:small_gain_adapt}) reduces to the much simpler
\[
\beta_y \beta_x g_{x_{2,2}} g_{y_{2,2}}
\left(\frac{D_y}{D_{y,1}}+1\right)\left(\frac{D_x}{D_{x,1}}+1\right)<
1
\]
Notice also that the mappings $\gamma_{x_{2,2}}(\cdot)$,
$\gamma_{y_{2,2}}(\cdot)$ are defined by properties of the target dynamics (\ref{eq:target_dynamics_connected}), and, in principle,
these can be made arbitrarily small. This eventually leads to the following conclusion: the smaller the $L_2$-gains of the target dynamics of systems $\mathcal{S}_1$, $\mathcal{S}_2$, the wider the class of nonlinearities (bounds for $\beta_x$, $\beta_y$, domains of $D_x$, $D_{1,x}$, $D_y$, $D_{1,y}$) which admit a solution to Problem \ref{problem:decentralized}.

\paragraph{Example}

Let us illustrate application of Theorem
\ref{theorem:interconnection} to the problem of decentralized control of two coupled oscillators with nonlinear damping.
Consider the following interconnected systems:
\begin{equation}\label{eq:example_dec_model}
\left\{\begin{array}{ll}
\dot{x}_{1}&=x_{2}\\
\dot{x}_{2}&=f_x(x_{1},\theta_x)+k_1 y_{1} + u_x,
\end{array} \right. \ \
\left\{
\begin{array}{ll}
\dot{y}_{1}&=y_{2}\\
\dot{y}_{22}&=f_y(y_{1},\theta_y)+k_2 x_{1}+ u_y,
\end{array}\right.
\end{equation}
where $k_1$, $k_2\in\mathbb{R}$ are uncertain parameters of coupling,
functions $f(x_{1},\theta_x)$, $f(y_{1},\theta_y)$
stand for the nonlinear damping terms, and
$\theta_{x}$, $\theta_y$ are unknown parameters. For illustrative purpose we assume the following mathematical model for functions
$f_x(\cdot)$, $f_y(\cdot)$ in (\ref{eq:example_dec_model}):
\begin{equation}\label{eq:example_dec_uncertainty}
\begin{split}
f_x(x_{1},\theta_x)&= \theta_x (x_{1}-x_0)+0.5\sin
(\theta_x(x_{1}-x_0)),\\
\ f_y(y_{1},\theta_y)&= \theta_y (y_{1}-y_0)+0.6\sin
(\theta_y(y_{1}-y_0))
\end{split}
\end{equation}
where $x_0$, $y_0$ are known. Let the control goal be to steer states $\mathbf{x}$ and $\mathbf{y}$ to the origin. Consider the following goal functions
\begin{equation}\label{eq:example_psi}
\psi_x(\mathbf{x},t)=x_1+x_2, \ \psi_y(\mathbf{y},t)= y_1+y_2
\end{equation}
Taking into account equations (\ref{eq:example_dec_model}) and
(\ref{eq:example_psi}) we can derive that
\begin{equation}\label{eq:example_relative_dynamics}
\dot{x}_1=-x_1+\psi_x(\mathbf{x}(t),t), \ \dot{y}_1=-y_1+\psi_y(\mathbf{y},t)
\end{equation}
This automatically implies that
\[
\begin{split}
\|x_1(t)\|_{\infty,[t_0,T]}&\leq
\|x_1(t_0)\|+\|\psi_x(\mathbf{x}(t),t)\|_{\infty,[t_0,T]}\\
\|y_1(t)\|_{\infty,[t_0,T]}&\leq
\|y_1(t_0)\|+\|\psi_y(\mathbf{y}(t),t)\|_{\infty,[t_0,T]}
\end{split}
\]
Hence, Assumption \ref{assume:psi} is satisfied for chosen goal functions $\psi_x(\cdot)$ and $\psi_y(\cdot)$. Notice also that equalities (\ref{eq:example_relative_dynamics}) imply that
\begin{equation}\label{eq:example_L2_gains}
\begin{split}
\|x_1(t)\|_{2,[t_0,T]}&\leq 2^{-1/2}\|x_1(t_0)\|+
\|\psi_x(\mathbf{x},t)\|_{2,[t_0,T]}\\
\|y_1(t)\|_{2,[t_0,T]}&\leq 2^{-1/2}\|y_1(t_0)\|+
\|\psi_y(\mathbf{y},t)\|_{2,[t_0,T]}
\end{split}
\end{equation}
Moreover, according to (\ref{eq:example_relative_dynamics})
limiting relations
\begin{equation}\label{eq:example_control_goal_limit}
\begin{split}
&
\lim_{t\rightarrow\infty}\psi_x(\mathbf{x}(t),t)=\lim_{t\rightarrow\infty}x_1(t)+x_2(t)=0,\\
&
\lim_{t\rightarrow\infty}\psi_y(\mathbf{y}(t),t)=\lim_{t\rightarrow\infty}y_1(t)+y_2(t)=0
\end{split}
\end{equation}
guarantee that
\[
\lim_{t\rightarrow\infty} x_1(t)=0, \
\lim_{t\rightarrow\infty}x_2(t)=0, \ \lim_{t\rightarrow\infty}
y_1(t)=0, \ \lim_{t\rightarrow\infty}y_2(t)=0
\]
Hence, property (\ref{eq:example_control_goal_limit}) ensures asymptotic reaching of the control goal.

According to equations (\ref{control_s1}), (\ref{control_s2})
control functions
\begin{equation}\label{eq:example_control}
\begin{split}
u_x&=-\lambda_x\psi_x-x_2-f_x(x_1,\hat{\theta}_x)\\
u_y&=-\lambda_y\psi_y-y_2-f_y(y_1,\hat{\theta}_y), \ \lambda_x, \
\lambda_y>0
\end{split}
\end{equation}
transform system (\ref{eq:example_dec_model}) into the following form
\begin{equation}\label{eq:example_error_model}
\begin{split}
\dot{\psi}_x&=-\lambda_x \psi_x +
f_x(x_1,\theta_x)-f_x(x_1,\hat{\theta}_x)+k_1 y_1\\
\dot{\psi}_x&=-\lambda_x \psi_x +
f_x(x_1,\theta_x)-f_x(x_1,\hat{\theta}_x)+k_2 x_1
\end{split}
\end{equation}
Notice that systems
\[
\dot{\psi}_x=-\lambda_x \psi_x +\xi_x(t), \
\dot{\psi}_y=-\lambda_y \psi_t +\xi_y(t)
\]
satisfy Assumption \ref{assume:gain} with
\[
\gamma_{x_{2,2}}=\frac{1}{\lambda_x}\|\psi_x(\mathbf{x}(t),t)\|_{2,[t_0,T]},
\
\gamma_{y_{2,2}}=\frac{1}{\lambda_y}\|\psi_y(\mathbf{y}(t),t)\|_{2,[t_0,T]}
\]
respectively, and functions $f_x(\cdot)$, $f_y(\cdot)$ satisfy Assumptions \ref{assume:alpha}, \ref{assume:alpha_upper} with
\[
\begin{split}
&D_{x}=1.5, \ D_{x,1}=0.5, \ \alpha_x(\mathbf{x},t)= x_1-x_0, \\
&D_{y}=1.6, \ D_{y,1}=0.4, \ \alpha_y(\mathbf{y},t)= y_1-y_0
\end{split}
\]
Hence conditions 1)-4) of Theorem \ref{theorem:interconnection}
are satisfied. Furthermore, according to the remarks regarding condition 5) of the theorem, requirements
(\ref{eq:disturbance_gain}) can be replaced with implicit constraints (\ref{eq:disturbance_gain_1}). These, however,
according to (\ref{eq:example_L2_gains}) also hold with
$\beta_x=k_1$, $\beta_y=k_2$.

Given that $\alpha_x(\mathbf{x},t)=x_1-x_0$, $\alpha_y(\mathbf{y},t)=y_1-y_0$,
Assumption \ref{assume:explicit_realizability} will be satisfied for functions $\alpha_x(\mathbf{x},t)$, $\alpha_y(\mathbf{y},t)$ with
$\Psi_x(\cdot)=0$, $\Psi_y(\cdot)=0$. Therefore, adaptation algorithms (\ref{fin_forms_ours_tr1x}),
(\ref{fin_forms_ours_tr1y}) will have the following form:
\begin{eqnarray}\label{eq:example_adaptation}
\hat{\theta}_x&=& \Gamma_x((x_1+x_2) (x_1-x_0) +
\hat{\theta}_{x,I}),\nonumber \\
\dot{\hat\theta}_{x,I}&=& \lambda_x (x_1+x_2)(x_1-x_0) - (x_1+x_2)x_2\nonumber \\
\hat{\theta}_y&=& \Gamma_y((y_1+y_2) (y_1-y_0) +
\hat{\theta}_{y,I}),\\
\dot{\hat\theta}_{y,I}&=& \lambda_y (y_1+y_2)(y_1-y_0) -
(y_1+y_2)y_2\nonumber
\end{eqnarray}
Hence, according to Theorem \ref{theorem:interconnection}
boundedness of the solutions in the closed loop system
(\ref{eq:example_error_model}), (\ref{eq:example_adaptation}) is ensured upon the following condition
\begin{equation}\label{eq:example_condition_boundedness}
\frac{k_1 k_2}{\lambda_x
\lambda_y}\left(1+\frac{D_x}{D_{x,1}}\right)\left(1+\frac{D_y}{D_{y,1}}\right)<1
\Rightarrow k_1 k_2 < \frac{\lambda_x\lambda_y}{20}
\end{equation}
Moreover, given that properties H\ref{hyp:locally_bound_uniform_f}--
H\ref{hyp:locally_bound_uniform_phi} hold for the chosen functions
$\psi_x(\mathbf{x},t)$, $\psi_y(\mathbf{y},t)$, condition
(\ref{eq:example_condition_boundedness}) guarantees that limiting relations (\ref{eq:convergence_psi_xy}),
(\ref{eq:convergence_f_xy}) hold.

Trajectories of the closed loop system
(\ref{eq:example_dec_model}), (\ref{eq:example_control}),
(\ref{eq:example_adaptation}) with the following values of parameters $\Gamma_x=\Gamma_y=1$, $\lambda_x=\lambda_y=2$,
$x_0=y_0=1$, $\theta_x=\theta_y=1$ and initial conditions
$x_1(0)=-1$, $x_2(0)=0$, $y_1(0)=1$, $y_2(0)=0$,
$\hat{\theta}_{x,I}(0)=-1$, $\hat{\theta}_{y,I}(0)=-2$ are provided in Fig. \ref{fig:decentralized:example}.

\begin{figure}
\begin{center}
\includegraphics[width=300pt]{example_decentralized.eps}
\end{center}
\begin{center}
\caption{Plots of trajectories $x_1(t)$ (panel a), $x_2(t)$ (panel b), $y_1(t)$ (panel c), $y_2(t)$ (panel d) as functions of $t$ in closed loop system (\ref{eq:example_dec_model}),
(\ref{eq:example_control}), (\ref{eq:example_adaptation}). Dotted lines correspond to the case when $k_1=k_2=0.4$, and solid lines stand for solutions obtained with the following values of coupling
$k_1=1$, $k_2=0.1$}\label{fig:decentralized:example}
\end{center}
\end{figure}

\section{Conclusion}

We provided new tools for the design and analysis of adaptive decentralized control schemes. Our method allows the desired dynamics to be Lyapunov unstable and the parametrization of the uncertainties to be nonlinear. The results are based on a formulation of the problem for adaptive control as a problem of regulation in functional spaces (in particular, $L_2^1[t_0,T]$
spaces) rather than of simply reaching of the control goal in
$\mathbb{R}^n$. This allows us to introduce adaptation algorithms with new properties and apply a small-gain argument to establish applicability of these schemes to the problem of decentralized control.

In order to avoid unnecessary complications, state feedback was assumed in the main-loop controllers which transform original equation into the error coupled model. Extension of the results to output-feedback main loop controllers is a topic for future study.

\section{Proofs of the theorems}

\subsection{Proof of Theorem \ref{stability_theorem}}

Let us first show that property P1) holds. Consider solutions of system (\ref{system1}), (\ref{error_model_d}),
(\ref{fin_forms_ours_tr1}), (\ref{fin_forms_ours_tr11}) passing through the point $\mathbf{x}(t_0)$, $\hat{{\boldsymbol{\theta}}}_I(t_0)$ for
$t\in[t_0,T^\ast]$
. Let us calculate the time-derivative of function
$\hat{{\boldsymbol{\theta}}}(\mathbf{x},t)$:
$\dot{\hat{{\boldsymbol{\theta}}}}(\mathbf{x},t)=\Gamma({\dot{\hat{{\boldsymbol{\theta}}}}_{P}}+\dot{\hat{\boldsymbol{\theta}}}_I)=\Gamma({\dot\psi}\boldsymbol{\alpha}(\mathbf{x},t)+\psi\dot{\boldsymbol{\alpha}}(\mathbf{x},t)-\dot{\Psi}(\mathbf{x},t)+\dot{\hat{\boldsymbol{\theta}}}_I)$.
Notice that
\begin{equation}\label{t2_1}
\begin{split}
&\psi\dot{\boldsymbol{\alpha}}(\mathbf{x},t)-\dot{\Psi}(\mathbf{x},t)+\dot{\hat{{\boldsymbol{\theta}}}}_I=\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} \mathbf{x}_1}\dot{\mathbf{x}}_1+\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x})}{{\partial} \mathbf{x}_2}\dot{\mathbf{x}}_2 +\\
& \psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} t}-
\frac{{\partial} \Psi(\mathbf{x},t)}{{\partial} \mathbf{x}_1}\dot{\mathbf{x}}_1-\frac{{\partial}
\Psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}\dot{\mathbf{x}}_2-\frac{{\partial} \Psi(\mathbf{x},t)}{{\partial} t}+\dot{\hat{\boldsymbol{\theta}}}_I
\end{split}
\end{equation}
According to Assumption \ref{assume:explicit_realizability},
$\frac{{\partial} \Psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}=\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} \mathbf{x}_2}
$. Then taking into account (\ref{t2_1}), we obtain
\begin{equation}\label{t2_2}
\begin{split}
&
\psi\dot{\boldsymbol{\alpha}}(\mathbf{x},t)-\dot{\Psi}(\mathbf{x},t)+\dot{\hat{{\boldsymbol{\theta}}}}_I=\left(\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} \mathbf{x}_1}-\frac{{\partial} \Psi}{{\partial} \mathbf{x}_1
}\right)\dot{\mathbf{x}}_1\\
&+\psi(\mathbf{x},t)\frac{{\partial} \boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} t}-\frac{\Psi(\mathbf{x},t)}{{\partial} t}
\end{split}
\end{equation}
Notice that according to the proposed notation we can rewrite the term $\left(\psi(\mathbf{x},t)\frac{{\partial} \boldsymbol{\alpha}(\mathbf{x},t)}{{\partial}
\mathbf{x}_1}-\frac{{\partial} \Psi}{{\partial} \mathbf{x}_1 }\right)\dot{\mathbf{x}}_1$ in the following form: $\psi(\mathbf{x},t)L_{\mathbf{f}_1}
\boldsymbol{\alpha}(\mathbf{x},t)-L_{\mathbf{f}_1} \Psi(\mathbf{x},t)+
\left(\psi(\mathbf{x},t)L_{\mathbf{g}_1} \boldsymbol{\alpha}(\mathbf{x},t)-L_{\mathbf{g}_1}
\Psi(\mathbf{x},t)\right)u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)$. Hence, it follows from (\ref{fin_forms_ours_tr1}) and (\ref{t2_2}) that
$\psi\dot{\boldsymbol{\alpha}}(\mathbf{x},t)-\dot{\Psi}(\mathbf{x},t)+\dot{\hat{{\boldsymbol{\theta}}}}_I=\varphi(\psi)\boldsymbol{\alpha}(\mathbf{x},t)
$. Therefore, the derivative $\dot{\hat{\boldsymbol{\theta}}}(\mathbf{x},t)$ can be written in the following way:
\begin{equation}\label{algorithm_dpsi}
\dot{\hat{{\boldsymbol{\theta}}}}=\Gamma({\dot\psi}+\varphi(\psi))\boldsymbol{\alpha}(\mathbf{x},t)
\end{equation}
Asymptotic properties of nonlinear parameterized control systems with adaptation algorithm (\ref{algorithm_dpsi}) under assumption of Lyapunov stability of the target dynamics were investigated in
\cite{tpt2003_tac}. In the present contribution we aim to provide characterizations of the closed loop system in terms of functional mappings between functions $\psi(\mathbf{x}(t),t)$, $\varepsilon(t)$,
and $f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)$ and without requiring Lyapunov stability of the target dynamics
(\ref{eq:target_dynamics}).


Categories: physics.gen-ph
Abstract: The evolution of Earth-Moon system is described by the dark matter field
fluid model proposed in the Meeting of Division of Particle and Field 2004,
American Physical Society. The current behavior of the Earth-Moon system agrees
with this model very well and the general pattern of the evolution of the
Moon-Earth system described by this model agrees with geological and fossil
evidence. The closest distance of the Moon to Earth was about 259000 km at 4.5
billion years ago, which is far beyond the Roche's limit. The result suggests
that the tidal friction may not be the primary cause for the evolution of the
Earth-Moon system. The average dark matter field fluid constant derived from
Earth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts
that the Mars's rotation is also slowing with the angular acceleration rate
about -4.38 x 10^(-22) rad s^(-2).

Categories: nlin.PS, physics.chem-ph, q-bio.MN
Abstract: Spatiotemporal pattern formation in a product-activated enzymic reaction at
high enzyme concentrations is investigated. Stochastic simulations show that
catalytic turnover cycles of individual enzymes can become coherent and that
complex wave patterns of molecular synchronization can develop. The analysis
based on the mean-field approximation indicates that the observed patterns
result from the presence of Hopf and wave bifurcations in the considered
system.

Categories: physics.optics, physics.comp-ph
Abstract: We performed a rigorous theoretical convergence analysis of the discrete
dipole approximation (DDA). We prove that errors in any measured quantity are
bounded by a sum of a linear and quadratic term in the size of a dipole d, when
the latter is in the range of DDA applicability. Moreover, the linear term is
significantly smaller for cubically than for non-cubically shaped scatterers.
Therefore, for small d errors for cubically shaped particles are much smaller
than for non-cubically shaped. The relative importance of the linear term
decreases with increasing size, hence convergence of DDA for large enough
scatterers is quadratic in the common range of d. Extensive numerical
simulations were carried out for a wide range of d. Finally we discuss a number
of new developments in DDA and their consequences for convergence.

Categories: physics.optics, physics.comp-ph
Abstract: We propose an extrapolation technique that allows accuracy improvement of the
discrete dipole approximation computations. The performance of this technique
was studied empirically based on extensive simulations for 5 test cases using
many different discretizations. The quality of the extrapolation improves with
refining discretization reaching extraordinary performance especially for
cubically shaped particles. A two order of magnitude decrease of error was
demonstrated. We also propose estimates of the extrapolation error, which were
proven to be reliable. Finally we propose a simple method to directly separate
shape and discretization errors and illustrated this for one test case.

Categories: physics.optics, physics.comp-ph
Abstract: In this manuscript we investigate the capabilities of the Discrete Dipole
Approximation (DDA) to simulate scattering from particles that are much larger
than the wavelength of the incident light, and describe an optimized publicly
available DDA computer program that processes the large number of dipoles
required for such simulations. Numerical simulations of light scattering by
spheres with size parameters x up to 160 and 40 for refractive index m=1.05 and
2 respectively are presented and compared with exact results of the Mie theory.
Errors of both integral and angle-resolved scattering quantities generally
increase with m and show no systematic dependence on x. Computational times
increase steeply with both x and m, reaching values of more than 2 weeks on a
cluster of 64 processors. The main distinctive feature of the computer program
is the ability to parallelize a single DDA simulation over a cluster of
computers, which allows it to simulate light scattering by very large
particles, like the ones that are considered in this manuscript. Current
limitations and possible ways for improvement are discussed.

Categories: physics.optics, physics.comp-ph
Abstract: We present a review of the discrete dipole approximation (DDA), which is a
general method to simulate light scattering by arbitrarily shaped particles. We
put the method in historical context and discuss recent developments, taking
the viewpoint of a general framework based on the integral equations for the
electric field. We review both the theory of the DDA and its numerical aspects,
the latter being of critical importance for any practical application of the
method. Finally, the position of the DDA among other methods of light
scattering simulation is shown and possible future developments are discussed.

Categories: physics.gen-ph, quant-ph
Abstract: It is outlined the possibility to extend the quantum formalism in relation to
the requirements of the general systems theory. It can be done by using a
quantum semantics arising from the deep logical structure of quantum theory. It
is so possible taking into account the logical openness relationship between
observer and system. We are going to show how considering the truth-values of
quantum propositions within the context of the fuzzy sets is here more useful
for systemics . In conclusion we propose an example of formal quantum
coherence.

Categories: astro-ph, nlin.CD, physics.plasm-ph, physics.space-ph
Abstract: We present a theoretical framework for plasma turbulence in astrophysical
plasmas (solar wind, interstellar medium, galaxy clusters, accretion disks).
The key assumptions are that the turbulence is anisotropic with respect to the
mean magnetic field and frequencies are low compared to the ion cyclotron
frequency. The energy injected at the outer scale scale has to be converted
into heat, which ultimately cannot be done without collisions. A KINETIC
CASCADE develops that brings the energy to collisional scales both in space and
velocity. Its nature depends on the physics of plasma fluctuations. In each of
the physically distinct scale ranges, the kinetic problem is systematically
reduced to a more tractable set of equations. In the "inertial range" above the
ion gyroscale, the kinetic cascade splits into a cascade of Alfvenic
fluctuations, which are governed by the RMHD equations at both the collisional
and collisionless scales, and a passive cascade of compressive fluctuations,
which obey a linear kinetic equation along the moving field lines associated
with the Alfvenic component. In the "dissipation range" between the ion and
electron gyroscales, there are again two cascades: the kinetic-Alfven-wave
(KAW) cascade governed by two fluid-like Electron RMHD equations and a passive
phase-space cascade of ion entropy fluctuations. The latter cascade brings the
energy of the inertial-range fluctuations that was damped by collisionless
wave-particle interaction at the ion gyroscale to collisional scales in the
phase space and leads to ion heating. The KAW energy is similarly damped at the
electron gyroscale and converted into electron heat. Kolmogorov-style scaling
relations are derived for these cascades. Astrophysical and space-physical
applications are discussed in detail.

Categories: physics.ed-ph, quant-ph
Abstract: A novel way of picturing the processing of quantum information is described,
allowing a direct visualization of teleportation of quantum states and
providing a simple and intuitive understanding of this fascinating phenomenon.
The discussion is aimed at providing physicists a method of explaining
teleportation to non-scientists. The basic ideas of quantum physics are first
explained in lay terms, after which these ideas are used with a graphical
description, out of which teleportation arises naturally.

Categories: physics.pop-ph
Abstract: I shall present three arguments for the proposition that intelligent life is
very rare in the universe. First, I shall summarize the consensus opinion of
the founders of the Modern Synthesis (Simpson, Dobzhanski, and Mayr) that the
evolution of intelligent life is exceedingly improbable. Second, I shall
develop the Fermi Paradox: if they existed they'd be here. Third, I shall show
that if intelligent life were too common, it would use up all available
resources and die out. But I shall show that the quantum mechanical principle
of unitarity (actually a form of teleology!) requires intelligent life to
survive to the end of time. Finally, I shall argue that, if the universe is
indeed accelerating, then survival to the end of time requires that intelligent
life, though rare, to have evolved several times in the visible universe. I
shall argue that the acceleration is a consequence of the excess of matter over
antimatter in the universe. I shall suggest experiments to test these claims.

Categories: physics.soc-ph
Abstract: No abstract given; compares pairs of languages from World Atlas of Language
Structures.

Categories: physics.gen-ph
Abstract: The Dark Energy problem is forcing us to re-examine our models and our
understanding of relativity and space-time. Here a novel idea of Fundamental
Forces is introduced. This allows us to perceive the General Theory of
Relativity and Einstein's Equation from a new pesrpective. In addition to
providing us with an improved understanding of space and time, it will be shown
how it leads to a resolution of the Dark Energy problem.

Categories: cond-mat.soft, nlin.PS, physics.flu-dyn
Abstract: We employ granular hydrodynamics to investigate a paradigmatic problem of
clustering of particles in a freely cooling dilute granular gas. We consider
large-scale hydrodynamic motions where the viscosity and heat conduction can be
neglected, and one arrives at the equations of ideal gas dynamics with an
additional term describing bulk energy losses due to inelastic collisions. We
employ Lagrangian coordinates and derive a broad family of exact non-stationary
analytical solutions that depend only on one spatial coordinate. These
solutions exhibit a new type of singularity, where the gas density blows up in
a finite time when starting from smooth initial conditions. The density blowups
signal formation of close-packed clusters of particles. As the density blow-up
time $t_c$ is approached, the maximum density exhibits a power law $\sim
(t_c-t)^{-2}$. The velocity gradient blows up as $\sim - (t_c-t)^{-1}$ while
the velocity itself remains continuous and develops a cusp (rather than a shock
discontinuity) at the singularity. The gas temperature vanishes at the
singularity, and the singularity follows the isobaric scenario: the gas
pressure remains finite and approximately uniform in space and constant in time
close to the singularity. An additional exact solution shows that the density
blowup, of the same type, may coexist with an "ordinary" shock, at which the
hydrodynamic fields are discontinuous but finite. We confirm stability of the
exact solutions with respect to small one-dimensional perturbations by solving
the ideal hydrodynamic equations numerically. Furthermore, numerical solutions
show that the local features of the density blowup hold universally,
independently of details of the initial and boundary conditions.

Categories: physics.optics
Abstract: The results of the spectral, energetical and temporal characteristics of
radiation in the presence of the photonic flame effect are presented.
Artificial opal posed on Cu plate at the temperature of liquid nitrogen boiling
point (77 K) being irradiated by nanosecond ruby laser pulse produces long-
term luminiscence with a duration till ten seconds with a finely structured
spectrum in the the antistocks part of the spectrum. Analogous visible
luminescence manifesting time delay appeared in other samples of the artificial
opals posed on the same plate. In the case of the opal infiltrated with
different nonlinear liquids the threshold of the luminiscence is reduced and
the spatial disribution of the bright emmiting area on the opal surface is
being changed. In the case of the putting the frozen nonlinear liquids on the
Cu plate long-term blue bright luminiscence took place in the frozen species of
the liquids. Temporal characteristics of this luminiscence are nearly the same
as in opal matrixes.

Categories: physics.data-an, physics.gen-ph
Abstract: Statistical modeling of experimental physical laws is based on the
probability density function of measured variables. It is expressed by
experimental data via a kernel estimator. The kernel is determined objectively
by the scattering of data during calibration of experimental setup. A physical
law, which relates measured variables, is optimally extracted from experimental
data by the conditional average estimator. It is derived directly from the
kernel estimator and corresponds to a general nonparametric regression. The
proposed method is demonstrated by the modeling of a return map of noisy
chaotic data. In this example, the nonparametric regression is used to predict
a future value of chaotic time series from the present one. The mean predictor
error is used in the definition of predictor quality, while the redundancy is
expressed by the mean square distance between data points. Both statistics are
used in a new definition of predictor cost function. From the minimum of the
predictor cost function, a proper number of data in the model is estimated.

Categories: cs.CE, cond-mat.stat-mech, cs.MS, cs.NA, physics.data-an
Abstract: Real Options for Project Schedules (ROPS) has three recursive
sampling/optimization shells. An outer Adaptive Simulated Annealing (ASA)
optimization shell optimizes parameters of strategic Plans containing multiple
Projects containing ordered Tasks. A middle shell samples probability
distributions of durations of Tasks. An inner shell samples probability
distributions of costs of Tasks. PATHTREE is used to develop options on
schedules.. Algorithms used for Trading in Risk Dimensions (TRD) are applied to
develop a relative risk analysis among projects.

Categories: physics.data-an
Abstract: A physical law is represented by the probability distribution of a measured
variable. The probability density is described by measured data using an
estimator whose kernel is the instrument scattering function. The experimental
information and data redundancy are defined in terms of information entropy.
The model cost function, comprised of data redundancy and estimation error, is
minimized by the creation-annihilation process.

Categories: nlin.CD, cond-mat.other, physics.optics
Abstract: The microwave phonon stimulated emission (SE) has been experimentally and
numerically investigated in a nonautonomous microwave acoustic quantum
generator, called also microwave phonon laser or phaser (see previous works
arXiv:cond-mat/0303188 ; arXiv:cond-mat/0402640 ; arXiv:nlin.CG/0703050)
Phenomena of branching and long-time refractority (absence of the reaction on
the external pulses) for deterministic chaotic and regular processes of SE were
observed in experiments with various levels of electromagnetic pumping. At the
pumping level growth, the clearly depined increasing of the number of
coexisting SE states has been observed both in real physical experiments and in
computer simulations. This confirms the analytical estimations of the branching
density in the phase space. The nature of the refractority of SE pulses is
closely connected with the pointed branching and reflects the crises of strange
attractors, i.e. their collisions with unstable periodic components of the
higher branches of SE states in the nonautonomous microwave phonon laser.

Categories: physics.gen-ph
Abstract: Based on overall experimental observations, especially the pair processes, I
developed a model structure of the vacuum along with a basic-particle formation
scheme begun in 2000 (with collaborator P-I Johansson). The model consists in
that the vacuum is, briefly, filled of neutral but polarizable vacuuons,
consisting each of a p-vaculeon and n- vaculeon of charges $+e$ and $-e$ of
zero rest masses but with spin motions, assumed interacting each other with a
Coulomb force. The model has been introduced in full in a book (Nova Sci, 2005)
and referred to in a number of journal/E-print papers. I outline in this easier
accessible paper the detailed derivation of the model and a corresponding
quantitative determination of the vacuuon size.

Categories: physics.gen-ph
Abstract: The 32-dimensional compounding fields and their quantum interplays in the
trigintaduonion space can be presented by analogy with octonion and sedenion
electromagnetic, gravitational, strong and weak interactions. In the
trigintaduonion fields which are associated with the electromagnetic,
gravitational, strong and weak interactions, the study deduces some conclusions
of field source particles (quarks and leptons) and intermediate particles which
are consistent with current some sorts of interaction theories. In the
trigintaduonion fields which are associated with the hyper-strong and
strong-weak fields, the paper draws some predicts and conclusions of the field
source particles (sub-quarks) and intermediate particles. The research results
show that there may exist some new particles in the nature.

Categories: physics.optics, physics.class-ph, quant-ph
Abstract: Statistical ensemble formalism of Kim, Mandel and Wolf (J. Opt. Soc. Am. A 4,
433 (1987)) offers a realistic model for characterizing the effect of
stochastic non-image forming optical media on the state of polarization of
transmittedlight. With suitable choice of the Jones ensemble, various Mueller
transformations - some of which have been unknown so far - are deduced. It is
observed that the ensemble approach is formally identical to the positive
operator valued measures (POVM) on the quantum density matrix. This
observation, in combination with the recent suggestion by Ahnert and Payne
(Phys. Rev. A 71, 012330, (2005)) - in the context of generalized quantum
measurement on single photon polarization states - that linear optics elements
can be employed in setting up all possible POVMs, enables us to propose a way
of realizing different types of Mueller devices.

Categories: physics.data-an, physics.comp-ph
Abstract: The extraction of a physical law y=yo(x) from joint experimental data about x
and y is treated. The joint, the marginal and the conditional probability
density functions (PDF) are expressed by given data over an estimator whose
kernel is the instrument scattering function. As an optimal estimator of yo(x)
the conditional average is proposed. The analysis of its properties is based
upon a new definition of prediction quality. The joint experimental information
and the redundancy of joint measurements are expressed by the relative entropy.
With the number of experiments the redundancy on average increases, while the
experimental information converges to a certain limit value. The difference
between this limit value and the experimental information at a finite number of
data represents the discrepancy between the experimentally determined and the
true properties of the phenomenon. The sum of the discrepancy measure and the
redundancy is utilized as a cost function. By its minimum a reasonable number
of data for the extraction of the law yo(x) is specified. The mutual
information is defined by the marginal and the conditional PDFs of the
variables. The ratio between mutual information and marginal information is
used to indicate which variable is the independent one. The properties of the
introduced statistics are demonstrated on deterministically and randomly
related variables.

Categories: physics.gen-ph
Abstract: Classical oscillator differential equation is replaced by the corresponding
(finite time) difference equation. The equation is, then, symmetrized so that
it remains invariant under the change d going to -d, where d is the smallest
span of time. This symmetric equation has solutions, which come in reciprocally
related pairs. One member of a pair agrees with the classical solution and the
other is an oscillating solution and does not converge to a limit as d goes to
0. This solution contributes to oscillator energy a term which is a multiple of
half-integers.

Categories: cond-mat.stat-mech, cond-mat.soft, physics.chem-ph
Abstract: An overview of some analytical approaches to the computation of the
structural and thermodynamic properties of single component and multicomponent
hard-sphere fluids is provided. For the structural properties, they yield a
thermodynamically consistent formulation, thus improving and extending the
known analytical results of the Percus-Yevick theory. Approximate expressions
for the contact values of the radial distribution functions and the
corresponding analytical equations of state are also discussed. Extensions of
this methodology to related systems, such as sticky hard spheres and
square-well fluids, as well as its use in connection with the perturbation
theory of fluids are briefly addressed.

Categories: physics.data-an, physics.comp-ph
Abstract: Redundancy of experimental data is the basic statistic from which the
complexity of a natural phenomenon and the proper number of experiments needed
for its exploration can be estimated. The redundancy is expressed by the
entropy of information pertaining to the probability density function of
experimental variables. Since the calculation of entropy is inconvenient due to
integration over a range of variables, an approximate expression for redundancy
is derived that includes only a sum over the set of experimental data about
these variables. The approximation makes feasible an efficient estimation of
the redundancy of data along with the related experimental information and
information cost function. From the experimental information the complexity of
the phenomenon can be simply estimated, while the proper number of experiments
needed for its exploration can be determined from the minimum of the cost
function. The performance of the approximate estimation of these statistics is
demonstrated on two-dimensional normally distributed random data.

Categories: physics.optics
Abstract: Using the recently reported mode locking effect we demonstrate a highly
robust control of electron spin coherence in an ensemble of (In,Ga)As quantum
dots during the single spin coherence time. The spin precession in a transverse
magnetic field can be fully controlled up to 25 K by the parameters of the
exciting pulsed laser protocol such as the pulse train sequence, leading to
adjustable quantum beat bursts in Faraday rotation. Flipping of the electron
spin precession phase was demonstrated by inverting the polarization within a
pulse doublet sequence.

Categories: physics.plasm-ph
Abstract: We calculate the equation of state of dense hydrogen within the chemical
picture. Fluid variational theory is generalized for a multi-component system
of molecules, atoms, electrons, and protons. Chemical equilibrium is supposed
for the reactions dissociation and ionization. We identify the region of
thermodynamic instability which is related to the plasma phase transition. The
reflectivity is calculated along the Hugoniot curve and compared with
experimental results. The equation-of-state data is used to calculate the
pressure and temperature profiles for the interior of Jupiter.

Categories: physics.optics, physics.comp-ph
Abstract: We investigate the use of a Genetic Algorithm (GA) to design a set of
photonic crystals (PCs) in one and two dimensions. Our flexible design
methodology allows us to optimize PC structures which are optimized for
specific objectives. In this paper, we report the results of several such
GA-based PC optimizations. We show that the GA performs well even in very
complex design spaces, and therefore has great potential for use as a robust
design tool in present and future applications.

Categories: physics.bio-ph, physics.data-an, q-bio.BM
Abstract: A number of recently discovered protein structures incorporate a rather
unexpected structural feature: a knot in the polypeptide backbone. These knots
are extremely rare, but their occurrence is likely connected to protein
function in as yet unexplored fashion. Our analysis of the complete Protein
Data Bank reveals several new knots which, along with previously discovered
ones, can shed light on such connections. In particular, we identify the most
complex knot discovered to date in human ubiquitin hydrolase, and suggest that
its entangled topology protects it against unfolding and degradation by the
proteasome. Knots in proteins are typically preserved across species and
sometimes even across kingdoms. However, we also identify a knot which only
appears in some transcarbamylases while being absent in homologous proteins of
similar structure. The emergence of the knot is accompanied by a shift in the
enzymatic function of the protein. We suggest that the simple insertion of a
short DNA fragment into the gene may suffice to turn an unknotted into a
knotted structure in this protein.

Categories: physics.optics
Abstract: We theoretically investigate the possibility of observing resonant activation
in the hopping dynamics of two-mode semiconductor lasers. We present a series
of simulations of a rate-equations model under random and periodic modulation
of the bias current. In both cases, for an optimal choice of the modulation
time-scale, the hopping times between the stable lasing modes attain a minimum.
The simulation data are understood by means of an effective one-dimensional
Langevin equation with multiplicative fluctuations. Our conclusions apply to
both Edge Emitting and Vertical Cavity Lasers, thus opening the way to several
experimental tests in such optical systems.

Categories: physics.optics, math-ph, math.MP
Abstract: There is currently a great deal of interest in the theoretical and practical
possibility of cloaking objects from the observation by electromagnetic waves.
The basic idea of these invisibility devices \cite{glu1, glu2, le},\cite{pss1}
is to use anisotropic {\it transformation media} whose permittivity and
permeability $\var^{\lambda\nu}, \mu^{\lambda\nu}$, are obtained from the ones,
$\var_0^{\lambda\nu}, \mu^{\lambda\nu}_0$, of isotropic media, by singular
transformations of coordinates. In this paper we study electromagnetic cloaking
in the time-domain using the formalism of time-dependent scattering theory.
This formalism allows us to settle in an unambiguous way the mathematical
problems posed by the singularities of the inverse of the permittivity and the
permeability of the {\it transformation media} on the boundary of the cloaked
objects. We write Maxwell's equations in Schr\"odinger form with the
electromagnetic propagator playing the role of the Hamiltonian. We prove that
the electromagnetic propagator outside of the cloaked objects is essentially
self-adjoint. Moreover, the unique self-adjoint extension is unitarily
equivalent to the electromagnetic propagator in the medium
$\var_0^{\lambda\nu}, \mu^{\lambda\nu}_0$. Using this fact, and since the
coordinate transformation is the identity outside of a ball, we prove that the
scattering operator is the identity. Our results give a rigorous proof that the
construction of \cite{glu1, glu2, le}, \cite{pss1} perfectly cloaks passive and
active devices from observation by electromagnetic waves. Furthermore, we prove
cloaking for general anisotropic materials. In particular, our results prove
that it is possible to cloak objects inside general crystals.

Categories: physics.flu-dyn, physics.plasm-ph
Abstract: We study material lines and passive vectors in a model of turbulent flow at
infinite-Reynolds number, the Kraichnan-Kazantsev ensemble of velocities that
are white-noise in time and rough (Hoelder continuous) in space. It is argued
that the phenomenon of ``spontaneous stochasticity'' generalizes to material
lines and that conservation of circulations generalizes to a ``martingale
property'' of the stochastic process of lines.

Categories: physics.comp-ph
Abstract: We present a new version of TaylUR, a Fortran 95 module to automatically
compute the numerical values of a complex-valued function's derivatives with
respect to several variables up to an arbitrary order in each variable, but
excluding mixed derivatives. The new version fixes a potentially serious bug in
the code for exponential-related functions that could corrupt the imaginary
parts of derivatives, as well as being compatible with a wider range of
compilers.

Categories: physics.atom-ph, cond-mat.other
Abstract: We present experimental and theoretical results showing the improved beam
quality and reduced divergence of an atom laser produced by an optical Raman
transition, compared to one produced by an RF transition. We show that Raman
outcoupling can eliminate the diverging lens effect that the condensate has on
the outcoupled atoms. This substantially improves the beam quality of the atom
laser, and the improvement may be greater than a factor of ten for experiments
with tight trapping potentials. We show that Raman outcoupling can produce atom
lasers whose quality is only limited by the wavefunction shape of the
condensate that produces them, typically a factor of 1.3 above the Heisenberg
limit.

Categories: astro-ph, physics.ao-ph
Abstract: Air fluorescence detectors measure the energy of ultra-high energy cosmic
rays by collecting fluorescence light emitted from nitrogen molecules along the
extensive air shower cascade. To ensure a reliable energy determination, the
light signal needs to be corrected for atmospheric effects, which not only
attenuate the signal, but also produce a non-negligible background component
due to scattered Cherenkov light and multiple-scattered light. The correction
requires regular measurements of the aerosol attenuation length and the aerosol
phase function, defined as the probability of light scattered in a given
direction. At the Pierre Auger Observatory in Malargue, Argentina, the phase
function is measured on an hourly basis using two Aerosol Phase Function (APF)
light sources. These sources direct a UV light beam across the field of view of
the fluorescence detectors; the phase function can be extracted from the image
of the shots in the fluorescence detector cameras. This paper describes the
design, current status, standard operation procedure, and performance of the
APF system at the Pierre Auger Observatory.

Categories: physics.bio-ph
Abstract: We present a model for the spontaneous formation of a striated pattern in
polymerizing microtubule solutions. It describes the buckling of a single
microtubule (MT) bundle within an elastic network formed by other similarly
aligned and buckling bundles and unaligned MTs. Phase contrast and polarization
microscopy studies of the temporal evolution of the pattern imply that the
polymerization of MTs within the bundles creates the driving compressional
force. Using the measured rate of buckling, the established MT force-velocity
curve and the pattern wavelength, we obtain reasonable estimates for the MT
bundle bending rigidity and the elastic constant of the network. The analysis
implies that the bundles buckle as solid rods.

Categories: physics.soc-ph
Abstract: The ever-increasing knowledge of the structure of various real-world networks
has uncovered their complex multi-mechanism-governed evolution processes.
Therefore, a better understanding of the structure and evolution of these
networked complex systems requires us to describe such processes in a more
detailed and realistic manner. In this paper, we introduce a new type of
network growth rule which comprises addition and deletion of nodes, and propose
an evolving network model to investigate the effect of node deleting on network
structure. It is found that, with the introduction of node deleting, network
structure is significantly transformed. In particular, degree distribution of
the network undergoes a transition from scale-free to exponential forms as the
intensity of node deleting increases. At the same time, nontrivial
disassortative degree correlation develops spontaneously as a natural result of
network evolution in the model. We also demonstrate that node deleting
introduced in the model does not destroy the connectedness of a growing network
so long as the increasing rate of edges is not excessively small. In addition,
it is found that node deleting will weaken but not eliminate the small-world
effect of a growing network, and generally it will decrease the clustering
coefficient in a network.

Categories: cond-mat.stat-mech, physics.ins-det
Abstract: We report on measurements of the transverse fluctuations of a string in a
turbulent air jet flow. Harmonic modes are excited by the fluctuating drag
force, at different wave-numbers. This simple mechanical probe makes it
possible to measure excitations of the flow at specific scales, averaged over
space and time: it is a scale-resolved, global measurement. We also measure the
dissipation associated to the string motion, and we consider the ratio of the
fluctuations over dissipation (FDR). In an exploratory approach, we investigate
the concept of {\it effective temperature} defined through the FDR. We compare
our observations with other definitions of temperature in turbulence. From the
theory of Kolmogorov (1941), we derive the exponent -11/3 expected for the
spectrum of the fluctuations. This simple model and our experimental results
are in good agreement, over the range of wave-numbers, and Reynolds number
accessible ($74000 \leq Re \leq 170000$).

Categories: physics.chem-ph
Abstract: In line with the local philicity concept proposed by Chattaraj et al.
(Chattaraj, P. K.; Maiti, B.; Sarkar, U. J. Phys. Chem. A. 2003, 107, 4973) and
a dual descriptor derived by Toro-Labbe and coworkers (Morell, C.; Grand, A.;
Toro-Labbe, A. J. Phys. Chem. A. 2005, 109, 205), we propose a multiphilic
descriptor. It is defined as the difference between nucleophilic (Wk+) and
electrophilic (Wk-) condensed philicity functions. This descriptor is capable
of simultaneously explaining the nucleophilicity and electrophilicity of the
given atomic sites in the molecule. Variation of these quantities along the
path of a soft reaction is also analyzed. Predictive ability of this descriptor
has been successfully tested on the selected systems and reactions.
Corresponding force profiles are also analyzed in some representative cases.
Also, to study the intra- and intermolecular reactivities another related
descriptor namely, the nucleophilicity excess (DelW-+) for a nucleophile, over
the electrophilicity in it has been defined and tested on all-metal aromatic
compounds.

Categories: physics.flu-dyn, physics.comp-ph
Abstract: In spite of the large number of papers appeared in the past which are devoted
to the lattice Boltzmann (LB) methods, basic aspects of the theory still remain
unchallenged. An unsolved theoretical issue is related to the construction of a
discrete kinetic theory which yields \textit{exactly} the fluid equations,
i.e., is non-asymptotic (here denoted as \textit{LB inverse kinetic theory}).
The purpose of this paper is theoretical and aims at developing an inverse
kinetic approach of this type. In principle infinite solutions exist to this
problem but the freedom can be exploited in order to meet important
requirements. In particular, the discrete kinetic theory can be defined so that
it yields exactly the fluid equation also for arbitrary non-equilibrium (but
suitably smooth) kinetic distribution functions and arbitrarily close to the
boundary of the fluid domain. Unlike previous entropic LB methods the theorem
can be obtained without functional constraints on the class of the initial
distribution functions. Possible realizations of the theory and asymptotic
approximations are provided which permit to determine the fluid equations
\textit{with prescribed accuracy.} As a result, asymptotic accuracy estimates
of customary LB approaches and comparisons with the Chorin artificial
compressibility method are discussed.

Categories: physics.soc-ph
Abstract: We study numerically the cascading failure problem by using artificially
created scale-free networks and the real network structure of the power grid.
The capacity for a vertex is assigned as a monotonically increasing function of
the load (or the betweenness centrality). Through the use of a simple
functional form with two free parameters, revealed is that it is indeed
possible to make networks more robust while spending less cost. We suggest that
our method to prevent cascade by protecting less vertices is particularly
important for the design of more robust real-world networks to cascading
failures.

Categories: physics.gen-ph
Abstract: Ponderable objects moving in free space according to Newton's First Law
constitute both rulers and clocks when one such object is viewed from the rest
frame of another. Together with the Reciprocity Principle this is used to
demonstrate, in both Galilean and special relativity, the invariance of the
measured length of a ruler in motion. The different times: `proper', `improper'
and `apparent' appearing in different formulations of the relativistic time
dilatation relation are discussed and exemplified by experimental applications.
A non-intuitive `length expansion' effect predicted by the Reciprocity
Principle as a necessary consequence of time dilatation is pointed out

Categories: physics.geo-ph
Abstract: This paper has been withdrawn due to copyright reasons.

Categories: physics.chem-ph
Abstract: The structure of three laminar premixed rich flames has been investigated: a
pure methane flame and two methane flames doped by allene and propyne,
respectively. The gases of the three flames contain 20.9% (molar) of methane
and 33.4% of oxygen, corresponding to an equivalence ratio of 1.25 for the pure
methane flame. In both doped flames, 2.49% of C3H4 was added, corresponding to
a ratio C3H4/CH4 of 12% and an equivalence ratio of 1.55. The three flames have
been stabilized on a burner at a pressure of 6.7 kPa using argon as dilutant,
with a gas velocity at the burner of 36 cm/s at 333 K. The concentration
profiles of stable species were measured by gas chromatography after sampling
with a quartz microprobe. Quantified species included carbon monoxide and
dioxide, methane, oxygen, hydrogen, ethane, ethylene, acetylene, propyne,
allene, propene, propane, 1,2-butadiene, 1,3-butadiene, 1-butene, isobutene,
1-butyne, vinylacetylene, and benzene. The temperature was measured using a
PtRh (6%)-PtRh (30%) thermocouple settled inside the enclosure and ranged from
700 K close to the burner up to 1850 K. In order to model these new results,
some improvements have been made to a mechanism previously developed in our
laboratory for the reactions of C3-C4 unsaturated hydrocarbons. The main
reaction pathways of consumption of allene and propyne and of formation of C6
aromatic species have been derived from flow rate analyses.

Categories: q-bio.NC, cond-mat.dis-nn, physics.soc-ph
Abstract: Structure entails function and thus a structural description of the brain
will help to understand its function and may provide insights into many
properties of brain systems, from their robustness and recovery from damage, to
their dynamics and even their evolution. Advances in the analysis of complex
networks provide useful new approaches to understanding structural and
functional properties of brain networks. Structural properties of networks
recently described allow their characterization as small-world, random
(exponential) and scale-free. They complement the set of other properties that
have been explored in the context of brain connectivity, such as topology,
hodology, clustering, and hierarchical organization. Here we apply new network
analysis methods to cortical inter-areal connectivity networks for the cat and
macaque brains. We compare these corticocortical fibre networks to benchmark
rewired, small-world, scale-free and random networks, using two analysis
strategies, in which we measure the effects of the removal of nodes and
connections on the structural properties of the cortical networks. The brain
networks' structural decay is in most respects similar to that of scale-free
networks. The results implicate highly connected hub-nodes and bottleneck
connections as structural basis for some of the conditional robustness of brain
systems. This informs the understanding of the development of brain networks'
connectivity.

Categories: quant-ph, hep-th, nlin.CD, physics.atom-ph, physics.chem-ph
Abstract: We present an analytic example of two dimensional quantum mechanical system,
where the exponential suppression of the probability of over-barrier reflection
changes non-monotonically with energy. The suppression is minimal at certain
"optimal" energies where reflection occurs with exponentially larger
probability than at other energies.

Categories: physics.optics
Abstract: Using complex plane analysis we show that left-handed slab may support either
leaky slab waves, which are backward because of negative refraction, or leaky
surface waves, which are backward or forward depending on the propagation
direction of the surface wave itself. Moreover, there is a general connection
between the reflection coefficient of the left-handed slab and the one of the
corresponding right-handed slab (with opposite permittivity and permeability)
so that leaky slab modes are excited for the same angle of incidence of the
impinging beam for both structures. Many negative giant lateral shifts can be
explained by the excitation of these leaky modes.

Categories: physics.optics
Abstract: We experimentally demonstrate controlled polarization-selective phenomena in
a whispering gallery mode resonator. We observed efficient ($\approx 75 %$)
polarization conversion of light in a silica microsphere coupled to a tapered
optical fiber with proper optimization of the polarization of the propagating
light. A simple model treating the microsphere as a ring resonator provides a
good fit to the observed behavior.

Categories: physics.chem-ph, physics.flu-dyn
Abstract: We report a new effect of surfactants in pinning a drop contact line,
specifically that lysozyme promotes while lauryl sulfate inhibits pinning. We
explain the pinning disparity assuming difference in wetting: the protein-laden
drop wets a "clean" surface and the surfactant-laden drop wets an
auto-precursored surface.

Categories: physics.gen-ph
Abstract: How to effectively solve the eigen solutions of the nonlinear spinor field
equation coupling with some other interaction fields is important to understand
the behavior of the elementary particles. In this paper, we derive a simplified
form of the eigen equation of the nonlinear spinor, and then propose a scheme
to solve their numerical solutions. This simplified equation has elegant and
neat structure, which is more convenient for both theoretical analysis and
numerical computation.

Categories: physics.optics, physics.gen-ph, quant-ph
Abstract: We show that two distinct quantum states of the electromagnetic field can be
associated to a classical vector X wave or a propagation-invariant solution of
Maxwell equations. The difference between the two states is of pure quantum
mechanical origin since they are internally entangled and disentangled,
respectively and can be generated by different linear or nonlinear processes.
Detection and generation of Schr\"odinger-cat states comprising two entangled
X-waves and their possible applications are discussed.

Categories: physics.ed-ph, physics.gen-ph
Abstract: We measured the correlation of the times between successive flaps of a flag
for a variety of wind speeds and found no evidence of low dimensional chaotic
behavior in the return maps of these times. We instead observed what is best
modeled as random times determined by an exponential distribution. This study
was done as an undergraduate experiment and illustrates the differences between
low dimensional chaotic and possibly higher dimensional chaotic systems.

Categories: physics.gen-ph
Abstract: Because observations of galaxies and clusters have been found inconsistent
with General Relativity (GR), the focus of effort in developing a Scalar
Potential Model (SPM) has been on the examination of galaxies and clusters. The
SPM has been found to be consistent with cluster cellular structure, the flow
of IGM from spiral galaxies to elliptical galaxies, intergalactic redshift
without an expanding universe, discrete redshift, rotation curve (RC) data
without dark matter, asymmetric RCs, galaxy central mass, galaxy central
velocity dispersion, and the Pioneer Anomaly. In addition, the SPM suggests a
model of past expansion, past contraction, and current expansion of the
universe. GR corresponds to the SPM in the limit in which the effect of the
Sources and Sinks approximate a flat scalar potential field such as between
clusters and on the solar system scale, which is small relative to the distance
to a Source.

Categories: quant-ph, cond-mat.other, physics.atom-ph
Abstract: In this paper we investigate some entanglement properties for the Hydrogen
molecule considered as a two interacting spin 1/2 (qubit) model. The
entanglement related to the $H_{2}$ molecule is evaluated both using the von
Neumann entropy and the Concurrence and it is compared with the corresponding
quantities for the two interacting spin system. Many aspects of these functions
are examinated employing in part analytical and, essentially, numerical
techniques. We have compared analogous results obtained by Huang and Kais a few
years ago. In this respect, some possible controversial situations are
presented and discussed.

Categories: physics.soc-ph
Abstract: Useful information about scientific collaboration structures and patterns can
be inferred from computer databases of published papers. The genetic
programming bibliography is the most complete reference of papers on GP\@. In
addition to locating publications, it contains coauthor and coeditor
relationships from which a more complete picture of the field emerges. We treat
these relationships as undirected small world graphs whose study reveals the
community structure of the GP collaborative social network. Automatic analysis
discovers new communities and highlights new facets of them. The investigation
reveals many similarities between GP and coauthorship networks in other
scientific fields but also some subtle differences such as a smaller central
network component and a high clustering.

Categories: physics.comp-ph, physics.chem-ph
Abstract: During a crossover via a switching mechanism from one 2-body potential to
another as might be applied in modeling (chemical) reactions in the vicinity of
bond formation, energy violations would occur due to finite step size which
determines the trajectory of the particles relative to the potential
interactions of the unbonded state by numerical (e.g. Verlet) integration. This
problem is overcome by an algorithm which preserves the coordinates of the
system for each move, but corrects for energy discrepancies by ensuring both
energy and momentum conservation in the dynamics. The algorithm is tested for a
hysteresis loop reaction model with an without the implementation of the
algorithm. The tests involve checking the rate of energy flow out of the MD
simulation box; in the equilibrium state, no net rate of flows within
experimental error should be observed. The temperature and pressure of the box
should also be invariant within the range of fluctuation of these quantities.
It is demonstrated that the algorithm satisfies these criteria.

Categories: physics.atom-ph, physics.gen-ph
Abstract: An overview is presented of laser spectroscopy experiments with cold,
trapped, highly-charged ions, which will be performed at the HITRAP facility at
GSI in Darmstadt (Germany). These high-resolution measurements of ground state
hyperfine splittings will be three orders of magnitude more precise than
previous measurements. Moreover, from a comparison of measurements of the
hyperfine splittings in hydrogen- and lithium-like ions of the same isotope,
QED effects at high electromagnetic fields can be determined within a few
percent. Several candidate ions suited for these laser spectroscopy studies are
presented.

Categories: physics.optics
Abstract: A new method, FM-FTS, combining Frequency Modulation heterodyne laser
spectroscopy and Fourier Transform Spectroscopy is presented. It provides
simultaneous sensitive measurement of absorption and dispersion profiles with
broadband spectral coverage capabilities. Experimental demonstration is made on
the overtone spectrum of C2H2 in the 1.5 $\mu$m region.

Categories: physics.gen-ph
Abstract: In the last years the traditional scenario of Big Bang has been deeply
modified by the study of the quantum features of the Universe evolution,
proposing again the problem of using local physical laws on cosmic scale, with
particular regard to the cosmological constant role. The group extention method
shows that the De Sitter group univocally generalizes the Poincare group,
formally justifies the cosmological constant use and suggests a new
interpretation for Hartle-Hawking boundary conditions in Quantum Cosmology.

Categories: physics.class-ph
Abstract: We discuss an alternative non-perturbative proof of Bertrand's theorem that
leads in a concise way directly to the two allowed fields: the newtonian and
the isotropic harmonic oscillator central fields.

Categories: q-fin.GN, physics.soc-ph, q-fin.ST
Abstract: We analyze 27 house price indexes of Las Vegas from Jun. 1983 to Mar. 2005,
corresponding to 27 different zip codes. These analyses confirm the existence
of a real-estate bubble, defined as a price acceleration faster than
exponential, which is found however to be confined to a rather limited time
interval in the recent past from approximately 2003 to mid-2004 and has
progressively transformed into a more normal growth rate comparable to
pre-bubble levels in 2005. There has been no bubble till 2002 except for a
medium-sized surge in 1990. In addition, we have identified a strong yearly
periodicity which provides a good potential for fine-tuned prediction from
month to month. A monthly monitoring using a model that we have developed could
confirm, by testing the intra-year structure, if indeed the market has returned
to ``normal'' or if more turbulence is expected ahead. We predict the evolution
of the indexes one year ahead, which is validated with new data up to Sep.
2006. The present analysis demonstrates the existence of very significant
variations at the local scale, in the sense that the bubble in Las Vegas seems
to have preceded the more global USA bubble and has ended approximately two
years earlier (mid 2004 for Las Vegas compared with mid-2006 for the whole of
the USA).

Categories: cond-mat.other, physics.optics, quant-ph
Abstract: We give a microscopic derivation of the Clausius-Mossotti relations for a
homogeneous and isotropic magneto-dielectric medium consisting of radiatively
broadened atomic oscillators. To this end the diagram series of electromagnetic
propagators is calculated exactly for an infinite bi-cubic lattice of
dielectric and magnetic dipoles for a lattice constant small compared to the
resonance wavelength $\lambda$. Modifications of transition frequencies and
linewidth of the elementary oscillators are taken into account in a
selfconsistent way by a proper incorporation of the singular self-interaction
terms. We show that in radiatively broadened media sufficiently close to the
free-space resonance the real part of the index of refraction approaches the
value -2 in the limit of $\rho \lambda^3 \gg 1$, where $\rho$ is the number
density of scatterers. Since at the same time the imaginary part vanishes as
$1/\rho$ local field effects can have important consequences for realizing
low-loss negative index materials.

Categories: physics.gen-ph, q-bio.PE
Abstract: Despite their claimed biological plausibility, most self organizing networks
have strict topological constraints and consequently they cannot take into
account a wide range of external stimuli. Furthermore their evolution is
conditioned by deterministic laws which often are not correlated with the
structural parameters and the global status of the network, as it should happen
in a real biological system. In nature the environmental inputs are noise
affected and fuzzy. Which thing sets the problem to investigate the possibility
of emergent behaviour in a not strictly constrained net and subjected to
different inputs. It is here presented a new model of Evolutionary Neural Gas
(ENG) with any topological constraints, trained by probabilistic laws depending
on the local distortion errors and the network dimension. The network is
considered as a population of nodes that coexist in an ecosystem sharing local
and global resources. Those particular features allow the network to quickly
adapt to the environment, according to its dimensions. The ENG model analysis
shows that the net evolves as a scale-free graph, and justifies in a deeply
physical sense- the term gas here used.

Categories: physics.optics, cond-mat.soft, nlin.PS, physics.flu-dyn
Abstract: We investigate the formation of collisionless shocks along the spatial
profile of a gaussian laser beam propagating in nonlocal nonlinear media. For
defocusing nonlinearity the shock survives the smoothing effect of the nonlocal
response, though its dynamics is qualitatively affected by the latter, whereas
for focusing nonlinearity it dominates over filamentation. The patterns
observed in a thermal defocusing medium are interpreted in the framework of our
theory.

Categories: physics.comp-ph, physics.data-an
Abstract: Efficient control of a laser welding process requires the reliable prediction
of process behavior. A statistical method of field modeling, based on
normalized RBFNN, can be successfully used to predict the spatiotemporal
dynamics of surface optical activity in the laser welding process. In this
article we demonstrate how to optimize RBFNN to maximize prediction quality.
Special attention is paid to the structure of sample vectors, which represent
the bridge between the field distributions in the past and future.

Categories: q-fin.ST, physics.data-an, physics.soc-ph
Abstract: We show that recent stock market fluctuations are characterized by the
cumulative distributions whose tails on short, minute time scales exhibit power
scaling with the scaling index alpha > 3 and this index tends to increase
quickly with decreasing sampling frequency. Our study is based on
high-frequency recordings of the S&P500, DAX and WIG20 indices over the
interval May 2004 - May 2006. Our findings suggest that dynamics of the
contemporary market may differ from the one observed in the past. This effect
indicates a constantly increasing efficiency of world markets.

Categories: cond-mat.soft, cond-mat.stat-mech, physics.ins-det, physics.optics
Abstract: We report on a new type of experiment that enables us to monitor spatially
and temporally heterogeneous dynamic properties in complex fluids. Our approach
is based on the analysis of near-field speckles produced by light diffusely
reflected from the superficial volume of a strongly scattering medium. By
periodic modulation of an incident speckle beam we obtain pixel-wise ensemble
averages of the structure function coefficient, a measure of the dynamic
activity. To illustrate the application of our approach we follow the different
stages in the drying process of a colloidal thin film. We show that we can
access ensemble averaged dynamic properties on length scales as small as ten
micrometers over the full field of view.

Categories: physics.soc-ph
Abstract: The purpose of this paper is to assess the statistical characterization of
weighted networks in terms of the generalization of the relevant parameters,
namely average path length, degree distribution and clustering coefficient.
Although the degree distribution and the average path length admit
straightforward generalizations, for the clustering coefficient several
different definitions have been proposed in the literature. We examined the
different definitions and identified the similarities and differences between
them. In order to elucidate the significance of different definitions of the
weighted clustering coefficient, we studied their dependence on the weights of
the connections. For this purpose, we introduce the relative perturbation norm
of the weights as an index to assess the weight distribution. This study
revealed new interesting statistical regularities in terms of the relative
perturbation norm useful for the statistical characterization of weighted
graphs.

Categories: physics.soc-ph
Abstract: Simulations of physicists for the competition between adult languages since
2003 are reviewed. How many languages are spoken by how many people? How many
languages are contained in various language families? How do language
similarities decay with geographical distance, and what effects do natural
boundaries have? New simulations of bilinguality are given in an appendix.

Categories: hep-ph, physics.atom-ph
Abstract: Photon splitting due to vacuum polarization in a laser field is considered.
Using an operator technique, we derive the amplitudes for arbitrary strength,
spectral content and polarization of the laser field. The case of a
monochromatic circularly polarized laser field is studied in detail and the
amplitudes are obtained as three-fold integrals. The asymptotic behavior of the
amplitudes for various limits of interest are investigated also in the case of
a linearly polarized laser field. Using the obtained results, the possibility
of experimental observation of the process is discussed.

Categories: physics.chem-ph
Abstract: The thermal decomposition of norbornane (dissolved in benzene) has been
studied in a jet stirred reactor at temperatures between 873 and 973 K, at
residence times ranging from 1 to 4 s and at atmospheric pressure, leading to
conversions from 0.04 to 22.6%. 25 reaction products were identified and
quantified by gas chromatography, amongst which the main ones are hydrogen,
ethylene and 1,3-cyclopentadiene. A mechanism investigation of the thermal
decomposition of the norbornane - benzene binary mixture has been performed.
Reactions involved in the mechanism have been reviewed: unimolecular
initiations 1 by C-C bond scission of norbornane, fate of the generated
diradicals, reactions of transfer and propagation of norbornyl radicals,
reactions of benzene and cross-coupling reactions.

Categories: physics.chem-ph
Abstract: This work reports a theoretical study of the gas phase unimolecular
decomposition of cyclobutane, cyclopentane and cyclohexane by means of quantum
chemical calculations. A biradical mechanism has been envisaged for each
cycloalkane, and the main routes for the decomposition of the biradicals formed
have been investigated at the CBS-QB3 level of theory. Thermochemical data
(\delta H^0_f, S^0, C^0_p) for all the involved species have been obtained by
means of isodesmic reactions. The contribution of hindered rotors has also been
included. Activation barriers of each reaction have been analyzed to assess the
1 energetically most favorable pathways for the decomposition of biradicals.
Rate constants have been derived for all elementary reactions using transition
state theory at 1 atm and temperatures ranging from 600 to 2000 K. Global rate
constant for the decomposition of the cyclic alkanes in molecular products have
been calculated. Comparison between calculated and experimental results allowed
to validate the theoretical approach. An important result is that the
rotational barriers between the conformers, which are usually neglected, are of
importance in decomposition rate of the largest biradicals. Ring strain
energies (RSE) in transition states for ring opening have been estimated and
show that the main part of RSE contained in the cyclic reactants is removed
upon the activation process.

Categories: physics.optics
Abstract: A review of theoretical and experimental studies of thermal effects in
solid-state lasers is presented, with a special focus on diode-pumped
ytterbium-doped materials. A large part of this review provides however general
information applicable to any kind of solid-state laser. Our aim here is not to
make a list of the techniques that have been used to minimize thermal effects,
but instead to give an overview of the theoretical aspects underneath, and give
a state-of-the-art of the tools at the disposal of the laser scientist to
measure thermal effects. After a presentation of some general properties of
Yb-doped materials, we address the issue of evaluating the temperature map in
Yb-doped laser crystals, both theoretically and experimentally. This is the
first step before studying the complex problem of thermal lensing (part III).
We will focus on some newly discussed aspects, like the definition of the
thermo-optic coefficient: we will highlight some misleading interpretations of
thermal lensing experiments due to the use of the dn/dT parameter in a context
where it is not relevant. Part IV will be devoted to a state-of-the-art of
experimental techniques used to measure thermal lensing. Eventually, in part V,
we will give some concrete examples in Yb-doped materials, where their
peculiarities will be pointed out.

Categories: physics.optics
Abstract: We present a numerical study and analytical model of the optical near-field
diffracted in the vicinity of subwavelength grooves milled in silver surfaces.
The Green's tensor approach permits computation of the phase and amplitude
dependence of the diffracted wave as a function of the groove geometry. It is
shown that the field diffracted along the interface by the groove is equivalent
to replacing the groove by an oscillating dipolar line source. An analytic
expression is derived from the Green's function formalism, that reproduces well
the asymptotic surface plasmon polariton (SPP) wave as well as the transient
surface wave in the near-zone close to the groove. The agreement between this
model and the full simulation is very good, showing that the transient
"near-zone" regime does not depend on the precise shape of the groove. Finally,
it is shown that a composite diffractive evanescent wave model that includes
the asymptotic SPP can describe the wavelength evolution in this transient
near-zone. Such a semi-analytical model may be useful for the design and
optimization of more elaborate photonic circuits whose behavior in large part
will be controlled by surface waves.


Successful predictions are among the most compelling validations of any
model. Extracting falsifiable predictions from nonlinear multiparameter models
is complicated by the fact that such models are commonly sloppy, possessing
sensitivities to different parameter combinations that range over many decades.
Here we discuss how sloppiness affects the sorts of data that best constrain
model predictions, makes linear uncertainty approximations dangerous, and
introduces computational difficulties in Monte-Carlo uncertainty analysis. We
also present a useful test problem and suggest refinements to the standards by
which models are communicated.

In most vertebrate species, the body axis is generated by the formation of
repeated transient structures called somites. This spatial periodicity in
somitogenesis has been related to the temporally sustained oscillations in
certain mRNAs and their associated gene products in the cells forming the
presomatic mesoderm. The mechanism underlying these oscillations have been
identified as due to the delays involved in the synthesis of mRNA and
translation into protein molecules [J. Lewis, Current Biol. {\bf 13}, 1398
(2003)]. In addition, in the zebrafish embryo intercellular Notch signalling
couples these oscillators and a longitudinal positional information signal in
the form of an Fgf8 gradient exists that could be used to transform these
coupled temporal oscillations into the observed spatial periodicity of somites.
Here we consider a simple model based on this known biology and study its
consequences for somitogenesis. Comparison is made with the known properties of
somite formation in the zebrafish embryo . We also study the effects of
localized Fgf8 perturbations on somite patterning.

We have developed a linearization method to investigate the subthreshold
oscillatory behaviors in nonlinear autonomous systems. By considering firstly
the neuronal system as an example, we show that this theoretical approach can
predict quantitatively the subthreshold oscillatory activities, including the
damping coefficients and the oscillatory frequencies which are in good
agreement with those observed in experiments. Then we generalize the
linearization method to an arbitrary autonomous nonlinear system. The detailed
extension of this theoretical approach is also presented and further discussed.

The widespread use of genetic testing in high risk pregnancies has created
strong interest in rapid and accurate molecular diagnostics for common
chromosomal aneuploidies. We show here that digital polymerase chain reaction
(dPCR) can be used for accurate measurement of trisomy 21 (Down's Syndrome),
the most common human aneuploidy. dPCR is generally applicable to any
aneuploidy, does not depend on allelic distribution or gender, and is able to
detect signals in the presence of mosaics or contaminating maternal DNA.

Biologists are leading current research on genome characterization
(sequencing, alignment, transcription), providing a huge quantity of raw data
about many genome organisms. Extracting knowledge from this raw data is an
important process for biologists, using usually data mining approaches.
However, it is difficult to deals with these genomic information using actual
bioinformatics data mining tools, because data are heterogeneous, huge in
quantity and geographically distributed. In this paper, we present a new
approach between data mining and virtual reality visualization, called visual
data mining. Indeed Virtual Reality becomes ripe, with efficient display
devices and intuitive interaction in an immersive context. Moreover, biologists
use to work with 3D representation of their molecules, but in a desktop
context. We present a software solution, Genome3DExplorer, which addresses the
problem of genomic data visualization, of scene management and interaction.
This solution is based on a well-adapted graphical and interaction paradigm,
where local and global topological characteristics of data are easily visible,
on the contrary to traditional genomic database browsers, always focused on the
zoom and details level.

This paper presents a stability test for a class of interconnected nonlinear
systems motivated by biochemical reaction networks. One of the main results
determines global asymptotic stability of the network from the diagonal
stability of a "dissipativity matrix" which incorporates information about the
passivity properties of the subsystems, the interconnection structure of the
network, and the signs of the interconnection terms. This stability test
encompasses the "secant criterion" for cyclic networks presented in our
previous paper, and extends it to a general interconnection structure
represented by a graph. A second main result allows one to accommodate state
products. This extension makes the new stability criterion applicable to a
broader class of models, even in the case of cyclic systems. The new stability
test is illustrated on a mitogen activated protein kinase (MAPK) cascade model,
and on a branched interconnection structure motivated by metabolic networks.
Finally, another result addresses the robustness of stability in the presence
of diffusion terms in a compartmental system made out of identical systems.

Mechanistic home range models are important tools in modeling animal dynamics
in spatially-complex environments. We introduce a class of stochastic models
for animal movement in a habitat of varying preference. Such models interpolate
between spatially-implicit resource selection analysis (RSA) and
advection-diffusion models, possessing these two models as limiting cases. We
find a closed-form solution for the steady-state (equilibrium) probability
distribution u* using a factorization of the redistribution operator into
symmetric and diagonal parts. How space use is controlled by the preference
function w then depends on the characteristic width of the redistribution
kernel: when w changes rapidly compared to this width, u* ~ w, whereas on
global scales large compared to this width, u* ~ w^2. We analyse the behavior
at discontinuities in w which occur at habitat type boundaries. We simulate the
dynamics of space use given two-dimensional prey-availability data and explore
the effect of the redistribution kernel width. Our factorization allows such
numerical simulations to be done extremely fast; we expect this to aid the
computationally-intensive task of model parameter fitting and inverse modeling.

Transcription networks, and other directed networks can be characterized by
some topological observables such as for example subgraph occurrence (network
motifs). In order to perform such kind of analysis, it is necessary to be able
to generate suitable randomized network ensembles. Typically, one considers
null networks with the same degree sequences of the original ones. The commonly
used algorithms sometimes have long convergence times, and sampling problems.
We present here an alternative, based on a variant of the importance sampling
Montecarlo developed by Chen et al. [1].

It is basic question in biology and other fields to identify the char-
acteristic properties that on one hand are shared by structures from a
particular realm, like gene regulation, protein-protein interaction or neu- ral
networks or foodwebs, and that on the other hand distinguish them from other
structures. We introduce and apply a general method, based on the spectrum of
the normalized graph Laplacian, that yields repre- sentations, the spectral
plots, that allow us to find and visualize such properties systematically. We
present such visualizations for a wide range of biological networks and compare
them with those for networks derived from theoretical schemes. The differences
that we find are quite striking and suggest that the search for universal
properties of biological networks should be complemented by an understanding of
more specific features of biological organization principles at different
scales.

The classical attenuation regulation of gene expression in bacteria is
considered. We propose to represent the secondary RNA structure in the leader
region of a gene or an operon by a term, and we give a probabilistic term
rewriting system modeling the whole process of such a regulation.

Escherichia coli is a motile bacterium that moves up a chemoattractant
gradient by performing a biased random walk composed of alternating runs and
tumbles. Previous models of run and tumble chemotaxis neglect one or more
features of the motion, namely (i) a cell cannot directly detect a
chemoattractant gradient but rather makes temporal comparisons of
chemoattractant concentration, (ii) rather than being entirely random, tumbles
exhibit persistence of direction, meaning that the new direction after a tumble
is more likely to be in the forward hemisphere, and (iii) rotational Brownian
motion makes it impossible for an E. coli cell to swim in a straight line
during a run. This paper presents an analytic calculation of the chemotactic
drift velocity taking account of (i), (ii) and (iii), for weak chemotaxis. The
analytic results are verified by Monte Carlo simulation. The results reveal a
synergy between temporal comparisons and persistence that enhances the drift
velocity, while rotational Brownian motion reduces the drift velocity.

An eutactic star, in a n-dimensional space, is a set of N vectors which can
be viewed as the projection of N orthogonal vectors in a N-dimensional space.
By adequately associating a star of vectors to a particular sea urchin we
propose that a measure of the eutacticity of the star constitutes a measure of
the regularity of the sea urchin. Then we study changes of regularity
(eutacticity) in a macroevolutive and taxonomic level of sea urchins belonging
to the Echinoidea Class. An analysis considering changes through geological
time suggests a high degree of regularity in the shape of these organisms
through their evolution. Rare deviations from regularity measured in
Holasteroida order are discussed.

Statistical mechanics is one of the most powerful and elegant tools in the
quantitative sciences. One key virtue of statistical mechanics is that it is
designed to examine large systems with many interacting degrees of freedom,
providing a clue that it might have some bearing on the analysis of the
molecules of living matter. As a result of data on biological systems becoming
increasingly quantitative, there is a concomitant demand that the models set
forth to describe biological systems be themselves quantitative. We describe
how statistical mechanics is part of the quantitative toolkit that is needed to
respond to such data. The power of statistical mechanics is not limited to
traditional physical and chemical problems and there are a host of interesting
ways in which these ideas can be applied in biology. This article reports on
our efforts to teach statistical mechanics to life science students and
provides a framework for others interested in bringing these tools to a
nontraditional audience in the life sciences.

MOTIVATION: Microarray technology makes it possible to measure thousands of
variables and to compare their values under hundreds of conditions. Once
microarray data are quantified, normalized and classified, the analysis phase
is essentially a manual and subjective task based on visual inspection of
classes in the light of the vast amount of information available. Currently,
data interpretation clearly constitutes the bottleneck of such analyses and
there is an obvious need for tools able to fill the gap between data processed
with mathematical methods and existing biological knowledge. RESULTS: THEA
(Tools for High-throughput Experiments Analysis) is an integrated information
processing system allowing convenient handling of data. It allows to
automatically annotate data issued from classification systems with selected
biological information coming from a knowledge base and to either manually
search and browse through these annotations or automatically generate
meaningful generalizations according to statistical criteria (data mining).
AVAILABILITY: The software is available on the website http://thea.unice.fr/

In this paper we address a general parameter estimation methodology for an
extended biokinetic degradation model [1] for poorly degradable
micropollutants. In particular we concentrate on parameter estimation of the
micropollutant degradation sub-model by specialised microorganisms. In this
case we focus on the case when only substrate degradation data are available
and prove the structural identifiability of the model. Further we consider the
problem of practical identifiability and propose experimental and related
numerical methods for unambiguous parameter estimation based on multiple
substrate degradation curves with different initial concentrations. Finally by
means of simulated pseudo-experiments we have found convincing indications that
the proposed algorithm is stable and yields appropriate parameter estimates
even in unfavourable regimes.

Predicting interactions between small molecules and proteins is a crucial
ingredient of the drug discovery process. In particular, accurate predictive
models are increasingly used to preselect potential lead compounds from large
molecule databases, or to screen for side-effects. While classical in silico
approaches focus on predicting interactions with a given specific target, new
chemogenomics approaches adopt cross-target views. Building on recent
developments in the use of kernel methods in bio- and chemoinformatics, we
present a systematic framework to screen the chemical space of small molecules
for interaction with the biological space of proteins. We show that this
framework allows information sharing across the targets, resulting in a
dramatic improvement of ligand prediction accuracy for three important classes
of drug targets: enzymes, GPCR and ion channels.

BACKGROUND: One of the most evident achievements of bioinformatics is the
development of methods that transfer biological knowledge from characterised
proteins to uncharacterised sequences. This mode of protein function assignment
is mostly based on the detection of sequence similarity and the premise that
functional properties are conserved during evolution. Most automatic approaches
developed to date rely on the identification of clusters of homologous proteins
and the mapping of new proteins onto these clusters, which are expected to
share functional characteristics. RESULTS: Here, we inverse the logic of this
process, by considering the mapping of sequences directly to a functional
classification instead of mapping functions to a sequence clustering. In this
mode, the starting point is a database of labelled proteins according to a
functional classification scheme, and the subsequent use of sequence similarity
allows defining the membership of new proteins to these functional classes. In
this framework, we define the Correspondence Indicators as measures of
relationship between sequence and function and further formulate two Bayesian
approaches to estimate the probability for a sequence of unknown function to
belong to a functional class. This approach allows the parametrisation of
different sequence search strategies and provides a direct measure of
annotation error rates. We validate this approach with a database of enzymes
labelled by their corresponding four-digit EC numbers and analyse specific
cases. CONCLUSION: The performance of this method is significantly higher than
the simple strategy consisting in transferring the annotation from the highest
scoring BLAST match and is expected to find applications in automated
functional annotation pipelines.

In many biochemical processes, proteins bound to DNA at distant sites are
brought into close proximity by loops in the underlying DNA. For example, the
function of some gene-regulatory proteins depends on such DNA looping
interactions. We present a new technique for characterizing the kinetics of
loop formation in vitro, as observed using the tethered particle method, and
apply it to experimental data on looping induced by lambda repressor. Our
method uses a modified (diffusive) hidden Markov analysis that directly
incorporates the Brownian motion of the observed tethered bead. We compare
looping lifetimes found with our method (which we find are consistent over a
range of sampling frequencies) to those obtained via the traditional
threshold-crossing analysis (which can vary depending on how the raw data are
filtered in the time domain). Our method does not involve any time filtering
and can detect sudden changes in looping behavior. For example, we show how our
method can identify transitions between long-lived, kinetically distinct states
that would otherwise be difficult to discern.

We propose a general framework for converting global and local similarities
between biological sequences to quasi-metrics. In contrast to previous works,
our formulation allows asymmetric distances, originating from uneven weighting
of strings, that may induce non-trivial partial orders on sets of biosequences.
Furthermore, the $\ell^p$-type distances considered are more general than
traditional generalized string edit distances corresponding to the $\ell^1$
case, and enable conversion of sequence similarities to distances for a much
wider class of scoring schemes. Our constructions require much less restrictive
gap penalties than the ones regularly used. Numerous examples are provided to
illustrate the concepts introduced and their potential applications.

Environment specific substitution tables have been used effectively for
distinguishing structural and functional constraints on proteins and thereby
identify their active sites (Chelliah et al. (2004)). This work explores
whether a similar approach can be used to identify specificity determining
residues (SDRs) responsible for cofactor dependence, substrate specificity or
subtle catalytic variations. We combine structure-sequence information and
functional annotation from various data sources to create structural alignments
for homologous enzymes and functional partitions therein. We develop a scoring
procedure to predict SDRs and assess their accuracy using information from
bound specific ligands and published literature.

Transforming growth factor (TGF) $\beta$ is known to have properties of both
a tumor suppressor and a tumor promoter. While it inhibits cell proliferation,
it also increases cell motility and decreases cell--cell adhesion. Coupling
mathematical modeling and experiments, we investigate the growth and motility
of oncogene--expressing human mammary epithelial cells under exposure to
TGF--$\beta$. We use a version of the well--known Fisher--Kolmogorov equation,
and prescribe a procedure for its parametrization. We quantify the simultaneous
effects of TGF--$\beta$ to increase the tendency of individual cells and cell
clusters to move randomly and to decrease overall population growth. We
demonstrate that in experiments with TGF--$\beta$ treated cells \textit{in
vitro}, TGF--$\beta$ increases cell motility by a factor of 2 and decreases
cell proliferation by a factor of 1/2 in comparison with untreated cells.

Fast, efficient and reliable algorithms for pairwise alignment of protein
structures are in ever increasing demand for analyzing the rapidly growing data
of protein structures. CLePAPS is a tool developed for this purpose. It
distinguishes itself from other existing algorithms by the use of
conformational letters, which are discretized states of 3D segmental structural
states. A letter corresponds to a cluster of combinations of the three angles
formed by C_alpha pseudobonds of four contiguous residues. A substitution
matrix called CLESUM is available to measure similarity between any two such
letters. CLePAPS regards an aligned fragment pair (AFP) as an ungapped string
pair with a high sum of pairwise CLESUM scores. Using CLESUM scores as the
similarity measure, CLePAPS searches for AFPs by simple string comparison. The
transformation which best superimposes a highly similar AFP can be used to
superimpose the structure pairs under comparison. A highly scored AFP which is
consistent with several other AFPs determines an initial alignment. CLePAPS
then joins consistent AFPs guided by their similarity scores to extend the
alignment by several `zoom-in' iteration steps. A follow-up refinement produces
the final alignment. CLePAPS does not implement dynamic programming. The
utility of CLePAPS is tested on various protein structure pairs.

The key to understanding a protein's function often lies in its
conformational dynamics. We develop a coarse-grained variational model to
investigate the interplay between structural transitions, conformational
flexibility and function of N-terminal calmodulin (nCaM) domain. In this model,
two energy basins corresponding to the ``closed'' apo conformation and ``open''
holo conformation of nCaM domain are connected by a uniform interpolation
parameter. The resulting detailed transition route from our model is largely
consistent with the recently proposed EF$\beta$-scaffold mechanism in EF-hand
family proteins. We find that the N-terminal part in calcium binding loops I
and II shows higher flexibility than the C-terminal part which form this
EF$\beta$-scaffold structure. The structural transition of binding loops I and
II are compared in detail. Our model predicts that binding loop II, with higher
flexibility and early structural change than binding loop I, dominates the
conformational transition in nCaM domain.

Various physical properties such as dipole moment, heat of formation and
energy of the most stable formation of nucleotides and bases were calculated by
PM3 (modified neglect of diatomic overlap, parametric method number 3) and AM1
(Austin model 1) methods. As distinct from previous calculations, for
nucleotides the interaction with neighbours is taken into account up to
gradient of convergence equaling 1. The dependences of these variables from the
place in the codon and the determinative degree were obtained. The difference
of these variables for codons and anticodons is shown.

A multitude of measures have been proposed to quantify the similarity between
protein 3-D structure. Among these measures, contact map overlap (CMO)
maximization deserved sustained attention during past decade because it offers
a fine estimation of the natural homology relation between proteins. Despite
this large involvement of the bioinformatics and computer science community,
the performance of known algorithms remains modest. Due to the complexity of
the problem, they got stuck on relatively small instances and are not
applicable for large scale comparison. This paper offers a clear improvement
over past methods in this respect. We present a new integer programming model
for CMO and propose an exact B &B algorithm with bounds computed by solving
Lagrangian relaxation. The efficiency of the approach is demonstrated on a
popular small benchmark (Skolnick set, 40 domains). On this set our algorithm
significantly outperforms the best existing exact algorithms, and yet provides
lower and upper bounds of better quality. Some hard CMO instances have been
solved for the first time and within reasonable time limits. From the values of
the running time and the relative gap (relative difference between upper and
lower bounds), we obtained the right classification for this test. These
encouraging result led us to design a harder benchmark to better assess the
classification capability of our approach. We constructed a large scale set of
300 protein domains (a subset of ASTRAL database) that we have called Proteus
300. Using the relative gap of any of the 44850 couples as a similarity
measure, we obtained a classification in very good agreement with SCOP. Our
algorithm provides thus a powerful classification tool for large structure
databases.

This note discusses a theoretical issue regarding the application of the
"Modular Response Analysis" method to quasi-steady state (rather than
steady-state) data.

By convention, and even more often, as an unintentional consequence of
design, time distributions of latency and infectious durations in stochastic
epidemic simulations are often exponential. The skewed distribtion typically
leads to unrealistically short times. We examine the effects of altering the
distribution latency and infectious times by comparing the key results after
simulation with exponential and gamma distributions in a homogeneous mixing
model aswell as a model with regional divisions connected by a travel intensity
matrix. We show a delay in spread with more realistic latency times and offer
an explanation of the effect.

Sensitivity analysis is an effective tool for systematically identifying
specific perturbations in parameters that have significant effects on the
behavior of a given biosystem, at the scale investigated. In this work, using a
two-dimensional, multiscale non-small cell lung cancer (NSCLC) model, we
examine the effects of perturbations in system parameters which span both
molecular and cellular levels, i.e. across scales of interest. This is achieved
by first linking molecular and cellular activities and then assessing the
influence of parameters at the molecular level on the tumor's spatio-temporal
expansion rate, which serves as the output behavior at the cellular level.
Overall, the algorithm operated reliably over relatively large variations of
most parameters, hence confirming the robustness of the model. However, three
pathway components (proteins PKC, MEK, and ERK) and eleven reaction steps were
determined to be of critical importance by employing a sensitivity coefficient
as an evaluation index. Each of these sensitive parameters exhibited a similar
changing pattern in that a relatively larger increase or decrease in its value
resulted in a lesser influence on the system's cellular performance. This study
provides a novel cross-scaled approach to analyzing sensitivities of
computational model parameters and proposes its application to
interdisciplinary biomarker studies.

Heavy-tailed or power-law distributions are becoming increasingly common in
biological literature. A wide range of biological data has been fitted to
distributions with heavy tails. Many of these studies use simple fitting
methods to find the parameters in the distribution, which can give highly
misleading results. The potential pitfalls that can occur when using these
methods are pointed out, and a step-by-step guide to fitting power-law
distributions and assessing their goodness-of-fit is offered.

Despite recent molecular technique improvements, biological knowledge remains
incomplete. Reasoning on living systems hence implies to integrate
heterogeneous and partial informations. Although current investigations
successfully focus on qualitative behaviors of macromolecular networks, others
approaches show partial quantitative informations like protein concentration
variations over times. We consider that both informations, qualitative and
quantitative, have to be combined into a modeling method to provide a better
understanding of the biological system. We propose here such a method using a
probabilistic-like approach. After its exhaustive description, we illustrate
its advantages by modeling the carbon starvation response in Escherichia coli.
In this purpose, we build an original qualitative model based on available
observations. After the formal verification of its qualitative properties, the
probabilistic model shows quantitative results corresponding to biological
expectations which confirm the interest of our probabilistic approach.

Many complex biological, social, and economical networks show topologies
drastically differing from random graphs. But, what is a complex network, i.e.\
how can one quantify the complexity of a graph? Here the Offdiagonal Complexity
(OdC), a new, and computationally cheap, measure of complexity is defined,
based on the node-node link cross-distribution, whose nondiagonal elements
characterize the graph structure beyond link distribution, cluster coefficient
and average path length. The OdC apporach is applied to the {\sl Helicobacter
pylori} protein interaction network and randomly rewired surrogates thereof. In
addition, OdC is used to characterize the spatial complexity of cell
aggregates. We investigate the earliest embryo development states of
Caenorhabditis elegans. The development states of the premorphogenetic phase
are represented by symmetric binary-valued cell connection matrices with
dimension growing from 4 to 385. These matrices can be interpreted as adjacency
matrix of an undirected graph, or network. The OdC approach allows to describe
quantitatively the complexity of the cell aggregate geometry.

Two recent streams of work suggest that pairwise interactions may be
sufficient to capture the complexity of biological systems ranging from protein
structure to networks of neurons. In one approach, possible amino acid
sequences in a family of proteins are generated by Monte Carlo annealing of a
"Hamiltonian" that forces pairwise correlations among amino acid substitutions
to be close to the observed correlations. In the other approach, the observed
correlations among pairs of neurons are used to construct a maximum entropy
model for the states of the network as a whole. We show that, in certain
limits, these two approaches are mathematically equivalent, and we comment on
open problems suggested by this framework

Given a metabolic network in terms of its metabolites and reactions, our goal
is to efficiently compute the minimal knock out sets of reactions required to
block a given behaviour. We describe an algorithm which improves the
computation of these knock out sets when the elementary modes (minimal
functional subsystems) of the network are given. We also describe an algorithm
which computes both the knock out sets and the elementary modes containing the
blocked reactions directly from the description of the network and whose
worst-case computational complexity is better than the algorithms currently in
use for these problems. Computational results are included.

Over the last decade, a large variety of clustering algorithms have been
developed to detect coregulatory relationships among genes from microarray gene
expression data. Model based clustering approaches have emerged as
statistically well grounded methods, but the properties of these algorithms
when applied to large-scale data sets are not always well understood. An
in-depth analysis can reveal important insights about the performance of the
algorithm, the expected quality of the output clusters, and the possibilities
for extracting more relevant information out of a particular data set. We have
extended an existing algorithm for model based clustering of genes to
simultaneously cluster genes and conditions, and used three large compendia of
gene expression data for S. cerevisiae to analyze its properties. The algorithm
uses a Bayesian approach and a Gibbs sampling procedure to iteratively update
the cluster assignment of each gene and condition. For large-scale data sets,
the posterior distribution is strongly peaked on a limited number of
equiprobable clusterings. A GO annotation analysis shows that these local
maxima are all biologically equally significant, and that simultaneously
clustering genes and conditions performs better than only clustering genes and
assuming independent conditions. A collection of distinct equivalent
clusterings can be summarized as a weighted graph on the set of genes, from
which we extract fuzzy, overlapping clusters using a graph spectral method. The
cores of these fuzzy clusters contain tight sets of strongly coexpressed genes,
while the overlaps exhibit relations between genes showing only partial
coexpression.

The G-protein coupled receptor (GPCR) superfamily is currently the largest
class of therapeutic targets. \textit{In silico} prediction of interactions
between GPCRs and small molecules is therefore a crucial step in the drug
discovery process, which remains a daunting task due to the difficulty to
characterize the 3D structure of most GPCRs, and to the limited amount of known
ligands for some members of the superfamily. Chemogenomics, which attempts to
characterize interactions between all members of a target class and all small
molecules simultaneously, has recently been proposed as an interesting
alternative to traditional docking or ligand-based virtual screening
strategies. We propose new methods for in silico chemogenomics and validate
them on the virtual screening of GPCRs. The methods represent an extension of a
recently proposed machine learning strategy, based on support vector machines
(SVM), which provides a flexible framework to incorporate various information
sources on the biological space of targets and on the chemical space of small
molecules. We investigate the use of 2D and 3D descriptors for small molecules,
and test a variety of descriptors for GPCRs. We show fo instance that
incorporating information about the known hierarchical classification of the
target family and about key residues in their inferred binding pockets
significantly improves the prediction accuracy of our model. In particular we
are able to predict ligands of orphan GPCRs with an estimated accuracy of
78.1%.

A composite, exponential relaxation function, modulated by a periodic
component, was used to fit to an experimental time series of blood glucose
levels. The 11 parameters function that allows for the detection of a possible
rhythm transition was fitted to the experimental time series using a genetic
algorithm. It has been found that the relaxation from a hyperglycemic condition
following a change in the anti-diabetic treatment, can be characterized by a
change from an initial 12 hours ultradian rhythm to a near-24 hours circadian
rhythm.

In many experiments, the aim is to deduce an underlying multi-substate on-off
kinetic scheme (KS) from the statistical properties of a two-state trajectory.
However, the mapping of a KS into a two-state trajectory leads to the loss of
information about the KS, and so, in many cases, more than one KS can be
associated with the data. We recently showed that the optimal way to solve this
problem is to use canonical forms of reduced dimensions (RD). RD forms are
on-off networks with connections only between substates of different states,
where the connections can have non-exponential waiting time probability density
functions (WT-PDFs). In theory, only a single RD form can be associated with
the data. To utilize RD forms in the analysis of the data, a RD form should be
associated with the data. Here, we give a toolbox for building a RD form from a
finite two-state trajectory. The methods in the toolbox are based on known
statistical methods in data analysis, combined with statistical methods and
numerical algorithms designed specifically for the current problem. Our toolbox
is self-contained - it builds a mechanism based only on the information it
extracts from the data, and its implementation on the data is fast (analyzing a
10^6 cycle trajectory from a thirty-parameter mechanism takes a couple of hours
on a PC with a 2.66 GHz processor). The toolbox is automated and is freely
available for academic research upon electronic request.

MOTIVATION: The use of oligonucleotide microarray technology requires a very
detailed attention to the design of specific probes spotted on the solid phase.
These problems are far from being commonplace since they refer to complex
physicochemical constraints. Whereas there are more and more publicly available
programs for microarray oligonucleotide design, most of them use the same
algorithm or criteria to design oligos, with only little variation. RESULTS: We
show that classical approaches used in oligo design software may be inefficient
under certain experimental conditions, especially when dealing with complex
target mixtures. Indeed, our biological model is a human obligate parasite, the
microsporidia Encephalitozoon cuniculi. Targets that are extracted from
biological samples are composed of a mixture of pathogen transcripts and host
cell transcripts. We propose a new approach to design oligonucleotides which
combines good specificity with a potentially high sensitivity. This approach is
original in the biological point of view as well as in the algorithmic point of
view. We also present an experimental validation of this new strategy by
comparing results obtained with standard oligos and with our composite oligos.
A specific E.cuniculi microarray will overcome the difficulty to discriminate
the parasite mRNAs from the host cell mRNAs demonstrating the power of the
microarray approach to elucidate the lifestyle of an intracellular pathogen
using mix mRNAs.

Living cells are the product of gene expression programs that involve the
regulated transcription of thousands of genes. The elucidation of
transcriptional regulatory networks in thus needed to understand the cell's
working mechanism, and can for example be useful for the discovery of novel
therapeutic targets. Although several methods have been proposed to infer gene
regulatory networks from gene expression data, a recent comparison on a
large-scale benchmark experiment revealed that most current methods only
predict a limited number of known regulations at a reasonable precision level.
We propose SIRENE, a new method for the inference of gene regulatory networks
from a compendium of expression data. The method decomposes the problem of gene
regulatory network inference into a large number of local binary classification
problems, that focus on separating target genes from non-targets for each TF.
SIRENE is thus conceptually simple and computationally efficient. We test it on
a benchmark experiment aimed at predicting regulations in E. coli, and show
that it retrieves of the order of 6 times more known regulations than other
state-of-the-art inference methods.

We define the complexity of DNA sequences as the information content per
nucleotide, calculated by means of some Lempel-Ziv data compression algorithm.
It is possible to use the statistics of the complexity values of the functional
regions of different complete genomes to distinguish among genomes of different
domains of life (Archaea, Bacteria and Eukarya). We shall focus on the
distribution function of the complexity of noncoding regions. We show that the
three domains may be plotted in separate regions within the two-dimensional
space where the axes are the skewness coefficient and the curtosis coefficient
of the aforementioned distribution. Preliminary results on 15 genomes are
introduced.

Models of the dynamics of cellular interaction networks have become
increasingly larger in recent years. Formal verification based on model
checking provides a powerful technology to keep up with this increase in scale
and complexity. The application of model-checking approaches is hampered,
however, by the difficulty for non-expert users to formulate appropriate
questions in temporal logic. In order to deal with this problem, we propose the
use of patterns, that is, high-level query templates that capture recurring
biological questions and that can be automatically translated into temporal
logic. The applicability of the developed set of patterns has been investigated
by the analysis of an extended model of the network of global regulators
controlling the carbon starvation response in Escherichia coli.

Combination therapies are often needed for effective clinical outcomes in the
management of complex diseases, but presently they are generally based on
empirical clinical experience. Here we suggest a novel application of search
algorithms, originally developed for digital communication, modified to
optimize combinations of therapeutic interventions. In biological experiments
measuring the restoration of the decline with age in heart function and
exercise capacity in Drosophila melanogaster, we found that search algorithms
correctly identified optimal combinations of four drugs with only one third of
the tests performed in a fully factorial search. In experiments identifying
combinations of three doses of up to six drugs for selective killing of human
cancer cells, search algorithms resulted in a highly significant enrichment of
selective combinations compared with random searches. In simulations using a
network model of cell death, we found that the search algorithms identified the
optimal combinations of 6-9 interventions in 80-90% of tests, compared with
15-30% for an equivalent random search. These findings suggest that modified
search algorithms from information theory have the potential to enhance the
discovery of novel therapeutic drug combinations. This report also helps to
frame a biomedical problem that will benefit from an interdisciplinary effort
and suggests a general strategy for its solution.

Any cutting-edge scientific research project requires a myriad of
computational tools for data generation, management, analysis and
visualization. Python is a flexible and extensible scientific programming
platform that offered the perfect solution in our recent comparative genomics
investigation (J. B. Lucks, D. R. Nelson, G. Kudla, J. B. Plotkin. Genome
landscapes and bacteriophage codon usage, PLoS Computational Biology, 4,
1000001, 2008). In this paper, we discuss the challenges of this project, and
how the combined power of Biopython, Matplotlib and SWIG were utilized for the
required computational tasks. We finish by discussing how python goes beyond
being a convenient programming language, and promotes good scientific practice
by enabling clean code, integration with professional programming techniques
such as unit testing, and strong data provenance.

Summary: In anticipation of the individualized proteomics era and the need to
integrate knowledge from disease studies, we have augmented our peptide
identification software RAId DbS to take into account annotated single amino
acid polymorphisms, post-translational modifications, and their documented
disease associations while analyzing a tandem mass spectrum. To facilitate new
discoveries, RAId DbS allows users to conduct searches permitting novel
polymorphisms. Availability: The webserver link is http://www.ncbi.nlm.nih.gov/
/CBBResearch/qmbp/raid dbs/index.html. The relevant databases and binaries of
RAId DbS for Linux, Windows, and Mac OS X are available from the same web page.
Contact: yyu@ncbi.nlm.nih.gov

Models of reaction chemistry based on the stochastic simulation algorithm
(SSA) have become a crucial tool for simulating complicated biological reaction
networks due to their ability to handle extremely complicated reaction networks
and to represent noise in small-scale chemistry. These methods can, however,
become highly inefficient for stiff reaction systems, those in which different
reaction channels operate on widely varying time scales. In this paper, we
develop two methods for accelerating sampling in SSA models: an exact method
and a scheme allowing for sampling accuracy up to any arbitrary error bound.
Both methods depend on analysis of the eigenvalues of continuous time Markov
model graphs that define the behavior of the SSA. We demonstrate these methods
for the specific application of sampling breakage times for multiply-connected
bond networks, a class of stiff system important to models of self-assembly
processes. We show theoretically and empirically that our eigenvalue methods
provide substantially reduced sampling times for a wide range of network
breakage models. These techniques are also likely to have broad use in
accelerating SSA models so as to apply them to systems and parameter ranges
that are currently computationally intractable.

Statistical inference of genetic regulatory networks is essential for
understanding temporal interactions of regulatory elements inside the cells.
For inferences of large networks, identification of network structure is
typical achieved under the assumption of sparsity of the networks.
  When the number of time points in the expression experiment is not too small,
we propose to infer the parameters in the ordinary differential equations using
the techniques from functional data analysis (FDA) by regarding the observed
time course expression data as continuous-time curves. For networks with a
large number of genes, we take advantage of the sparsity of the networks by
penalizing the linear coefficients with a L_1 norm. The ability of the
algorithm to infer network structure is demonstrated using the cell-cycle time
course data for Saccharomyces cerevisiae.

In Proteomics, only the de novo peptide sequencing approach allows a partial
amino acid sequence of a peptide to be found from a MS/MS spectrum. In this
article a preliminary work is presented to discover a complete protein sequence
from spectral data (MS and MS/MS spectra). For the moment, our approach only
uses MS spectra. A Genetic Algorithm (GA) has been designed with a new
evaluation function which works directly with a complete MS spectrum as input
and not with a mass list like the other methods using this kind of data. Thus
the mono isotopic peak extraction step which needs a human intervention is
deleted. The goal of this approach is to discover the sequence of unknown
proteins and to allow a better understanding of the differences between
experimental proteins and proteins from databases.

Some problems with the mathematical analysis on which the UK Non-Native
Organism Risk Assessment Scheme is based are outlined.

This report presents the implementation of a protein sequence comparison
algorithm specifically designed for speeding up time consuming part on parallel
hardware such as SSE instructions, multicore architectures or graphic boards.
Three programs have been developed: PLAST-P, TPLAST-N and PLAST-X. They provide
equivalent results compared to the NCBI BLAST family programs (BLAST-P,
TBLAST-N and BLAST-X) with a speed-up factor ranging from 5 to 10.

Information theory is a branch of probability and statistics involving the
analysis of communications. Information theory enables us to analyze and
quantify the information content of predictions made in the context of plant
disease management and related disciplines. In this article, some applications
of information theory in plant disease management are outlined.

The functioning of many biochemical networks is often robust -- remarkably
stable under changes in external conditions and internal reaction parameters.
Much recent work on robustness and evolvability has focused on the structure of
neutral spaces, in which system behavior remains invariant to mutations.
Recently we have shown that the collective behavior of multiparameter models is
most often 'sloppy': insensitive to changes except along a few 'stiff'
combinations of parameters, with an enormous sloppy neutral subspace.
Robustness is often assumed to be an emergent evolved property, but the
sloppiness natural to biochemical networks offers an alternative non-adaptive
explanation. Conversely, ideas developed to study evolvability in robust
systems can be usefully extended to characterize sloppy systems.

We review a recent trend in computational systems biology which aims at using
pattern recognition algorithms to infer the structure of large-scale biological
networks from heterogeneous genomic data. We present several strategies that
have been proposed and that lead to different pattern recognition problems and
algorithms. The strenght of these approaches is illustrated on the
reconstruction of metabolic, protein-protein and regulatory networks of model
organisms. In all cases, state-of-the-art performance is reported.

In this short note, we analyze the assumptions made by McDougal et al (2006),
both explicit and implicit, in their estimation of the proportion of "true
recent infections" using the BED CEIA. This enables us to write down
expressions for the sensitivity, short term specificity and long term
specificity of a test for recent infection defined by a BED ODn below a
threshold. We then derive an identity which shows the relationship between
these parameters, allowing the elimination of sensitivity and short term
specificity from an expression relating the proportion of "true recent
infections" to the proportion of seropositive individuals testing below
threshold. This has two important consequences. Firstly, the simplified formula
is substantially more amenable to calibration. Secondly, naively treating the
parameters as independent would lead to an incorrect estimate of uncertainty
due to imperfect calibration.

We provide a complete thermodynamic solution of a 1D hopping model in the
presence of a random potential by obtaining the density of states. Since the
partition function is related to the density of states by a Laplace transform,
the density of states determines completely the thermodynamic behavior of the
system. We have also shown that the transfer matrix technique, or the so-called
dynamic programming, used to obtain the density of states in the 1D hopping
model may be generalized to tackle a long-standing problem in statistical
significance assessment for one of the most important proteomic tasks - peptide
sequencing using tandem mass spectrometry data.

Statistically meaningful comparison/combination of peptide identification
results from various search methods is impeded by the lack of a universal
statistical standard. Providing an E-value calibration protocol, we
demonstrated earlier the feasibility of translating either the score or
heuristic E-value reported by any method into the textbook-defined E-value,
which may serve as the universal statistical standard. This protocol, although
robust, may lose spectrum-specific statistics and might require a new
calibration when changes in experimental setup occur. To mitigate these issues,
we developed a new MS/MS search tool, RAId_aPS, that is able to provide
spectrum-specific E-values for additive scoring functions. Given a selection of
scoring functions out of RAId score, K-score, Hyperscore and XCorr, RAId_aPS
generates the corresponding score histograms of all possible peptides using
dynamic programming. Using these score histograms to assign E-values enables a
calibration-free protocol for accurate significance assignment for each scoring
function. RAId_aPS features four different modes: (i) compute the total number
of possible peptides for a given molecular mass range, (ii) generate the score
histogram given a MS/MS spectrum and a scoring function, (iii) reassign
E-values for a list of candidate peptides given a MS/MS spectrum and the
scoring functions chosen, and (iv) perform database searches using selected
scoring functions. In modes (iii) and (iv), RAId_aPS is also capable of
combining results from different scoring functions using spectrum-specific
statistics. The web link is
http://www.ncbi.nlm.nih.gov/CBBresearch/Yu/raid_aps/index.html. Relevant
binaries for Linux, Windows, and Mac OS X are available from the same page.

Networks of person-person contacts form the substrate along which infectious
diseases spread. Most network-based studies of the spread focus on the impact
of variations in degree (the number of contacts an individual has). However,
other effects such as clustering, variations in infectiousness or
susceptibility, or variations in closeness of contacts may play a significant
role. We develop analytic techniques to predict how these effects alter the
growth rate, probability, and size of epidemics and validate the predictions
with a realistic social network. We find that (for given degree distribution
and average transmissibility) clustering is the dominant factor controlling the
growth rate, heterogeneity in infectiousness is the dominant factor controlling
the probability of an epidemic, and heterogeneity in susceptibility is the
dominant factor controlling the size of an epidemic. Edge weights (measuring
closeness or duration of contacts) have impact only if correlations exist
between different edges. Combined, these effects can play a minor role in
reinforcing one another, with the impact of clustering largest when the
population is maximally heterogeneous or if the closer contacts are also
strongly clustered. Our most significant contribution is a systematic way to
address clustering in infectious disease models, and our results have a number
of implications for the design of interventions.

The Tribolium genome contains 21 nuclear receptors, representing all of the
six known subfamilies. When compared to other species, this first complete set
for a Coleoptera reveals a strong conservation of the number and identity of
nuclear receptors in holometabolous insects. Two novelties are observed: the
atypical NR0 gene knirps is present only in brachyceran flies, while the NR2E6
gene is found only in Tribolium and in Apis. Using a quantitative analysis of
the evolutionary rate, we discovered that nuclear receptors could be divided
into two groups. In one group of 13 proteins, the rates follow the trend of the
Mecopterida genome-wide acceleration. In a second group of five nuclear
receptors, all acting together at the top of the ecdysone cascade, we observed
an overacceleration of the evolutionary rate during the early divergence of
Mecopterida. We thus extended our analysis to the twelve classic ecdysone
transcriptional regulators and found that six of them (ECR, USP, HR3, E75, HR4
and Kr-h1) underwent an overacceleration at the base of the Mecopterida
lineage. By contrast, E74, E93, BR, HR39, FTZ-F1 and E78 do not show this
divergence. We suggest that coevolution occurred within a network of regulators
that control the ecdysone cascade. The advent of Tribolium as a powerful model
should allow a better understanding of this evolution.

In this report we review modern nonlinearity methods that can be used in the
preterm birth analysis. The nonlinear analysis of uterine contraction signals
can provide information regarding physiological changes during the menstrual
cycle and pregnancy. This information can be used both for the preterm birth
prediction and the preterm labor control.
  Keywords: preterm birth, complex data analysis, nonlinear methods

Clustering is a concept used in a huge variety of applications. We review a
conceptually very simple algorithm for hierarchical clustering called in the
following the {\it mutual information clustering} (MIC) algorithm. It uses
mutual information (MI) as a similarity measure and exploits its grouping
property: The MI between three objects X, Y, and Z is equal to the sum of the
MI between X and Y, plus the MI between Z and the combined object (XY). We use
MIC both in the Shannon (probabilistic) version of information theory, where
the "objects" are probability distributions represented by random samples, and
in the Kolmogorov (algorithmic) version, where the "objects" are symbol
sequences. We apply our method to the construction of phylogenetic trees from
mitochondrial DNA sequences and we reconstruct the fetal ECG from the output of
independent components analysis (ICA) applied to the ECG of a pregnant woman.

We discuss the property of a.e. and in mean convergence of the Kohonen
algorithm considered as a stochastic process. The various conditions ensuring
the a.e. convergence are described and the connection with the rate decay of
the learning parameter is analyzed. The rate of convergence is discussed for
different choices of learning parameters. We proof rigorously that the rate of
decay of the learning parameter which is most used in the applications is a
sufficient condition for a.e. convergence and we check it numerically. The aim
of the paper is also to clarify the state of the art on the convergence
property of the algorithm in view of the growing number of applications of the
Kohonen neural networks. We apply our theorem and considerations to the case of
genetic classification which is a rapidly developing field.

We propose that certain patterns (scars) -- theoretically and numerically
predicted to be formed by electrons arranged on a sphere to minimize the
repulsive Coulomb potential (the Thomson problem) and experimentally found in
spherical crystals formed by self-assembled polystyrene beads (an instance of
the {\it generalized} Thomson problem) -- could be relevant to extend the
classic Caspar and Klug construction for icosahedrally-shaped virus capsids.
The main idea is that scars could be produced on the capsid at an intermediate
stage of its evolution and the release of the bending energy present in scars
into stretching energy could allow for shape-changes. The conjecture can be
tested in experiments and/or in numerical simulations.

We apply Markov chain lumping techniques to aggregate codons from an
empirical substitution matrix. The standard genetic code as well as higher
order amino acid substitution groups are identified. Since the aggregates are
derived from first principles they do not rely on system dependent assumptions
made beforehand, e.g. regarding criteria on what should constitute an amino
acid group. We therefore argue that the acquired aggregations more accurately
capture the multi-level structure of the substitution dynamics than alternative
techniques.

We apply the concept of subset seeds proposed in [1] to similarity search in
protein sequences. The main question studied is the design of efficient seed
alphabets to construct seeds with optimal sensitivity/selectivity trade-offs.
We propose several different design methods and use them to construct several
alphabets.We then perform an analysis of seeds built over those alphabet and
compare them with the standard Blastp seeding method [2,3], as well as with the
family of vector seeds proposed in [4]. While the formalism of subset seed is
less expressive (but less costly to implement) than the accumulative principle
used in Blastp and vector seeds, our seeds show a similar or even better
performance than Blastp on Bernoulli models of proteins compatible with the
common BLOSUM62 matrix.

Molecular docking is an essential tool for drug design. It helps the
scientist to rapidly know if two molecules, respectively called ligand and
receptor, can be combined together to obtain a stable complex. We propose a new
multi-objective model combining an energy term and a surface term to gain such
complexes. The aim of our model is to provide complexes with a low energy and
low surface. This model has been validated with two multi-objective genetic
algorithms on instances from the literature dedicated to the docking
benchmarking.

Recent advances in experimental neuroscience allow, for the first time,
non-invasive studies of the white matter tracts in the human central nervous
system, thus making available cutting-edge brain anatomical data describing
these global connectivity patterns. This new, non-invasive, technique uses
magnetic resonance imaging to construct a snap-shot of the cortical network
within the living human brain. Here, we report on the initial success of a new
weighted network communicability measure in distinguishing local and global
differences between diseased patients and controls. This approach builds on
recent advances in network science, where an underlying connectivity structure
is used as a means to measure the ease with which information can flow between
nodes. One advantage of our method is that it deals directly with the
real-valued connectivity data, thereby avoiding the need to discretise the
corresponding adjacency matrix, that is, to round weights up to 1 or down to 0,
depending upon some threshold value. Experimental results indicate that the new
approach is able to highlight biologically relevant features that are not
immediately apparent from the raw connectivity data.

An approach for multiplex qualitative and quantitative microarray-based PCR
analysis has been proposed. The characteristics of PCR executed on a gel-based
oligonucleotide microarray with immobilized forward primers and a single common
reverse primer in solution were investigated for several DNA targets. One-stage
multiplex on-chip PCR was studied for simultaneous amplification of herpes
simplex viruses types 1 and 2, cytomegalovirus DNA, and bacteriophage lambda
DNA as an internal control. Additionally the joint analysis of increased number
of targets (with addition of Chlamydia trachomatis, Mycoplasma hominis, and
Ureaplasma urealyticum DNA) was done in two-stage version of assay: first stage
was in-tube PCR with target-specific primers, while the reverse ones contained
5'-adapter region; the second stage was on-chip amplification with immobilized
target-specific forward primers and adapter as common reverse primer in
solution. The possible application of one-stage reaction for human cDNA
analysis was additionally demonstrated with utilization of a common
poly-T-containing primer in solution. SYBR green I; and Cy-5 labeled dUTP were
used for real-time and end-point detection of specific PCR products. The
efficiencies of both one-stage and two-stage reactions was shown to be strongly
dependent on magnesium and primers concentrations. Quantitative PCR in the both
versions was studied with 10-fold serial dilutions of phage lambda DNA. The
method enabled detection of 6 DNA copies per reaction for both versions of
assay. The quantitative interval for one-stage reaction covered eight orders of
concentration. The revealed significant effect of gel pad size on microarray
PCR effectiveness has been discussed.

The Automated Protein Structure Analysis (APSA) method is used for the
classification of supersecondary structures. Basis for the classification is
the encoding of three-dimensional (3D) residue conformations into a 16-letter
code (3D-1D projection). It is shown that the letter code of the protein makes
it possible to reconstruct its overall shape without ambiguity (1D-3D
translation). Accordingly, the letter code is used for the development of
classification rules that distinguish supersecondary structures by the
properties of their turns and the orientation of the flanking helix or strand
structures. The orientations of turn and flanking structures are collected in
an octant system that helps to specify 196 supersecondary groups for
(alpha,alpha)-, (alpha,beta)-, (beta,alpha)-, (beta,beta)-class. 391 protein
chains leading to 2499 super secondary structures were analyzed. Frequently
occurring super secondary structures are identified with the help of the octant
classification system and explained on the basis of their letter and
classification codes.

A new method for the Automated Protein Structure Analysis (APSA) is derived,
which simplifies the protein backbone to a smooth curve in 3-dimensional space.
For the purpose of obtaining this smooth line each amino acid is represented by
its C$_{\alpha}$ atom, which serves as suitable anchor point for a cubic spline
fit. The backbone line is characterized by arc length $s$, curvature
$\kappa(s)$, and torsion $\tau(s)$. The $\kappa(s)$ and $\tau(s)$ diagrams of
the protein backbone suppress, because of the level of coarse graining applied,
details of the bond framework of the backbone, however reveal accurately all
secondary structure features of a protein. Advantages of APSA are its
quantitative representation and analysis of 3-dimensional structure in form of
2-dimensional curvature and torsion patterns, its easy visualization of
complicated conformational features, and its general applicability. Typical
differences between 3$_{10}$-,$\alpha$-, $\pi$-helices, and $\beta$-strands are
quantified with the help of the $\kappa(s)$ and $\tau(s)$ diagrams. For a test
set of 20 proteins, 63 % of all helical residues and 48.5 % of all extended
residues are identified to be in ideal conformational environments with the
help of APSA. APSA is compared with other methods for protein structure
analysis and its applicability to higher levels of protein structure is
discussed.

We have investigated the binding interaction between the bacteriophage lambda
repressor CI and its target DNA using total internal reflection fluorescence
microscopy. Large, step-wise changes in the intensity of the red fluorescent
protein fused to CI were observed as it associated and dissociated from
individually labeled single molecule DNA targets. The stochastic association
and dissociation were characterized by Poisson statistics. Dark and bright
intervals were measured for thousands of individual events. The exponential
distribution of the intervals allowed direct determination of the association
and dissociation rate constants, ka and kd respectively. We resolved in detail
how ka and kd varied as a function of 3 control parameters, the DNA length L,
the CI dimer concentration, and the binding affinity. Our results show that
although interaction with non-operator DNA sequences are observable, CI binding
to the operator site is not dependent on the length of flanking non-operator
DNA.

This note studies feedforward circuits as models for perfect adaptation to
step signals in biological systems. A global convergence theorem is proved in a
general framework, which includes examples from the literature as particular
cases. A notable aspect of these circuits is that they do not adapt to pulse
signals, because they display a memory phenomenon. Estimates are given of the
magnitude of this effect.

This article is addressing a recurrent problem in biology: mining newly built
large scale networks. Our approach consists in comparing these new networks to
well known ones. The visual backbone of this comparative analysis is provided
by a network classification hierarchy. This method makes sense when dealing
with metabolic networks since comparison could be done using pathways
(clusters). Moreover each network models an organism and it exists organism
classification such as taxonomies. Video demonstration:
http://www.labri.fr/perso/bourqui/video.wmv

Random Threshold Networks (RTNs) are an idealized model of diluted, non
symmetric spin glasses, neural networks or gene regulatory networks. RTNs also
serve as an interesting general example of any coordinated causal system. Here
we study the conditions for maximal information transfer and behavior diversity
in RTNs. These conditions are likely to play a major role in physical and
biological systems, perhaps serving as important selective traits in biological
systems. We show that the pairwise mutual information is maximized in
dynamically critical networks. Also, we show that the correlated behavior
diversity is maximized for slightly chaotic networks, close to the critical
region. Importantly, critical networks maximize coordinated, diverse dynamical
behavior across the network and across time: the information transmission
between source and receiver nodes and the diversity of dynamical behaviors,
when measured with a time delay between the source and receiver, are maximized
for critical networks.


This is a missing chapter from Hans Magnus Enzensberger's mathematical
adventure The Number Devil (Henry Holt and Company, New York, 1997). In the
book, a math-hating boy named Robert is visited in his dreams by the clever
Number Devil, who teaches him to love all things numerical. However, we all
forget our dreams from time to time. Here is one adventure that Enzensberger
overlooked, where the Number Devil introduces Robert to geometry not-of-Euclid,
great circles, parallel transport, the pendulum of Foucault, and the genius of
Euler.

In the stability analysis of an equilibrium, given by a stationary point of a
functional F[n] (free energy functional, e.g.), the second derivative of F[n]
plays the essential role. If the system in equilibrium is subject to the
conservation constraint of some extensive property (e.g. volume, material, or
energy conservation), the Euler equation determining the stationary point
corresponding to the equilibrium alters according to the method of Lagrange
multipliers. Here, the question as to how the effects of constraints can be
taken into account in a stability analysis based on second functional
derivatives is examined. It is shown that the concept of constrained second
derivatives incorporates all the effects due to constraints; therefore
constrained second derivatives provide the proper tool for the stability
analysis of equilibria under constraints. For a physically important type of
constraints, it is demonstrated how the presented theory works. Further, the
rigorous derivation of a recently obtained stability condition for a special
case of equilibrium of ultrathin-film binary mixtures is given, presenting a
guide for similar analyses. [For details on constrained derivatives, see also
math-ph/0603027, physics/0603129, physics/0701145.]

Quantum mechanics is difficult to learn because it is counterintuitive, hard
to visualize, mathematically challenging, and abstract. The Physics Education
Technology (PhET) Project, known for its interactive computer simulations for
teaching and learning physics, now includes 18 simulations on quantum mechanics
designed to improve learning of this difficult subject. Our simulations include
several key features to help students build mental models and intuitions about
quantum mechanics: visual representations of abstract concepts and microscopic
processes that cannot be directly observed, interactive environments that
directly couple students' actions to animations, connections to everyday life,
and efficient calculations so students can focus on the concepts rather than
the math. Like all PhET simulations, these are developed using the results of
education research and feedback from educators, and are tested in student
interviews and classroom studies. This article provides an overview of the PhET
quantum simulations and their development. We also describe research
demonstrating their effectiveness and share some insights about student
thinking that we have gained from our research on quantum simulations.

Daganzo's criticisms of second-order fluid approximations of traffic flow [C.
Daganzo, Transpn. Res. B. 29, 277-286 (1995)] and Aw and Rascle's proposal how
to overcome them [A. Aw and M. Rascle, SIAM J. Appl. Math. 60, 916-938 (2000)]
have stimulated an intensive scientific activity in the field of traffic
modeling. Here, we will revisit their arguments and the interpretations behind
them. We will start by analyzing the linear stability of traffic models, which
is a widely established approach to study the ability of traffic models to
describe emergent traffic jams. Besides deriving a collection of useful
formulas for stability analyses, the main attention is put on the
characteristic speeds, which are related to the group velocities of the
linearized model equations. Most macroscopic traffic models with a dynamic
velocity equation appear to predict two characteristic speeds, one of which is
faster than the average velocity. This has been claimed to constitute a
theoretical inconsistency. We will carefully discuss arguments for and against
this view. In particular, we will shed some new light on the problem by
comparing Payne's macroscopic traffic model with the Aw-Rascle model and
macroscopic with microscopic traffic models.

Boussinesq systems of nonlinear partial differential equations are
fundamental equations in geophysical fluid dynamics. In this paper, we use
asymmetric ideas and moving frames to solve the two-dimensional Boussinesq
equations with partial viscosity terms studied by Chae ({\it Adv. Math.} {\bf
203} (2006), 497-513) and the three-dimensional stratified rotating Boussinesq
equations studied by Hsia, Ma and Wang ({\it J. Math. Phys.} {\bf 48} (2007),
no. 6, 06560). We obtain new families of explicit exact solutions with multiple
parameter functions. Many of them are the periodic, quasi-periodic, aperiodic
solutions that may have practical significance. By Fourier expansion and some
of our solutions, one can obtain discontinuous solutions. In addition, Lie
point symmetries are used to simplify our arguments.

We study a simple reaction-diffusion population model [proposed by A. Windus
and H. J. Jensen, J. Phys. A: Math. Theor. 40, 2287 (2007)] on scale-free
networks. In the case of fully random diffusion, the network topology cannot
affect the critical death rate, whereas the heterogeneous connectivity can
cause smaller steady population density and critical population density. In the
case of modified diffusion, we obtain a larger critical death rate and steady
population density, at the meanwhile, lower critical population density, which
is good for the survival of species. The results were obtained using a
mean-field-like framework and were confirmed by computer simulations.

A special version of multi--dimensional simple waves given in [G. Boillat,
{\it J. Math. Phys.} {\bf 11}, 1482-3 (1970)] and [G.M. Webb, R. Ratkiewicz, M.
Brio and G.P. Zank, {\it J. Plasma Phys.} {\bf 59}, 417-460 (1998)] is employed
for fully relativistic fluid and plasma flows. Three essential modes: vortex,
entropy and sound modes are derived where each of them is different from its
nonrelativistic analogue. Vortex and entropy modes are formally solved in both
the laboratory frame and the wave frame (co-moving with the wave front) while
the sound mode is formally solved only in the wave frame at ultra-relativistic
temperatures. In addition, the surface which is the boundary between the
permitted and forbidden regions of the solution is introduced and determined.
Finally a symmetry analysis is performed for the vortex mode equation up to
both point and contact transformations. Fundamental invariants and a form of
general solutions of point transformations along with some specific examples
are also derived.

We analyze the low-energy e-N2 collisions within the framework of the
Modified-Effective Range Theory (MERT) for the long-range potentials, developed
by O'Malley, Spruch and Rosenberg [Journal of Math. Phys. 2, 491 (1961)]. In
comparison to the traditional MERT we do not expand the total cross-section in
the series of the incident momentum \hbar k, but instead we apply the exact
analytical solutions of the Schroedinger equation for the long-range
polarization potential, as proposed in the original formulation of O'Malley et
al. This extends the applicability of MERT up to few eV regime, as we confirm
using some simplified model potential of the electron-molecule interaction. The
parameters of the effective-range expansion (i.e. the scattering length and the
effective range) are determined from experimental, integral elastic cross
sections in the 0.1 - 1.0 eV energy range by fitting procedure. Surprisingly,
our treatment predicts a shape resonance that appears slightly higher than
experimentally well known resonance in the total cross section. Agreement with
the experimentally observed shape-resonance can be improved by assuming the
position of the resonance in a given partial wave. Influence of the quadrupole
potential on resonances is also discussed: we show that it can be disregarded
for N2. In conclusion, the modified-effective range formalism treating the
long-range part of the potential in an exact way, reproduces well both the very
low-energy behavior of the integral cross section as well as the presence of
resonances in the few eV range.

A self-focusing of a coasting relativistic beam in a plasma channel that is
confined by an external magnetic field is studied as a means of reconditioning
the beam emerging from a beam injector [a radio frequency quadrupole (RFQ)] for
a linac. A detailed study of the beam stability in the self-focused beam has
been carried out. In order to explain beam filaments and the resistive hose
instability in a unified way, we treat all the azimuthal modes in the
derivation of the dispersion relation in a finite plasma channel that exhibit
many unstable modes, which are classified by Weinberg's scheme [Steven
Weinberg, J. Math. 8, 614 (1967)].

We present and analyze a penalization method wich extends the the method of
[1] to the case of a rigid body moving freely in an incompressible fluid. The
fluid-solid system is viewed as a single variable density flow with an
interface captured by a level set method. The solid velocity is computed by
averaging at avery time the flow velocity in the solid phase. This velocity is
used to penalize the flow velocity at the fluid-solid interface and to move the
interface. Numerical illustrations are provided to illustrate our convergence
result. A discussion of our result in the light of existing existence results
is also given. [1] Ph. Angot, C.-H. Bruneau and P. Fabrie, A penalization
method to take into account obstacles in incompressible viscous flows, Numer.
Math. 81: 497--520 (1999)

A unified energy principle approach is presented for analysing the
magnetohydrodynamic (MHD) stability of plasmas consisting of multiple ideal and
relaxed regions. By choosing an appropriate gauge, we show that the plasma
displacement satisfies the same Euler-Lagrange equation in ideal and relaxed
regions, except in the neighbourhood of magnetic surfaces. The difference at
singular surfaces is analysed in cylindrical geometry: in ideal MHD only
Newcomb's [W. A. Newcomb (2006) Ann. Phys., 10, 232] small solutions are
allowed, whereas in relaxed MHD only the odd-parity large solution and
even-parity small solution are allowed. A procedure for constructing global
multi-region solutions in cylindrical geometry is presented. Focussing on the
limit where the two interfaces approach each other arbitrarily closely, it is
shown that the singular-limit problem encountered previously [M.J. Hole et al.
(2006) J. Plasma Phys., 77, 1167] in multi-region relaxed MHD is stabilised if
the relaxed-MHD region between the coalescing interfaces is replaced by an
ideal-MHD region. We then present a stable (k, pressure) phase space plot,
which allows us to determine the form a stable pressure and field profile must
take in the region between the interfaces. From this knowledge, we conclude
that there exists a class of single interface plasmas that were found stable by
Kaiser and Uecker [R. Kaiser et al (2004) Q. Jl Mech. Appl. Math., 57, 1], but
are shown to be unstable when the interface is resolved.

This article is the continued version of the analytical solutions for the
pressureless Navier-Stokes equations with density-dependent viscosity in "M.W.
Yuen, Analyitcal Solutions to the Navier-Stokes Equations, J. Math. Phys., 49
(2008) No. 11, 113102, 10pp". We are able to extend the similar solutions
structure to the case with pressure under some restriction for $\gamma$ and
$\theta$.

We point out that the {\em spacetime void} inferred by Castro[J. Math. Phys.
49, 042501, (2008)] results from his choice of a discontinuous radial gauge.
Further since the integration constant $\alpha_0 = 2M_0$ ($G=c=1$) occurring in
the vacuum Hilbert/Schwarzschild solution of a neutral "point mass" is zero
[Arnowitt et al., in Gravitation: An Introduction to Current Research, ed. L.
Witten, Wiley, Chap. 7, p.227; also Phys. Rev. Lett., 4, 375, (1960)]; A.
Mitra, Adv. Sp. Res., 38, 2917 (2006)] Castro's gauge reduces to the well
behaved and physical Hilbert gauge. Physically this means that true
Hilbert/Schwarzschild black holes have unique gravitational mass M=0.
Accordingly, the unphysical {\em spacetime viod} inferred by Castro is actually
non-existent.

This work is directed towards investigating the fate of three-dimensional
long perturbation waves in a plane incompressible wake. The analysis is posed
as an initial-value problem in space. More specifically, input is made at an
initial location in the downstream direction and then tracing the resulting
behavior further downstream subject to the restriction of finite kinetic
energy. This presentation follows the outline given by Criminale and Drazin
[Stud. in Applied Math. \textbf{83}, 123 (1990)] that describes the system in
terms of perturbation vorticity and velocity. The analysis is based on large
scale waves and expansions using multi scales and multi times for the partial
differential equations. The multiscaling is based on an approach where the
small parameter is linked to the perturbation property independently from the
flow control parameter. Solutions of the perturbative equations are determined
numerically after the introduction of a regular perturbation scheme
analytically deduced up to the second order. Numerically, the complete linear
system is also integrated. Since the results relevant to the complete problem
are in very good agreement with the results of the first order analysis, the
numerical solution at the second order was deemed not necessary. The use for an
arbitrary initial-value problem will be shown to contain a wealth of
information for the different transient behaviors associated to the symmetry,
angle of obliquity and spatial decay of the long waves. The amplification
factor of transversal perturbations never presents the trend - a growth
followed by a long damping - usually seen in waves with wavenumber of order one
or less. Asymptotical instability is always observed.

In some recent works [G. Dimarco, L. Pareschi, Hybrid multiscale methods I.
Hyperbolic Relaxation Problems, Comm. Math. Sci., 1, (2006), pp. 155-177], [G.
Dimarco, L. Pareschi, Hybrid multiscale methods II. Kinetic equations, SIAM
Multiscale Modeling and Simulation Vol 6., No 4,pp. 1169-1197, (2008)] we
developed a general framework for the construction of hybrid algorithms which
are able to face efficiently the multiscale nature of some hyperbolic and
kinetic problems. Here, at variance with respect to the previous methods, we
construct a method form-fitting to any type of finite volume or finite
difference scheme for the reduced equilibrium system. Thanks to the coupling of
Monte Carlo techniques for the solution of the kinetic equations with
macroscopic methods for the limiting fluid equations, we show how it is
possible to solve multiscale fluid dynamic phenomena faster with respect to
traditional deterministic/stochastic methods for the full kinetic equations. In
addition, due to the hybrid nature of the schemes, the numerical solution is
affected by less fluctuations when compared to standard Monte Carlo schemes.
Applications to the Boltzmann-BGK equation are presented to show the
performance of the new methods in comparison with classical approaches used in
the simulation of kinetic equations.

In this work we study the hemodynamics in a stented artery connected either
to a collateral artery or to an aneurysmal sac. The blood flow is driven by the
pressure drop. Our aim is to characterize the flow-rate and the pressure in the
contiguous zone to the main artery: using boundary layer theory we construct a
homogenized first order approximation with respect to epsilon, the size of the
stent's wires. This provides an explicit expression of the velocity profile
through and along the stent. The profile depends only on the input/output
pressure data of the problem and some homogenized constant quantities: it is
explicit. In the collateral artery this gives the flow-rate. In the case of the
aneurysm, it shows that : (i) the zeroth order term of the pressure in the sac
equals the averaged pressure along the stent in the main artery, (ii) the
presence of the stent inverses the rotation of the vortex. Extending the tools
set up in [Bonnetier et al, Adv. Math. Fluids, 2009, Milisic, Meth. Apl. Ann.,
2009] we prove rigorously that our asymptotic approximation is first order
accurate with respect to . We derive then new implicit interface conditions
that our approximation formally satisfies, generalizing our analysis to other
possible geometrical configurations. In the last part we provide numerical
results that illustrate and validate the theoretical approach.

We show that the exact integrator for the classical Kepler motion, recently
found by Kozlov ({\it J. Phys. A: Math. Theor.\} {\bf 40} (2007) 4529-4539),
can be derived in a simple natural way (using well known exact discretization
of the harmonic oscillator). We also turn attention on important earlier
references, where the exact discretization of the 4-dimensional isotropic
harmonic oscillator has been applied to the perturbed Kepler problem.

Expansion of a wave function in a basis of eigenfunctions of a differential
eigenvalue problem lies at the heart of the R-matrix methods for both the
Schr\"odinger and Dirac particles. A central issue that should be carefully
analyzed when functional series are applied is their convergence. In the
present paper, we study the properties of the eigenfunction expansions
appearing in nonrelativistic and relativistic $R$-matrix theories. In
particular, we confirm the findings of Rosenthal [J. Phys. G: Nucl. Phys. 13,
491 (1987)] and Szmytkowski and Hinze [J. Phys. B: At. Mol. Opt. Phys. 29, 761
(1996); J. Phys. A: Math. Gen. 29, 6125 (1996)] that in the most popular
formulation of the R-matrix theory for Dirac particles, the functional series
fails to converge to a claimed limit.

In one of the very few exact quantum mechanical calculations of fugacity
coefficients, Dodd and Gibbs (\textit{J. Math.Phys}.,\textbf{15}, 41 (1974))
obtained $b_{2}$ and $b_{3}$ for a one dimensional Bose gas, subject to
repulsive delta-function interactions, by direct integration of the wave
functions. For $b_{2}$, we have shown (\textit{Mol. Phys}.,\textbf{103}, 1301
(2005)) that Dodd and Gibbs' result can be obtained from a phase shift
formalism, if one also includes the contribution of oscillating terms, usually
contributing only in 1 dimension. Now, we develop an exact expression for
$b_{3}-b_{3}^{0}$ (where $b_{3}^{0}$ is the free particle fugacity coefficient)
in terms of sums and differences of 3-body eigenphase shifts. Further, we show
that if we obtain these eigenphase shifts in a distorted-Born approximation,
then, to first order, we reproduce the leading low temperature behaviour,
obtained from an expansion of the two-fold integral of Dodd and Gibbs. The
contributions of the oscillating terms cancel. The formalism that we propose is
not limited to one dimension, but seeks to provide a general method to obtain
virial coefficients, fugacity coefficients, in terms of asymptotic quantities.
The exact one dimensional results allow us to confirm the validity of our
approach in this domain.

In this paper we propose an alternative approach for the assessment of
network vulnerability under random and intentional attacks as compared to the
results obtained from the "vulnerability function" given by Criado et al.
[Criado et al. (Int. J. Comput. Math., 86 (2) (2009), pp. 209-218)]. By using
spectral and statistical measurements, we assess robustness as the antonym to
vulnerability of complex networks and suggest a tentative ranking for
vulnerability, based on the interpretation of quantified network
characteristics. We conclude that vulnerability function, derived from the
network's degree distribution and its variations only, is not general enough to
reflect the lack of robustness due to the specific configurations in graphs
with hierarchical or centralized structures. The spectral and statistical
metrics, on the other hand, capture different aspects of network topology which
provide a more thorough assessment of network vulnerability.

For the first time the kinetic description of Landau diamagnetism for
degenerate collisional plasma is given. The correct expression for transverse
electric conductivity of the quantum plasma, found by authors (see
arXiv:1002.1017 [math-ph] 4 Feb 2010) is used. In work S. Dattagupta, A.M.
Jayannavar and N. Kumar [Current science, V. 80, No. 7, 10 April, 2001] was
discussed the important problem of dissipation (collisions) influence on Landau
diamagnetism. The analysis of this problem is given with the use of exact
expression for transverse conductivity of quantum plasma.

The Fast Multipole Method (FMM) is well known to possess a bottleneck arising
from decreasing workload on higher levels of the FMM tree [Greengard and Gropp,
Comp. Math. Appl., 20(7), 1990]. We show that this potential bottleneck can be
eliminated by overlapping multipole and local expansion computations with
direct kernel evaluations on the finest level grid.

Dynamics of a randomly-perturbed quantum system with 3/2-degrees of freedom
is considered. We introduce a transfer operator being the quantum analogue of
the specific Poincar\'e map. This map was proposed in (Makarov, Uleysky, J.
Phys. A: Math. Gen., 2006) for exploring domains of finite-time stability,
which survive under random excitation. Our attention is concentrated on level
spacing distribution of the transfer operator, averaged over ensemble of
realizations. The problem of sound propagation in an oceanic waveguide is
considered as an example. For the acoustic frequency of 200 Hz, level spacing
distribution undergoes the crossover from Poissonian to Wigner-like statistics
with increasing time, as it is consistent with classical predictions via the
specific Poincar\'e map. For the frequency of 600 Hz, the level spacing
statistics becomes non-universal due to large number of nearly-degenerate
levels whose contribution grows with time. Occurrence of nearly-degenerate
levels is attributed to bifurcations of classical periodic orbits, caused by
fast spatial oscillations of the random perturbation.

Research of influence of collisions on Friedel oscillations in quantum
degenerate collisional plasma (T=0) is carried out for the first time. It is
shown that presence of collisions in plasma leads to exponential decreasing of
amplitude and phase shift of the Friedel oscillations. In linear approximation
the phase shift is equal to the half of quantity inverse to product of Fermi's
wave number by free length path of electrons. The correct expression for
longitudinal dielectric permeability of the quantum collisional plasma found by
the authors (see arxiv:1001.3937 [math-ph] 22 Jan 2010) is used.

An Horizontal Visibility Graph (for short, HVG) is defined in association
with an ordered set of non-negative reals. HVGs realize a methodology in the
analysis of time series, their degree distribution being a good discriminator
between randomness and chaos [B. Luque, et al., Phys. Rev. E 80 (2009),
046103]. We prove that a graph is an HVG if and only if outerplanar and has a
Hamilton path. Therefore, an HVG is a noncrossing graph, as defined in
algebraic combinatorics [P. Flajolet and M. Noy, Discrete Math., 204 (1999)
203-229]. Our characterization of HVGs implies a linear time recognition
algorithm. Treating ordered sets as words, we characterize subfamilies of HVGs
highlighting various connections with combinatorial statistics and introducing
the notion of a visible pair. With this technique we determine asymptotically
the average number of edges of HVGs.

We argue that there is a fundamental problem regarding the analysis that
serves as the foundation for the papers {\it Information theory explanation of
the fluctuation theorem, maximum entropy production and self-organized
criticality in non-equilibrium stationary states} [R. Dewar, J. Phys. A: Math.
Gen. {\bf 36} (2003), 631-641] and {\it Maximum entropy production and the
fluctuation theorem} [R. Dewar, J. Phys. A: Math. Gen. {\bf 38} (2005),
L371-L381]. In particular, we demonstrate that this analysis is based on an
assumption that is physically unrealistic and that, hence, the results obtained
in those papers cannot be regarded as physically meaningful.

A paradigm based on the absolute equilibrium of Galerkin-truncated inviscid
systems to aid in understanding turbulence [T.-D. Lee, "On some statistical
properties of hydrodynamical and magnetohydrodynamical fields," Q. Appl. Math.
10, 69 (1952)] is taken to study gyrokinetic plasma turbulence: A finite set of
Fourier modes of the collisionless gyrokinetic equations are kept and the
statistical equilibria are calculated; possible implications for plasma
turbulence in various situations are discussed. For the case of two spatial and
one velocity dimension, in the calculation with discretization also of velocity
$v$ with $N$ grid points (where $N+1$ quantities are conserved, corresponding
to an energy invariant and $N$ entropy-related invariants), the negative
temperature states, corresponding to the condensation of the generalized energy
into the lowest modes, are found. This indicates a generic feature of inverse
energy cascade. Comparisons are made with some classical results, such as those
of Charney-Hasegawa-Mima in the cold-ion limit. There is a universal shape for
statistical equilibrium of gyrokinetics in three spatial and two velocity
dimensions with just one conserved quantity. Possible physical relevance to
turbulence, such as ITG zonal flows, and to a critical balance hypothesis are
also discussed.

By applying Birkhoff's theorem to the problem of the general relativistic
collapse of a uniform density dust, we directly show that the density of the
dust $\rho=0$ even when its proper number density $n$ would be assumed to be
finite! The physical reason behind this exact result can be traced back to the
observation of Arnowitt et al. that the gravitational mass of a neutral point
particle is zero: $m=0$ (PRL, 4, 375, 1960). And since, a dust is a mere
collection of {\em neutral point particles, unlike a continuous hydrodynamic
fluid}, its density $\rho = m n=0$. It is nonetheless found that for $k=-1$, a
homogeneous dust can collapse and expand special relativistically in the
fashion of a Milne universe. Thus, in reality, general relativistic homogeneous
dust collapse does not lead to the formation of any black hole in conformity of
many previous studies (Logunov, Mestverishvili, Kiselev, Phys.Part.Nucl. 37,
317, 2006; Kisevev, Logunov & Mestvirishvili, Theor. Math. Phys., 164, 972,
2010; Mitra, J. Math. Phys. 50, 042502, 2009; Suggett, J. Phys. A, 12, 375
1979).
  Interestingly, this result is in agreement with the intuition of Oppenheimer
& Snyder (Phys. Rev. 56, p.456, 1939) too:
  "Physically such a singularity would mean that the expressions used for the
energy-momentum tensor does not take into account some essential physical fact
which would really smooth the singularity out. Further, a star in its early
stages of development would not possess a singular density or pressure, it is
impossible for a singularity to develop in a finite time."

The purpose of the present paper is to study the influence of wall-echo on
pressure fluctuations $p'$, and on statistical correlations containing $p'$,
{\em viz} redistribution $\phi_{ij}$, pressure diffusion $d_{ij}^{(p)}$, and
velocity/pressure-gradient $\Pi_{ij}$. We extend the usual analysis of
turbulent correlations containing pressure fluctuations in wall-bounded
\tsc{dns} computations [Kim J.: {\em J. Fluid Mech.} {\bf 205} (1989)
421--451], separating $p'$ not only into rapid $p_{(\mathrm{r})}'$ and slow
$p_{(\mathrm{s})}'$ parts [Chou P.Y.: {\em Quart. Appl. Math.} {\bf 3} (1945)
38--54], but further into volume ($p'_{(\mathrm{r};\mathfrak{V})}$ and
$p'_{(\mathrm{s};\mathfrak{V})}$) and surface (wall-echo; $p'_{(\mathrm{r};w)}$
and $p'_{(\mathrm{s};w)}$) terms. An algorithm, based on a Green's function
approach, is developed to compute the above splittings for various correlations
containing pressure fluctuations (redistribution, pressure diffusion,
velocity/pressure-gradient), in fully developed turbulent plane channel flow.
This exact analysis confirms previous results based on a method-of-images
approximation [Manceau R., Wang M., Laurence D.: {\em J. Fluid Mech.} {\bf 438}
(2001) 307--338] showing that, at the wall, $p'_{(\mathfrak{V})}$ and
$p'_{(w)}$ are usually of the same sign and approximately equal. The above
results are then used to study the contribution of each mechanism on the
pressure correlations in low Reynolds-number plane channel flow, and to discuss
standard second-moment-closure modelling practices.

In several applications, such as \tsc{weno} interpolation and reconstruction
[Shu C.W.: SIAM Rev. 51 (2009) 82--126], we are interested in the analytical
expression of the weight-functions which allow the representation of the
approximating function on a given stencil (Chebyshev-system) as the weighted
combination of the corresponding approximating functions on substencils
(Chebyshev-subsystems). We show that the weight-functions in such
representations [M\"uhlbach G.: Num. Math. 31 (1978) 97--110] can be generated
by a general recurrence relation based on the existence of a 1-level
subdivision rule. As an example of application we apply this recurrence to the
computation of the weight-functions for Lagrange interpolation [Carlini E.,
Ferretti R., Russo G.: SIAM J. Sci. Comp. 27 (2005) 1071--1091] for a general
subdivision of the stencil ${x_{i-M_-},...,x_{i+M_+}}$ of $M+1:=M_-+M_++1$
distinct ordered points into $K_\mathrm{s}+1\leq M:=M_-+M_+>1$ (Neville)
substencils ${x_{i-M_-+k_\mathrm{s}},...,x_{i+M_+-K_\mathrm{s}+k_\mathrm{s}}}$
($k_\mathrm{s}\in{0,...,K_\mathrm{s}}$) all containing the same number of
$M-K_\mathrm{s}+1$ points but each shifted by 1 cell with respect to its
neighbour, and give a general proof for the conditions of positivity of the
weight-functions (implying convexity of the combination), extending previous
results obtained for particular stencils and subdvisions [Liu Y.Y., Shu C.W.,
Zhang M.P.: Acta Math. Appl. Sinica 25 (2009) 503--538]. Finally, we apply the
recurrence relation to the representation by combination of substencils of
derivatives of arbitrary order of the Lagrange interpolating polynomial.

The Lagrange reconstructing polynomial [Shu C.W.: {\em SIAM Rev.} {\bf 51}
(2009) 82--126] of a function $f(x)$ on a given set of equidistant ($\Delta
x=\const$) points $\bigl\{x_i+\ell\Delta x;\;\ell\in\{-M_-,...,+M_+\}\bigr\}$
is defined [Gerolymos G.A.: {\em J. Approx. Theory} {\bf 163} (2011) 267--305]
as the polynomial whose sliding (with $x$) averages on $[x-\tfrac{1}{2}\Delta
x,x+\tfrac{1}{2}\Delta x]$ are equal to the Lagrange interpolating polynomial
of $f(x)$ on the same stencil. We first study the fundamental functions of
Lagrange reconstruction, show that these polynomials have only real and
distinct roots, which are never located at the cell-interfaces (half-points)
$x_i+n\tfrac{1}{2}\Delta x$ ($n\in\mathbb{Z}$), and obtain several identities.
Using these identities, by analogy to the recursive Neville-Aitken-like
algorithm applied to the Lagrange interpolating polynomial, we show that there
exists a unique representation of the Lagrange reconstructing polynomial on
$\{i-M_-,...,i+M_+\}$ as a combination of the Lagrange reconstructing
polynomials on the $K_\mathrm{s}+1\leq M:=M_-+M_+>1$ substencils
$\{i-M_-+k_\mathrm{s},...,i+M_+-K_\mathrm{s}+k_\mathrm{s}\}$
($k_\mathrm{s}\in\{0,...,K_\mathrm{s}\}$), with weights
$\sigma_{R_1,M_-,M_+,K_\mathrm{s},k_\mathrm{s}}(\xi)$ which are rational
functions of $\xi$ ($x=x_i+\xi\Delta x$) [Liu Y.Y., Shu C.W., Zhang M.P.: {\em
Acta Math. Appl. Sinica} {\bf 25} (2009) 503--538], and give an analytical
recursive expression of the weight-functions. We then use the analytical
expression of the weight-functions
$\sigma_{R_1,M_-,M_+,K_\mathrm{s},k_\mathrm{s}}(\xi)$ to obtain a formal proof
of convexity (positivity of the weight-functions) in the neighborhood of
$\xi=\tfrac{1}{2}$, under the condition that all of the substencils contain
either point $i$ or point $i+1$ (or both).

We present modeling of the incompressible viscous flows in the domain
containing an unconfined fluid and a porous medium. For such setting a rigorous
derivation of the Beavers-Joseph-Saffman interface condition was undertaken by
J\"ager and Mikeli\'c [SIAM J. Appl. Math. \rm 60 (2000), p. 1111-1127] using
the homogenization method. So far the interface law for the pressure was
conceived and confirmed only numerically. In this article we justify rigorously
the pressure jump condition using the corresponding boundary layer.

There were elaborated different models of Finsler geometry using the Cartan
(metric compatible), or Berwald and Chern (metric non-compatible) connections,
the Ricci flag curvature etc. In a series of works, we studied (non)commutative
metric compatible Finsler and nonholonomic generalizations of the Ricci flow
theory [see S. Vacaru, J. Math. Phys. 49 (2008) 043504; 50 (2009) 073503 and
references therein]. The goal of this work is to prove that there are some
models of Finsler gravity and geometric evolution theories with generalized
Perelman's functionals, and correspondingly derived nonholonomic Hamilton
evolution equations, when metric noncompatible Finsler connections are
involved. Following such an approach, we have to consider distortion tensors,
uniquely defined by the Finsler metric, from the Cartan and/or the canonical
metric compatible connections. We conclude that, in general, it is not possible
to elaborate self-consistent models of geometric evolution with arbitrary
Finsler metric noncompatible connections.

In the present work we analyze the problem of adaptation and evolution of RNA
virus populations, by defining the basic stochastic model as a multivariate
branching process in close relation with the branching process advanced by
Demetrius, Schuster and Sigmund ("Polynucleotide evolution and branching
processes", Bull. Math. Biol. 46 (1985) 239-262), in their study of
polynucleotide evolution. We show that in the absence of beneficial forces the
model is exactly solvable. As a result it is possible to prove several key
results directly related to known typical properties of these systems like (i)
proof, in the context of the theory of branching processes, of the lethal
mutagenesis criterion proposed by Bull, Sanju\'an and Wilke ("Theory of lethal
mutagenesis for viruses", J. Virology 18 (2007) 2930-2939); (ii) a new proposal
for the notion of relaxation time with a quantitative prescription for its
evaluation and (iii) the quantitative description of the evolution of the
expected values in four distinct regimes: transient, "stationary" equilibrium,
extinction threshold and lethal mutagenesis. Moreover, new insights on the
dynamics of evolving virus populations can be foreseen.

Following our paper [J. Math. Phys. 50 (2009) 123102], we systematically
carry out Lie symmetry analysis for the barotropic vorticity equation on the
rotating sphere. All finite-dimensional subalgebras of the corresponding
maximal Lie invariance algebra, which is infinite-dimensional, are classified.
Appropriate subalgebras are then used to exhaustively determine Lie reductions
of the equation under consideration. The relevance of the constructed exact
solutions for the description of real-world physical processes is discussed. It
is shown that the results of the above paper are directly related to the
results of the recent letter by N. H. Ibragimov and R. N. Ibragimov [Phys.
Lett. A 375 (2011) 3858] in which Lie symmetries and some exact solutions of
the nonlinear Euler equations for an atmospheric layer in spherical geometry
were determined.

We provide direct evidence of market manipulation at the beginning of the
financial crisis in November 2007. The type of manipulation, a "bear raid,"
would have been prevented by a regulation that was repealed by the Securities
and Exchange Commission in July 2007. The regulation, the uptick rule, was
designed to prevent manipulation and promote stability and was in force from
1938 as a key part of the government response to the 1929 market crash and its
aftermath. On November 1, 2007, Citigroup experienced an unusual increase in
trading volume and decrease in price. Our analysis of financial industry data
shows that this decline coincided with an anomalous increase in borrowed
shares, the selling of which would be a large fraction of the total trading
volume. The selling of borrowed shares cannot be explained by news events as
there is no corresponding increase in selling by share owners. A similar number
of shares were returned on a single day six days later. The magnitude and
coincidence of borrowing and returning of shares is evidence of a concerted
effort to drive down Citigroup's stock price and achieve a profit, i.e., a bear
raid. Interpretations and analyses of financial markets should consider the
possibility that the intentional actions of individual actors or coordinated
groups can impact market behavior. Markets are not sufficiently transparent to
reveal even major market manipulation events. Our results point to the need for
regulations that prevent intentional actions that cause markets to deviate from
equilibrium and contribute to crashes. Enforcement actions cannot reverse
severe damage to the economic system. The current "alternative" uptick rule
which is only in effect for stocks dropping by over 10% in a single day is
insufficient. Prevention may be achieved through improved availability of
market data and the original uptick rule or other transaction limitations.

In a previous paper (S. Ghosal and Z. Chen Bull. Math. Biol. 2010, vol. 72,
pg. 2047) it was shown that the evolution of the solute concentration in
capillary electrophoresis is described by a nonlinear wave equation that
reduced to Burger's equation if the nonlinearity was weak. It was assumed that
only strong electrolytes (fully dissociated) were present. In the present paper
it is shown that the same governing equation also describes the situation where
the electrolytic buffer consists of a single weak acid (or base). A simple
approximate formula is derived for the dimensionless peak variance which is
shown to agree well with published experimental data.

The differential migration of ions in an applied electric field is the basis
for separation of chemical species by capillary electrophoresis. Axial
diffusion of the concentration peak limits the separation efficiency.
Electromigration dispersion is observed when the concentration of sample ions
is comparable to that of the background ions. Under such conditions, the local
electrical conductivity is significantly altered in the sample zone making the
electric field, and therefore, the ion migration velocity concentration
dependent. The resulting nonlinear wave exhibits shock like features, and,
under certain simplifying assumptions, is described by Burgers' equation (S.
Ghosal and Z. Chen Bull. Math. Biol. 2010, vol.72, pg. 2047).In this paper, we
consider the more general situation where the walls of the separation channel
may have a non-zero zeta potential and are therefore able to sustain an
electro-osmotic bulk flow. The main result is a one dimensional nonlinear
advection diffusion equation for the area averaged concentration. This
homogenized equation accounts for the Taylor-Aris dispersion resulting from the
variation in the electro-osmotic slip velocity along the wall. It is shown that
in a certain range of parameters, the electro-osmotic flow can actually reduce
the total dispersion by delaying the formation of a concentration shock.
However, if the electro-osmotic flow is sufficiently high, the total dispersion
is increased because of the Taylor-Aris contribution.

In this paper we revisit and adapt to viral evolution an approach based on
the theory of branching process advanced by Demetrius, Schuster and Sigmund
("Polynucleotide evolution and branching processes", Bull. Math. Biol. 46
(1985) 239-262), in their study of polynucleotide evolution. By taking into
account beneficial effects we obtain a non-trivial multivariate generalization
of their single-type branching process model. Perturbative techniques allows us
to obtain analytical asymptotic expressions for the main global parameters of
the model which lead to the following rigorous results: (i) a new criterion for
"no sure extinction", (ii) a generalization and proof, for this particular
class of models, of the lethal mutagenesis criterion proposed by Bull,
Sanju\'an and Wilke ("Theory of lethal mutagenesis for viruses", J. Virology 18
(2007) 2930-2939), (iii) a new proposal for the notion of relaxation time with
a quantitative prescription for its evaluation, (iv) the quantitative
description of the evolution of the expected values in in four distinct
"stages": extinction threshold, lethal mutagenesis, stationary "equilibrium"
and transient. Finally, based on these quantitative results we are able to draw
some qualitative conclusions.

There is a very reason to consider that to solve Zeno's paradoxes is to
propose the theory of mechanical world view. We believe that this is not only
our opinion but also most philosophers' opinion. Recently, in order to justify
Heisenberg`s uncertainty principle (cf. Rep. Math. Phys Vol. 29, No. 3, 1991)
more firmly. we proposed the linguistic interpretation of quantum mechanics
(called quantum and classical measurement theory), which was characterized as
the metaphysical and linguistic turn of the Copenhagen interpretation. This
turn from physics to language does not only extend quantum mechanicsto
classical systems but also yield the (quantum and classical) mechanical world
view (and therefore, establish the method of science). If it be so, we may
assert that Zeno's paradoxes (Flying Arrow Paradox, Achilles and the tortoise,
etc.) were already solved in measurement theory. The purpose of this paper is
to examine this assertion.

In capillary electrophoresis, sample ions migrate along a micro-capillary
filled with a background electrolyte under the influence of an applied electric
field. If the sample concentration is sufficiently high, the electrical
conductivity in the sample zone could differ significantly from the
background.Under such conditions, the local migration velocity of sample ions
becomes concentration dependent resulting in a nonlinear wave that exhibits
shock like features. If the nonlinearity is weak, the sample concentration
profile, under certain simplifying assumptions, can be shown to obey Burgers'
equation (S. Ghosal and Z. Chen Bull. Math. Biol. 2010, 72(8), pg. 2047) which
has an exact analytical solution for arbitrary initial condition.In this paper,
we use a numerical method to study the problem in the more general case where
the sample concentration is not small in comparison to the concentration of
background ions. In the case of low concentrations, the numerical results agree
with the weakly nonlinear theory presented earlier, but at high concentrations,
the wave evolves in a way that is qualitatively different.

We show how Noether conservation laws can be obtained from the particle
relabelling symmetries in the Euler-Poincar\'e theory of ideal fluids with
advected quantities. All calculations can be performed without Lagrangian
variables, by using the Eulerian vector fields that generate the symmetries,
and we identify the time-evolution equation that these vector fields satisfy.
When advected quantities (such as advected scalars or densities) are present,
there is an additional constraint that the vector fields must leave the
advected quantities invariant. We show that if this constraint is satisfied
initially then it will be satisfied for all times. We then show how to solve
these constraint equations in various examples to obtain evolution equations
from the conservation laws. We also discuss some fluid conservation laws in the
Euler-Poincar\'e theory that do not arise from Noether symmetries, and explain
the relationship between the conservation laws obtained here, and the
Kelvin-Noether theorem given in Section 4 of Holm, Marsden and Ratiu, {\it Adv.
in Math.}, 1998.

This note is a correction to a paper of Cortez, Peskin, Stockie & Varela
[SIAM J. Appl. Math., 65(2):494-520, 2004], who studied the stability of a
parametrically-forced, circular, elastic fiber immersed in an incompressible
fluid in 2D, and showed the existence of parametric resonance. The results were
represented as plots that separate parameter space into regions where the
solution is either stable or unstable. We uncovered two errors in the paper:
the first was in the derivation of the eigenvalue problem, and the second was
in the code to used to calculate the stability contours.

A model of discrete space-time is presented which is, in a sense, both
Lorentz invariant and has no restriction on the relative velocity between
particles (except v < c). The space-time has an inbuilt indeterminacy.
  Published originally as 'A quantisation of time', J. Phys. A: Math. Gen., 10,
2115, 1977; identical to the original, apart from one or two minor corrections,
and some simplification towards the end of Section 6. The paper presents a
discrete model of time, in which the latter comprises a succession of instants
which are identified as collisions with particles called chronons. Proper-time
intervals are discrete; the structure of space-time is given by a radar map and
has an inbuilt indeterminacy, which leads naturally to Heisenberg's uncertainty
principle. If I were writing this paper today I would identify the chronon with
the virtual Higgs boson. Without the latter all particles would be massless and
would follow null paths; there would be no such thing as proper time. Time is
an emergent phenomenon, and the Higgs boson is the agent of that emergence.

Undergraduate research is widely regarded as a high impact practice. However,
usually only the highest achieving students are rewarded with undergraduate
research opportunities. This paper reports on the successful implementation of
a student research program offering the weakest 10% of incoming freshmen
opportunities to conduct original research in one of several science or
engineering disciplines with the possibility of publication if the research and
report meet a suitable standard, defined as earning an A on the final research
project report in the introductory math course. The opportunity has been
offered now for two years to incoming cadets at the United States Air Force
Academy who are placed in Basic Math. The cadets placed in this course score in
the bottom 5% of incoming cadets on the math placement exam. During the second
semester of their freshman year, cadets enrolled in Calculus 1 are also offered
a similar research opportunity. About 10% of cadets are enrolled in this course
each Spring, the 5% who began in Basic Math and matriculate to Calculus 1 and
the 5% who failed Calculus 1 in their first attempt. During the first four
semesters, the program has yielded 22 cadet papers which have been published or
are currently under review and expected to be published. This represents
approximately 38% of the projects in the program, because the majority of the
projects do not earn As and are not suitable for publication. Over 80% of the
cadet co-authors on the publication quality papers are minorities, women,
and/or intercollegiate athletes.

We introduce an analytical kernel, the "cusp" kernel, to model the effects of
velocity-changing collisions on optically pumped atoms in low-pressure buffer
gases. Like the widely used Keilson-Storer kernel [J. Keilson and J. E. Storer,
Q. Appl. Math. 10, 243 (1952)], cusp kernels are characterized by a single
parameter and preserve a Maxwellian velocity distribution. Cusp kernels and
their superpositions are more useful than Keilson-Storer kernels, because they
are more similar to real kernels inferred from measurements or theory and are
easier to invert to find steady-state velocity distributions.

We apply our general method of duality, introduced in [Giardina', Kurchan,
Redig, J. Math. Phys. 48, 033301 (2007)], to models of population dynamics. The
classical dualities between forward and ancestral processes can be viewed as a
change of representation in the classical creation and annihilation operators,
both for diffusions dual to coalescents of Kingman's type, as well as for
models with finite population size. Next, using SU(1,1) raising and lowering
operators, we find new dualities between the Wright-Fisher diffusion with $d$
types and the Moran model, both in presence and absence of mutations. These new
dualities relates two forward evolutions. From our general scheme we also
identify self-duality of the Moran model.

The Generalized Riemann Problems (GRP) for nonlinear hyperbolic systems of
balance laws in one space dimension are now well-known and can be formulated as
follows: Given initial-data which are smooth on two sides of a discontinuity,
determine the time evolution of the solution near the discontinuity. While the
classical Riemann problem serves as a primary building block in the
construction of many numerical schemes (most notably the Godunov scheme), the
analytic study of GRP will lead to an array of GRP schemes, which extend the
Godunov scheme. Currently there are extensive studies on the second-order GRP
scheme, which proves to be robust and is capable of resolving complex
multidimensional fluid dynamic problems [M. Ben-Artzi and J. Falcovitz,
"Generalized Riemann Problems in Computational Fluid Dynamics", Cambridge
University Press, 2003]. A more general formulation of the second-order GRP
solver is still confined with a class of weakly coupled systems [Numer. Math.
(2007) 106:369-425]. This paper provides a unified approach for solving the GRP
in the general context of hyperbolic balance laws, without weakly coupled
constraint, towards high order accuracy. The derivation of the second-order GRP
solver is more concise compared to those in previous works and the third-order
quadratic GRP is resolved for the first time. The latter is shown to be
necessary through numerical experiments with strong discontinuities. Our method
relies heavily on the new treatment of the rarefaction wave by deriving the
L(Q)-equations, an ODE system capturing the "evolution" of the characteristic
derivatives in x-t space for generalized Riemann invariants. The case of a
sonic point is incorporated into a general treatment. The accuracy of the
derived GRP solvers are justified and numerical examples are presented for the
performance of the resulting scheme.
