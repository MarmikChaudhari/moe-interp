\title{\bf Decentralized adaptation in interconnected uncertain systems with nonlinear parametrization}

\begin{abstract}
We propose a technique for the design and analysis of decentralized adaptation algorithms in interconnected dynamical systems. Our technique does not require Lyapunov stability of the target dynamics and allows nonlinearly parameterized uncertainties. We show that for the considered class of systems,
conditions for reaching the control goals can be formulated in terms of the nonlinear $L_2$-gains of target dynamics of each interconnected subsystem. Equations for decentralized controllers and corresponding adaptation algorithms are also explicitly provided.

{\it Keywords:} nonlinear parametrization; unstable,
non-equilibrium dynamics; decentralized adaptive control; monotone functions
\end{abstract}

\section*{Notation}

According to the standard convention, $\mathbb{R}$ defines the field of real numbers and $\mathbb{R}_{\geq c}=\{x\in\mathbb{R}|x\geq c\}$,
$\mathbb{R}_{+}=\mathbb{R}_{\geq 0}$; symbol $\mathbb{R}^n$ stands for a linear space $\mathcal{L}(\mathbb{R})$ over the field of reals with
$\mathrm{dim}\{\mathcal{L}(\mathbb{R})\}=n$; $\|\mathbf{x}\|$ denotes the Euclidian norm of $\mathbf{x}\in\mathbb{R}^n$; $\mathcal{C}^k$ denotes the space of functions that are at least $k$ times differentiable;
$\mathcal{K}$ denotes the class of all strictly increasing functions $\kappa: \mathbb{R}_+\rightarrow \mathbb{R}_+$ such that
$\kappa(0)=0$. By ${L}_{p}^n[t_0,T]$, where $T>0$, $p\geq 1$ we denote the space of all functions $\mathbf{f}:\mathbb{R}_+\rightarrow\mathbb{R}^n$
such that
$\|\mathbf{f}\|_{p,[t_0,T]}=\left(\int_{0}^T\|\mathbf{f}(\tau)\|^{p}d\tau\right)^{1/p}<\infty$;
$\|\mathbf{f}\|_{p,[t_0,T]}$ denotes the ${L}_{p}^n[t_0,T]$-norm of
$\mathbf{f}(t)$. By ${L}^n_\infty[t_0,T]$ we denote the space of all functions $\mathbf{f}:\mathbb{R}_+\rightarrow\mathbb{R}^n$ such that
$\|\mathbf{f}\|_{\infty,[t_0,T]}={\mathrm{ess}} \sup\{\|\mathbf{f}(t)\|,t \in
[t_0,T]\}<\infty$, and $\|\mathbf{f}\|_{\infty,[t_0,T]}$ stands for the
${L}^n_\infty[t_0,T]$ norm of $\mathbf{f}(t)$.

A function $\mathbf{f}(\mathbf{x}): \mathbb{R}^{n}\rightarrow \mathbb{R}^m$ is said to be locally bounded if for any $\|\mathbf{x}\|<\delta$ there exists a constant $D(\delta)>0$ such that the following inequality holds:
$\|\mathbf{f}(\mathbf{x})\|\leq D(\delta)$. Let $\Gamma$ be an $n\times n$
square matrix, then $\Gamma>0$ denotes a positive definite
(symmetric) matrix, and $\Gamma^{-1}$ is the inverse of $\Gamma$.
By $\Gamma\geq 0$ we denote a positive semi-definite matrix,
$\|\mathbf{x}\|_{\Gamma}^2$ to denotes the quadratic form:
$\mathbf{x}^{T}\Gamma\mathbf{x}$, $\mathbf{x}\in\mathbb{R}^n$. The notation $|\cdot|$
stands for the modulus of a scalar. The solution of a system of differential equations $\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},t,{\boldsymbol{\theta}},\mathbf{u}), \
\mathbf{x}(t_0)=\mathbf{x}_0$, $\mathbf{u}:\mathbb{R}_+\rightarrow\mathbb{R}^m$,
${\boldsymbol{\theta}}\in\mathbb{R}^d$ for $t\geq t_0$ will be denoted as
$\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},\mathbf{u})$, or simply as $\mathbf{x}(t)$ if it is clear from the context what the values of $\mathbf{x}_0,{\boldsymbol{\theta}}$
are and how the function $\mathbf{u}(t)$ is defined.

Let $\mathbf{u}:\mathbb{R}^n\times\mathbb{R}^d\times\mathbb{R}_+\rightarrow\mathbb{R}^m$ be a function of state $\mathbf{x}$, parameters $\hat{{\boldsymbol{\theta}}}$, and time
$t$. Let in addition both $\mathbf{x}$ and $\hat{{\boldsymbol{\theta}}}$ be functions of $t$. Then in case the arguments of $\mathbf{u}$ are clearly defined by the context, we will simply write $\mathbf{u}(t)$ instead of
$\mathbf{u}(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)$.

The (forward complete) system
$\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},t,{\boldsymbol{\theta}},\mathbf{u}(t))$, is said to have an
$L_{p}^m [t_0,T]\mapsto L_{q}^n[t_0,T]$, gain ($T\geq t_0$,
$p,q\in\mathbb{R}_{\geq 1}\cup\infty$) with respect to its input
$\mathbf{u}(t)$ if and only if $\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},\mathbf{u}(t))\in L_{q}^n [t_0,T]$ for any $\mathbf{u}(t)\in L_{p}^m [t_0,T]$ and there exists a function
$\gamma_{q,p}:\mathbb{R}^n\times\mathbb{R}^d\times\mathbb{R}_+\rightarrow\mathbb{R}_+$
such that the following inequality holds:
$\|\mathbf{x}(t)\|_{q,[t_0,T]}\leq
\gamma_{q,p}(\mathbf{x}_0,{\boldsymbol{\theta}},\|\mathbf{u}(t)\|_{p,[t_0,T]})$. The function $\gamma_{q,p}(\mathbf{x}_0,{\boldsymbol{\theta}},\|\mathbf{u}(t)\|_{p,[t_0,T]})$
is assumed to be non-decreasing in $\|\mathbf{u}(t)\|_{p,[t_0,T]}$, and locally bounded in its arguments.

For notational convenience when dealing with vector fields and partial derivatives we will use the following extended notion of the Lie derivative of a function. Let $\mathbf{x}\in\mathbb{R}^n$ and assume
$\mathbf{x}$ can be partitioned as follows $\mathbf{x}=\mathbf{x}_1\oplus\mathbf{x}_2$,
where $\mathbf{x}_1\in\mathbb{R}^q$, $\mathbf{x}_1=(x_{11},\dots,x_{1q})^T$,
$\mathbf{x}_2\in\mathbb{R}^p$, $\mathbf{x}_2=(x_{21},\dots,x_{2p})^T$, $q+p=n$, and
$\oplus$ denotes the concatenation of two vectors. Define
$\mathbf{f}:\mathbb{R}^{n}\rightarrow\mathbb{R}^n$ such that
$\mathbf{f}(\mathbf{x})=\mathbf{f}_1(\mathbf{x})\oplus\mathbf{f}_2(\mathbf{x})$, where
$\mathbf{f}_1:\mathbb{R}^n\rightarrow\mathbb{R}^q$,
$\mathbf{f}_1(\cdot)=(f_{11}(\cdot),\dots,f_{1q}(\cdot))^T$,
$\mathbf{f}_2:\mathbb{R}^n\rightarrow\mathbb{R}^p$,
$\mathbf{f}_2(\cdot)=(f_{21}(\cdot),\dots,f_{2p}(\cdot))^T$. Then
$L_{\mathbf{f}_i(\mathbf{x})}\psi(\mathbf{x},t)$, $i\in\{1,2\}$ denotes the Lie derivative of the function $\psi(\mathbf{x},t)$ with respect to the vector field $\mathbf{f}_i(\mathbf{x},{\boldsymbol{\theta}})$:
$L_{\mathbf{f}_i(\mathbf{x})}\psi(\mathbf{x},t)=\sum_{j}^{\dim{\mathbf{x}_i}}\frac{{\partial}
\psi(\mathbf{x},t) }{{\partial} x_{ij}}f_{ij}(\mathbf{x},{\boldsymbol{\theta}})$.

\section{Introduction}

We consider the problem how to control the behavior of complex dynamical systems composed of interconnected lower-dimensional subsystems. Centralized control of these systems is practically inefficient because of high demands for computational power,
measurements and prohibitive communication cost. On the other hand, standard decentralized solutions often face severe limitations due to the deficiency of information about the interconnected subsystems. In addition, the nature of their their interconnections may vary depending on conditions in the environment. In order to address these problems in their most general setup, decentralized adaptive control is needed.

Currently there is a large literature on decentralized adaptive control which contains successful solutions to problems of adaptive stabilization \cite{Gavel_1989,Jain_1997}, tracking
\cite{Ioannou86,Jain_1997,Shi_1992,Passino96}, and output regulation \cite{Jiang_2000,Huang_2003} of linear and nonlinear systems. In most of these cases the problem of decentralized control is solved within the conventional framework of adaptive stabilization/tracking/regulation by a family of linearly parameterized controllers. While these results may be successfully implemented in a large variety of technical and artificial systems, there is room for further improvements. In particular,
when the target dynamics of the systems is not stable in the Lyapunov sense but intermittent, meta-stable, or multi-stable
\cite{Arecchi_2004,Raffone_2003,Tsuda_2004} or when the uncertainties are nonlinearly parameterized
\cite{Armstrong_1993,Boskovic_1995,Canudas_1999,Kitching_2000},
and no domination of the uncertainties by feedback is allowed.

In the present article we address these issues at once for a class of nonlinear dynamical systems. Our contribution is that we provide conditions ensuring forward-completeness, boundedness and asymptotic reaching of the goal for a pair of interconnected systems with uncertain coupling and parameters. Our method does not require availability of a Lyapunov function for the desired motions in each subsystem, nor linear parametrization of the controllers. Our results can straightforwardly be extended to interconnection of arbitrary many (but still, a finite number of)
subsystems. Explicit equations for corresponding decentralized adaptive controllers are also provided.

The paper is organized as follows. In Section 2 we provide a formal statement of the problem, Section 3 contains necessary preliminaries and auxiliary results. In Section 4 we present the main results of our current contribution, and in Section 5 we provide concluding remarks to our approach.

\section{Problem Formulation}

Let us consider two interconnected systems $\mathcal{S}_x$ and
$\mathcal{S}_y$:
\begin{eqnarray}
&\mathcal{S}_x: & \
\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}}_x)+\gamma_y(\mathbf{y},t)+
\mathbf{g}(\mathbf{x})u_x \label{eq:system:s1} \\
&\mathcal{S}_y: & \
\dot{\mathbf{y}}=\mathbf{q}(\mathbf{y},{\boldsymbol{\theta}}_y)+\gamma_x(\mathbf{x},t)+\mathbf{z}(\mathbf{y})u_y\label{eq:system:s2}
\end{eqnarray}
where $\mathbf{x}\in\mathbb{R}^{n_x}$, $\mathbf{y}\in\mathbb{R}^{n_y}$ are the state vectors of systems $\mathcal{S}_x$ and $\mathcal{S}_y$, vectors
${\boldsymbol{\theta}}_x\in\mathbb{R}^{n_{\theta_x}}$,
${\boldsymbol{\theta}}_y\in\mathbb{R}^{n_{\theta_y}}$ are unknown parameters,
functions
$\mathbf{f}:\mathbb{R}^{n_x}\times\mathbb{R}^{n_{\theta_x}}\rightarrow\mathbb{R}^{n_x}$,
$\mathbf{q}:\mathbb{R}^{n_y}\times\mathbb{R}^{n_{\theta_y}}\rightarrow\mathbb{R}^{n_y}$,
$\mathbf{g}:\mathbb{R}^{n_x}\rightarrow\mathbb{R}^{n_x}$,
$\mathbf{z}:\mathbb{R}^{n_y}\rightarrow\mathbb{R}^{n_y}$ are continuous and locally bounded. Functions
$\gamma_y:\mathbb{R}^{n_y}\times\mathbb{R}_+\rightarrow\mathbb{R}_n$,
$\gamma_x:\mathbb{R}^{n_x}\times\mathbb{R}_+\rightarrow\mathbb{R}^{n_y}$, stand for nonlinear, non-stationary and, in general, unknown couplings between systems $\mathcal{S}_x$ and $\mathcal{S}_y$, and
$u_x\in\mathbb{R}$, $u_y\in\mathbb{R}$ are the control inputs.

In the present paper we are interested in the following problem

\begin{problem}\label{problem:decentralized}\normalfont Let $\psi_x:\mathbb{R}^{n_x}\times\mathbb{R}_+\rightarrow\mathbb{R}$,
$\psi_y:\mathbb{R}^{n_y}\times\mathbb{R}_+\rightarrow\mathbb{R}$ be the goal functions for systems $\mathcal{S}_x$, $\mathcal{S}_y$
respectively. In the other words, for some values
$\varepsilon_x\in\mathbb{R}_{+}$, $\varepsilon_y\in\mathbb{R}_+$ and time instant $t^\ast\in\mathbb{R}_+$, inequalities
\begin{equation}\label{eq:goal_functionals}
\|\psi_x(\mathbf{x}(t),t)\|_{\infty,[t^\ast,\infty]}\leq\varepsilon_x, \
\|\psi_y(\mathbf{y}(t),t)\|_{\infty,[t^\ast,\infty]}\leq\varepsilon_y
\end{equation}
specify the desired state of interconnection (\ref{eq:system:s1}),
(\ref{eq:system:s2}). Derive functions $u_x(\mathbf{x},t)$, $u_y(\mathbf{y},t)$
such that for all ${\boldsymbol{\theta}}_x\in\mathbb{R}^{n_{\theta_x}}$,
${\boldsymbol{\theta}}_y\in\mathbb{R}^{n_{\theta_y}}$

1) interconnection (\ref{eq:system:s1}), (\ref{eq:system:s2}) is forward-complete;

2) the trajectories $\mathbf{x}(t)$, $\mathbf{y}(t)$ are bounded;

3) for given values of $\varepsilon_x$, $\varepsilon_y$, some
$t^\ast\in\mathbb{R}_+$ exists such that inequalities
(\ref{eq:goal_functionals}) are satisfied or, possibly, both functions $\psi_x(\mathbf{x}(t),t)$, $\psi_y(\mathbf{y}(t),t)$ converge to zero as $t\rightarrow\infty$.

Function $u_x(\cdot)$ should not depend explicitly on $\mathbf{y}$ and,
symmetrically, function $u_y(\cdot)$ should not depend explicitly on $\mathbf{x}$. The general structure of the desired configuration of the control scheme is provided in Figure 1.
\end{problem}

\begin{figure}
\begin{center}
\includegraphics[width=110pt]{decentralized.eps}
\end{center}
\begin{center}
\caption{General structure of interconnection}\label{fig:decentralized:singularity}
\end{center}
\end{figure}

In the next sections we provide sufficient conditions, ensuring solvability of Problem \ref{problem:decentralized} and we also explicitly derive functions $u_x(\mathbf{x},t)$ and $u_y(\mathbf{y},t)$ which satisfy requirements 1) -- 3) of Problem
\ref{problem:decentralized}. We start with the introduction of a new class of adaptive control schemes and continue by providing the input-output characterizations of the controlled systems.
These results are given in Section \ref{sec:preliminary}. Then,
using these characterizations, in Section \ref{sec:main} we provide the main results of our study.

\section{Assumptions and properties of the decoupled systems}\label{sec:preliminary}

Let the following system be given:
\begin{equation}\label{system1}
\begin{split}
\dot{\mathbf{x}}_1=&\mathbf{f}_1(\mathbf{x})+\mathbf{g}_1(\mathbf{x})u, \\
\dot{\mathbf{x}}_2=&\mathbf{f}_2(\mathbf{x},{\boldsymbol{\theta}})+\mathbf{g}_2(\mathbf{x})u,
\end{split}
\end{equation}
where
\[
\mathbf{x}_1=(x_{11},\dots,x_{1 q})^T\in \mathbb{R}^q; \
\mathbf{x}_2=(x_{21},\dots,x_{2 p})^T\in \mathbb{R}^p;
\]
\[
\mathbf{x}=(x_{11},\dots,x_{1 q},x_{21},\dots,x_{2 p})^T\in \mathbb{R}^{n}
\]
${\boldsymbol{\theta}}\in \Omega_\theta\in \mathbb{R}^d$ is a vector of unknown parameters, and $\Omega_\theta$ is a closed bounded subset of
$\mathbb{R}^d$; $u\in\mathbb{R}$ is the control input, and functions
$\mathbf{f}_1:\mathbb{R}^{n}\rightarrow \mathbb{R}^{q}$,
$\mathbf{f}_2:\mathbb{R}^{n}\times\mathbb{R}^d\rightarrow \mathbb{R}^{p}$,
$\mathbf{g}_1:\mathbb{R}^{n}\rightarrow \mathbb{R}^q$,
$\mathbf{g}_2:\mathbb{R}^{n}\rightarrow\mathbb{R}^{p}$ are continuous and locally bounded. The vector $\mathbf{x}\in\mathbb{R}^n$ is the state vector, and vectors $\mathbf{x}_1$, $\mathbf{x}_2$ are referred to as {\it uncertainty-independent} and {\it uncertainty-dependent} partition of $\mathbf{x}$, respectively. For the sake of compactness we will also use the following description of (\ref{system1}):
\begin{equation}\label{system}
\dot{\mathbf{x}}=\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})+\mathbf{g}(\mathbf{x})u,
\end{equation}
where
\[
\mathbf{g}(\mathbf{x})=(g_{11}(\mathbf{x}),\dots,g_{1q}(\mathbf{x}),g_{21}(\mathbf{x}),\dots,g_{2 p}(\mathbf{x}))^{T},
\]
\[
\mathbf{f}(\mathbf{x})=(f_{11}(\mathbf{x}),\dots,f_{1q}(\mathbf{x}),f_{21}(\mathbf{x},{\boldsymbol{\theta}}),\dots,f_{2 p}(\mathbf{x},{\boldsymbol{\theta}}))^{T}.
\]

As a measure of closeness of trajectories $\mathbf{x}(t)$ to the desired state we introduce the error or goal function $\psi:\mathbb{R}^n\times
\mathbb{R}_+\rightarrow \mathbb{R}, \ \psi\in \mathcal{C}^1$.
We suppose also that for the chosen function $\psi(\mathbf{x},t)$
satisfies the following:
\begin{assume}[Target operator]\label{assume:psi} For the given function $\psi(\mathbf{x},t)\in \mathcal{C}^1$ the following property holds:
\begin{equation}\label{eq:assume_psi}
\|\mathbf{x}(t)\|_{\infty,[t_0,T]}\leq
\tilde{\gamma}\left(\mathbf{x}_0,{\boldsymbol{\theta}},\|\psi(\mathbf{x}(t),t)\|_{\infty,[t_0,T]}\right)
\end{equation}
where
$\tilde{\gamma}\left(\mathbf{x}_0,{\boldsymbol{\theta}},\|\psi(\mathbf{x}(t),t)\|_{\infty,[t_0,T]}\right)$
is a locally bounded and non-negative function of its arguments.
\end{assume}
Assumption \ref{assume:psi} can be interpreted as a sort of {\it unboundedness observability} property \cite{Jiang_1994} of system
(\ref{system1}) with respect to the ``output" function
$\psi(\mathbf{x},t)$. It can also be viewed as a {\it bounded input -
bounded state} assumption for system (\ref{system1}) along the constraint
$\psi(\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},u(\mathbf{x}(t),t)),t)=\upsilon(t)$,
where the signal $\upsilon(t)$ serves as a new input. If, however,
boundedness of the state is not explicitly required (i.e. it is guaranteed by additional control or follows from the physical properties of the system itself), Assumption \ref{assume:psi} can be removed from the statements of our results.

Let us specify a class of control inputs $u$ which can ensure boundedness of $\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},u)$ for every
${\boldsymbol{\theta}}\in \Omega_\theta$ and $\mathbf{x}_0\in\mathbb{R}^n$. According to
(\ref{eq:assume_psi}), boundedness of
$\mathbf{x}(t,\mathbf{x}_0,t_0,{\boldsymbol{\theta}},u)$ is ensured if we find a control input $u$ such that $\psi(\mathbf{x}(t),t)\in L_\infty^1[t_0,\infty]$.
For this objective consider the dynamics of system (\ref{system})
with respect to $\psi(\mathbf{x},t)$:
\begin{equation}\label{dpsi}
\dot{\psi}=L_{\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})}\psi(\mathbf{x},t)+L_{\mathbf{g}(\mathbf{x})}\psi(\mathbf{x},t)u+\frac{{\partial}
\psi(\mathbf{x},t)}{{\partial} t},
\end{equation}
Assuming that the inverse
$\left(L_{\mathbf{g}(\mathbf{x})}\psi(\mathbf{x},t)\right)^{-1}$ exists everywhere,
we may choose the control input $u$ in the following class of functions:
\begin{equation}\label{control}
\begin{split}
u(\mathbf{x},\hat{\boldsymbol{\theta}},{\boldsymbol{\omega}},t)&=\frac{1}{L_{\mathbf{g}(\mathbf{x})}\psi(\mathbf{x},t)}\left(-L_{\mathbf{f}(\mathbf{x},\hat{{\boldsymbol{\theta}}})}\psi(\mathbf{x},t)-\varphi(\psi,{\boldsymbol{\omega}},t)-\frac{{\partial}\psi(\mathbf{x},t)}{{\partial} t}\right) \\
& \ \varphi: \ \mathbb{R}\times\mathbb{R}^w\times\mathbb{R}_+\rightarrow\mathbb{R}
\end{split}
\end{equation}
where ${\boldsymbol{\omega}}\in\Omega_\omega\subset\mathbb{R}^w$ is a vector of
{\it known} parameters of the function
$\varphi(\psi,{\boldsymbol{\omega}},t)$. Denoting
$L_{\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})}\psi(\mathbf{x},t)=f(\mathbf{x},{\boldsymbol{\theta}},t)$ and taking into account (\ref{control}) we may rewrite equation
(\ref{dpsi}) in the following manner:
\begin{equation}\label{error_model}
{\dot\psi}=f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-\varphi(\psi,{\boldsymbol{\omega}},t)
\end{equation}

For the purpose of the present article, instead of
(\ref{error_model}) it is worthwhile to consider the extended equation:
\begin{equation}\label{error_model_d}
{\dot\psi}=f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-\varphi(\psi,{\boldsymbol{\omega}},t)+\varepsilon(t),
\end{equation}
where, if not stated overwise, the function
$\varepsilon:\mathbb{R}_+\rightarrow\mathbb{R}$, $\varepsilon\in L_{2}^1
[t_0,\infty]\cap C^0$. One of the immediate advantages of equation
(\ref{error_model_d}) in comparison with (\ref{error_model}) is that it allows us to take the presence of coupling between interconnected systems into consideration.

Let us now specify the desired properties of the function
$\varphi(\psi,{\boldsymbol{\omega}},t)$ in (\ref{control}),
(\ref{error_model_d}). The majority of known algorithms for parameter estimation and adaptive control
\cite{Kokotovich95,Fradkov99,Narendra89,Sastry89} assume global
(Lyapunov) stability of system
(\ref{error_model_d}) for ${\boldsymbol{\theta}}\equiv\hat{{\boldsymbol{\theta}}}$. In our study, however, we refrain from this standard, restrictive requirement. Instead we propose that finite energy of the signal
$f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)$, defined for example by its $L_{2}^1[t_0,\infty]$ norm with respect to the variable $t$, results in finite deviation from the target set given by the equality $\psi(\mathbf{x},t)=0$. Formally this requirement is introduced in Assumption \ref{assume:gain}:
\begin{assume}[Target dynamics operator]\label{assume:gain} Consider the following system:
\begin{equation}\label{eq:target_dynamics}
{\dot\psi}=-\varphi(\psi,{\boldsymbol{\omega}},t)+\zeta(t),
\end{equation}
where $\zeta:\mathbb{R}_+\rightarrow\mathbb{R}$ and
$\varphi(\psi,{\boldsymbol{\omega}},t)$ is defined in (\ref{error_model_d}).
Then for every ${\boldsymbol{\omega}}\in\Omega_\omega$ system
(\ref{eq:target_dynamics}) has $L_{2}^1 [t_0,\infty]\mapsto L_\infty^1[t_0,\infty]$ gain with respect to input $\zeta(t)$. In other words, there exists a function $\gamma_{\infty,2}$ such that
\begin{equation}\label{eq:gain_psi_L2}
\|\psi(t)\|_{\infty,[t_0,T]}\leq
\gamma_{\infty,2}(\psi_0,{\boldsymbol{\omega}},\|\zeta(t)\|_{2,[t_0,T]}), \ \
\forall \ \zeta(t)\in L_{2}^1[t_0,T]
\end{equation}
\end{assume}
In contrast to conventional approaches, Assumption
\ref{assume:gain} does not require global {\it asymptotic stability} of the origin of the unperturbed (i.e for $\zeta(t)=0$)
system (\ref{eq:target_dynamics}). When the stability of the target dynamics ${\dot\psi}=-\varphi(\psi,{\boldsymbol{\omega}},t)$ is known a-priori, one of the benefits of Assumption \ref{assume:gain} is that there is no need to know a {\it particular Lyapunov function}
of the unperturbed system.

So far we have introduced basic assumptions on system
(\ref{system1}) and the class of feedback considered in this article. Let us now specify the class of functions
$f(\mathbf{x},{\boldsymbol{\theta}},t)$ in (\ref{error_model_d}). Since general parametrization of function $f(\mathbf{x},{\boldsymbol{\theta}},t)$ is methodologically difficult to deal with, but solutions provided for nonlinearities with convenient linear re-parametrization often yield physically implausible models and large number of unknown parameters, we have opted for a new class of parameterizations.
As a candidate for such a parametrization we suggest nonlinear functions that satisfy the following assumption:
\begin{assume}[Monotonicity and Growth Rate in Parameters]\label{assume:alpha}For the given function
$f(\mathbf{x},{\boldsymbol{\theta}},t)$ in (\ref{error_model_d}) there exists function $\boldsymbol{\alpha}(\mathbf{x},t): \mathbb{R}^{n}\times \mathbb{R}_+\rightarrow
\mathbb{R}^d, \ \boldsymbol{\alpha}(\mathbf{x},t)\in \mathcal{C}^1$ and positive constant $D>0$ such that
\begin{equation}\label{eq:assume_alpha}
(f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-f(\mathbf{x},{\boldsymbol{\theta}},t))(\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}}))\geq0
\end{equation}
\begin{equation}\label{eq:assume_gamma}
|f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-f(\mathbf{x},{\boldsymbol{\theta}},t)|\leq D
|\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}})|
\end{equation}
\end{assume}
This set of conditions naturally extends from systems that are linear in parameters to those with nonlinear parametrization.
Examples and models of physical and artificial systems which satisfy Assumption \ref{assume:alpha} (at least for bounded
${\boldsymbol{\theta}},\hat{{\boldsymbol{\theta}}}\in \Omega_\theta$) can be found in the following references
\cite{Armstrong_1993,Boskovic_1995,Canudas_1999,Abbott_2001,Kitching_2000}.
Assumption \ref{assume:alpha} bounds the growth rate of the difference $|f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)|$ by the functional
$D|\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}})|$.
In addition, it might also be useful to have an estimate of
$|f(\mathbf{x},{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)|$ from below, as specified in Assumption \ref{assume:alpha_upper}:
\begin{assume}\label{assume:alpha_upper} For the given function
$f(\mathbf{x},{\boldsymbol{\theta}},t)$ in (\ref{error_model_d}) and function
$\boldsymbol{\alpha}(\mathbf{x},t)$, satisfying Assumption \ref{assume:alpha},
there exists a positive constant $D_1>0$ such that
\begin{equation}\label{eq:assume_alpha_upper}
|f(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)-f(\mathbf{x},{\boldsymbol{\theta}},t)|\geq D_1
|\boldsymbol{\alpha}(\mathbf{x},t)^{T}(\hat{{\boldsymbol{\theta}}}-{\boldsymbol{\theta}})|
\end{equation}
\end{assume}

\noindent In problems of adaptation, parameter and optimization estimation, effectiveness of the algorithms often depends on how
"good" the nonlinearity $f(\mathbf{x},{\boldsymbol{\theta}},t)$ is, and how predictable is the system's behavior. As a measure of goodness and predictability usually the substitutes as smoothness and boundedness are considered. In our study, we distinguish several of such specific properties of the functions $f(\mathbf{x},{\boldsymbol{\theta}},t)$
and $\varphi(\psi,{\boldsymbol{\omega}},t)$. These properties are provided below.

\begin{hyp}\label{hyp:locally_bound_uniform_f} The function $f(\mathbf{x},{\boldsymbol{\theta}},t)$ is locally bounded with respect to $\mathbf{x}$, ${{\boldsymbol{\theta}}}$ uniformly in $t$.
\end{hyp}

\begin{hyp}\label{hyp:locally_bound_uniform_df} The function $f(\mathbf{x},{\boldsymbol{\theta}},t)\in \mathcal{C}^1$, and $ {\partial}
{f(\mathbf{x},{\boldsymbol{\theta}},t)}/{{\partial} t}$ is locally bounded with respect to
$\mathbf{x}$, ${{\boldsymbol{\theta}}}$ uniformly in $t$.
\end{hyp}

\begin{hyp}\label{hyp:locally_bound_uniform_phi} The function $\varphi(\psi,{\boldsymbol{\omega}},t)$ is locally bounded in $\psi$,
${\boldsymbol{\omega}}$ uniformly in $t$.
\end{hyp}

Let us show that under an additional structural requirement, which relates properties of the function $\boldsymbol{\alpha}(\mathbf{x},t)$ and vector-field
$\mathbf{f}(\mathbf{x},{\boldsymbol{\theta}})=\mathbf{f}_1(\mathbf{x},{\boldsymbol{\theta}})\oplus\mathbf{f}_2(\mathbf{x},{\boldsymbol{\theta}})$
in (\ref{system1}), (\ref{system}), there exist adaptive algorithms ensuring that the following desired property holds:
\begin{equation}\label{eq:desired_prop}
\mathbf{x}(t)\in L_\infty^n[t_0,\infty]; \
f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x},\hat{{\boldsymbol{\theta}}}(t),t)\in L_{2}^1[t_0,\infty]
\end{equation}

Consider the following adaptation algorithms:
\begin{equation}\label{fin_forms_ours_tr1}
\begin{split}
\hat{{\boldsymbol{\theta}}}(\mathbf{x},t)&=\Gamma(\hat{{\boldsymbol{\theta}}}_P(\mathbf{x},t)+\hat{{\boldsymbol{\theta}}}_I(t));
\ \Gamma\in\mathbb{R}^{d\times d}, \ \Gamma>0
\\ \hat{{\boldsymbol{\theta}}}_P(\mathbf{x},t)&=
\psi(\mathbf{x},t)\boldsymbol{\alpha}(\mathbf{x},t)-\Psi(\mathbf{x},t) \\
\dot{\hat{{\boldsymbol{\theta}}}}_I&=\varphi(\psi(\mathbf{x},t),{\boldsymbol{\omega}},t)\boldsymbol{\alpha}(\mathbf{x},t)+\mathcal{R}(\mathbf{x},\hat{{\boldsymbol{\theta}}},u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t),t),
\end{split}
\end{equation}
where the function
$\mathcal{R}(\mathbf{x},\hat{{\boldsymbol{\theta}}},u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t),t):\mathbb{R}^n\times\mathbb{R}^d\times\mathbb{R}\times\mathbb{R}_+\rightarrow\mathbb{R}^d$
in (\ref{fin_forms_ours_tr1}) is given as follows:
\begin{equation}\label{fin_forms_ours_tr11}
\begin{split}
&\mathcal{R}(\mathbf{x},u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t),t)={{\partial}
\Psi(\mathbf{x},t)}/{{\partial} t}-\psi(\mathbf{x},t)({{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}/{{\partial} t}+L_{\mathbf{f}_1}\boldsymbol{\alpha}(\mathbf{x},t))\\
& + L_{\mathbf{f}_1}
\Psi(\mathbf{x},t)-(\psi(\mathbf{x},t)L_{\mathbf{g}_1}\boldsymbol{\alpha}(\mathbf{x},t)-L_{\mathbf{g}_1}
\Psi(\mathbf{x},t))u(\mathbf{x},\hat{{\boldsymbol{\theta}}},t)
\end{split}
\end{equation}
and function
$\Psi(\mathbf{x},t):\mathbb{R}^{n}\times\mathbb{R}_+\rightarrow\mathbb{R}_d$,
$\Psi(\mathbf{x},t)\in \mathcal{C}^1$ satisfies Assumption
\ref{assume:explicit_realizability}.
\begin{assume}\label{assume:explicit_realizability} There exists a function $\Psi(\mathbf{x},t)$ such that
\begin{equation}\label{eq:assume_explicit}
\frac{{\partial} \Psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}-\psi(\mathbf{x},t)\frac{{\partial}
\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} \mathbf{x}_2}=0
\end{equation}
\end{assume}
Additional restrictions imposed by this assumption will be discussed in some details after we summarize the properties of system (\ref{system1}), (\ref{control}),
(\ref{fin_forms_ours_tr1}), (\ref{fin_forms_ours_tr11}) in the following theorem.

\begin{theorem}[Properties of the decoupled systems]\label{stability_theorem}
Let system (\ref{system1}), (\ref{error_model_d}),
(\ref{fin_forms_ours_tr1}), (\ref{fin_forms_ours_tr11}) be given and Assumptions \ref{assume:alpha}, \ref{assume:alpha_upper},
\ref{assume:explicit_realizability} be satisfied. Then the following properties hold

P1) Let for the given initial conditions $\mathbf{x}(t_0)$,
$\hat{{\boldsymbol{\theta}}}_I(t_0)$ and parameters vector ${\boldsymbol{\theta}}$,
interval $[t_0,T^\ast]$ be the (maximal) time-interval of existence of solutions of the closed loop system (\ref{system1}),
(\ref{error_model_d}), (\ref{fin_forms_ours_tr1}),
(\ref{fin_forms_ours_tr11}). Then
\begin{equation}\label{eq:f_diff_L2}
\|f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t))\|_{2,[t_0,T^\ast]}\leq D_f({\boldsymbol{\theta}},t_0,\Gamma,\|\varepsilon(t)\|_{2,[t_0,T^\ast]});
\end{equation}
\[
D_f({\boldsymbol{\theta}},t_0,\Gamma,\|\varepsilon(t)\|_{2,[t_0,T^\ast]})=\left(\frac{D}{2}\|{\boldsymbol{\theta}}-\hat{{\boldsymbol{\theta}}}(t_0)\|^{2}_{\Gamma^{-1}}\right)^{0.5}
+ \frac{D}{D_1}\|\varepsilon(t)\|_{2,[t_0,T^\ast]}
\]
\[
\|{\boldsymbol{\theta}}-\hat{\boldsymbol{\theta}}(t)\|^{2}_{\Gamma^{-1}}\leq
\|\hat{{\boldsymbol{\theta}}}(t_0)-{\boldsymbol{\theta}}\|^{2}_{\Gamma^{-1}}+\frac{D}{2 D_1^2}\|\varepsilon(t)\|^{2}_{2,[t_0,T^\ast]}
\]

\noindent In addition, if Assumptions \ref{assume:psi} and
\ref{assume:gain} are satisfied then

P2) $\psi(\mathbf{x}(t),t)\in L_\infty^1[t_0,\infty]$, $\mathbf{x}(t)\in L_{\infty}^n[t_0,\infty]$ and
\begin{equation}\label{eq:psi_gain}
\|\psi(\mathbf{x}(t),t)\|_{\infty,[t_0,\infty]}\leq
\gamma_{\infty,2}\left(\psi(\mathbf{x}_0,t_0),{\boldsymbol{\omega}},\mathcal{D}\right)
\end{equation}
\[
\mathcal{D}=D_f({\boldsymbol{\theta}},t_0,\Gamma,\|\varepsilon(t)\|_{2,[t_0,\infty]})+\|\varepsilon(t)\|_{2,[t_0,\infty]}
\]

P3) if properties H\ref{hyp:locally_bound_uniform_f},
H\ref{hyp:locally_bound_uniform_phi} hold, and system
(\ref{eq:target_dynamics}) has $L_{2}^1 [t_0,\infty]\mapsto L_{p}^1 [t_0,\infty]$, $p>1$ gain with respect to input $\zeta(t)$
and output $\psi$ then
\begin{equation}\label{eq:convergence_psi_theorem}
\varepsilon(t)\in L_{2}^1 [t_0,\infty]\cap L_{\infty}^1[t_0,\infty]\Rightarrow
\lim_{t\rightarrow\infty}\psi(\mathbf{x}(t),t)=0
\end{equation}

If, in addition, property H\ref{hyp:locally_bound_uniform_df}
holds, and the functions $\boldsymbol{\alpha}(\mathbf{x},t)$, ${\partial}
\psi(\mathbf{x},t)/{\partial} t$ are locally bounded with respect to $\mathbf{x}$
uniformly in $t$, then

P4) the following holds
\begin{equation}\label{eq:convergence_f_theorem}
\lim_{t\rightarrow\infty}f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}(t),\hat{{\boldsymbol{\theta}}}(t),t)=0
\end{equation}

\end{theorem}
The proof of Theorem \ref{stability_theorem} and subsequent results are given in Section 6.

Let us briefly comment on Assumption
\ref{assume:explicit_realizability}.
Let $\boldsymbol{\alpha}(\mathbf{x},t)\in
\mathcal{C}^2$,
$\boldsymbol{\alpha}(\mathbf{x},t)=\mathrm{col}(\alpha_1(\mathbf{x},t),\dots,\alpha_d(\mathbf{x},t))$,
then necessary and sufficient conditions for existence of the function $\Psi(\mathbf{x},t)$ follow from the Poincar$\acute{\mathrm{e}}$ lemma:
\begin{equation}\label{eq:poincare}
\frac{{\partial}}{{\partial} \mathbf{x}_2}\left(\psi(\mathbf{x},t)\frac{{\partial}
\alpha_i(\mathbf{x},t)}{{\partial}
\mathbf{x}_2}
\right)=\left(\frac{{\partial}}{{\partial}
\mathbf{x}_2}\left(\psi(\mathbf{x},t)\frac{{\partial} \alpha_i(\mathbf{x},t)}{{\partial}
\mathbf{x}_2}
\right)
\right)^T
\end{equation}
This relation, in the form of conditions of existence of the solutions for function $\Psi(\mathbf{x},t)$ in
(\ref{eq:assume_explicit}), takes into account structural properties of system (\ref{system1}), (\ref{error_model_d}).
Indeed,
consider partial derivatives ${\partial} \alpha_i(\mathbf{x},t)/{\partial} \mathbf{x}_2$,
${\partial} \psi(\mathbf{x},t)/{\partial} \mathbf{x}_2$ with respect to the vector
$\mathbf{x}_2=(x_{21},\dots,x_{2p})^T$. Let
\begin{equation}\label{eq:single_dim}
\begin{split}
\frac{{\partial} \psi(\mathbf{x},t)}{{\partial} \mathbf{x}_2}=\left(\begin{array}{cccccccc}
0& 0
& \cdots & 0& \ast & 0&\cdots&0
\end{array}\right), \
\frac{{\partial}
\alpha_i(\mathbf{x},t)}{{\partial}\mathbf{x}_2}=\left(\begin{array}{cccccccc}
0 & 0
& \cdots & 0&
\ast &
0&\cdots&0
\end{array}\right)
\end{split}
\end{equation}
where the symbol $\ast$ denotes a function of $\mathbf{x}$ and $t$. Then condition (\ref{eq:single_dim}) guarantees that equality
(\ref{eq:poincare}) (and, subsequently, Assumption
\ref{assume:explicit_realizability}) holds. In case ${\partial}
\alpha(\mathbf{x}_1\oplus \mathbf{x}_2,t)/{\partial} \mathbf{x}_2=0$, Assumption
\ref{assume:explicit_realizability} holds for arbitrary
$\psi(\mathbf{x},t)\in \mathcal{C}^1$. If $\psi(\mathbf{x},t)$,
$\boldsymbol{\alpha}(\mathbf{x},t)$ depend on a single component of $\mathbf{x}_2$, for instance $x_{2k}, \ k\in\{0,\dots,p\}$, then conditions
(\ref{eq:single_dim}) hold and the function $\Psi(\mathbf{x},t)$ can be derived explicitly by integration
\begin{equation}\label{eq:single_dim_int}
\Psi(\mathbf{x},t)=\int\psi(\mathbf{x},t)\frac{\boldsymbol{\alpha}(\mathbf{x},t)}{{\partial} x_{2k}}d x_{2k}
\end{equation}
In all other cases, existence of the required function
$\Psi(\mathbf{x},t)$ follows from (\ref{eq:poincare}).

In the general case, when $\dim\{\mathbf{x}_2\}>1$, the problems of finding a function $\Psi(\mathbf{x},t)$ satisfying condition
(\ref{eq:assume_explicit}) can be avoided (or converted into one with an already known solutions such as (\ref{eq:poincare}),
(\ref{eq:single_dim_int})) by the {\it embedding} technique proposed in \cite{ECC_2003}. The main idea of the method is to introduce an auxiliary system that is forward-complete with respect to input $\mathbf{x}(t)$
\begin{equation}\label{eq:embed}
\begin{split}
\dot{{\boldsymbol{\xi}}}&=\mathbf{f}_{\boldsymbol{\xi}}(\mathbf{x},{\boldsymbol{\xi}},t), \ {\boldsymbol{\xi}}\in\mathbb{R}^z \\
\mathbf{h}_\xi&=\mathbf{h}_\xi({\boldsymbol{\xi}},t), \
\mathbb{R}^z\times\mathbb{R}_+\rightarrow\mathbb{R}^h
\end{split}
\end{equation}
such that
\begin{equation}\label{eq:embed_L2}
\|f(\mathbf{x}(t),{\boldsymbol{\theta}},t)-f(\mathbf{x}_1(t)\oplus\mathbf{h}_\xi(t)\oplus\mathbf{x}_2'(t),{\boldsymbol{\theta}},t)\|_{2,[t_0,T]}
\leq C_\xi\in\mathbb{R}_+
\end{equation}
for all $T\geq t_0$, and $\dim\{{\mathbf{h}_\xi}\}+\dim{\{\mathbf{x}_2'\}}=p$.
Then (\ref{error_model_d}) can be rewritten as follows:
\begin{equation}\label{error_model_d1}
{\dot\psi}=f(\mathbf{x}_1\oplus\mathbf{h}_\xi\oplus\mathbf{x}_2',{\boldsymbol{\theta}},t)-f(\mathbf{x}_1\oplus\mathbf{h}_\xi\oplus\mathbf{x}_2',\hat{\boldsymbol{\theta}},t)-\varphi(\psi,{\boldsymbol{\omega}},t)+\varepsilon_\xi(t),
\end{equation}
where $\varepsilon_\xi(t)\in L_{2}^1 [t_0,\infty]$, and
$\dim\{\mathbf{x}_2'\}=p-h<p$. In principle, the dimension of $\mathbf{x}_2'$
could be reduced to $1$ or $0$. As soon as this is ensured,
Assumption \ref{assume:explicit_realizability} will be satisfied and the results of Theorem \ref{stability_theorem} follow.
Sufficient conditions ensuring the existence of such an embedding in the general case are provided in \cite{ECC_2003}. For systems in which the parametric uncertainty can be reduced to vector fields with low-triangular structure the embedding is given in
\cite{ALCOSP_2004}.

\section{Main Results}\label{sec:main}

Without loss of generality let us rewrite interconnection
(\ref{eq:system:s1}), (\ref{eq:system:s2}) as follows
:
\begin{equation}\label{eq:system:s11}
\begin{split}
\dot{\mathbf{x}}_1&=\mathbf{f}_1(\mathbf{x})+\mathbf{g}_1(\mathbf{x})u_x\\
\dot{\mathbf{x}}_2 &=\mathbf{f}_2(\mathbf{x},{\boldsymbol{\theta}}_x)+\gamma_y(\mathbf{y},t)+
\mathbf{g}_2(\mathbf{x})u_x
\end{split}
\end{equation}

Categories: astro-ph, nlin.CD, physics.plasm-ph, physics.space-ph
Abstract: We present a theoretical framework for plasma turbulence in astrophysical
plasmas (solar wind, interstellar medium, galaxy clusters, accretion disks).
The key assumptions are that the turbulence is anisotropic with respect to the
mean magnetic field and frequencies are low compared to the ion cyclotron
frequency. The energy injected at the outer scale scale has to be converted
into heat, which ultimately cannot be done without collisions. A KINETIC
CASCADE develops that brings the energy to collisional scales both in space and
velocity. Its nature depends on the physics of plasma fluctuations. In each of
the physically distinct scale ranges, the kinetic problem is systematically
reduced to a more tractable set of equations. In the "inertial range" above the
ion gyroscale, the kinetic cascade splits into a cascade of Alfvenic
fluctuations, which are governed by the RMHD equations at both the collisional
and collisionless scales, and a passive cascade of compressive fluctuations,
which obey a linear kinetic equation along the moving field lines associated
with the Alfvenic component. In the "dissipation range" between the ion and
electron gyroscales, there are again two cascades: the kinetic-Alfven-wave
(KAW) cascade governed by two fluid-like Electron RMHD equations and a passive
phase-space cascade of ion entropy fluctuations. The latter cascade brings the
energy of the inertial-range fluctuations that was damped by collisionless
wave-particle interaction at the ion gyroscale to collisional scales in the
phase space and leads to ion heating. The KAW energy is similarly damped at the
electron gyroscale and converted into electron heat. Kolmogorov-style scaling
relations are derived for these cascades. Astrophysical and space-physical
applications are discussed in detail.

Categories: physics.ed-ph, quant-ph
Abstract: A novel way of picturing the processing of quantum information is described,
allowing a direct visualization of teleportation of quantum states and
providing a simple and intuitive understanding of this fascinating phenomenon.
The discussion is aimed at providing physicists a method of explaining
teleportation to non-scientists. The basic ideas of quantum physics are first
explained in lay terms, after which these ideas are used with a graphical
description, out of which teleportation arises naturally.

Categories: physics.pop-ph
Abstract: I shall present three arguments for the proposition that intelligent life is
very rare in the universe. First, I shall summarize the consensus opinion of
the founders of the Modern Synthesis (Simpson, Dobzhanski, and Mayr) that the
evolution of intelligent life is exceedingly improbable. Second, I shall
develop the Fermi Paradox: if they existed they'd be here. Third, I shall show
that if intelligent life were too common, it would use up all available
resources and die out. But I shall show that the quantum mechanical principle
of unitarity (actually a form of teleology!) requires intelligent life to
survive to the end of time. Finally, I shall argue that, if the universe is
indeed accelerating, then survival to the end of time requires that intelligent
life, though rare, to have evolved several times in the visible universe. I
shall argue that the acceleration is a consequence of the excess of matter over
antimatter in the universe. I shall suggest experiments to test these claims.

Categories: physics.soc-ph
Abstract: No abstract given; compares pairs of languages from World Atlas of Language
Structures.

Categories: physics.gen-ph
Abstract: The Dark Energy problem is forcing us to re-examine our models and our
understanding of relativity and space-time. Here a novel idea of Fundamental
Forces is introduced. This allows us to perceive the General Theory of
Relativity and Einstein's Equation from a new pesrpective. In addition to
providing us with an improved understanding of space and time, it will be shown
how it leads to a resolution of the Dark Energy problem.

Categories: cond-mat.soft, nlin.PS, physics.flu-dyn
Abstract: We employ granular hydrodynamics to investigate a paradigmatic problem of
clustering of particles in a freely cooling dilute granular gas. We consider
large-scale hydrodynamic motions where the viscosity and heat conduction can be
neglected, and one arrives at the equations of ideal gas dynamics with an
additional term describing bulk energy losses due to inelastic collisions. We
employ Lagrangian coordinates and derive a broad family of exact non-stationary
analytical solutions that depend only on one spatial coordinate. These
solutions exhibit a new type of singularity, where the gas density blows up in
a finite time when starting from smooth initial conditions. The density blowups
signal formation of close-packed clusters of particles. As the density blow-up
time $t_c$ is approached, the maximum density exhibits a power law $\sim
(t_c-t)^{-2}$. The velocity gradient blows up as $\sim - (t_c-t)^{-1}$ while
the velocity itself remains continuous and develops a cusp (rather than a shock
discontinuity) at the singularity. The gas temperature vanishes at the
singularity, and the singularity follows the isobaric scenario: the gas
pressure remains finite and approximately uniform in space and constant in time
close to the singularity. An additional exact solution shows that the density
blowup, of the same type, may coexist with an "ordinary" shock, at which the
hydrodynamic fields are discontinuous but finite. We confirm stability of the
exact solutions with respect to small one-dimensional perturbations by solving
the ideal hydrodynamic equations numerically. Furthermore, numerical solutions
show that the local features of the density blowup hold universally,
independently of details of the initial and boundary conditions.

Categories: physics.optics
Abstract: The results of the spectral, energetical and temporal characteristics of
radiation in the presence of the photonic flame effect are presented.
Artificial opal posed on Cu plate at the temperature of liquid nitrogen boiling
point (77 K) being irradiated by nanosecond ruby laser pulse produces long-
term luminiscence with a duration till ten seconds with a finely structured
spectrum in the the antistocks part of the spectrum. Analogous visible
luminescence manifesting time delay appeared in other samples of the artificial
opals posed on the same plate. In the case of the opal infiltrated with
different nonlinear liquids the threshold of the luminiscence is reduced and
the spatial disribution of the bright emmiting area on the opal surface is
being changed. In the case of the putting the frozen nonlinear liquids on the
Cu plate long-term blue bright luminiscence took place in the frozen species of
the liquids. Temporal characteristics of this luminiscence are nearly the same
as in opal matrixes.

Categories: physics.data-an, physics.gen-ph
Abstract: Statistical modeling of experimental physical laws is based on the
probability density function of measured variables. It is expressed by
experimental data via a kernel estimator. The kernel is determined objectively
by the scattering of data during calibration of experimental setup. A physical
law, which relates measured variables, is optimally extracted from experimental
data by the conditional average estimator. It is derived directly from the
kernel estimator and corresponds to a general nonparametric regression. The
proposed method is demonstrated by the modeling of a return map of noisy
chaotic data. In this example, the nonparametric regression is used to predict
a future value of chaotic time series from the present one. The mean predictor
error is used in the definition of predictor quality, while the redundancy is
expressed by the mean square distance between data points. Both statistics are
used in a new definition of predictor cost function. From the minimum of the
predictor cost function, a proper number of data in the model is estimated.

Categories: cs.CE, cond-mat.stat-mech, cs.MS, cs.NA, physics.data-an
Abstract: Real Options for Project Schedules (ROPS) has three recursive
sampling/optimization shells. An outer Adaptive Simulated Annealing (ASA)
optimization shell optimizes parameters of strategic Plans containing multiple
Projects containing ordered Tasks. A middle shell samples probability
distributions of durations of Tasks. An inner shell samples probability
distributions of costs of Tasks. PATHTREE is used to develop options on
schedules.. Algorithms used for Trading in Risk Dimensions (TRD) are applied to
develop a relative risk analysis among projects.

Categories: physics.data-an
Abstract: A physical law is represented by the probability distribution of a measured
variable. The probability density is described by measured data using an
estimator whose kernel is the instrument scattering function. The experimental
information and data redundancy are defined in terms of information entropy.
The model cost function, comprised of data redundancy and estimation error, is
minimized by the creation-annihilation process.

Categories: nlin.CD, cond-mat.other, physics.optics
Abstract: The microwave phonon stimulated emission (SE) has been experimentally and
numerically investigated in a nonautonomous microwave acoustic quantum
generator, called also microwave phonon laser or phaser (see previous works
arXiv:cond-mat/0303188 ; arXiv:cond-mat/0402640 ; arXiv:nlin.CG/0703050)
Phenomena of branching and long-time refractority (absence of the reaction on
the external pulses) for deterministic chaotic and regular processes of SE were
observed in experiments with various levels of electromagnetic pumping. At the
pumping level growth, the clearly depined increasing of the number of
coexisting SE states has been observed both in real physical experiments and in
computer simulations. This confirms the analytical estimations of the branching
density in the phase space. The nature of the refractority of SE pulses is
closely connected with the pointed branching and reflects the crises of strange
attractors, i.e. their collisions with unstable periodic components of the
higher branches of SE states in the nonautonomous microwave phonon laser.

Categories: physics.gen-ph
Abstract: Based on overall experimental observations, especially the pair processes, I
developed a model structure of the vacuum along with a basic-particle formation
scheme begun in 2000 (with collaborator P-I Johansson). The model consists in
that the vacuum is, briefly, filled of neutral but polarizable vacuuons,
consisting each of a p-vaculeon and n- vaculeon of charges $+e$ and $-e$ of
zero rest masses but with spin motions, assumed interacting each other with a
Coulomb force. The model has been introduced in full in a book (Nova Sci, 2005)
and referred to in a number of journal/E-print papers. I outline in this easier
accessible paper the detailed derivation of the model and a corresponding
quantitative determination of the vacuuon size.

Categories: physics.gen-ph
Abstract: The 32-dimensional compounding fields and their quantum interplays in the
trigintaduonion space can be presented by analogy with octonion and sedenion
electromagnetic, gravitational, strong and weak interactions. In the
trigintaduonion fields which are associated with the electromagnetic,
gravitational, strong and weak interactions, the study deduces some conclusions
of field source particles (quarks and leptons) and intermediate particles which
are consistent with current some sorts of interaction theories. In the
trigintaduonion fields which are associated with the hyper-strong and
strong-weak fields, the paper draws some predicts and conclusions of the field
source particles (sub-quarks) and intermediate particles. The research results
show that there may exist some new particles in the nature.

Categories: physics.optics, physics.class-ph, quant-ph
Abstract: Statistical ensemble formalism of Kim, Mandel and Wolf (J. Opt. Soc. Am. A 4,
433 (1987)) offers a realistic model for characterizing the effect of
stochastic non-image forming optical media on the state of polarization of
transmittedlight. With suitable choice of the Jones ensemble, various Mueller
transformations - some of which have been unknown so far - are deduced. It is
observed that the ensemble approach is formally identical to the positive
operator valued measures (POVM) on the quantum density matrix. This
observation, in combination with the recent suggestion by Ahnert and Payne
(Phys. Rev. A 71, 012330, (2005)) - in the context of generalized quantum
measurement on single photon polarization states - that linear optics elements
can be employed in setting up all possible POVMs, enables us to propose a way
of realizing different types of Mueller devices.

Categories: physics.data-an, physics.comp-ph
Abstract: The extraction of a physical law y=yo(x) from joint experimental data about x
and y is treated. The joint, the marginal and the conditional probability
density functions (PDF) are expressed by given data over an estimator whose
kernel is the instrument scattering function. As an optimal estimator of yo(x)
the conditional average is proposed. The analysis of its properties is based
upon a new definition of prediction quality. The joint experimental information
and the redundancy of joint measurements are expressed by the relative entropy.
With the number of experiments the redundancy on average increases, while the
experimental information converges to a certain limit value. The difference
between this limit value and the experimental information at a finite number of
data represents the discrepancy between the experimentally determined and the
true properties of the phenomenon. The sum of the discrepancy measure and the
redundancy is utilized as a cost function. By its minimum a reasonable number
of data for the extraction of the law yo(x) is specified. The mutual
information is defined by the marginal and the conditional PDFs of the
variables. The ratio between mutual information and marginal information is
used to indicate which variable is the independent one. The properties of the
introduced statistics are demonstrated on deterministically and randomly
related variables.

Categories: physics.gen-ph
Abstract: Classical oscillator differential equation is replaced by the corresponding
(finite time) difference equation. The equation is, then, symmetrized so that
it remains invariant under the change d going to -d, where d is the smallest
span of time. This symmetric equation has solutions, which come in reciprocally
related pairs. One member of a pair agrees with the classical solution and the
other is an oscillating solution and does not converge to a limit as d goes to
0. This solution contributes to oscillator energy a term which is a multiple of
half-integers.

Categories: cond-mat.stat-mech, cond-mat.soft, physics.chem-ph
Abstract: An overview of some analytical approaches to the computation of the
structural and thermodynamic properties of single component and multicomponent
hard-sphere fluids is provided. For the structural properties, they yield a
thermodynamically consistent formulation, thus improving and extending the
known analytical results of the Percus-Yevick theory. Approximate expressions
for the contact values of the radial distribution functions and the
corresponding analytical equations of state are also discussed. Extensions of
this methodology to related systems, such as sticky hard spheres and
square-well fluids, as well as its use in connection with the perturbation
theory of fluids are briefly addressed.

Categories: physics.data-an, physics.comp-ph
Abstract: Redundancy of experimental data is the basic statistic from which the
complexity of a natural phenomenon and the proper number of experiments needed
for its exploration can be estimated. The redundancy is expressed by the
entropy of information pertaining to the probability density function of
experimental variables. Since the calculation of entropy is inconvenient due to
integration over a range of variables, an approximate expression for redundancy
is derived that includes only a sum over the set of experimental data about
these variables. The approximation makes feasible an efficient estimation of
the redundancy of data along with the related experimental information and
information cost function. From the experimental information the complexity of
the phenomenon can be simply estimated, while the proper number of experiments
needed for its exploration can be determined from the minimum of the cost
function. The performance of the approximate estimation of these statistics is
demonstrated on two-dimensional normally distributed random data.

Categories: physics.optics
Abstract: Using the recently reported mode locking effect we demonstrate a highly
robust control of electron spin coherence in an ensemble of (In,Ga)As quantum
dots during the single spin coherence time. The spin precession in a transverse
magnetic field can be fully controlled up to 25 K by the parameters of the
exciting pulsed laser protocol such as the pulse train sequence, leading to
adjustable quantum beat bursts in Faraday rotation. Flipping of the electron
spin precession phase was demonstrated by inverting the polarization within a
pulse doublet sequence.

Categories: physics.plasm-ph
Abstract: We calculate the equation of state of dense hydrogen within the chemical
picture. Fluid variational theory is generalized for a multi-component system
of molecules, atoms, electrons, and protons. Chemical equilibrium is supposed
for the reactions dissociation and ionization. We identify the region of
thermodynamic instability which is related to the plasma phase transition. The
reflectivity is calculated along the Hugoniot curve and compared with
experimental results. The equation-of-state data is used to calculate the
pressure and temperature profiles for the interior of Jupiter.

Categories: physics.optics, physics.comp-ph
Abstract: We investigate the use of a Genetic Algorithm (GA) to design a set of
photonic crystals (PCs) in one and two dimensions. Our flexible design
methodology allows us to optimize PC structures which are optimized for
specific objectives. In this paper, we report the results of several such
GA-based PC optimizations. We show that the GA performs well even in very
complex design spaces, and therefore has great potential for use as a robust
design tool in present and future applications.

Categories: physics.bio-ph, physics.data-an, q-bio.BM
Abstract: A number of recently discovered protein structures incorporate a rather
unexpected structural feature: a knot in the polypeptide backbone. These knots
are extremely rare, but their occurrence is likely connected to protein
function in as yet unexplored fashion. Our analysis of the complete Protein
Data Bank reveals several new knots which, along with previously discovered
ones, can shed light on such connections. In particular, we identify the most
complex knot discovered to date in human ubiquitin hydrolase, and suggest that
its entangled topology protects it against unfolding and degradation by the
proteasome. Knots in proteins are typically preserved across species and
sometimes even across kingdoms. However, we also identify a knot which only
appears in some transcarbamylases while being absent in homologous proteins of
similar structure. The emergence of the knot is accompanied by a shift in the
enzymatic function of the protein. We suggest that the simple insertion of a
short DNA fragment into the gene may suffice to turn an unknotted into a
knotted structure in this protein.

Categories: physics.optics
Abstract: We theoretically investigate the possibility of observing resonant activation
in the hopping dynamics of two-mode semiconductor lasers. We present a series
of simulations of a rate-equations model under random and periodic modulation
of the bias current. In both cases, for an optimal choice of the modulation
time-scale, the hopping times between the stable lasing modes attain a minimum.
The simulation data are understood by means of an effective one-dimensional
Langevin equation with multiplicative fluctuations. Our conclusions apply to
both Edge Emitting and Vertical Cavity Lasers, thus opening the way to several
experimental tests in such optical systems.

Categories: physics.optics, math-ph, math.MP
Abstract: There is currently a great deal of interest in the theoretical and practical
possibility of cloaking objects from the observation by electromagnetic waves.
The basic idea of these invisibility devices \cite{glu1, glu2, le},\cite{pss1}
is to use anisotropic {\it transformation media} whose permittivity and
permeability $\var^{\lambda\nu}, \mu^{\lambda\nu}$, are obtained from the ones,
$\var_0^{\lambda\nu}, \mu^{\lambda\nu}_0$, of isotropic media, by singular
transformations of coordinates. In this paper we study electromagnetic cloaking
in the time-domain using the formalism of time-dependent scattering theory.
This formalism allows us to settle in an unambiguous way the mathematical
problems posed by the singularities of the inverse of the permittivity and the
permeability of the {\it transformation media} on the boundary of the cloaked
objects. We write Maxwell's equations in Schr\"odinger form with the
electromagnetic propagator playing the role of the Hamiltonian. We prove that
the electromagnetic propagator outside of the cloaked objects is essentially
self-adjoint. Moreover, the unique self-adjoint extension is unitarily
equivalent to the electromagnetic propagator in the medium
$\var_0^{\lambda\nu}, \mu^{\lambda\nu}_0$. Using this fact, and since the
coordinate transformation is the identity outside of a ball, we prove that the
scattering operator is the identity. Our results give a rigorous proof that the
construction of \cite{glu1, glu2, le}, \cite{pss1} perfectly cloaks passive and
active devices from observation by electromagnetic waves. Furthermore, we prove
cloaking for general anisotropic materials. In particular, our results prove
that it is possible to cloak objects inside general crystals.

Categories: physics.flu-dyn, physics.plasm-ph
Abstract: We study material lines and passive vectors in a model of turbulent flow at
infinite-Reynolds number, the Kraichnan-Kazantsev ensemble of velocities that
are white-noise in time and rough (Hoelder continuous) in space. It is argued
that the phenomenon of ``spontaneous stochasticity'' generalizes to material
lines and that conservation of circulations generalizes to a ``martingale
property'' of the stochastic process of lines.

Categories: physics.comp-ph
Abstract: We present a new version of TaylUR, a Fortran 95 module to automatically
compute the numerical values of a complex-valued function's derivatives with
respect to several variables up to an arbitrary order in each variable, but
excluding mixed derivatives. The new version fixes a potentially serious bug in
the code for exponential-related functions that could corrupt the imaginary
parts of derivatives, as well as being compatible with a wider range of
compilers.

Categories: physics.atom-ph, cond-mat.other
Abstract: We present experimental and theoretical results showing the improved beam
quality and reduced divergence of an atom laser produced by an optical Raman
transition, compared to one produced by an RF transition. We show that Raman
outcoupling can eliminate the diverging lens effect that the condensate has on
the outcoupled atoms. This substantially improves the beam quality of the atom
laser, and the improvement may be greater than a factor of ten for experiments
with tight trapping potentials. We show that Raman outcoupling can produce atom
lasers whose quality is only limited by the wavefunction shape of the
condensate that produces them, typically a factor of 1.3 above the Heisenberg
limit.

Categories: astro-ph, physics.ao-ph
Abstract: Air fluorescence detectors measure the energy of ultra-high energy cosmic
rays by collecting fluorescence light emitted from nitrogen molecules along the
extensive air shower cascade. To ensure a reliable energy determination, the
light signal needs to be corrected for atmospheric effects, which not only
attenuate the signal, but also produce a non-negligible background component
due to scattered Cherenkov light and multiple-scattered light. The correction
requires regular measurements of the aerosol attenuation length and the aerosol
phase function, defined as the probability of light scattered in a given
direction. At the Pierre Auger Observatory in Malargue, Argentina, the phase
function is measured on an hourly basis using two Aerosol Phase Function (APF)
light sources. These sources direct a UV light beam across the field of view of
the fluorescence detectors; the phase function can be extracted from the image
of the shots in the fluorescence detector cameras. This paper describes the
design, current status, standard operation procedure, and performance of the
APF system at the Pierre Auger Observatory.

Categories: physics.bio-ph
Abstract: We present a model for the spontaneous formation of a striated pattern in
polymerizing microtubule solutions. It describes the buckling of a single
microtubule (MT) bundle within an elastic network formed by other similarly
aligned and buckling bundles and unaligned MTs. Phase contrast and polarization
microscopy studies of the temporal evolution of the pattern imply that the
polymerization of MTs within the bundles creates the driving compressional
force. Using the measured rate of buckling, the established MT force-velocity
curve and the pattern wavelength, we obtain reasonable estimates for the MT
bundle bending rigidity and the elastic constant of the network. The analysis
implies that the bundles buckle as solid rods.

Categories: physics.soc-ph
Abstract: The ever-increasing knowledge of the structure of various real-world networks
has uncovered their complex multi-mechanism-governed evolution processes.
Therefore, a better understanding of the structure and evolution of these
networked complex systems requires us to describe such processes in a more
detailed and realistic manner. In this paper, we introduce a new type of
network growth rule which comprises addition and deletion of nodes, and propose
an evolving network model to investigate the effect of node deleting on network
structure. It is found that, with the introduction of node deleting, network
structure is significantly transformed. In particular, degree distribution of
the network undergoes a transition from scale-free to exponential forms as the
intensity of node deleting increases. At the same time, nontrivial
disassortative degree correlation develops spontaneously as a natural result of
network evolution in the model. We also demonstrate that node deleting
introduced in the model does not destroy the connectedness of a growing network
so long as the increasing rate of edges is not excessively small. In addition,
it is found that node deleting will weaken but not eliminate the small-world
effect of a growing network, and generally it will decrease the clustering
coefficient in a network.

Categories: cond-mat.stat-mech, physics.ins-det
Abstract: We report on measurements of the transverse fluctuations of a string in a
turbulent air jet flow. Harmonic modes are excited by the fluctuating drag
force, at different wave-numbers. This simple mechanical probe makes it
possible to measure excitations of the flow at specific scales, averaged over
space and time: it is a scale-resolved, global measurement. We also measure the
dissipation associated to the string motion, and we consider the ratio of the
fluctuations over dissipation (FDR). In an exploratory approach, we investigate
the concept of {\it effective temperature} defined through the FDR. We compare
our observations with other definitions of temperature in turbulence. From the
theory of Kolmogorov (1941), we derive the exponent -11/3 expected for the
spectrum of the fluctuations. This simple model and our experimental results
are in good agreement, over the range of wave-numbers, and Reynolds number
accessible ($74000 \leq Re \leq 170000$).

Categories: physics.chem-ph
Abstract: In line with the local philicity concept proposed by Chattaraj et al.
(Chattaraj, P. K.; Maiti, B.; Sarkar, U. J. Phys. Chem. A. 2003, 107, 4973) and
a dual descriptor derived by Toro-Labbe and coworkers (Morell, C.; Grand, A.;
Toro-Labbe, A. J. Phys. Chem. A. 2005, 109, 205), we propose a multiphilic
descriptor. It is defined as the difference between nucleophilic (Wk+) and
electrophilic (Wk-) condensed philicity functions. This descriptor is capable
of simultaneously explaining the nucleophilicity and electrophilicity of the
given atomic sites in the molecule. Variation of these quantities along the
path of a soft reaction is also analyzed. Predictive ability of this descriptor
has been successfully tested on the selected systems and reactions.
Corresponding force profiles are also analyzed in some representative cases.
Also, to study the intra- and intermolecular reactivities another related
descriptor namely, the nucleophilicity excess (DelW-+) for a nucleophile, over
the electrophilicity in it has been defined and tested on all-metal aromatic
compounds.

Categories: physics.flu-dyn, physics.comp-ph
Abstract: In spite of the large number of papers appeared in the past which are devoted
to the lattice Boltzmann (LB) methods, basic aspects of the theory still remain
unchallenged. An unsolved theoretical issue is related to the construction of a
discrete kinetic theory which yields \textit{exactly} the fluid equations,
i.e., is non-asymptotic (here denoted as \textit{LB inverse kinetic theory}).
The purpose of this paper is theoretical and aims at developing an inverse
kinetic approach of this type. In principle infinite solutions exist to this
problem but the freedom can be exploited in order to meet important
requirements. In particular, the discrete kinetic theory can be defined so that
it yields exactly the fluid equation also for arbitrary non-equilibrium (but
suitably smooth) kinetic distribution functions and arbitrarily close to the
boundary of the fluid domain. Unlike previous entropic LB methods the theorem
can be obtained without functional constraints on the class of the initial
distribution functions. Possible realizations of the theory and asymptotic
approximations are provided which permit to determine the fluid equations
\textit{with prescribed accuracy.} As a result, asymptotic accuracy estimates
of customary LB approaches and comparisons with the Chorin artificial
compressibility method are discussed.

Categories: physics.soc-ph
Abstract: We study numerically the cascading failure problem by using artificially
created scale-free networks and the real network structure of the power grid.
The capacity for a vertex is assigned as a monotonically increasing function of
the load (or the betweenness centrality). Through the use of a simple
functional form with two free parameters, revealed is that it is indeed
possible to make networks more robust while spending less cost. We suggest that
our method to prevent cascade by protecting less vertices is particularly
important for the design of more robust real-world networks to cascading
failures.

Categories: physics.gen-ph
Abstract: Ponderable objects moving in free space according to Newton's First Law
constitute both rulers and clocks when one such object is viewed from the rest
frame of another. Together with the Reciprocity Principle this is used to
demonstrate, in both Galilean and special relativity, the invariance of the
measured length of a ruler in motion. The different times: `proper', `improper'
and `apparent' appearing in different formulations of the relativistic time
dilatation relation are discussed and exemplified by experimental applications.
A non-intuitive `length expansion' effect predicted by the Reciprocity
Principle as a necessary consequence of time dilatation is pointed out

Categories: physics.geo-ph
Abstract: This paper has been withdrawn due to copyright reasons.

Categories: physics.chem-ph
Abstract: The structure of three laminar premixed rich flames has been investigated: a
pure methane flame and two methane flames doped by allene and propyne,
respectively. The gases of the three flames contain 20.9% (molar) of methane
and 33.4% of oxygen, corresponding to an equivalence ratio of 1.25 for the pure
methane flame. In both doped flames, 2.49% of C3H4 was added, corresponding to
a ratio C3H4/CH4 of 12% and an equivalence ratio of 1.55. The three flames have
been stabilized on a burner at a pressure of 6.7 kPa using argon as dilutant,
with a gas velocity at the burner of 36 cm/s at 333 K. The concentration
profiles of stable species were measured by gas chromatography after sampling
with a quartz microprobe. Quantified species included carbon monoxide and
dioxide, methane, oxygen, hydrogen, ethane, ethylene, acetylene, propyne,
allene, propene, propane, 1,2-butadiene, 1,3-butadiene, 1-butene, isobutene,
1-butyne, vinylacetylene, and benzene. The temperature was measured using a
PtRh (6%)-PtRh (30%) thermocouple settled inside the enclosure and ranged from
700 K close to the burner up to 1850 K. In order to model these new results,
some improvements have been made to a mechanism previously developed in our
laboratory for the reactions of C3-C4 unsaturated hydrocarbons. The main
reaction pathways of consumption of allene and propyne and of formation of C6
aromatic species have been derived from flow rate analyses.

Categories: q-bio.NC, cond-mat.dis-nn, physics.soc-ph
Abstract: Structure entails function and thus a structural description of the brain
will help to understand its function and may provide insights into many
properties of brain systems, from their robustness and recovery from damage, to
their dynamics and even their evolution. Advances in the analysis of complex
networks provide useful new approaches to understanding structural and
functional properties of brain networks. Structural properties of networks
recently described allow their characterization as small-world, random
(exponential) and scale-free. They complement the set of other properties that
have been explored in the context of brain connectivity, such as topology,
hodology, clustering, and hierarchical organization. Here we apply new network
analysis methods to cortical inter-areal connectivity networks for the cat and
macaque brains. We compare these corticocortical fibre networks to benchmark
rewired, small-world, scale-free and random networks, using two analysis
strategies, in which we measure the effects of the removal of nodes and
connections on the structural properties of the cortical networks. The brain
networks' structural decay is in most respects similar to that of scale-free
networks. The results implicate highly connected hub-nodes and bottleneck
connections as structural basis for some of the conditional robustness of brain
systems. This informs the understanding of the development of brain networks'
connectivity.

Given a metabolic network in terms of its metabolites and reactions, our goal
is to efficiently compute the minimal knock out sets of reactions required to
block a given behaviour. We describe an algorithm which improves the
computation of these knock out sets when the elementary modes (minimal
functional subsystems) of the network are given. We also describe an algorithm
which computes both the knock out sets and the elementary modes containing the
blocked reactions directly from the description of the network and whose
worst-case computational complexity is better than the algorithms currently in
use for these problems. Computational results are included.

Over the last decade, a large variety of clustering algorithms have been
developed to detect coregulatory relationships among genes from microarray gene
expression data. Model based clustering approaches have emerged as
statistically well grounded methods, but the properties of these algorithms
when applied to large-scale data sets are not always well understood. An
in-depth analysis can reveal important insights about the performance of the
algorithm, the expected quality of the output clusters, and the possibilities
for extracting more relevant information out of a particular data set. We have
extended an existing algorithm for model based clustering of genes to
simultaneously cluster genes and conditions, and used three large compendia of
gene expression data for S. cerevisiae to analyze its properties. The algorithm
uses a Bayesian approach and a Gibbs sampling procedure to iteratively update
the cluster assignment of each gene and condition. For large-scale data sets,
the posterior distribution is strongly peaked on a limited number of
equiprobable clusterings. A GO annotation analysis shows that these local
maxima are all biologically equally significant, and that simultaneously
clustering genes and conditions performs better than only clustering genes and
assuming independent conditions. A collection of distinct equivalent
clusterings can be summarized as a weighted graph on the set of genes, from
which we extract fuzzy, overlapping clusters using a graph spectral method. The
cores of these fuzzy clusters contain tight sets of strongly coexpressed genes,
while the overlaps exhibit relations between genes showing only partial
coexpression.

The G-protein coupled receptor (GPCR) superfamily is currently the largest
class of therapeutic targets. \textit{In silico} prediction of interactions
between GPCRs and small molecules is therefore a crucial step in the drug
discovery process, which remains a daunting task due to the difficulty to
characterize the 3D structure of most GPCRs, and to the limited amount of known
ligands for some members of the superfamily. Chemogenomics, which attempts to
characterize interactions between all members of a target class and all small
molecules simultaneously, has recently been proposed as an interesting
alternative to traditional docking or ligand-based virtual screening
strategies. We propose new methods for in silico chemogenomics and validate
them on the virtual screening of GPCRs. The methods represent an extension of a
recently proposed machine learning strategy, based on support vector machines
(SVM), which provides a flexible framework to incorporate various information
sources on the biological space of targets and on the chemical space of small
molecules. We investigate the use of 2D and 3D descriptors for small molecules,
and test a variety of descriptors for GPCRs. We show fo instance that
incorporating information about the known hierarchical classification of the
target family and about key residues in their inferred binding pockets
significantly improves the prediction accuracy of our model. In particular we
are able to predict ligands of orphan GPCRs with an estimated accuracy of
78.1%.

A composite, exponential relaxation function, modulated by a periodic
component, was used to fit to an experimental time series of blood glucose
levels. The 11 parameters function that allows for the detection of a possible
rhythm transition was fitted to the experimental time series using a genetic
algorithm. It has been found that the relaxation from a hyperglycemic condition
following a change in the anti-diabetic treatment, can be characterized by a
change from an initial 12 hours ultradian rhythm to a near-24 hours circadian
rhythm.

In many experiments, the aim is to deduce an underlying multi-substate on-off
kinetic scheme (KS) from the statistical properties of a two-state trajectory.
However, the mapping of a KS into a two-state trajectory leads to the loss of
information about the KS, and so, in many cases, more than one KS can be
associated with the data. We recently showed that the optimal way to solve this
problem is to use canonical forms of reduced dimensions (RD). RD forms are
on-off networks with connections only between substates of different states,
where the connections can have non-exponential waiting time probability density
functions (WT-PDFs). In theory, only a single RD form can be associated with
the data. To utilize RD forms in the analysis of the data, a RD form should be
associated with the data. Here, we give a toolbox for building a RD form from a
finite two-state trajectory. The methods in the toolbox are based on known
statistical methods in data analysis, combined with statistical methods and
numerical algorithms designed specifically for the current problem. Our toolbox
is self-contained - it builds a mechanism based only on the information it
extracts from the data, and its implementation on the data is fast (analyzing a
10^6 cycle trajectory from a thirty-parameter mechanism takes a couple of hours
on a PC with a 2.66 GHz processor). The toolbox is automated and is freely
available for academic research upon electronic request.

MOTIVATION: The use of oligonucleotide microarray technology requires a very
detailed attention to the design of specific probes spotted on the solid phase.
These problems are far from being commonplace since they refer to complex
physicochemical constraints. Whereas there are more and more publicly available
programs for microarray oligonucleotide design, most of them use the same
algorithm or criteria to design oligos, with only little variation. RESULTS: We
show that classical approaches used in oligo design software may be inefficient
under certain experimental conditions, especially when dealing with complex
target mixtures. Indeed, our biological model is a human obligate parasite, the
microsporidia Encephalitozoon cuniculi. Targets that are extracted from
biological samples are composed of a mixture of pathogen transcripts and host
cell transcripts. We propose a new approach to design oligonucleotides which
combines good specificity with a potentially high sensitivity. This approach is
original in the biological point of view as well as in the algorithmic point of
view. We also present an experimental validation of this new strategy by
comparing results obtained with standard oligos and with our composite oligos.
A specific E.cuniculi microarray will overcome the difficulty to discriminate
the parasite mRNAs from the host cell mRNAs demonstrating the power of the
microarray approach to elucidate the lifestyle of an intracellular pathogen
using mix mRNAs.

Living cells are the product of gene expression programs that involve the
regulated transcription of thousands of genes. The elucidation of
transcriptional regulatory networks in thus needed to understand the cell's
working mechanism, and can for example be useful for the discovery of novel
therapeutic targets. Although several methods have been proposed to infer gene
regulatory networks from gene expression data, a recent comparison on a
large-scale benchmark experiment revealed that most current methods only
predict a limited number of known regulations at a reasonable precision level.
We propose SIRENE, a new method for the inference of gene regulatory networks
from a compendium of expression data. The method decomposes the problem of gene
regulatory network inference into a large number of local binary classification
problems, that focus on separating target genes from non-targets for each TF.
SIRENE is thus conceptually simple and computationally efficient. We test it on
a benchmark experiment aimed at predicting regulations in E. coli, and show
that it retrieves of the order of 6 times more known regulations than other
state-of-the-art inference methods.

We define the complexity of DNA sequences as the information content per
nucleotide, calculated by means of some Lempel-Ziv data compression algorithm.
It is possible to use the statistics of the complexity values of the functional
regions of different complete genomes to distinguish among genomes of different
domains of life (Archaea, Bacteria and Eukarya). We shall focus on the
distribution function of the complexity of noncoding regions. We show that the
three domains may be plotted in separate regions within the two-dimensional
space where the axes are the skewness coefficient and the curtosis coefficient
of the aforementioned distribution. Preliminary results on 15 genomes are
introduced.

Models of the dynamics of cellular interaction networks have become
increasingly larger in recent years. Formal verification based on model
checking provides a powerful technology to keep up with this increase in scale
and complexity. The application of model-checking approaches is hampered,
however, by the difficulty for non-expert users to formulate appropriate
questions in temporal logic. In order to deal with this problem, we propose the
use of patterns, that is, high-level query templates that capture recurring
biological questions and that can be automatically translated into temporal
logic. The applicability of the developed set of patterns has been investigated
by the analysis of an extended model of the network of global regulators
controlling the carbon starvation response in Escherichia coli.

Combination therapies are often needed for effective clinical outcomes in the
management of complex diseases, but presently they are generally based on
empirical clinical experience. Here we suggest a novel application of search
algorithms, originally developed for digital communication, modified to
optimize combinations of therapeutic interventions. In biological experiments
measuring the restoration of the decline with age in heart function and
exercise capacity in Drosophila melanogaster, we found that search algorithms
correctly identified optimal combinations of four drugs with only one third of
the tests performed in a fully factorial search. In experiments identifying
combinations of three doses of up to six drugs for selective killing of human
cancer cells, search algorithms resulted in a highly significant enrichment of
selective combinations compared with random searches. In simulations using a
network model of cell death, we found that the search algorithms identified the
optimal combinations of 6-9 interventions in 80-90% of tests, compared with
15-30% for an equivalent random search. These findings suggest that modified
search algorithms from information theory have the potential to enhance the
discovery of novel therapeutic drug combinations. This report also helps to
frame a biomedical problem that will benefit from an interdisciplinary effort
and suggests a general strategy for its solution.

Any cutting-edge scientific research project requires a myriad of
computational tools for data generation, management, analysis and
visualization. Python is a flexible and extensible scientific programming
platform that offered the perfect solution in our recent comparative genomics
investigation (J. B. Lucks, D. R. Nelson, G. Kudla, J. B. Plotkin. Genome
landscapes and bacteriophage codon usage, PLoS Computational Biology, 4,
1000001, 2008). In this paper, we discuss the challenges of this project, and
how the combined power of Biopython, Matplotlib and SWIG were utilized for the
required computational tasks. We finish by discussing how python goes beyond
being a convenient programming language, and promotes good scientific practice
by enabling clean code, integration with professional programming techniques
such as unit testing, and strong data provenance.

Summary: In anticipation of the individualized proteomics era and the need to
integrate knowledge from disease studies, we have augmented our peptide
identification software RAId DbS to take into account annotated single amino
acid polymorphisms, post-translational modifications, and their documented
disease associations while analyzing a tandem mass spectrum. To facilitate new
discoveries, RAId DbS allows users to conduct searches permitting novel
polymorphisms. Availability: The webserver link is http://www.ncbi.nlm.nih.gov/
/CBBResearch/qmbp/raid dbs/index.html. The relevant databases and binaries of
RAId DbS for Linux, Windows, and Mac OS X are available from the same web page.
Contact: yyu@ncbi.nlm.nih.gov

Models of reaction chemistry based on the stochastic simulation algorithm
(SSA) have become a crucial tool for simulating complicated biological reaction
networks due to their ability to handle extremely complicated reaction networks
and to represent noise in small-scale chemistry. These methods can, however,
become highly inefficient for stiff reaction systems, those in which different
reaction channels operate on widely varying time scales. In this paper, we
develop two methods for accelerating sampling in SSA models: an exact method
and a scheme allowing for sampling accuracy up to any arbitrary error bound.
Both methods depend on analysis of the eigenvalues of continuous time Markov
model graphs that define the behavior of the SSA. We demonstrate these methods
for the specific application of sampling breakage times for multiply-connected
bond networks, a class of stiff system important to models of self-assembly
processes. We show theoretically and empirically that our eigenvalue methods
provide substantially reduced sampling times for a wide range of network
breakage models. These techniques are also likely to have broad use in
accelerating SSA models so as to apply them to systems and parameter ranges
that are currently computationally intractable.

Statistical inference of genetic regulatory networks is essential for
understanding temporal interactions of regulatory elements inside the cells.
For inferences of large networks, identification of network structure is
typical achieved under the assumption of sparsity of the networks.
  When the number of time points in the expression experiment is not too small,
we propose to infer the parameters in the ordinary differential equations using
the techniques from functional data analysis (FDA) by regarding the observed
time course expression data as continuous-time curves. For networks with a
large number of genes, we take advantage of the sparsity of the networks by
penalizing the linear coefficients with a L_1 norm. The ability of the
algorithm to infer network structure is demonstrated using the cell-cycle time
course data for Saccharomyces cerevisiae.

In Proteomics, only the de novo peptide sequencing approach allows a partial
amino acid sequence of a peptide to be found from a MS/MS spectrum. In this
article a preliminary work is presented to discover a complete protein sequence
from spectral data (MS and MS/MS spectra). For the moment, our approach only
uses MS spectra. A Genetic Algorithm (GA) has been designed with a new
evaluation function which works directly with a complete MS spectrum as input
and not with a mass list like the other methods using this kind of data. Thus
the mono isotopic peak extraction step which needs a human intervention is
deleted. The goal of this approach is to discover the sequence of unknown
proteins and to allow a better understanding of the differences between
experimental proteins and proteins from databases.

Some problems with the mathematical analysis on which the UK Non-Native
Organism Risk Assessment Scheme is based are outlined.

This report presents the implementation of a protein sequence comparison
algorithm specifically designed for speeding up time consuming part on parallel
hardware such as SSE instructions, multicore architectures or graphic boards.
Three programs have been developed: PLAST-P, TPLAST-N and PLAST-X. They provide
equivalent results compared to the NCBI BLAST family programs (BLAST-P,
TBLAST-N and BLAST-X) with a speed-up factor ranging from 5 to 10.

Information theory is a branch of probability and statistics involving the
analysis of communications. Information theory enables us to analyze and
quantify the information content of predictions made in the context of plant
disease management and related disciplines. In this article, some applications
of information theory in plant disease management are outlined.

The functioning of many biochemical networks is often robust -- remarkably
stable under changes in external conditions and internal reaction parameters.
Much recent work on robustness and evolvability has focused on the structure of
neutral spaces, in which system behavior remains invariant to mutations.
Recently we have shown that the collective behavior of multiparameter models is
most often 'sloppy': insensitive to changes except along a few 'stiff'
combinations of parameters, with an enormous sloppy neutral subspace.
Robustness is often assumed to be an emergent evolved property, but the
sloppiness natural to biochemical networks offers an alternative non-adaptive
explanation. Conversely, ideas developed to study evolvability in robust
systems can be usefully extended to characterize sloppy systems.

We review a recent trend in computational systems biology which aims at using
pattern recognition algorithms to infer the structure of large-scale biological
networks from heterogeneous genomic data. We present several strategies that
have been proposed and that lead to different pattern recognition problems and
algorithms. The strenght of these approaches is illustrated on the
reconstruction of metabolic, protein-protein and regulatory networks of model
organisms. In all cases, state-of-the-art performance is reported.

In this short note, we analyze the assumptions made by McDougal et al (2006),
both explicit and implicit, in their estimation of the proportion of "true
recent infections" using the BED CEIA. This enables us to write down
expressions for the sensitivity, short term specificity and long term
specificity of a test for recent infection defined by a BED ODn below a
threshold. We then derive an identity which shows the relationship between
these parameters, allowing the elimination of sensitivity and short term
specificity from an expression relating the proportion of "true recent
infections" to the proportion of seropositive individuals testing below
threshold. This has two important consequences. Firstly, the simplified formula
is substantially more amenable to calibration. Secondly, naively treating the
parameters as independent would lead to an incorrect estimate of uncertainty
due to imperfect calibration.

We provide a complete thermodynamic solution of a 1D hopping model in the
presence of a random potential by obtaining the density of states. Since the
partition function is related to the density of states by a Laplace transform,
the density of states determines completely the thermodynamic behavior of the
system. We have also shown that the transfer matrix technique, or the so-called
dynamic programming, used to obtain the density of states in the 1D hopping
model may be generalized to tackle a long-standing problem in statistical
significance assessment for one of the most important proteomic tasks - peptide
sequencing using tandem mass spectrometry data.

Statistically meaningful comparison/combination of peptide identification
results from various search methods is impeded by the lack of a universal
statistical standard. Providing an E-value calibration protocol, we
demonstrated earlier the feasibility of translating either the score or
heuristic E-value reported by any method into the textbook-defined E-value,
which may serve as the universal statistical standard. This protocol, although
robust, may lose spectrum-specific statistics and might require a new
calibration when changes in experimental setup occur. To mitigate these issues,
we developed a new MS/MS search tool, RAId_aPS, that is able to provide
spectrum-specific E-values for additive scoring functions. Given a selection of
scoring functions out of RAId score, K-score, Hyperscore and XCorr, RAId_aPS
generates the corresponding score histograms of all possible peptides using
dynamic programming. Using these score histograms to assign E-values enables a
calibration-free protocol for accurate significance assignment for each scoring
function. RAId_aPS features four different modes: (i) compute the total number
of possible peptides for a given molecular mass range, (ii) generate the score
histogram given a MS/MS spectrum and a scoring function, (iii) reassign
E-values for a list of candidate peptides given a MS/MS spectrum and the
scoring functions chosen, and (iv) perform database searches using selected
scoring functions. In modes (iii) and (iv), RAId_aPS is also capable of
combining results from different scoring functions using spectrum-specific
statistics. The web link is
http://www.ncbi.nlm.nih.gov/CBBresearch/Yu/raid_aps/index.html. Relevant
binaries for Linux, Windows, and Mac OS X are available from the same page.

Networks of person-person contacts form the substrate along which infectious
diseases spread. Most network-based studies of the spread focus on the impact
of variations in degree (the number of contacts an individual has). However,
other effects such as clustering, variations in infectiousness or
susceptibility, or variations in closeness of contacts may play a significant
role. We develop analytic techniques to predict how these effects alter the
growth rate, probability, and size of epidemics and validate the predictions
with a realistic social network. We find that (for given degree distribution
and average transmissibility) clustering is the dominant factor controlling the
growth rate, heterogeneity in infectiousness is the dominant factor controlling
the probability of an epidemic, and heterogeneity in susceptibility is the
dominant factor controlling the size of an epidemic. Edge weights (measuring
closeness or duration of contacts) have impact only if correlations exist
between different edges. Combined, these effects can play a minor role in
reinforcing one another, with the impact of clustering largest when the
population is maximally heterogeneous or if the closer contacts are also
strongly clustered. Our most significant contribution is a systematic way to
address clustering in infectious disease models, and our results have a number
of implications for the design of interventions.

The Tribolium genome contains 21 nuclear receptors, representing all of the
six known subfamilies. When compared to other species, this first complete set
for a Coleoptera reveals a strong conservation of the number and identity of
nuclear receptors in holometabolous insects. Two novelties are observed: the
atypical NR0 gene knirps is present only in brachyceran flies, while the NR2E6
gene is found only in Tribolium and in Apis. Using a quantitative analysis of
the evolutionary rate, we discovered that nuclear receptors could be divided
into two groups. In one group of 13 proteins, the rates follow the trend of the
Mecopterida genome-wide acceleration. In a second group of five nuclear
receptors, all acting together at the top of the ecdysone cascade, we observed
an overacceleration of the evolutionary rate during the early divergence of
Mecopterida. We thus extended our analysis to the twelve classic ecdysone
transcriptional regulators and found that six of them (ECR, USP, HR3, E75, HR4
and Kr-h1) underwent an overacceleration at the base of the Mecopterida
lineage. By contrast, E74, E93, BR, HR39, FTZ-F1 and E78 do not show this
divergence. We suggest that coevolution occurred within a network of regulators
that control the ecdysone cascade. The advent of Tribolium as a powerful model
should allow a better understanding of this evolution.

In this report we review modern nonlinearity methods that can be used in the
preterm birth analysis. The nonlinear analysis of uterine contraction signals
can provide information regarding physiological changes during the menstrual
cycle and pregnancy. This information can be used both for the preterm birth
prediction and the preterm labor control.
  Keywords: preterm birth, complex data analysis, nonlinear methods

Clustering is a concept used in a huge variety of applications. We review a
conceptually very simple algorithm for hierarchical clustering called in the
following the {\it mutual information clustering} (MIC) algorithm. It uses
mutual information (MI) as a similarity measure and exploits its grouping
property: The MI between three objects X, Y, and Z is equal to the sum of the
MI between X and Y, plus the MI between Z and the combined object (XY). We use
MIC both in the Shannon (probabilistic) version of information theory, where
the "objects" are probability distributions represented by random samples, and
in the Kolmogorov (algorithmic) version, where the "objects" are symbol
sequences. We apply our method to the construction of phylogenetic trees from
mitochondrial DNA sequences and we reconstruct the fetal ECG from the output of
independent components analysis (ICA) applied to the ECG of a pregnant woman.

We discuss the property of a.e. and in mean convergence of the Kohonen
algorithm considered as a stochastic process. The various conditions ensuring
the a.e. convergence are described and the connection with the rate decay of
the learning parameter is analyzed. The rate of convergence is discussed for
different choices of learning parameters. We proof rigorously that the rate of
decay of the learning parameter which is most used in the applications is a
sufficient condition for a.e. convergence and we check it numerically. The aim
of the paper is also to clarify the state of the art on the convergence
property of the algorithm in view of the growing number of applications of the
Kohonen neural networks. We apply our theorem and considerations to the case of
genetic classification which is a rapidly developing field.

We propose that certain patterns (scars) -- theoretically and numerically
predicted to be formed by electrons arranged on a sphere to minimize the
repulsive Coulomb potential (the Thomson problem) and experimentally found in
spherical crystals formed by self-assembled polystyrene beads (an instance of
the {\it generalized} Thomson problem) -- could be relevant to extend the
classic Caspar and Klug construction for icosahedrally-shaped virus capsids.
The main idea is that scars could be produced on the capsid at an intermediate
stage of its evolution and the release of the bending energy present in scars
into stretching energy could allow for shape-changes. The conjecture can be
tested in experiments and/or in numerical simulations.

We apply Markov chain lumping techniques to aggregate codons from an
empirical substitution matrix. The standard genetic code as well as higher
order amino acid substitution groups are identified. Since the aggregates are
derived from first principles they do not rely on system dependent assumptions
made beforehand, e.g. regarding criteria on what should constitute an amino
acid group. We therefore argue that the acquired aggregations more accurately
capture the multi-level structure of the substitution dynamics than alternative
techniques.

We apply the concept of subset seeds proposed in [1] to similarity search in
protein sequences. The main question studied is the design of efficient seed
alphabets to construct seeds with optimal sensitivity/selectivity trade-offs.
We propose several different design methods and use them to construct several
alphabets.We then perform an analysis of seeds built over those alphabet and
compare them with the standard Blastp seeding method [2,3], as well as with the
family of vector seeds proposed in [4]. While the formalism of subset seed is
less expressive (but less costly to implement) than the accumulative principle
used in Blastp and vector seeds, our seeds show a similar or even better
performance than Blastp on Bernoulli models of proteins compatible with the
common BLOSUM62 matrix.

Molecular docking is an essential tool for drug design. It helps the
scientist to rapidly know if two molecules, respectively called ligand and
receptor, can be combined together to obtain a stable complex. We propose a new
multi-objective model combining an energy term and a surface term to gain such
complexes. The aim of our model is to provide complexes with a low energy and
low surface. This model has been validated with two multi-objective genetic
algorithms on instances from the literature dedicated to the docking
benchmarking.

Recent advances in experimental neuroscience allow, for the first time,
non-invasive studies of the white matter tracts in the human central nervous
system, thus making available cutting-edge brain anatomical data describing
these global connectivity patterns. This new, non-invasive, technique uses
magnetic resonance imaging to construct a snap-shot of the cortical network
within the living human brain. Here, we report on the initial success of a new
weighted network communicability measure in distinguishing local and global
differences between diseased patients and controls. This approach builds on
recent advances in network science, where an underlying connectivity structure
is used as a means to measure the ease with which information can flow between
nodes. One advantage of our method is that it deals directly with the
real-valued connectivity data, thereby avoiding the need to discretise the
corresponding adjacency matrix, that is, to round weights up to 1 or down to 0,
depending upon some threshold value. Experimental results indicate that the new
approach is able to highlight biologically relevant features that are not
immediately apparent from the raw connectivity data.

An approach for multiplex qualitative and quantitative microarray-based PCR
analysis has been proposed. The characteristics of PCR executed on a gel-based
oligonucleotide microarray with immobilized forward primers and a single common
reverse primer in solution were investigated for several DNA targets. One-stage
multiplex on-chip PCR was studied for simultaneous amplification of herpes
simplex viruses types 1 and 2, cytomegalovirus DNA, and bacteriophage lambda
DNA as an internal control. Additionally the joint analysis of increased number
of targets (with addition of Chlamydia trachomatis, Mycoplasma hominis, and
Ureaplasma urealyticum DNA) was done in two-stage version of assay: first stage
was in-tube PCR with target-specific primers, while the reverse ones contained
5'-adapter region; the second stage was on-chip amplification with immobilized
target-specific forward primers and adapter as common reverse primer in
solution. The possible application of one-stage reaction for human cDNA
analysis was additionally demonstrated with utilization of a common
poly-T-containing primer in solution. SYBR green I; and Cy-5 labeled dUTP were
used for real-time and end-point detection of specific PCR products. The
efficiencies of both one-stage and two-stage reactions was shown to be strongly
dependent on magnesium and primers concentrations. Quantitative PCR in the both
versions was studied with 10-fold serial dilutions of phage lambda DNA. The
method enabled detection of 6 DNA copies per reaction for both versions of
assay. The quantitative interval for one-stage reaction covered eight orders of
concentration. The revealed significant effect of gel pad size on microarray
PCR effectiveness has been discussed.

The Automated Protein Structure Analysis (APSA) method is used for the
classification of supersecondary structures. Basis for the classification is
the encoding of three-dimensional (3D) residue conformations into a 16-letter
code (3D-1D projection). It is shown that the letter code of the protein makes
it possible to reconstruct its overall shape without ambiguity (1D-3D
translation). Accordingly, the letter code is used for the development of
classification rules that distinguish supersecondary structures by the
properties of their turns and the orientation of the flanking helix or strand
structures. The orientations of turn and flanking structures are collected in
an octant system that helps to specify 196 supersecondary groups for
(alpha,alpha)-, (alpha,beta)-, (beta,alpha)-, (beta,beta)-class. 391 protein
chains leading to 2499 super secondary structures were analyzed. Frequently
occurring super secondary structures are identified with the help of the octant
classification system and explained on the basis of their letter and
classification codes.

A new method for the Automated Protein Structure Analysis (APSA) is derived,
which simplifies the protein backbone to a smooth curve in 3-dimensional space.
For the purpose of obtaining this smooth line each amino acid is represented by
its C$_{\alpha}$ atom, which serves as suitable anchor point for a cubic spline
fit. The backbone line is characterized by arc length $s$, curvature
$\kappa(s)$, and torsion $\tau(s)$. The $\kappa(s)$ and $\tau(s)$ diagrams of
the protein backbone suppress, because of the level of coarse graining applied,
details of the bond framework of the backbone, however reveal accurately all
secondary structure features of a protein. Advantages of APSA are its
quantitative representation and analysis of 3-dimensional structure in form of
2-dimensional curvature and torsion patterns, its easy visualization of
complicated conformational features, and its general applicability. Typical
differences between 3$_{10}$-,$\alpha$-, $\pi$-helices, and $\beta$-strands are
quantified with the help of the $\kappa(s)$ and $\tau(s)$ diagrams. For a test
set of 20 proteins, 63 % of all helical residues and 48.5 % of all extended
residues are identified to be in ideal conformational environments with the
help of APSA. APSA is compared with other methods for protein structure
analysis and its applicability to higher levels of protein structure is
discussed.

We have investigated the binding interaction between the bacteriophage lambda
repressor CI and its target DNA using total internal reflection fluorescence
microscopy. Large, step-wise changes in the intensity of the red fluorescent
protein fused to CI were observed as it associated and dissociated from
individually labeled single molecule DNA targets. The stochastic association
and dissociation were characterized by Poisson statistics. Dark and bright
intervals were measured for thousands of individual events. The exponential
distribution of the intervals allowed direct determination of the association
and dissociation rate constants, ka and kd respectively. We resolved in detail
how ka and kd varied as a function of 3 control parameters, the DNA length L,
the CI dimer concentration, and the binding affinity. Our results show that
although interaction with non-operator DNA sequences are observable, CI binding
to the operator site is not dependent on the length of flanking non-operator
DNA.

This note studies feedforward circuits as models for perfect adaptation to
step signals in biological systems. A global convergence theorem is proved in a
general framework, which includes examples from the literature as particular
cases. A notable aspect of these circuits is that they do not adapt to pulse
signals, because they display a memory phenomenon. Estimates are given of the
magnitude of this effect.

This article is addressing a recurrent problem in biology: mining newly built
large scale networks. Our approach consists in comparing these new networks to
well known ones. The visual backbone of this comparative analysis is provided
by a network classification hierarchy. This method makes sense when dealing
with metabolic networks since comparison could be done using pathways
(clusters). Moreover each network models an organism and it exists organism
classification such as taxonomies. Video demonstration:
http://www.labri.fr/perso/bourqui/video.wmv

Random Threshold Networks (RTNs) are an idealized model of diluted, non
symmetric spin glasses, neural networks or gene regulatory networks. RTNs also
serve as an interesting general example of any coordinated causal system. Here
we study the conditions for maximal information transfer and behavior diversity
in RTNs. These conditions are likely to play a major role in physical and
biological systems, perhaps serving as important selective traits in biological
systems. We show that the pairwise mutual information is maximized in
dynamically critical networks. Also, we show that the correlated behavior
diversity is maximized for slightly chaotic networks, close to the critical
region. Importantly, critical networks maximize coordinated, diverse dynamical
behavior across the network and across time: the information transmission
between source and receiver nodes and the diversity of dynamical behaviors,
when measured with a time delay between the source and receiver, are maximized
for critical networks.


This is a missing chapter from Hans Magnus Enzensberger's mathematical
adventure The Number Devil (Henry Holt and Company, New York, 1997). In the
book, a math-hating boy named Robert is visited in his dreams by the clever
Number Devil, who teaches him to love all things numerical. However, we all
forget our dreams from time to time. Here is one adventure that Enzensberger
overlooked, where the Number Devil introduces Robert to geometry not-of-Euclid,
great circles, parallel transport, the pendulum of Foucault, and the genius of
Euler.

In the stability analysis of an equilibrium, given by a stationary point of a
functional F[n] (free energy functional, e.g.), the second derivative of F[n]
plays the essential role. If the system in equilibrium is subject to the
conservation constraint of some extensive property (e.g. volume, material, or
energy conservation), the Euler equation determining the stationary point
corresponding to the equilibrium alters according to the method of Lagrange
multipliers. Here, the question as to how the effects of constraints can be
taken into account in a stability analysis based on second functional
derivatives is examined. It is shown that the concept of constrained second
derivatives incorporates all the effects due to constraints; therefore
constrained second derivatives provide the proper tool for the stability
analysis of equilibria under constraints. For a physically important type of
constraints, it is demonstrated how the presented theory works. Further, the
rigorous derivation of a recently obtained stability condition for a special
case of equilibrium of ultrathin-film binary mixtures is given, presenting a
guide for similar analyses. [For details on constrained derivatives, see also
math-ph/0603027, physics/0603129, physics/0701145.]

Quantum mechanics is difficult to learn because it is counterintuitive, hard
to visualize, mathematically challenging, and abstract. The Physics Education
Technology (PhET) Project, known for its interactive computer simulations for
teaching and learning physics, now includes 18 simulations on quantum mechanics
designed to improve learning of this difficult subject. Our simulations include
several key features to help students build mental models and intuitions about
quantum mechanics: visual representations of abstract concepts and microscopic
processes that cannot be directly observed, interactive environments that
directly couple students' actions to animations, connections to everyday life,
and efficient calculations so students can focus on the concepts rather than
the math. Like all PhET simulations, these are developed using the results of
education research and feedback from educators, and are tested in student
interviews and classroom studies. This article provides an overview of the PhET
quantum simulations and their development. We also describe research
demonstrating their effectiveness and share some insights about student
thinking that we have gained from our research on quantum simulations.

Daganzo's criticisms of second-order fluid approximations of traffic flow [C.
Daganzo, Transpn. Res. B. 29, 277-286 (1995)] and Aw and Rascle's proposal how
to overcome them [A. Aw and M. Rascle, SIAM J. Appl. Math. 60, 916-938 (2000)]
have stimulated an intensive scientific activity in the field of traffic
modeling. Here, we will revisit their arguments and the interpretations behind
them. We will start by analyzing the linear stability of traffic models, which
is a widely established approach to study the ability of traffic models to
describe emergent traffic jams. Besides deriving a collection of useful
formulas for stability analyses, the main attention is put on the
characteristic speeds, which are related to the group velocities of the
linearized model equations. Most macroscopic traffic models with a dynamic
velocity equation appear to predict two characteristic speeds, one of which is
faster than the average velocity. This has been claimed to constitute a
theoretical inconsistency. We will carefully discuss arguments for and against
this view. In particular, we will shed some new light on the problem by
comparing Payne's macroscopic traffic model with the Aw-Rascle model and
macroscopic with microscopic traffic models.

Boussinesq systems of nonlinear partial differential equations are
fundamental equations in geophysical fluid dynamics. In this paper, we use
asymmetric ideas and moving frames to solve the two-dimensional Boussinesq
equations with partial viscosity terms studied by Chae ({\it Adv. Math.} {\bf
203} (2006), 497-513) and the three-dimensional stratified rotating Boussinesq
equations studied by Hsia, Ma and Wang ({\it J. Math. Phys.} {\bf 48} (2007),
no. 6, 06560). We obtain new families of explicit exact solutions with multiple
parameter functions. Many of them are the periodic, quasi-periodic, aperiodic
solutions that may have practical significance. By Fourier expansion and some
of our solutions, one can obtain discontinuous solutions. In addition, Lie
point symmetries are used to simplify our arguments.

We study a simple reaction-diffusion population model [proposed by A. Windus
and H. J. Jensen, J. Phys. A: Math. Theor. 40, 2287 (2007)] on scale-free
networks. In the case of fully random diffusion, the network topology cannot
affect the critical death rate, whereas the heterogeneous connectivity can
cause smaller steady population density and critical population density. In the
case of modified diffusion, we obtain a larger critical death rate and steady
population density, at the meanwhile, lower critical population density, which
is good for the survival of species. The results were obtained using a
mean-field-like framework and were confirmed by computer simulations.

A special version of multi--dimensional simple waves given in [G. Boillat,
{\it J. Math. Phys.} {\bf 11}, 1482-3 (1970)] and [G.M. Webb, R. Ratkiewicz, M.
Brio and G.P. Zank, {\it J. Plasma Phys.} {\bf 59}, 417-460 (1998)] is employed
for fully relativistic fluid and plasma flows. Three essential modes: vortex,
entropy and sound modes are derived where each of them is different from its
nonrelativistic analogue. Vortex and entropy modes are formally solved in both
the laboratory frame and the wave frame (co-moving with the wave front) while
the sound mode is formally solved only in the wave frame at ultra-relativistic
temperatures. In addition, the surface which is the boundary between the
permitted and forbidden regions of the solution is introduced and determined.
Finally a symmetry analysis is performed for the vortex mode equation up to
both point and contact transformations. Fundamental invariants and a form of
general solutions of point transformations along with some specific examples
are also derived.

We analyze the low-energy e-N2 collisions within the framework of the
Modified-Effective Range Theory (MERT) for the long-range potentials, developed
by O'Malley, Spruch and Rosenberg [Journal of Math. Phys. 2, 491 (1961)]. In
comparison to the traditional MERT we do not expand the total cross-section in
the series of the incident momentum \hbar k, but instead we apply the exact
analytical solutions of the Schroedinger equation for the long-range
polarization potential, as proposed in the original formulation of O'Malley et
al. This extends the applicability of MERT up to few eV regime, as we confirm
using some simplified model potential of the electron-molecule interaction. The
parameters of the effective-range expansion (i.e. the scattering length and the
effective range) are determined from experimental, integral elastic cross
sections in the 0.1 - 1.0 eV energy range by fitting procedure. Surprisingly,
our treatment predicts a shape resonance that appears slightly higher than
experimentally well known resonance in the total cross section. Agreement with
the experimentally observed shape-resonance can be improved by assuming the
position of the resonance in a given partial wave. Influence of the quadrupole
potential on resonances is also discussed: we show that it can be disregarded
for N2. In conclusion, the modified-effective range formalism treating the
long-range part of the potential in an exact way, reproduces well both the very
low-energy behavior of the integral cross section as well as the presence of
resonances in the few eV range.

A self-focusing of a coasting relativistic beam in a plasma channel that is
confined by an external magnetic field is studied as a means of reconditioning
the beam emerging from a beam injector [a radio frequency quadrupole (RFQ)] for
a linac. A detailed study of the beam stability in the self-focused beam has
been carried out. In order to explain beam filaments and the resistive hose
instability in a unified way, we treat all the azimuthal modes in the
derivation of the dispersion relation in a finite plasma channel that exhibit
many unstable modes, which are classified by Weinberg's scheme [Steven
Weinberg, J. Math. 8, 614 (1967)].

We present and analyze a penalization method wich extends the the method of
[1] to the case of a rigid body moving freely in an incompressible fluid. The
fluid-solid system is viewed as a single variable density flow with an
interface captured by a level set method. The solid velocity is computed by
averaging at avery time the flow velocity in the solid phase. This velocity is
used to penalize the flow velocity at the fluid-solid interface and to move the
interface. Numerical illustrations are provided to illustrate our convergence
result. A discussion of our result in the light of existing existence results
is also given. [1] Ph. Angot, C.-H. Bruneau and P. Fabrie, A penalization
method to take into account obstacles in incompressible viscous flows, Numer.
Math. 81: 497--520 (1999)

A unified energy principle approach is presented for analysing the
magnetohydrodynamic (MHD) stability of plasmas consisting of multiple ideal and
relaxed regions. By choosing an appropriate gauge, we show that the plasma
displacement satisfies the same Euler-Lagrange equation in ideal and relaxed
regions, except in the neighbourhood of magnetic surfaces. The difference at
singular surfaces is analysed in cylindrical geometry: in ideal MHD only
Newcomb's [W. A. Newcomb (2006) Ann. Phys., 10, 232] small solutions are
allowed, whereas in relaxed MHD only the odd-parity large solution and
even-parity small solution are allowed. A procedure for constructing global
multi-region solutions in cylindrical geometry is presented. Focussing on the
limit where the two interfaces approach each other arbitrarily closely, it is
shown that the singular-limit problem encountered previously [M.J. Hole et al.
(2006) J. Plasma Phys., 77, 1167] in multi-region relaxed MHD is stabilised if
the relaxed-MHD region between the coalescing interfaces is replaced by an
ideal-MHD region. We then present a stable (k, pressure) phase space plot,
which allows us to determine the form a stable pressure and field profile must
take in the region between the interfaces. From this knowledge, we conclude
that there exists a class of single interface plasmas that were found stable by
Kaiser and Uecker [R. Kaiser et al (2004) Q. Jl Mech. Appl. Math., 57, 1], but
are shown to be unstable when the interface is resolved.

This article is the continued version of the analytical solutions for the
pressureless Navier-Stokes equations with density-dependent viscosity in "M.W.
Yuen, Analyitcal Solutions to the Navier-Stokes Equations, J. Math. Phys., 49
(2008) No. 11, 113102, 10pp". We are able to extend the similar solutions
structure to the case with pressure under some restriction for $\gamma$ and
$\theta$.

We point out that the {\em spacetime void} inferred by Castro[J. Math. Phys.
49, 042501, (2008)] results from his choice of a discontinuous radial gauge.
Further since the integration constant $\alpha_0 = 2M_0$ ($G=c=1$) occurring in
the vacuum Hilbert/Schwarzschild solution of a neutral "point mass" is zero
[Arnowitt et al., in Gravitation: An Introduction to Current Research, ed. L.
Witten, Wiley, Chap. 7, p.227; also Phys. Rev. Lett., 4, 375, (1960)]; A.
Mitra, Adv. Sp. Res., 38, 2917 (2006)] Castro's gauge reduces to the well
behaved and physical Hilbert gauge. Physically this means that true
Hilbert/Schwarzschild black holes have unique gravitational mass M=0.
Accordingly, the unphysical {\em spacetime viod} inferred by Castro is actually
non-existent.

This work is directed towards investigating the fate of three-dimensional
long perturbation waves in a plane incompressible wake. The analysis is posed
as an initial-value problem in space. More specifically, input is made at an
initial location in the downstream direction and then tracing the resulting
behavior further downstream subject to the restriction of finite kinetic
energy. This presentation follows the outline given by Criminale and Drazin
[Stud. in Applied Math. \textbf{83}, 123 (1990)] that describes the system in
terms of perturbation vorticity and velocity. The analysis is based on large
scale waves and expansions using multi scales and multi times for the partial
differential equations. The multiscaling is based on an approach where the
small parameter is linked to the perturbation property independently from the
flow control parameter. Solutions of the perturbative equations are determined
numerically after the introduction of a regular perturbation scheme
analytically deduced up to the second order. Numerically, the complete linear
system is also integrated. Since the results relevant to the complete problem
are in very good agreement with the results of the first order analysis, the
numerical solution at the second order was deemed not necessary. The use for an
arbitrary initial-value problem will be shown to contain a wealth of
information for the different transient behaviors associated to the symmetry,
angle of obliquity and spatial decay of the long waves. The amplification
factor of transversal perturbations never presents the trend - a growth
followed by a long damping - usually seen in waves with wavenumber of order one
or less. Asymptotical instability is always observed.

In some recent works [G. Dimarco, L. Pareschi, Hybrid multiscale methods I.
Hyperbolic Relaxation Problems, Comm. Math. Sci., 1, (2006), pp. 155-177], [G.
Dimarco, L. Pareschi, Hybrid multiscale methods II. Kinetic equations, SIAM
Multiscale Modeling and Simulation Vol 6., No 4,pp. 1169-1197, (2008)] we
developed a general framework for the construction of hybrid algorithms which
are able to face efficiently the multiscale nature of some hyperbolic and
kinetic problems. Here, at variance with respect to the previous methods, we
construct a method form-fitting to any type of finite volume or finite
difference scheme for the reduced equilibrium system. Thanks to the coupling of
Monte Carlo techniques for the solution of the kinetic equations with
macroscopic methods for the limiting fluid equations, we show how it is
possible to solve multiscale fluid dynamic phenomena faster with respect to
traditional deterministic/stochastic methods for the full kinetic equations. In
addition, due to the hybrid nature of the schemes, the numerical solution is
affected by less fluctuations when compared to standard Monte Carlo schemes.
Applications to the Boltzmann-BGK equation are presented to show the
performance of the new methods in comparison with classical approaches used in
the simulation of kinetic equations.

In this work we study the hemodynamics in a stented artery connected either
to a collateral artery or to an aneurysmal sac. The blood flow is driven by the
pressure drop. Our aim is to characterize the flow-rate and the pressure in the
contiguous zone to the main artery: using boundary layer theory we construct a
homogenized first order approximation with respect to epsilon, the size of the
stent's wires. This provides an explicit expression of the velocity profile
through and along the stent. The profile depends only on the input/output
pressure data of the problem and some homogenized constant quantities: it is
explicit. In the collateral artery this gives the flow-rate. In the case of the
aneurysm, it shows that : (i) the zeroth order term of the pressure in the sac
equals the averaged pressure along the stent in the main artery, (ii) the
presence of the stent inverses the rotation of the vortex. Extending the tools
set up in [Bonnetier et al, Adv. Math. Fluids, 2009, Milisic, Meth. Apl. Ann.,
2009] we prove rigorously that our asymptotic approximation is first order
accurate with respect to . We derive then new implicit interface conditions
that our approximation formally satisfies, generalizing our analysis to other
possible geometrical configurations. In the last part we provide numerical
results that illustrate and validate the theoretical approach.

We show that the exact integrator for the classical Kepler motion, recently
found by Kozlov ({\it J. Phys. A: Math. Theor.\} {\bf 40} (2007) 4529-4539),
can be derived in a simple natural way (using well known exact discretization
of the harmonic oscillator). We also turn attention on important earlier
references, where the exact discretization of the 4-dimensional isotropic
harmonic oscillator has been applied to the perturbed Kepler problem.

Expansion of a wave function in a basis of eigenfunctions of a differential
eigenvalue problem lies at the heart of the R-matrix methods for both the
Schr\"odinger and Dirac particles. A central issue that should be carefully
analyzed when functional series are applied is their convergence. In the
present paper, we study the properties of the eigenfunction expansions
appearing in nonrelativistic and relativistic $R$-matrix theories. In
particular, we confirm the findings of Rosenthal [J. Phys. G: Nucl. Phys. 13,
491 (1987)] and Szmytkowski and Hinze [J. Phys. B: At. Mol. Opt. Phys. 29, 761
(1996); J. Phys. A: Math. Gen. 29, 6125 (1996)] that in the most popular
formulation of the R-matrix theory for Dirac particles, the functional series
fails to converge to a claimed limit.

In one of the very few exact quantum mechanical calculations of fugacity
coefficients, Dodd and Gibbs (\textit{J. Math.Phys}.,\textbf{15}, 41 (1974))
obtained $b_{2}$ and $b_{3}$ for a one dimensional Bose gas, subject to
repulsive delta-function interactions, by direct integration of the wave
functions. For $b_{2}$, we have shown (\textit{Mol. Phys}.,\textbf{103}, 1301
(2005)) that Dodd and Gibbs' result can be obtained from a phase shift
formalism, if one also includes the contribution of oscillating terms, usually
contributing only in 1 dimension. Now, we develop an exact expression for
$b_{3}-b_{3}^{0}$ (where $b_{3}^{0}$ is the free particle fugacity coefficient)
in terms of sums and differences of 3-body eigenphase shifts. Further, we show
that if we obtain these eigenphase shifts in a distorted-Born approximation,
then, to first order, we reproduce the leading low temperature behaviour,
obtained from an expansion of the two-fold integral of Dodd and Gibbs. The
contributions of the oscillating terms cancel. The formalism that we propose is
not limited to one dimension, but seeks to provide a general method to obtain
virial coefficients, fugacity coefficients, in terms of asymptotic quantities.
The exact one dimensional results allow us to confirm the validity of our
approach in this domain.

In this paper we propose an alternative approach for the assessment of
network vulnerability under random and intentional attacks as compared to the
results obtained from the "vulnerability function" given by Criado et al.
[Criado et al. (Int. J. Comput. Math., 86 (2) (2009), pp. 209-218)]. By using
spectral and statistical measurements, we assess robustness as the antonym to
vulnerability of complex networks and suggest a tentative ranking for
vulnerability, based on the interpretation of quantified network
characteristics. We conclude that vulnerability function, derived from the
network's degree distribution and its variations only, is not general enough to
reflect the lack of robustness due to the specific configurations in graphs
with hierarchical or centralized structures. The spectral and statistical
metrics, on the other hand, capture different aspects of network topology which
provide a more thorough assessment of network vulnerability.

For the first time the kinetic description of Landau diamagnetism for
degenerate collisional plasma is given. The correct expression for transverse
electric conductivity of the quantum plasma, found by authors (see
arXiv:1002.1017 [math-ph] 4 Feb 2010) is used. In work S. Dattagupta, A.M.
Jayannavar and N. Kumar [Current science, V. 80, No. 7, 10 April, 2001] was
discussed the important problem of dissipation (collisions) influence on Landau
diamagnetism. The analysis of this problem is given with the use of exact
expression for transverse conductivity of quantum plasma.

The Fast Multipole Method (FMM) is well known to possess a bottleneck arising
from decreasing workload on higher levels of the FMM tree [Greengard and Gropp,
Comp. Math. Appl., 20(7), 1990]. We show that this potential bottleneck can be
eliminated by overlapping multipole and local expansion computations with
direct kernel evaluations on the finest level grid.

Dynamics of a randomly-perturbed quantum system with 3/2-degrees of freedom
is considered. We introduce a transfer operator being the quantum analogue of
the specific Poincar\'e map. This map was proposed in (Makarov, Uleysky, J.
Phys. A: Math. Gen., 2006) for exploring domains of finite-time stability,
which survive under random excitation. Our attention is concentrated on level
spacing distribution of the transfer operator, averaged over ensemble of
realizations. The problem of sound propagation in an oceanic waveguide is
considered as an example. For the acoustic frequency of 200 Hz, level spacing
distribution undergoes the crossover from Poissonian to Wigner-like statistics
with increasing time, as it is consistent with classical predictions via the
specific Poincar\'e map. For the frequency of 600 Hz, the level spacing
statistics becomes non-universal due to large number of nearly-degenerate
levels whose contribution grows with time. Occurrence of nearly-degenerate
levels is attributed to bifurcations of classical periodic orbits, caused by
fast spatial oscillations of the random perturbation.

Research of influence of collisions on Friedel oscillations in quantum
degenerate collisional plasma (T=0) is carried out for the first time. It is
shown that presence of collisions in plasma leads to exponential decreasing of
amplitude and phase shift of the Friedel oscillations. In linear approximation
the phase shift is equal to the half of quantity inverse to product of Fermi's
wave number by free length path of electrons. The correct expression for
longitudinal dielectric permeability of the quantum collisional plasma found by
the authors (see arxiv:1001.3937 [math-ph] 22 Jan 2010) is used.

An Horizontal Visibility Graph (for short, HVG) is defined in association
with an ordered set of non-negative reals. HVGs realize a methodology in the
analysis of time series, their degree distribution being a good discriminator
between randomness and chaos [B. Luque, et al., Phys. Rev. E 80 (2009),
046103]. We prove that a graph is an HVG if and only if outerplanar and has a
Hamilton path. Therefore, an HVG is a noncrossing graph, as defined in
algebraic combinatorics [P. Flajolet and M. Noy, Discrete Math., 204 (1999)
203-229]. Our characterization of HVGs implies a linear time recognition
algorithm. Treating ordered sets as words, we characterize subfamilies of HVGs
highlighting various connections with combinatorial statistics and introducing
the notion of a visible pair. With this technique we determine asymptotically
the average number of edges of HVGs.

We argue that there is a fundamental problem regarding the analysis that
serves as the foundation for the papers {\it Information theory explanation of
the fluctuation theorem, maximum entropy production and self-organized
criticality in non-equilibrium stationary states} [R. Dewar, J. Phys. A: Math.
Gen. {\bf 36} (2003), 631-641] and {\it Maximum entropy production and the
fluctuation theorem} [R. Dewar, J. Phys. A: Math. Gen. {\bf 38} (2005),
L371-L381]. In particular, we demonstrate that this analysis is based on an
assumption that is physically unrealistic and that, hence, the results obtained
in those papers cannot be regarded as physically meaningful.

A paradigm based on the absolute equilibrium of Galerkin-truncated inviscid
systems to aid in understanding turbulence [T.-D. Lee, "On some statistical
properties of hydrodynamical and magnetohydrodynamical fields," Q. Appl. Math.
10, 69 (1952)] is taken to study gyrokinetic plasma turbulence: A finite set of
Fourier modes of the collisionless gyrokinetic equations are kept and the
statistical equilibria are calculated; possible implications for plasma
turbulence in various situations are discussed. For the case of two spatial and
one velocity dimension, in the calculation with discretization also of velocity
$v$ with $N$ grid points (where $N+1$ quantities are conserved, corresponding
to an energy invariant and $N$ entropy-related invariants), the negative
temperature states, corresponding to the condensation of the generalized energy
into the lowest modes, are found. This indicates a generic feature of inverse
energy cascade. Comparisons are made with some classical results, such as those
of Charney-Hasegawa-Mima in the cold-ion limit. There is a universal shape for
statistical equilibrium of gyrokinetics in three spatial and two velocity
dimensions with just one conserved quantity. Possible physical relevance to
turbulence, such as ITG zonal flows, and to a critical balance hypothesis are
also discussed.