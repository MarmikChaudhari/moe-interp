{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the optimal available device\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        # Enable TF32 for better performance on Ampere GPUs (A100, A6000, etc)\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        # Set memory allocation settings\n",
    "        torch.cuda.empty_cache()\n",
    "        # Enable CUDNN benchmarking for better performance\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28805b4b5b0d499185a4c76355a07750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DeepseekForCausalLM(\n",
       "  (model): DeepseekModel(\n",
       "    (embed_tokens): Embedding(102400, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0): DeepseekDecoderLayer(\n",
       "        (self_attn): DeepseekSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): DeepseekRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): DeepseekMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=10944, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=10944, bias=False)\n",
       "          (down_proj): Linear(in_features=10944, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): DeepseekRMSNorm()\n",
       "        (post_attention_layernorm): DeepseekRMSNorm()\n",
       "      )\n",
       "      (1-27): 27 x DeepseekDecoderLayer(\n",
       "        (self_attn): DeepseekSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): DeepseekRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): DeepseekMoE(\n",
       "          (experts): ModuleList(\n",
       "            (0-63): 64 x DeepseekMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
       "              (down_proj): Linear(in_features=1408, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (gate): MoEGate()\n",
       "          (shared_experts): DeepseekMLP(\n",
       "            (gate_proj): Linear(in_features=2048, out_features=2816, bias=False)\n",
       "            (up_proj): Linear(in_features=2048, out_features=2816, bias=False)\n",
       "            (down_proj): Linear(in_features=2816, out_features=2048, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): DeepseekRMSNorm()\n",
       "        (post_attention_layernorm): DeepseekRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): DeepseekRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=102400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-moe-16b-base\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-moe-16b-base\", trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOEExpertLens:\n",
    "    def __init__(self, state_dict: Dict[str, torch.Tensor], tokenizer, device=None):\n",
    "        \"\"\"Initialize the MoE Expert analyzer.\"\"\"\n",
    "        self.device = device if device is not None else get_device()\n",
    "        self.state_dict = {k: v.to(self.device) for k, v in state_dict.items()}\n",
    "        self.tokenizer = tokenizer\n",
    "        self.hidden_size = self.state_dict[\"model.embed_tokens.weight\"].shape[1]\n",
    "        self.vocab_size = self.state_dict[\"model.embed_tokens.weight\"].shape[0]\n",
    "        # Get model dtype from embeddings\n",
    "        self.dtype = self.state_dict[\"model.embed_tokens.weight\"].dtype\n",
    "\n",
    "    def _process_expert(self, layer_idx: int, expert_idx: int, hidden_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Process hidden state through an expert's weights.\"\"\"\n",
    "        # Get expert weights and ensure dtype match\n",
    "        gate_proj = self.state_dict[f\"model.layers.{layer_idx}.mlp.experts.{expert_idx}.gate_proj.weight\"]\n",
    "        up_proj = self.state_dict[f\"model.layers.{layer_idx}.mlp.experts.{expert_idx}.up_proj.weight\"]\n",
    "        down_proj = self.state_dict[f\"model.layers.{layer_idx}.mlp.experts.{expert_idx}.down_proj.weight\"]\n",
    "\n",
    "        hidden_state = hidden_state.to(self.dtype)\n",
    "        \n",
    "        # Apply MLPs sequentially while maintaining batch and sequence dimensions\n",
    "        gate_output = F.silu(F.linear(hidden_state, gate_proj))\n",
    "        up_output = F.linear(hidden_state, up_proj)\n",
    "        \n",
    "        # Element-wise multiplication and final projection\n",
    "        x = gate_output * up_output\n",
    "        return F.linear(x, down_proj)\n",
    "\n",
    "    def _get_router_output(self, layer_idx: int, hidden_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get router logits for a layer.\"\"\"\n",
    "        router_weights = self.state_dict[f\"model.layers.{layer_idx}.mlp.gate.weight\"]\n",
    "        hidden_state = hidden_state.to(self.dtype)\n",
    "        return F.linear(hidden_state, router_weights)\n",
    "\n",
    "    def _process_attention(self, layer_idx: int, hidden_state: torch.Tensor, \n",
    "                         attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"Process hidden state through self-attention while preserving token-wise information.\"\"\"\n",
    "        q_proj = self.state_dict[f\"model.layers.{layer_idx}.self_attn.q_proj.weight\"]\n",
    "        k_proj = self.state_dict[f\"model.layers.{layer_idx}.self_attn.k_proj.weight\"]\n",
    "        v_proj = self.state_dict[f\"model.layers.{layer_idx}.self_attn.v_proj.weight\"]\n",
    "        o_proj = self.state_dict[f\"model.layers.{layer_idx}.self_attn.o_proj.weight\"]\n",
    "\n",
    "        # Ensure hidden state has correct dtype\n",
    "        hidden_state = hidden_state.to(self.dtype)\n",
    "\n",
    "        # Get shapes\n",
    "        batch_size, seq_len, hidden_dim = hidden_state.shape\n",
    "        num_heads = 32  # DeepSeek specific\n",
    "        head_dim = hidden_dim // num_heads\n",
    "\n",
    "        # Compute QKV with shape preservation\n",
    "        q = F.linear(hidden_state, q_proj).view(batch_size, seq_len, num_heads, head_dim)\n",
    "        k = F.linear(hidden_state, k_proj).view(batch_size, seq_len, num_heads, head_dim)\n",
    "        v = F.linear(hidden_state, v_proj).view(batch_size, seq_len, num_heads, head_dim)\n",
    "\n",
    "        # Transpose for attention computation\n",
    "        q = q.transpose(1, 2)  # [batch, num_heads, seq_len, head_dim]\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        # Compute attention scores\n",
    "        # Cast to float32 for better numerical stability in attention computation\n",
    "        q_float = q.float()\n",
    "        k_float = k.float()\n",
    "        v_float = v.float()\n",
    "\n",
    "        attn_weights = torch.matmul(q_float, k_float.transpose(-2, -1)) / math.sqrt(head_dim)\n",
    "        \n",
    "        # Apply causal mask\n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.bool, device=self.device), diagonal=1)\n",
    "        attn_weights.masked_fill_(causal_mask, float('-inf'))\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            attn_weights = attn_weights + attention_mask\n",
    "\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        context = torch.matmul(attn_weights, v_float)\n",
    "        \n",
    "        # Convert back to original dtype\n",
    "        context = context.to(self.dtype)\n",
    "        \n",
    "        # Reshape and project to output\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, hidden_dim)\n",
    "        return F.linear(context, o_proj)\n",
    "\n",
    "    def _apply_layer_norm(self, layer_idx: int, hidden_state: torch.Tensor, norm_type: str) -> torch.Tensor:\n",
    "        \"\"\"Apply layer normalization while maintaining token information.\"\"\"\n",
    "        weight = self.state_dict[f\"model.layers.{layer_idx}.{norm_type}.weight\"]\n",
    "        hidden_state = hidden_state.to(self.dtype)\n",
    "        return F.layer_norm(hidden_state, (self.hidden_size,), weight=weight)\n",
    "\n",
    "    def _project_to_vocab(self, hidden_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Project hidden state to vocabulary space while preserving token-wise information.\"\"\"\n",
    "        lm_head_weights = self.state_dict[\"lm_head.weight\"]\n",
    "        hidden_state = hidden_state.to(self.dtype)\n",
    "        return F.linear(hidden_state, lm_head_weights)\n",
    "\n",
    "    def analyze_text(self, input_ids: torch.Tensor) -> Dict:\n",
    "        \"\"\"Analyze text through expert lens with proper token state propagation.\"\"\"\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        # Initialize hidden states from embeddings\n",
    "        hidden_states = self.state_dict[\"model.embed_tokens.weight\"][input_ids]\n",
    "        results = {}\n",
    "\n",
    "        # Create causal attention mask (in float32 for numerical stability)\n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.bool, device=self.device), diagonal=1)\n",
    "        attention_mask = torch.zeros(batch_size, 1, seq_len, seq_len, dtype=torch.float32, device=self.device)\n",
    "        attention_mask.masked_fill_(causal_mask, float('-inf'))\n",
    "\n",
    "        for layer_idx in range(1, 28):  # Layers 1-27\n",
    "            layer_results = {\"tokens\": {}}\n",
    "            \n",
    "            # Apply input layer norm while preserving token information\n",
    "            normed_states = self._apply_layer_norm(layer_idx, hidden_states, \"input_layernorm\")\n",
    "            \n",
    "            # Process through attention mechanism\n",
    "            attn_output = self._process_attention(layer_idx, normed_states, attention_mask)\n",
    "            hidden_states = hidden_states + attn_output  # Residual connection\n",
    "            \n",
    "            # Post-attention layer norm\n",
    "            normed_states = self._apply_layer_norm(layer_idx, hidden_states, \"post_attention_layernorm\")\n",
    "            \n",
    "            # Get router decisions for each token\n",
    "            router_logits = self._get_router_output(layer_idx, normed_states)\n",
    "            \n",
    "            # Process each token position separately\n",
    "            for pos in range(seq_len):\n",
    "                token = self.tokenizer.decode([input_ids[0, pos].item()])\n",
    "                token_state = normed_states[:, pos:pos+1]  # Keep batch dimension\n",
    "                \n",
    "                # Get top-k experts for this token\n",
    "                top_k_experts = torch.topk(router_logits[:, pos], k=7, dim=-1)\n",
    "                expert_weights = F.softmax(top_k_experts.values, dim=-1)\n",
    "                \n",
    "                expert_outputs = []\n",
    "                # Process through selected experts\n",
    "                for idx, expert_idx in enumerate(top_k_experts.indices[0]):\n",
    "                    expert_output = self._process_expert(layer_idx, expert_idx.item(), token_state)\n",
    "                    weight = expert_weights[0, idx].item()\n",
    "                    \n",
    "                    # Project expert output to vocab space for analysis\n",
    "                    logits = self._project_to_vocab(expert_output)\n",
    "                    top_tokens = torch.topk(logits.squeeze(1), k=5)\n",
    "                    \n",
    "                    expert_outputs.append({\n",
    "                        \"expert_id\": expert_idx.item(),\n",
    "                        \"weight\": weight,\n",
    "                        \"top_tokens\": [\n",
    "                            (self.tokenizer.decode([idx.item()]), prob.item())\n",
    "                            for idx, prob in zip(top_tokens.indices[0], \n",
    "                                               F.softmax(top_tokens.values[0], dim=-1))\n",
    "                        ]\n",
    "                    })\n",
    "                \n",
    "                layer_results[\"tokens\"][token] = {\n",
    "                    \"position\": pos,\n",
    "                    \"expert_outputs\": expert_outputs\n",
    "                }\n",
    "                \n",
    "                # Update hidden states for this token with weighted expert outputs\n",
    "                token_output = torch.zeros_like(token_state)\n",
    "                for expert_out in expert_outputs:\n",
    "                    expert_idx = expert_out[\"expert_id\"]\n",
    "                    weight = expert_out[\"weight\"]\n",
    "                    expert_output = self._process_expert(layer_idx, expert_idx, token_state)\n",
    "                    token_output += weight * expert_output\n",
    "                \n",
    "                # Update the hidden states for this position\n",
    "                hidden_states[:, pos:pos+1] = hidden_states[:, pos:pos+1] + token_output\n",
    "\n",
    "            results[f\"layer_{layer_idx}\"] = layer_results\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_layer_analysis(tokenizer, results: Dict, token_position: int, input_text: str):\n",
    "    \"\"\"\n",
    "    Creates a plotly visualization of expert activations across layers for a specific token.\n",
    "    Shows all 64 experts with zero weights for non-selected experts.\n",
    "    \"\"\"\n",
    "    # Create lists to store data \n",
    "    layer_nums = []\n",
    "    expert_ids = []\n",
    "    weights = []\n",
    "    hover_texts = []\n",
    "    \n",
    "    total_experts = 64  # Total number of experts in the model\n",
    "    \n",
    "    # Extract token we're visualizing by tokenizing input text first\n",
    "    tokens = tokenizer.encode(input_text)\n",
    "    token = tokenizer.decode([tokens[token_position]])  # Get tokenized token\n",
    "    print(f\"Visualizing token: {token}\")\n",
    "        \n",
    "    for layer_idx in range(1, 28):  # Layers 1-27\n",
    "        layer_data = results[f\"layer_{layer_idx}\"]\n",
    "        token_data = [data for data in layer_data[\"tokens\"].values() \n",
    "                     if data[\"position\"] == token_position][0]\n",
    "        \n",
    "        # Create a mapping of expert_id to its data for this layer\n",
    "        expert_map = {exp[\"expert_id\"]: exp for exp in token_data[\"expert_outputs\"]}\n",
    "        \n",
    "        # Go through all possible experts\n",
    "        for expert_id in range(total_experts):\n",
    "            layer_nums.append(layer_idx)\n",
    "            expert_ids.append(expert_id)\n",
    "            \n",
    "            if expert_id in expert_map:\n",
    "                # Expert was selected\n",
    "                expert_data = expert_map[expert_id]\n",
    "                weight = expert_data[\"weight\"]\n",
    "                top_tokens_text = \"<br>\".join([\n",
    "                    f\"{token}: {prob:.3f}\" \n",
    "                    for token, prob in expert_data[\"top_tokens\"][:5]\n",
    "                ])\n",
    "                hover_text = f\"Layer: {layer_idx}<br>Expert: {expert_id}<br>Weight: {weight:.3f}<br>Top tokens:<br>{top_tokens_text}\"\n",
    "                hover_texts.append(hover_text)\n",
    "            else:\n",
    "                # Expert was not selected\n",
    "                weight = 0\n",
    "                hover_texts.append(None)  # No hover text for unselected experts\n",
    "            \n",
    "            weights.append(weight)\n",
    "    \n",
    "    # Create plotly heatmap\n",
    "    fig = go.Figure(data=go.Scatter(\n",
    "        x=expert_ids,\n",
    "        y=layer_nums,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=9,\n",
    "            color=weights,\n",
    "            colorscale=[\n",
    "                [0, 'rgba(24, 21, 23, 0.8)'],  # Very dark/transparent for zero weights\n",
    "                [0.0001, 'rgb(68,1,84)'],      # Start of Viridis colorscale\n",
    "                [1, 'rgb(253,231,37)']         # End of Viridis colorscale\n",
    "            ],\n",
    "            cmin=0,  # Set minimum of color scale to 0\n",
    "            cmax=1,  # Set maximum of color scale to 1\n",
    "            showscale=True,\n",
    "            colorbar=dict(\n",
    "                title='Weight',\n",
    "                tickmode='linear',\n",
    "                tick0=0,\n",
    "                dtick=0.2\n",
    "            ),\n",
    "        ),\n",
    "        text=hover_texts,\n",
    "        hoverinfo='text',\n",
    "        hovertemplate='%{text}<extra></extra>',  # Only show hover when text exists\n",
    "    ))\n",
    "    \n",
    "    # Update layout with dark theme\n",
    "    fig.update_layout(\n",
    "        template='plotly_dark',\n",
    "        title=f'Expert Activations for Token \"{token}\" at Position {token_position}',\n",
    "        xaxis_title='Expert ID',\n",
    "        yaxis_title='Layer',\n",
    "        yaxis=dict(autorange='reversed'),  # Reverse y-axis to have layer 1 at top\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        showlegend=False,\n",
    "        plot_bgcolor='black',\n",
    "        paper_bgcolor='black'\n",
    "    )\n",
    "    \n",
    "    # Add grid lines\n",
    "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='rgba(128, 128, 128, 0.2)', \n",
    "                     range=[-1, total_experts])\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='rgba(128, 128, 128, 0.2)')\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_enhanced_logit_lens(model_outputs, tokenizer, input_text, position=None):\n",
    "#     \"\"\"\n",
    "#     Creates enhanced visualization of logit lens analysis using plotly.\n",
    "    \n",
    "#     Args:\n",
    "#         model_outputs: Dictionary containing layer outputs and logits\n",
    "#         tokenizer: The model's tokenizer\n",
    "#         input_text: The input text being analyzed\n",
    "#         position: Optional specific position to analyze\n",
    "#     \"\"\"\n",
    "#     import plotly.graph_objects as go\n",
    "#     from plotly.subplots import make_subplots\n",
    "#     import numpy as np\n",
    "    \n",
    "#     # Extract data\n",
    "#     layers = []\n",
    "#     tokens = []\n",
    "#     logits = []\n",
    "#     ranks = []\n",
    "    \n",
    "#     # Process each layer's outputs\n",
    "#     for layer_idx, layer_data in sorted(model_outputs.items()):\n",
    "#         if not layer_idx.startswith('layer_'):\n",
    "#             continue\n",
    "            \n",
    "#         layer_num = int(layer_idx.split('_')[1])\n",
    "#         if position is not None:\n",
    "#             token_data = [data for data in layer_data[\"tokens\"].values() \n",
    "#                          if data[\"position\"] == position][0]\n",
    "#         else:\n",
    "#             token_data = next(iter(layer_data[\"tokens\"].values()))\n",
    "            \n",
    "#         # Get top 5 predictions for this layer\n",
    "#         top_predictions = []\n",
    "#         top_logits = []\n",
    "#         for exp_output in token_data[\"expert_outputs\"]:\n",
    "#             for tok, prob in exp_output[\"top_tokens\"]:\n",
    "#                 if tok not in top_predictions:\n",
    "#                     top_predictions.append(tok)\n",
    "#                     top_logits.append(prob)\n",
    "#                 if len(top_predictions) >= 5:\n",
    "#                     break\n",
    "#             if len(top_predictions) >= 5:\n",
    "#                 break\n",
    "                \n",
    "#         layers.append(f\"Layer {layer_num}\")\n",
    "#         tokens.extend([t for t in top_predictions if t not in tokens])\n",
    "#         logits.append(top_logits)\n",
    "        \n",
    "#     # Create matrix of logits\n",
    "#     logit_matrix = np.zeros((len(layers), len(tokens)))\n",
    "#     for i, layer_logits in enumerate(logits):\n",
    "#         for j, token in enumerate(tokens[:len(layer_logits)]):\n",
    "#             logit_matrix[i, j] = layer_logits[j]\n",
    "            \n",
    "#     # Create subplots\n",
    "#     fig = make_subplots(rows=2, cols=1, \n",
    "#                        subplot_titles=(\"Token Logits Across Layers\", \n",
    "#                                      \"Top Token Rankings\"),\n",
    "#                        vertical_spacing=0.15)\n",
    "    \n",
    "#     # Add heatmap for logit values\n",
    "#     fig.add_trace(\n",
    "#         go.Heatmap(\n",
    "#             z=logit_matrix,\n",
    "#             x=tokens,\n",
    "#             y=layers,\n",
    "#             colorscale='Viridis',\n",
    "#             text=[[f\"{val:.2f}\" for val in row] for row in logit_matrix],\n",
    "#             texttemplate=\"%{text}\",\n",
    "#             textfont={\"size\":10},\n",
    "#             showscale=True,\n",
    "#             name=\"Logits\"\n",
    "#         ),\n",
    "#         row=1, col=1\n",
    "#     )\n",
    "    \n",
    "#     # Add scatter plot for rankings\n",
    "#     rank_data = []\n",
    "#     for i, layer in enumerate(layers):\n",
    "#         sorted_indices = np.argsort(-logit_matrix[i])  # Sort by descending logit value\n",
    "#         for rank, idx in enumerate(sorted_indices):\n",
    "#             rank_data.append({\n",
    "#                 'layer': layer,\n",
    "#                 'token': tokens[idx],\n",
    "#                 'rank': rank + 1,\n",
    "#                 'logit': logit_matrix[i, idx]\n",
    "#             })\n",
    "            \n",
    "#     fig.add_trace(\n",
    "#         go.Scatter(\n",
    "#             x=[d['layer'] for d in rank_data],\n",
    "#             y=[d['rank'] for d in rank_data],\n",
    "#             mode='markers+text',\n",
    "#             text=[d['token'] for d in rank_data],\n",
    "#             textposition=\"top center\",\n",
    "#             marker=dict(\n",
    "#                 size=10,\n",
    "#                 color=[d['logit'] for d in rank_data],\n",
    "#                 colorscale='Viridis',\n",
    "#                 showscale=True\n",
    "#             ),\n",
    "#             name=\"Token Rankings\"\n",
    "#         ),\n",
    "#         row=2, col=1\n",
    "#     )\n",
    "    \n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         height=1000,\n",
    "#         width=1200,\n",
    "#         title_text=f\"Enhanced Logit Lens Analysis\" + (f\" - Position {position}\" if position else \"\"),\n",
    "#         showlegend=False,\n",
    "#     )\n",
    "    \n",
    "#     # Update axes\n",
    "#     fig.update_xaxes(title_text=\"Tokens\", row=1, col=1)\n",
    "#     fig.update_yaxes(title_text=\"Layers\", row=1, col=1)\n",
    "#     fig.update_xaxes(title_text=\"Layers\", row=2, col=1)\n",
    "#     fig.update_yaxes(title_text=\"Rank\", row=2, col=1, autorange=\"reversed\")\n",
    "    \n",
    "#     return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_enhanced_logit_lens(model_outputs, tokenizer, input_text, position=None):\n",
    "    \"\"\"\n",
    "    Creates a visualization similar to the original logit lens paper style.\n",
    "    \"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    import numpy as np\n",
    "    \n",
    "    # Extract data\n",
    "    layers = []\n",
    "    tokens = []\n",
    "    logits = []\n",
    "    \n",
    "    for layer_idx, layer_data in sorted(model_outputs.items()):\n",
    "        if not layer_idx.startswith('layer_'):\n",
    "            continue\n",
    "            \n",
    "        layer_num = int(layer_idx.split('_')[1])\n",
    "        if position is not None:\n",
    "            token_data = [data for data in layer_data[\"tokens\"].values() \n",
    "                         if data[\"position\"] == position][0]\n",
    "        else:\n",
    "            token_data = next(iter(layer_data[\"tokens\"].values()))\n",
    "            \n",
    "        layer_name = f\"h{layer_num}_out\" if layer_num > 0 else \"h_out\"\n",
    "        layers.append(layer_name)\n",
    "        \n",
    "        # Get token predictions and logits\n",
    "        current_predictions = []\n",
    "        current_logits = []\n",
    "        for exp_output in token_data[\"expert_outputs\"]:\n",
    "            top_tokens = [(tok, prob) for tok, prob in exp_output[\"top_tokens\"]]\n",
    "            current_predictions.extend([t[0] for t in top_tokens])\n",
    "            current_logits.extend([t[1] for t in top_tokens])\n",
    "            \n",
    "        # Add new unique tokens to the global list\n",
    "        for tok in current_predictions:\n",
    "            if tok not in tokens:\n",
    "                tokens.append(tok)\n",
    "                \n",
    "        # Create full logit vector for this layer\n",
    "        layer_logits = []\n",
    "        for tok in tokens:\n",
    "            if tok in current_predictions:\n",
    "                idx = current_predictions.index(tok)\n",
    "                layer_logits.append(current_logits[idx])\n",
    "            else:\n",
    "                layer_logits.append(0)  # or some small negative number\n",
    "                \n",
    "        logits.append(layer_logits)\n",
    "    \n",
    "    # Convert to numpy array for easier manipulation\n",
    "    logit_matrix = np.array(logits)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=logit_matrix,\n",
    "        x=tokens,\n",
    "        y=layers,\n",
    "        colorscale=[\n",
    "            [0, \"rgb(0,0,0)\"],         # Black for lowest values\n",
    "            [0.25, \"rgb(0,0,128)\"],    # Dark blue\n",
    "            [0.5, \"rgb(30,144,255)\"],  # Dodger blue\n",
    "            [0.75, \"rgb(211,211,211)\"], # Light gray\n",
    "            [1, \"rgb(255,255,0)\"]      # Yellow for highest values\n",
    "        ],\n",
    "        text=[[f\"'{t}'\" for t in tokens] for _ in range(len(layers))],\n",
    "        texttemplate=\"%{text}\",\n",
    "        textfont={\"size\": 10, \"color\": \"white\"},\n",
    "        showscale=True,\n",
    "        colorbar=dict(\n",
    "            title=\"Logit Value\",\n",
    "            titleside=\"right\",\n",
    "            tickfont={\"size\": 10},\n",
    "            thickness=15,\n",
    "            len=0.75\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': \"Model's Top Token and its Logit\",\n",
    "            'y': 0.95,\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "            'font': {'size': 14}\n",
    "        },\n",
    "        width=1200,\n",
    "        height=1000,\n",
    "        xaxis=dict(\n",
    "            showgrid=False,\n",
    "            tickangle=45,\n",
    "            tickfont=dict(size=10),\n",
    "            tickmode='array',\n",
    "            ticktext=tokens,\n",
    "            tickvals=list(range(len(tokens)))\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=False,\n",
    "            tickfont=dict(size=10),\n",
    "            autorange='reversed'  # To match the paper's style with h_out at the top\n",
    "        ),\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "    \n",
    "    # Add cell borders using shapes\n",
    "    for i in range(len(layers)+1):\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=-0.5,\n",
    "            x1=len(tokens)-0.5,\n",
    "            y0=i-0.5,\n",
    "            y1=i-0.5,\n",
    "            line=dict(color=\"white\", width=0.5)\n",
    "        )\n",
    "    \n",
    "    for j in range(len(tokens)+1):\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=j-0.5,\n",
    "            x1=j-0.5,\n",
    "            y0=-0.5,\n",
    "            y1=len(layers)-0.5,\n",
    "            line=dict(color=\"white\", width=0.5)\n",
    "        )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_expert_contributions(model_outputs, position=None):\n",
    "    \"\"\"\n",
    "    Creates visualization of expert contributions at each layer.\n",
    "    \n",
    "    Args:\n",
    "        model_outputs: Dictionary containing layer outputs and expert information\n",
    "        position: Optional specific position to analyze\n",
    "    \"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    import numpy as np\n",
    "    \n",
    "    # Extract expert data\n",
    "    layers = []\n",
    "    expert_weights = []\n",
    "    expert_ids = []\n",
    "    \n",
    "    for layer_idx, layer_data in sorted(model_outputs.items()):\n",
    "        if not layer_idx.startswith('layer_'):\n",
    "            continue\n",
    "            \n",
    "        layer_num = int(layer_idx.split('_')[1])\n",
    "        if position is not None:\n",
    "            token_data = [data for data in layer_data[\"tokens\"].values() \n",
    "                         if data[\"position\"] == position][0]\n",
    "        else:\n",
    "            token_data = next(iter(layer_data[\"tokens\"].values()))\n",
    "            \n",
    "        layers.append(f\"Layer {layer_num}\")\n",
    "        \n",
    "        # Get expert weights and ids\n",
    "        layer_weights = []\n",
    "        layer_ids = []\n",
    "        for exp_output in token_data[\"expert_outputs\"]:\n",
    "            layer_weights.append(exp_output[\"weight\"])\n",
    "            layer_ids.append(exp_output[\"expert_id\"])\n",
    "            \n",
    "        expert_weights.append(layer_weights)\n",
    "        expert_ids.extend([id for id in layer_ids if id not in expert_ids])\n",
    "        \n",
    "    # Create matrix of expert weights\n",
    "    weight_matrix = np.zeros((len(layers), len(expert_ids)))\n",
    "    for i, weights in enumerate(expert_weights):\n",
    "        for w, id in zip(weights, expert_ids[:len(weights)]):\n",
    "            weight_matrix[i, expert_ids.index(id)] = w\n",
    "            \n",
    "    # Create figure\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=weight_matrix,\n",
    "        x=[f\"Expert {id}\" for id in expert_ids],\n",
    "        y=layers,\n",
    "        colorscale='Viridis',\n",
    "        text=[[f\"{val:.3f}\" if val > 0 else \"\" for val in row] for row in weight_matrix],\n",
    "        texttemplate=\"%{text}\",\n",
    "        textfont={\"size\":10},\n",
    "        showscale=True,\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Expert Contributions by Layer\" + (f\" - Position {position}\" if position else \"\"),\n",
    "        xaxis_title=\"Experts\",\n",
    "        yaxis_title=\"Layers\",\n",
    "        height=800,\n",
    "        width=1200,\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_moe_logit_lens_with_active_expert_outputs(model, inputs, tokenizer, num_active_experts=7):\n",
    "    model.eval()\n",
    "\n",
    "    # Initial embedding\n",
    "    x = model.model.embed_tokens(inputs)\n",
    "\n",
    "    # Process each layer\n",
    "    for layer_idx, layer in enumerate(model.model.layers):\n",
    "        print(f\"Layer {layer_idx + 1}\")\n",
    "        x = layer.input_layernorm(x)\n",
    "\n",
    "        # Self-attention output\n",
    "        # Remove the position_ids argument here, let the model handle it internally\n",
    "        attn_output = layer.self_attn(x, x, x)\n",
    "        x = attn_output + x  # Residual connection\n",
    "        x = layer.post_attention_layernorm(x)\n",
    "\n",
    "        # MoE Layer\n",
    "        moe_output = layer.mlp(x)\n",
    "        gate_values = moe_output[\"gate_values\"]\n",
    "        expert_outputs = moe_output[\"expert_outputs\"]\n",
    "\n",
    "        # Extract active experts\n",
    "        for batch_idx, gates in enumerate(gate_values):\n",
    "            active_experts = gates.argsort(descending=True)[:num_active_experts]\n",
    "            print(f\"  Batch {batch_idx + 1}:\")\n",
    "            for expert_idx in active_experts:\n",
    "                expert_weight = gates[expert_idx].item()\n",
    "                expert_output = expert_outputs[batch_idx, :, expert_idx]\n",
    "                top_tokens = expert_output.topk(5, dim=-1)\n",
    "                top_indices = top_tokens.indices\n",
    "                top_scores = top_tokens.values\n",
    "                decoded_tokens = tokenizer.decode(top_indices.tolist())\n",
    "                print(f\"    Expert {expert_idx}: Weight: {expert_weight:.4f}, Tokens: {decoded_tokens}, Scores: {top_scores.tolist()}\")\n",
    "\n",
    "    # Final logits\n",
    "    logits = model.lm_head(x)\n",
    "    top_tokens = logits.topk(5, dim=-1)\n",
    "    decoded_final_tokens = tokenizer.decode(top_tokens.indices.tolist())\n",
    "    print(f\"Final Layer: Tokens: {decoded_final_tokens}, Scores: {top_tokens.values.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the optimal available device\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        # Enable TF32 for better performance on Ampere GPUs (A100, A6000, etc)\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        # Set memory allocation settings\n",
    "        torch.cuda.empty_cache()\n",
    "        # Enable CUDNN benchmarking for better performance\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_moe_logit_lens_with_active_expert_outputs(model, inputs, tokenizer, num_active_experts=7):\n",
    "    model.eval()\n",
    "\n",
    "    # Initial embedding\n",
    "    x = model.model.embed_tokens(inputs)\n",
    "\n",
    "    # Process each layer\n",
    "    for layer_idx, layer in enumerate(model.model.layers):\n",
    "        print(f\"Layer {layer_idx + 1}\")\n",
    "        x = layer.input_layernorm(x)\n",
    "\n",
    "        # Self-attention output\n",
    "        # Remove the position_ids argument here, let the model handle it internally\n",
    "        attn_output = layer.self_attn(x, x, x)\n",
    "        x = attn_output + x  # Residual connection\n",
    "        x = layer.post_attention_layernorm(x)\n",
    "\n",
    "        # MoE Layer\n",
    "        moe_output = layer.mlp(x)\n",
    "        gate_values = moe_output[\"gate_values\"]\n",
    "        expert_outputs = moe_output[\"expert_outputs\"]\n",
    "\n",
    "        # Extract active experts\n",
    "        for batch_idx, gates in enumerate(gate_values):\n",
    "            active_experts = gates.argsort(descending=True)[:num_active_experts]\n",
    "            print(f\"  Batch {batch_idx + 1}:\")\n",
    "            for expert_idx in active_experts:\n",
    "                expert_weight = gates[expert_idx].item()\n",
    "                expert_output = expert_outputs[batch_idx, :, expert_idx]\n",
    "                top_tokens = expert_output.topk(5, dim=-1)\n",
    "                top_indices = top_tokens.indices\n",
    "                top_scores = top_tokens.values\n",
    "                decoded_tokens = tokenizer.decode(top_indices.tolist())\n",
    "                print(f\"    Expert {expert_idx}: Weight: {expert_weight:.4f}, Tokens: {decoded_tokens}, Scores: {top_scores.tolist()}\")\n",
    "\n",
    "    # Final logits\n",
    "    logits = model.lm_head(x)\n",
    "    top_tokens = logits.topk(5, dim=-1)\n",
    "    decoded_final_tokens = tokenizer.decode(top_tokens.indices.tolist())\n",
    "    print(f\"Final Layer: Tokens: {decoded_final_tokens}, Scores: {top_tokens.values.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_lens(model, input_tokens):\n",
    "    \"\"\"\n",
    "    Applies a logit lens to each layer of a mixture of experts (MoE) model for specific input tokens.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The MoE model.\n",
    "        input_tokens (torch.Tensor): Input tensor with token embeddings, shape [batch_size, seq_len].\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the logit lens outputs for each token at each layer.\n",
    "    \"\"\"\n",
    "    logit_outputs = {}\n",
    "\n",
    "    # Pass the input tokens through the embedding layer\n",
    "    embedding_output = model.embed_tokens(input_tokens)  # Shape: [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "    # Process tokens through each layer\n",
    "    for layer_idx, layer in enumerate(model.layers):\n",
    "        # Apply the layer and get its output\n",
    "        layer_outputs = layer(embedding_output)  # Shape: [batch_size, seq_len, feature_dim]\n",
    "\n",
    "        # Extract the mixture of experts (MoE) components for this layer\n",
    "        if hasattr(layer.mlp, \"experts\"):\n",
    "            gate_outputs = layer.mlp.gate(embedding_output)  # Shape: [batch_size, seq_len, num_experts]\n",
    "            expert_outputs = []\n",
    "\n",
    "            # Process each token separately to extract expert-specific outputs\n",
    "            for token_idx in range(input_tokens.shape[1]):\n",
    "                token_expert_outputs = []\n",
    "\n",
    "                for expert_idx, expert in enumerate(layer.mlp.experts):\n",
    "                    token_input = embedding_output[:, token_idx, :]  # Shape: [batch_size, embedding_dim]\n",
    "                    expert_output = expert(token_input)  # Shape: [batch_size, feature_dim]\n",
    "                    token_expert_outputs.append(expert_output)\n",
    "\n",
    "                # Stack expert outputs and apply gating\n",
    "                token_expert_outputs = torch.stack(token_expert_outputs, dim=1)  # Shape: [batch_size, num_experts, feature_dim]\n",
    "                token_gate_weights = gate_outputs[:, token_idx, :].unsqueeze(-1)  # Shape: [batch_size, num_experts, 1]\n",
    "                activated_experts_output = torch.sum(token_expert_outputs * token_gate_weights, dim=1)  # Shape: [batch_size, feature_dim]\n",
    "\n",
    "                # Save activated expert outputs for this token\n",
    "                logit_outputs[f\"layer_{layer_idx}_token_{token_idx}_activated_experts\"] = activated_experts_output\n",
    "\n",
    "        # Update the embedding for the next layer\n",
    "        embedding_output = layer_outputs\n",
    "\n",
    "    return logit_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and use as before\n",
    "analyzer = MOEExpertLens(model.state_dict(), tokenizer)\n",
    "text = \"the quick brown fox\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(get_device())\n",
    "results = analyzer.analyze_text(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing token: <｜begin▁of▁sentence｜>\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertemplate": "%{text}<extra></extra>",
         "marker": {
          "cmax": 1,
          "cmin": 0,
          "color": [
           0,
           0.063720703125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.4521484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.03497314453125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.30419921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.05828857421875,
           0,
           0,
           0.047027587890625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.03955078125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1695556640625,
           0,
           0.1287841796875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13427734375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.126708984375,
           0,
           0,
           0,
           0,
           0.1640625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.132080078125,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1446533203125,
           0,
           0,
           0.1148681640625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.141845703125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.136962890625,
           0,
           0,
           0,
           0.1304931640625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1312255859375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11578369140625,
           0,
           0,
           0,
           0.228759765625,
           0,
           0.1627197265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09564208984375,
           0,
           0.185546875,
           0,
           0,
           0,
           0.118896484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0.08544921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1217041015625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.230224609375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1949462890625,
           0,
           0,
           0,
           0,
           0.10003662109375,
           0.095947265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1107177734375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1771240234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1075439453125,
           0,
           0,
           0,
           0.213623046875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09564208984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10528564453125,
           0,
           0,
           0.222900390625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09857177734375,
           0.18408203125,
           0,
           0.1343994140625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1590576171875,
           0,
           0,
           0,
           0.1514892578125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.120361328125,
           0,
           0,
           0,
           0,
           0.2005615234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.129638671875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1309814453125,
           0.1141357421875,
           0,
           0,
           0,
           0,
           0,
           0.15283203125,
           0,
           0,
           0.126953125,
           0,
           0,
           0,
           0.1292724609375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1474609375,
           0,
           0,
           0,
           0,
           0,
           0.1588134765625,
           0,
           0,
           0.15478515625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1563720703125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1263427734375,
           0,
           0.2242431640625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1104736328125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11065673828125,
           0,
           0,
           0,
           0.13037109375,
           0,
           0,
           0.118408203125,
           0,
           0.12017822265625,
           0,
           0,
           0,
           0,
           0.1856689453125,
           0,
           0,
           0.218017578125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1826171875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11083984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.137939453125,
           0,
           0,
           0.10406494140625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13916015625,
           0,
           0.10736083984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0743408203125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.19921875,
           0,
           0,
           0,
           0,
           0,
           0.1312255859375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0755615234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1649169921875,
           0,
           0.1376953125,
           0,
           0.217041015625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11236572265625,
           0,
           0,
           0.181396484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0927734375,
           0,
           0,
           0.255615234375,
           0,
           0,
           0.1429443359375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.111328125,
           0,
           0,
           0,
           0.10345458984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1419677734375,
           0,
           0,
           0.1414794921875,
           0,
           0,
           0,
           0,
           0.1300048828125,
           0,
           0.13916015625,
           0.1300048828125,
           0,
           0.166748046875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.150634765625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2486572265625,
           0,
           0,
           0,
           0.1297607421875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11419677734375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10992431640625,
           0,
           0,
           0,
           0.14453125,
           0,
           0.1109619140625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1419677734375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.115234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.086181640625,
           0.1392822265625,
           0.34765625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1365966796875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.088623046875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.08642578125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09490966796875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12005615234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1767578125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1231689453125,
           0,
           0,
           0.1864013671875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11053466796875,
           0,
           0,
           0,
           0,
           0,
           0.188232421875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10357666015625,
           0,
           0.18603515625,
           0,
           0,
           0.093994140625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.130126953125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1490478515625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09808349609375,
           0,
           0.2392578125,
           0,
           0,
           0.17333984375,
           0.1556396484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.101806640625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10150146484375,
           0,
           0,
           0,
           0,
           0,
           0.14111328125,
           0,
           0,
           0.1883544921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1383056640625,
           0,
           0.0946044921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.095947265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1419677734375,
           0,
           0,
           0,
           0.2056884765625,
           0,
           0.1754150390625,
           0,
           0,
           0,
           0,
           0.143310546875,
           0,
           0,
           0,
           0,
           0,
           0.1431884765625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10455322265625,
           0.31494140625,
           0,
           0,
           0,
           0,
           0,
           0.1011962890625,
           0.1363525390625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0914306640625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12353515625,
           0,
           0,
           0,
           0,
           0,
           0.1280517578125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10540771484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.095703125,
           0,
           0,
           0,
           0.12890625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10186767578125,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09893798828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.32958984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1395263671875,
           0,
           0,
           0,
           0.11846923828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.17626953125,
           0.08673095703125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09521484375,
           0.2783203125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0877685546875,
           0,
           0,
           0.1572265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13330078125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09600830078125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1219482421875,
           0,
           0,
           0.10235595703125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.27490234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1124267578125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1591796875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18017578125,
           0,
           0,
           0.12890625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.127685546875,
           0,
           0.115966796875,
           0,
           0,
           0.1519775390625,
           0,
           0,
           0,
           0.1795654296875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11578369140625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2252197265625,
           0.1309814453125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0911865234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.08001708984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09405517578125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1759033203125,
           0,
           0,
           0,
           0,
           0,
           0.2025146484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.08447265625,
           0,
           0,
           0,
           0,
           0.2315673828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.08447265625,
           0,
           0.11346435546875,
           0,
           0,
           0,
           0.11346435546875,
           0.2822265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0904541015625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1419677734375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.051849365234375,
           0.05499267578125,
           0,
           0,
           0,
           0,
           0,
           0.152587890625,
           0,
           0.328125,
           0.05548095703125,
           0,
           0,
           0,
           0,
           0.215087890625,
           0
          ],
          "colorbar": {
           "dtick": 0.2,
           "tick0": 0,
           "tickmode": "linear",
           "title": {
            "text": "Weight"
           }
          },
          "colorscale": [
           [
            0,
            "rgba(24, 21, 23, 0.8)"
           ],
           [
            0.0001,
            "rgb(68,1,84)"
           ],
           [
            1,
            "rgb(253,231,37)"
           ]
          ],
          "showscale": true,
          "size": 9
         },
         "mode": "markers",
         "text": [
          null,
          "Layer: 1<br>Expert: 1<br>Weight: 0.064<br>Top tokens:<br>0: 0.223<br>7: 0.213<br>2: 0.195<br>9: 0.190<br>4: 0.180",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 14<br>Weight: 0.452<br>Top tokens:<br>lef: 0.236<br>алу: 0.226<br>盘: 0.189<br>�: 0.183<br> : 0.165",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 23<br>Weight: 0.035<br>Top tokens:<br>tia: 0.206<br>igable: 0.201<br>taw: 0.200<br>estrat: 0.197<br>tna: 0.196",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 34<br>Weight: 0.304<br>Top tokens:<br>чев: 0.214<br>府: 0.205<br>emos: 0.195<br>grave: 0.194<br>orat: 0.191",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 51<br>Weight: 0.058<br>Top tokens:<br>SETT: 0.240<br>gens: 0.206<br>==): 0.190<br>laze: 0.183<br>omen: 0.181",
          null,
          null,
          "Layer: 1<br>Expert: 54<br>Weight: 0.047<br>Top tokens:<br>its: 0.207<br>unders: 0.206<br>indo: 0.199<br>alc: 0.194<br>ICI: 0.194",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 63<br>Weight: 0.040<br>Top tokens:<br>хар: 0.206<br>роди: 0.202<br>стата: 0.199<br>Autor: 0.198<br>基: 0.196",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 9<br>Weight: 0.170<br>Top tokens:<br>ospit: 0.206<br>udad: 0.202<br>вис: 0.198<br>uliar: 0.198<br>ROUP: 0.197",
          null,
          "Layer: 2<br>Expert: 11<br>Weight: 0.129<br>Top tokens:<br>erland: 0.248<br>ixed: 0.202<br>issos: 0.188<br>erset: 0.183<br>icho: 0.178",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 27<br>Weight: 0.134<br>Top tokens:<br>alach: 0.227<br>增: 0.195<br>стина: 0.194<br>xen: 0.193<br>tawa: 0.190",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 41<br>Weight: 0.127<br>Top tokens:<br>vous: 0.225<br>ezna: 0.219<br>essor: 0.189<br>hest: 0.184<br>msa: 0.183",
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 46<br>Weight: 0.164<br>Top tokens:<br>ter: 0.220<br>�: 0.209<br>кор: 0.197<br>horn: 0.196<br>och: 0.177",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 56<br>Weight: 0.132<br>Top tokens:<br>APE: 0.211<br>apes: 0.200<br>sche: 0.199<br>ите: 0.196<br>rill: 0.194",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 63<br>Weight: 0.145<br>Top tokens:<br>ренски: 0.229<br>лота: 0.206<br>牌: 0.190<br>�: 0.188<br>lest: 0.187",
          null,
          null,
          "Layer: 3<br>Expert: 2<br>Weight: 0.115<br>Top tokens:<br> преп: 0.207<br>Spl: 0.206<br>�: 0.199<br>worn: 0.195<br> души: 0.193",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 19<br>Weight: 0.142<br>Top tokens:<br>клопе: 0.247<br>INSEE: 0.225<br>мани: 0.185<br>pressor: 0.172<br>援: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 31<br>Weight: 0.137<br>Top tokens:<br>借: 0.233<br>u: 0.204<br> back: 0.193<br>ur: 0.188<br>ity: 0.182",
          null,
          null,
          null,
          "Layer: 3<br>Expert: 35<br>Weight: 0.130<br>Top tokens:<br> U: 0.228<br>redible: 0.207<br>HE: 0.194<br>iano: 0.190<br>Ingress: 0.181",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 43<br>Weight: 0.131<br>Top tokens:<br>уна: 0.274<br>sega: 0.185<br>GREE: 0.184<br>icot: 0.180<br>gom: 0.177",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 58<br>Weight: 0.116<br>Top tokens:<br>artney: 0.234<br>卡: 0.226<br>AudioEvent: 0.190<br>пте: 0.176<br>oda: 0.175",
          null,
          null,
          null,
          "Layer: 3<br>Expert: 62<br>Weight: 0.229<br>Top tokens:<br>rences: 0.235<br>batim: 0.220<br> denomination: 0.186<br> Mediterrani: 0.179<br>али: 0.179",
          null,
          "Layer: 4<br>Expert: 0<br>Weight: 0.163<br>Top tokens:<br>ugat: 0.207<br>Msk: 0.205<br>尼奥: 0.200<br>alera: 0.194<br>学金: 0.194",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 13<br>Weight: 0.096<br>Top tokens:<br>psfrag: 0.234<br>OPLE: 0.200<br>工: 0.189<br>nida: 0.189<br>榄: 0.188",
          null,
          "Layer: 4<br>Expert: 15<br>Weight: 0.186<br>Top tokens:<br>��: 0.220<br>捷: 0.200<br>prop: 0.197<br> уче: 0.193<br>problem: 0.191",
          null,
          null,
          null,
          "Layer: 4<br>Expert: 19<br>Weight: 0.119<br>Top tokens:<br>ateurs: 0.216<br>iscellaneous: 0.202<br>暂: 0.200<br> suf: 0.193<br>欧: 0.189",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 26<br>Weight: 0.085<br>Top tokens:<br>heet: 0.225<br>6: 0.208<br>3: 0.191<br>7: 0.190<br>erns: 0.186",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 38<br>Weight: 0.122<br>Top tokens:<br> гри: 0.216<br>造: 0.216<br>opro: 0.190<br>ctions: 0.189<br>ourn: 0.189",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 59<br>Weight: 0.230<br>Top tokens:<br>geu: 0.229<br>ieth: 0.209<br>thorpe: 0.195<br>eenth: 0.193<br>ivil: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 7<br>Weight: 0.195<br>Top tokens:<br>лерия: 0.220<br>emplates: 0.218<br> dimit: 0.199<br>agher: 0.183<br>ophers: 0.181",
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 12<br>Weight: 0.100<br>Top tokens:<br> franceses: 0.220<br>eques: 0.211<br>мания: 0.200<br>хайм: 0.186<br>ствие: 0.183",
          "Layer: 5<br>Expert: 13<br>Weight: 0.096<br>Top tokens:<br>elier: 0.210<br>urbed: 0.209<br>ску: 0.198<br>ile: 0.192<br>ure: 0.190",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 32<br>Weight: 0.111<br>Top tokens:<br>otism: 0.220<br>DAG: 0.199<br>列: 0.199<br>ктори: 0.192<br>ynamic: 0.190",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 42<br>Weight: 0.177<br>Top tokens:<br>itives: 0.224<br>IABLE: 0.200<br>iola: 0.197<br> Fo: 0.190<br>Ђ: 0.188",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 49<br>Weight: 0.108<br>Top tokens:<br>бове: 0.234<br>透: 0.210<br>ASA: 0.189<br>esor: 0.187<br>entina: 0.181",
          null,
          null,
          null,
          "Layer: 5<br>Expert: 53<br>Weight: 0.214<br>Top tokens:<br>itutes: 0.211<br>пор: 0.201<br>iaries: 0.199<br>Matem: 0.199<br>istor: 0.190",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 4<br>Weight: 0.096<br>Top tokens:<br>ackage: 0.230<br>ject: 0.196<br>perty: 0.194<br>raved: 0.191<br> Pro: 0.190",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 19<br>Weight: 0.105<br>Top tokens:<br>添: 0.227<br>umes: 0.208<br>�: 0.200<br>居: 0.188<br>栈: 0.177",
          null,
          null,
          "Layer: 6<br>Expert: 22<br>Weight: 0.223<br>Top tokens:<br>asses: 0.213<br>6: 0.201<br>чина: 0.197<br>hene: 0.197<br>2: 0.192",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 45<br>Weight: 0.099<br>Top tokens:<br>AGR: 0.207<br>мил: 0.207<br>idy: 0.199<br>圆: 0.194<br>睐: 0.193",
          "Layer: 6<br>Expert: 46<br>Weight: 0.184<br>Top tokens:<br>erd: 0.232<br>ases: 0.200<br>refore: 0.199<br>ty: 0.185<br>公共场所: 0.183",
          null,
          "Layer: 6<br>Expert: 48<br>Weight: 0.134<br>Top tokens:<br>мисъл: 0.258<br>olas: 0.201<br>�: 0.187<br>�: 0.181<br>�: 0.173",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 60<br>Weight: 0.159<br>Top tokens:<br>ens: 0.306<br> Hamps: 0.215<br> quadrat: 0.163<br>挛: 0.160<br>бите: 0.156",
          null,
          null,
          null,
          "Layer: 7<br>Expert: 0<br>Weight: 0.151<br>Top tokens:<br>IRS: 0.209<br> &\\\\: 0.204<br>idual: 0.199<br>&\\!: 0.196<br>ymes: 0.192",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 12<br>Weight: 0.120<br>Top tokens:<br>�: 0.221<br>�: 0.201<br>�: 0.199<br>olat: 0.192<br>etry: 0.187",
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 17<br>Weight: 0.201<br>Top tokens:<br>raries: 0.205<br> reput: 0.200<br>чката: 0.199<br>дето: 0.198<br>rity: 0.198",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 26<br>Weight: 0.130<br>Top tokens:<br>фия: 0.208<br>obert: 0.203<br> @: 0.197<br> >: 0.196<br>íř: 0.195",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 54<br>Weight: 0.131<br>Top tokens:<br>Ад: 0.212<br>concent: 0.206<br> сцена: 0.198<br>ския: 0.197<br>acin: 0.187",
          "Layer: 7<br>Expert: 55<br>Weight: 0.114<br>Top tokens:<br> l: 0.227<br>oto: 0.195<br>submitted: 0.194<br>Lun: 0.193<br> -: 0.191",
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 61<br>Weight: 0.153<br>Top tokens:<br>0: 0.228<br>新区: 0.205<br>4: 0.197<br>er: 0.188<br>6: 0.182",
          null,
          null,
          "Layer: 8<br>Expert: 0<br>Weight: 0.127<br>Top tokens:<br>ggreg: 0.213<br>бол: 0.201<br>лети: 0.197<br>̀: 0.196<br>ometria: 0.193",
          null,
          null,
          null,
          "Layer: 8<br>Expert: 4<br>Weight: 0.129<br>Top tokens:<br>лича: 0.253<br>��: 0.195<br>itats: 0.194<br>仅代表作者本人观点: 0.179<br>tingu: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 34<br>Weight: 0.147<br>Top tokens:<br>ighed: 0.245<br>ερ: 0.202<br> Tolosa: 0.190<br>жде: 0.182<br>abet: 0.181",
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 40<br>Weight: 0.159<br>Top tokens:<br>abeth: 0.211<br> consigo: 0.208<br>ecut: 0.197<br>orsk: 0.193<br>ually: 0.190",
          null,
          null,
          "Layer: 8<br>Expert: 43<br>Weight: 0.155<br>Top tokens:<br>scribe: 0.209<br>denly: 0.204<br>PRB: 0.202<br>HDA: 0.194<br>onut: 0.190",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 51<br>Weight: 0.156<br>Top tokens:<br>尽致: 0.208<br>classv: 0.206<br>terness: 0.196<br>索: 0.195<br>ueix: 0.194",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 62<br>Weight: 0.126<br>Top tokens:<br>кор: 0.286<br>nees: 0.224<br>igner: 0.170<br>swire: 0.167<br>rization: 0.153",
          null,
          "Layer: 9<br>Expert: 0<br>Weight: 0.224<br>Top tokens:<br>Anal: 0.208<br>assed: 0.200<br>耕: 0.199<br>ратки: 0.199<br>ayo: 0.194",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 26<br>Weight: 0.110<br>Top tokens:<br>iceless: 0.319<br>etor: 0.235<br>encions: 0.196<br>ezna: 0.133<br>ленове: 0.118",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 47<br>Weight: 0.111<br>Top tokens:<br>пер: 0.210<br>e: 0.209<br>臂: 0.207<br>adopt: 0.188<br> e: 0.186",
          null,
          null,
          null,
          "Layer: 9<br>Expert: 51<br>Weight: 0.130<br>Top tokens:<br>refore: 0.299<br>FTWARE: 0.178<br>�: 0.178<br>osevelt: 0.174<br>itecture: 0.171",
          null,
          null,
          "Layer: 9<br>Expert: 54<br>Weight: 0.118<br>Top tokens:<br> b: 0.236<br>раел: 0.200<br>ambra: 0.193<br>igl: 0.186<br>留: 0.185",
          null,
          "Layer: 9<br>Expert: 56<br>Weight: 0.120<br>Top tokens:<br>0: 0.217<br>amp: 0.214<br>ful: 0.205<br>fully: 0.202<br>abor: 0.162",
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 61<br>Weight: 0.186<br>Top tokens:<br>isher: 0.218<br>ncies: 0.214<br>amf: 0.203<br>essee: 0.183<br>rences: 0.182",
          null,
          null,
          "Layer: 10<br>Expert: 0<br>Weight: 0.218<br>Top tokens:<br>ece: 0.261<br>�: 0.216<br>prises: 0.182<br> Chance: 0.175<br>sem: 0.166",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 8<br>Weight: 0.183<br>Top tokens:<br>gment: 0.229<br>riques: 0.222<br>��: 0.203<br>charg: 0.174<br>стики: 0.173",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 16<br>Weight: 0.111<br>Top tokens:<br>BB: 0.203<br> Ban: 0.200<br> ro: 0.200<br>critical: 0.200<br>RO: 0.196",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 24<br>Weight: 0.138<br>Top tokens:<br>pone: 0.237<br>tole: 0.215<br>wso: 0.187<br>роден: 0.185<br>uminate: 0.176",
          null,
          null,
          "Layer: 10<br>Expert: 27<br>Weight: 0.104<br>Top tokens:<br>path: 0.215<br>晓: 0.208<br>Path: 0.200<br>onge: 0.195<br>igo: 0.183",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 40<br>Weight: 0.139<br>Top tokens:<br>MD: 0.220<br>中国人民: 0.202<br>ставка: 0.194<br> n: 0.193<br>HE: 0.191",
          null,
          "Layer: 10<br>Expert: 42<br>Weight: 0.107<br>Top tokens:<br>isans: 0.258<br>spy: 0.191<br> вне: 0.187<br>жени: 0.182<br>ambda: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 11<br>Weight: 0.074<br>Top tokens:<br>�: 0.225<br>ovar: 0.218<br>мъ: 0.192<br>agal: 0.191<br> coco: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 24<br>Weight: 0.199<br>Top tokens:<br>Cci: 0.228<br> пър: 0.205<br>Quote: 0.196<br>etapes: 0.190<br> Roig: 0.181",
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 30<br>Weight: 0.131<br>Top tokens:<br> офор: 0.221<br>檬: 0.220<br>\"));: 0.193<br>.\"));: 0.184<br>ство: 0.183",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 44<br>Weight: 0.076<br>Top tokens:<br>avell: 0.274<br> nuclears: 0.200<br>planted: 0.195<br>stud: 0.173<br> comr: 0.159",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 54<br>Weight: 0.165<br>Top tokens:<br>numer: 0.226<br> fashion: 0.219<br>ikin: 0.194<br>strike: 0.181<br>ien: 0.181",
          null,
          "Layer: 11<br>Expert: 56<br>Weight: 0.138<br>Top tokens:<br>вле: 0.213<br>iners: 0.204<br>8: 0.196<br>it: 0.195<br>扇: 0.192",
          null,
          "Layer: 11<br>Expert: 58<br>Weight: 0.217<br>Top tokens:<br>itz: 0.210<br>AST: 0.205<br>istics: 0.197<br>azines: 0.195<br>�: 0.193",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 18<br>Weight: 0.112<br>Top tokens:<br>ed: 0.222<br>ned: 0.204<br>alic: 0.201<br>ifies: 0.192<br>伞: 0.182",
          null,
          null,
          "Layer: 12<br>Expert: 21<br>Weight: 0.181<br>Top tokens:<br>澡: 0.246<br>hom: 0.203<br>afr: 0.191<br>стира: 0.188<br>yses: 0.172",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 30<br>Weight: 0.093<br>Top tokens:<br>代: 0.343<br>代的: 0.230<br>َ: 0.152<br>artment: 0.138<br>结: 0.137",
          null,
          null,
          "Layer: 12<br>Expert: 33<br>Weight: 0.256<br>Top tokens:<br>oteca: 0.224<br>根: 0.217<br>crata: 0.205<br>TOOLSET: 0.189<br>Permalink: 0.165",
          null,
          null,
          "Layer: 12<br>Expert: 36<br>Weight: 0.143<br>Top tokens:<br>ainty: 0.227<br>áž: 0.215<br>воре: 0.191<br>HEMA: 0.185<br>}$~\\: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 50<br>Weight: 0.111<br>Top tokens:<br>ousk: 0.229<br>彭: 0.223<br>同学们: 0.207<br>atem: 0.175<br>uum: 0.166",
          null,
          null,
          null,
          "Layer: 12<br>Expert: 54<br>Weight: 0.103<br>Top tokens:<br>uir: 0.268<br>rafia: 0.227<br>мия: 0.222<br>饪: 0.146<br>rafo: 0.137",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 14<br>Weight: 0.142<br>Top tokens:<br>ishop: 0.242<br>nech: 0.213<br>inez: 0.202<br>inada: 0.173<br> seny: 0.170",
          null,
          null,
          "Layer: 13<br>Expert: 17<br>Weight: 0.141<br>Top tokens:<br> minoria: 0.232<br> газ: 0.218<br>ano: 0.204<br>anches: 0.185<br>}}).: 0.162",
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 22<br>Weight: 0.130<br>Top tokens:<br>ellers: 0.236<br>lips: 0.201<br>yards: 0.201<br> Пале: 0.185<br>ftime: 0.176",
          null,
          "Layer: 13<br>Expert: 24<br>Weight: 0.139<br>Top tokens:<br>�: 0.257<br>�: 0.230<br>工: 0.190<br>包: 0.167<br>树木: 0.156",
          "Layer: 13<br>Expert: 25<br>Weight: 0.130<br>Top tokens:<br>时: 0.333<br>сти: 0.176<br>时就: 0.167<br>ocrisy: 0.166<br>────────: 0.158",
          null,
          "Layer: 13<br>Expert: 27<br>Weight: 0.167<br>Top tokens:<br>aquen: 0.247<br>omorphism: 0.204<br>Afganistan: 0.186<br>刘: 0.185<br>oints: 0.178",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 51<br>Weight: 0.151<br>Top tokens:<br>riba: 0.249<br>ignan: 0.194<br>ELY: 0.190<br>uning: 0.187<br>%%%%: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 10<br>Weight: 0.249<br>Top tokens:<br>��: 0.314<br>igny: 0.189<br>jecture: 0.189<br>aried: 0.163<br>atges: 0.146",
          null,
          null,
          null,
          "Layer: 14<br>Expert: 14<br>Weight: 0.130<br>Top tokens:<br>сла: 0.212<br>ela: 0.205<br>вобо: 0.200<br>nas: 0.192<br>mael: 0.191",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 25<br>Weight: 0.114<br>Top tokens:<br>想说: 0.270<br>oot: 0.239<br>悬: 0.171<br>ania: 0.164<br> малка: 0.156",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 33<br>Weight: 0.110<br>Top tokens:<br>1: 0.251<br>3: 0.200<br>8: 0.186<br>4: 0.186<br>ler: 0.177",
          null,
          null,
          null,
          "Layer: 14<br>Expert: 37<br>Weight: 0.145<br>Top tokens:<br>2: 0.269<br>8: 0.223<br>3: 0.215<br>9: 0.156<br>7: 0.137",
          null,
          "Layer: 14<br>Expert: 39<br>Weight: 0.111<br>Top tokens:<br>wed: 0.219<br>缝: 0.211<br>Wind: 0.201<br>jak: 0.193<br>咬: 0.176",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 56<br>Weight: 0.142<br>Top tokens:<br>мин: 0.313<br>sses: 0.209<br>::__: 0.177<br>сал: 0.151<br>мина: 0.151",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 3<br>Weight: 0.115<br>Top tokens:<br>OrCreate: 0.247<br>бя: 0.196<br>rere: 0.193<br> Street: 0.190<br> X: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 16<br>Weight: 0.086<br>Top tokens:<br>gos: 0.251<br>rnia: 0.191<br>chen: 0.189<br>гау: 0.187<br>ων: 0.182",
          "Layer: 15<br>Expert: 17<br>Weight: 0.139<br>Top tokens:<br>скар: 0.273<br>iria: 0.195<br> sessi: 0.181<br>煞: 0.176<br>ския: 0.175",
          "Layer: 15<br>Expert: 18<br>Weight: 0.348<br>Top tokens:<br> Duncker: 0.242<br>\"&: 0.208<br>ът: 0.192<br>лова: 0.189<br> KML: 0.170",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 27<br>Weight: 0.137<br>Top tokens:<br>百花: 0.371<br>欠: 0.221<br>�: 0.144<br>OR: 0.134<br>�: 0.130",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 49<br>Weight: 0.089<br>Top tokens:<br>收回: 0.353<br>ter: 0.227<br>Fetcher: 0.148<br>tee: 0.144<br>fail: 0.128",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 60<br>Weight: 0.086<br>Top tokens:<br>ogenesis: 0.243<br>remount: 0.225<br> $.: 0.186<br>ogens: 0.174<br>menys: 0.172",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 8<br>Weight: 0.095<br>Top tokens:<br>home: 0.261<br>暴: 0.238<br> home: 0.181<br> parch: 0.163<br> Sur: 0.158",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 16<br>Weight: 0.120<br>Top tokens:<br>一个人的: 0.391<br> wind: 0.168<br> log: 0.150<br> perf: 0.146<br>ogu: 0.145",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 23<br>Weight: 0.177<br>Top tokens:<br>MNR: 0.229<br>WireFormat: 0.204<br>inians: 0.202<br>ryptfs: 0.183<br>бран: 0.181",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 33<br>Weight: 0.123<br>Top tokens:<br>refn: 0.484<br>enir: 0.206<br>withstanding: 0.107<br> parlant: 0.106<br> nin: 0.097",
          null,
          null,
          "Layer: 16<br>Expert: 36<br>Weight: 0.186<br>Top tokens:<br>isma: 0.253<br>chk: 0.213<br>лер: 0.200<br>iennes: 0.169<br>jord: 0.165",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 46<br>Weight: 0.111<br>Top tokens:<br> иконо: 0.212<br>�: 0.208<br>стре: 0.197<br>enca: 0.194<br> unary: 0.189",
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 52<br>Weight: 0.188<br>Top tokens:<br>0: 0.310<br>1: 0.192<br>IC: 0.182<br>2: 0.164<br>ph: 0.152",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 15<br>Weight: 0.104<br>Top tokens:<br> s: 0.252<br> o: 0.221<br>eria: 0.185<br> t: 0.173<br>man: 0.169",
          null,
          "Layer: 17<br>Expert: 17<br>Weight: 0.186<br>Top tokens:<br>mber: 0.245<br>amble: 0.203<br>oms: 0.201<br>不错的: 0.178<br>essen: 0.174",
          null,
          null,
          "Layer: 17<br>Expert: 20<br>Weight: 0.094<br>Top tokens:<br>рал: 0.390<br> operaciones: 0.166<br> партия: 0.160<br>aster: 0.150<br>мята: 0.134",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 32<br>Weight: 0.130<br>Top tokens:<br>9: 0.261<br>1: 0.248<br>Front: 0.172<br>8: 0.167<br>7: 0.151",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 45<br>Weight: 0.149<br>Top tokens:<br> r: 0.243<br>j: 0.221<br>t: 0.211<br>r: 0.180<br> t: 0.145",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 60<br>Weight: 0.098<br>Top tokens:<br>adal: 0.314<br>��: 0.188<br>ilden: 0.177<br>об: 0.172<br>orn: 0.148",
          null,
          "Layer: 17<br>Expert: 62<br>Weight: 0.239<br>Top tokens:<br>nimes: 0.269<br> Senat: 0.218<br>хар: 0.199<br> Симеон: 0.167<br> iput: 0.148",
          null,
          null,
          "Layer: 18<br>Expert: 1<br>Weight: 0.173<br>Top tokens:<br>фур: 0.383<br>стъ: 0.215<br>сите: 0.141<br>ela: 0.135<br>Uncle: 0.126",
          "Layer: 18<br>Expert: 2<br>Weight: 0.156<br>Top tokens:<br>�: 0.322<br>�: 0.195<br>目标: 0.173<br>�: 0.156<br>мени: 0.154",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 18<br>Weight: 0.102<br>Top tokens:<br>נ: 0.288<br>лен: 0.213<br>imales: 0.172<br>ше: 0.164<br>çà: 0.162",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 43<br>Weight: 0.102<br>Top tokens:<br>0: 0.245<br>1: 0.226<br>3: 0.204<br>7: 0.179<br>2: 0.146",
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 49<br>Weight: 0.141<br>Top tokens:<br>om: 0.258<br>oke: 0.221<br> **:: 0.209<br>ta: 0.158<br>ba: 0.153",
          null,
          null,
          "Layer: 18<br>Expert: 52<br>Weight: 0.188<br>Top tokens:<br>�: 0.241<br>man: 0.197<br>�: 0.190<br>打出: 0.187<br>mdc: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 62<br>Weight: 0.138<br>Top tokens:<br>8: 0.250<br>1: 0.222<br>6: 0.203<br>5: 0.188<br>ersonals: 0.137",
          null,
          "Layer: 19<br>Expert: 0<br>Weight: 0.095<br>Top tokens:<br> Santi: 0.214<br>ера: 0.212<br> americ: 0.203<br>CDCD: 0.187<br> jesu: 0.184",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 10<br>Weight: 0.096<br>Top tokens:<br>0: 0.273<br>5: 0.239<br>4: 0.215<br>9: 0.156<br>3: 0.116",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 41<br>Weight: 0.142<br>Top tokens:<br>tings: 0.258<br> Ен: 0.217<br>View: 0.193<br>ilinear: 0.167<br>覆: 0.165",
          null,
          null,
          null,
          "Layer: 19<br>Expert: 45<br>Weight: 0.206<br>Top tokens:<br>ajo: 0.428<br> turc: 0.181<br>特朗: 0.149<br> inactius: 0.141<br> второто: 0.101",
          null,
          "Layer: 19<br>Expert: 47<br>Weight: 0.175<br>Top tokens:<br>зар: 0.288<br>isco: 0.216<br>arda: 0.189<br>werp: 0.171<br>bread: 0.137",
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 52<br>Weight: 0.143<br>Top tokens:<br> плен: 0.357<br>行: 0.175<br>textquotedbl: 0.173<br>ък: 0.158<br>co: 0.137",
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 58<br>Weight: 0.143<br>Top tokens:<br>�起: 0.320<br>ardin: 0.221<br> Confl: 0.213<br>干: 0.128<br>Estats: 0.118",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 15<br>Weight: 0.105<br>Top tokens:<br>\"&: 0.229<br>Pages: 0.223<br>acia: 0.219<br>控: 0.170<br>千: 0.159",
          "Layer: 20<br>Expert: 16<br>Weight: 0.315<br>Top tokens:<br>abe: 0.356<br>ija: 0.231<br>adon: 0.143<br>ZE: 0.137<br>amom: 0.134",
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 22<br>Weight: 0.101<br>Top tokens:<br>agut: 0.267<br>TextField: 0.217<br>applications: 0.176<br> писа: 0.173<br>firstrow: 0.167",
          "Layer: 20<br>Expert: 23<br>Weight: 0.136<br>Top tokens:<br>тенберг: 0.248<br>PYG: 0.234<br>WireFormat: 0.186<br>дец: 0.179<br>URSS: 0.154",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 37<br>Weight: 0.091<br>Top tokens:<br>Cap: 0.333<br>cap: 0.211<br>lim: 0.167<br>�: 0.150<br>DLINE: 0.139",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 49<br>Weight: 0.124<br>Top tokens:<br>tender: 0.335<br>fancy: 0.227<br> PMOS: 0.150<br>thom: 0.146<br>нец: 0.142",
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 55<br>Weight: 0.128<br>Top tokens:<br> withal: 0.365<br> Методий: 0.198<br>obius: 0.180<br>ническата: 0.131<br>nids: 0.126",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 2<br>Weight: 0.105<br>Top tokens:<br>ends: 0.264<br>alera: 0.231<br>ucks: 0.189<br>ENDS: 0.175<br>ener: 0.140",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 12<br>Weight: 0.096<br>Top tokens:<br> min: 0.349<br>ir: 0.292<br> g: 0.146<br>a: 0.130<br>min: 0.083",
          null,
          null,
          null,
          "Layer: 21<br>Expert: 16<br>Weight: 0.129<br>Top tokens:<br>华夏: 0.218<br>dot: 0.217<br> blk: 0.196<br>лище: 0.190<br>ie: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 27<br>Weight: 0.102<br>Top tokens:<br>9: 0.361<br>7: 0.183<br>4: 0.163<br>portlet: 0.150<br>8: 0.143",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 34<br>Weight: 0.099<br>Top tokens:<br> small: 0.401<br>small: 0.196<br> Small: 0.138<br> SMALL: 0.135<br>tiny: 0.131",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 45<br>Weight: 0.330<br>Top tokens:<br>зина: 0.256<br>inder: 0.204<br> тор: 0.197<br>osi: 0.181<br> fact: 0.161",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 61<br>Weight: 0.140<br>Top tokens:<br>entr: 0.351<br>enz: 0.179<br>2: 0.175<br>ty: 0.161<br>тората: 0.134",
          null,
          null,
          null,
          "Layer: 22<br>Expert: 1<br>Weight: 0.118<br>Top tokens:<br>CLAIMED: 0.308<br>卵管: 0.274<br>启: 0.172<br>поред: 0.132<br>ichthys: 0.113",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 18<br>Weight: 0.176<br>Top tokens:<br>ossal: 0.250<br>tically: 0.226<br>edes: 0.200<br>шър: 0.193<br> massiva: 0.130",
          "Layer: 22<br>Expert: 19<br>Weight: 0.087<br>Top tokens:<br>1: 0.269<br>3: 0.202<br>9: 0.199<br>4: 0.196<br>7: 0.135",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 33<br>Weight: 0.095<br>Top tokens:<br>рам: 0.234<br>ware: 0.217<br>Ри: 0.210<br>ibol: 0.173<br>gest: 0.167",
          "Layer: 22<br>Expert: 34<br>Weight: 0.278<br>Top tokens:<br>fford: 0.217<br>abast: 0.214<br>тинген: 0.191<br>ROUP: 0.190<br>cling: 0.188",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 53<br>Weight: 0.088<br>Top tokens:<br>гру: 0.250<br>тере: 0.199<br>Js: 0.187<br>观: 0.182<br>края: 0.182",
          null,
          null,
          "Layer: 22<br>Expert: 56<br>Weight: 0.157<br>Top tokens:<br>sgi: 0.257<br>{{: 0.229<br>скоро: 0.200<br>ago: 0.176<br>CLUDE: 0.139",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 2<br>Weight: 0.133<br>Top tokens:<br>赵: 0.494<br>дата: 0.139<br> Humanitat: 0.138<br>开后: 0.124<br>uedes: 0.104",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 10<br>Weight: 0.096<br>Top tokens:<br>�: 0.393<br>rotron: 0.248<br>REP: 0.133<br>INLINE: 0.116<br>LETE: 0.110",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 28<br>Weight: 0.122<br>Top tokens:<br>Strunz: 0.252<br>TOOLSET: 0.233<br>Съби: 0.213<br>DOCKED: 0.199<br>Населени: 0.103",
          null,
          null,
          "Layer: 23<br>Expert: 31<br>Weight: 0.102<br>Top tokens:<br>eing: 0.468<br>ilet: 0.178<br>Gall: 0.129<br>ален: 0.119<br>Deg: 0.105",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 41<br>Weight: 0.275<br>Top tokens:<br> Asiatic: 0.286<br>骨: 0.225<br> st: 0.173<br>T: 0.163<br>stum: 0.152",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 50<br>Weight: 0.112<br>Top tokens:<br>пълно: 0.354<br>пки: 0.174<br>�: 0.166<br> express: 0.155<br>ил: 0.150",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 59<br>Weight: 0.159<br>Top tokens:<br>��: 0.367<br>uple: 0.175<br> Segre: 0.158<br>rament: 0.155<br>csname: 0.145",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 7<br>Weight: 0.180<br>Top tokens:<br>s: 0.320<br>b: 0.250<br>c: 0.181<br>钝: 0.130<br>лер: 0.118",
          null,
          null,
          "Layer: 24<br>Expert: 10<br>Weight: 0.129<br>Top tokens:<br>角: 0.267<br>amentally: 0.237<br>stia: 0.223<br>arx: 0.163<br>сна: 0.110",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 18<br>Weight: 0.128<br>Top tokens:<br>�: 0.365<br>�: 0.303<br>�: 0.165<br>�: 0.100<br>imir: 0.067",
          null,
          "Layer: 24<br>Expert: 20<br>Weight: 0.116<br>Top tokens:<br>1: 0.336<br>5: 0.290<br>2: 0.184<br>6: 0.099<br>8: 0.091",
          null,
          null,
          "Layer: 24<br>Expert: 23<br>Weight: 0.152<br>Top tokens:<br>зас: 0.268<br>ream: 0.210<br>ubble: 0.207<br>roqu: 0.173<br>俞: 0.142",
          null,
          null,
          null,
          "Layer: 24<br>Expert: 27<br>Weight: 0.180<br>Top tokens:<br>////////////////////////////////////////////////////////////////: 0.270<br> tong: 0.249<br>лича: 0.162<br>/***/: 0.160<br>----,: 0.159",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 53<br>Weight: 0.116<br>Top tokens:<br>�: 0.996<br>科: 0.004<br>�: 0.000<br>现: 0.000<br>科医院: 0.000",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 6<br>Weight: 0.225<br>Top tokens:<br>campi: 0.263<br> Кън: 0.236<br>PRB: 0.202<br> Llengu: 0.156<br>Strunz: 0.143",
          "Layer: 25<br>Expert: 7<br>Weight: 0.131<br>Top tokens:<br> Хърват: 0.285<br>OperationKind: 0.218<br>Exposici: 0.199<br>固醇: 0.155<br>escut: 0.143",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 20<br>Weight: 0.091<br>Top tokens:<br>抵: 1.000<br>�: 0.000<br>申: 0.000<br>�: 0.000<br>晖: 0.000",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 28<br>Weight: 0.080<br>Top tokens:<br>–: 0.311<br>-: 0.216<br>ableView: 0.208<br>gentleman: 0.136<br>连: 0.130",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 41<br>Weight: 0.094<br>Top tokens:<br>pass: 0.391<br> pass: 0.191<br>run: 0.171<br>passing: 0.131<br>use: 0.116",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 54<br>Weight: 0.176<br>Top tokens:<br>BUIL: 0.275<br>Италиан: 0.252<br>незия: 0.192<br> KHz: 0.168<br>tml: 0.114",
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 60<br>Weight: 0.203<br>Top tokens:<br>IEW: 0.239<br>кел: 0.235<br>edor: 0.192<br>orel: 0.176<br>SEPARATOR: 0.159",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 4<br>Weight: 0.084<br>Top tokens:<br> : 0.478<br> e: 0.221<br>PCA: 0.123<br>elt: 0.097<br>itat: 0.081",
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 9<br>Weight: 0.232<br>Top tokens:<br>ISH: 0.434<br>scriptors: 0.211<br>gency: 0.194<br>JOR: 0.081<br>ATE: 0.080",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 33<br>Weight: 0.084<br>Top tokens:<br>хия: 0.456<br>дър: 0.164<br>�: 0.152<br>mkern: 0.125<br>essee: 0.103",
          null,
          "Layer: 26<br>Expert: 35<br>Weight: 0.113<br>Top tokens:<br>она: 0.271<br>rien: 0.231<br>ა: 0.174<br>зен: 0.164<br> BASIS: 0.160",
          null,
          null,
          null,
          "Layer: 26<br>Expert: 39<br>Weight: 0.113<br>Top tokens:<br>0: 0.275<br>4: 0.236<br>3: 0.200<br>�: 0.155<br>1: 0.134",
          "Layer: 26<br>Expert: 40<br>Weight: 0.282<br>Top tokens:<br>1: 0.449<br>2: 0.240<br> : 0.158<br>3: 0.077<br>5: 0.076",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 57<br>Weight: 0.090<br>Top tokens:<br>ang: 0.300<br>st: 0.216<br>�: 0.172<br>roy: 0.160<br>ds: 0.152",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 30<br>Weight: 0.142<br>Top tokens:<br>on: 0.230<br>while: 0.229<br>if: 0.220<br>@: 0.168<br>\n: 0.153",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 47<br>Weight: 0.052<br>Top tokens:<br>�: 0.284<br>obil: 0.218<br>�: 0.168<br>向: 0.166<br>Perf: 0.165",
          "Layer: 27<br>Expert: 48<br>Weight: 0.055<br>Top tokens:<br>世界: 0.335<br>美: 0.251<br> Medium: 0.175<br> Ere: 0.138<br>hara: 0.102",
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 54<br>Weight: 0.153<br>Top tokens:<br>1: 0.234<br>3: 0.216<br>0: 0.196<br>4: 0.184<br>5: 0.171",
          null,
          "Layer: 27<br>Expert: 56<br>Weight: 0.328<br>Top tokens:<br>A: 0.271<br> (: 0.209<br>E: 0.174<br>4: 0.173<br>3: 0.172",
          "Layer: 27<br>Expert: 57<br>Weight: 0.055<br>Top tokens:<br>�: 0.313<br>�: 0.244<br>�: 0.204<br>�: 0.139<br>�: 0.101",
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 62<br>Weight: 0.215<br>Top tokens:<br>[: 0.337<br>(: 0.250<br>-: 0.229<br>/: 0.098<br>\": 0.086",
          null
         ],
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63
         ],
         "y": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27
         ]
        }
       ],
       "layout": {
        "height": 800,
        "paper_bgcolor": "black",
        "plot_bgcolor": "black",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Expert Activations for Token \"<｜begin▁of▁sentence｜>\" at Position 0"
        },
        "width": 1200,
        "xaxis": {
         "gridcolor": "rgba(128, 128, 128, 0.2)",
         "gridwidth": 1,
         "range": [
          -1,
          64
         ],
         "showgrid": true,
         "title": {
          "text": "Expert ID"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "gridcolor": "rgba(128, 128, 128, 0.2)",
         "gridwidth": 1,
         "showgrid": true,
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing token:  fox\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertemplate": "%{text}<extra></extra>",
         "marker": {
          "cmax": 1,
          "cmin": 0,
          "color": [
           0,
           0,
           0,
           0,
           0,
           0.2144775390625,
           0,
           0,
           0.09063720703125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1024169921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.08782958984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1834716796875,
           0,
           0.1480712890625,
           0,
           0.1732177734375,
           0,
           0.1290283203125,
           0,
           0,
           0.302001953125,
           0,
           0,
           0,
           0,
           0.1087646484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1129150390625,
           0,
           0,
           0,
           0,
           0,
           0,
           0.096923828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11370849609375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13671875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.54443359375,
           0,
           0,
           0,
           0,
           0,
           0,
           0.059112548828125,
           0,
           0.1102294921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.07275390625,
           0.10809326171875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.04815673828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.057342529296875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14306640625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11004638671875,
           0,
           0,
           0,
           0.1104736328125,
           0,
           0,
           0.17529296875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2054443359375,
           0,
           0,
           0,
           0.11083984375,
           0,
           0,
           0,
           0,
           0,
           0.1448974609375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.260009765625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0887451171875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.053924560546875,
           0.1866455078125,
           0,
           0,
           0.054168701171875,
           0.29296875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0633544921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1981201171875,
           0,
           0,
           0,
           0.1832275390625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1319580078125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.090576171875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.07928466796875,
           0,
           0,
           0,
           0,
           0,
           0.1982421875,
           0,
           0,
           0,
           0.11865234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2015380859375,
           0,
           0,
           0,
           0,
           0,
           0.10955810546875,
           0,
           0,
           0,
           0.105712890625,
           0,
           0,
           0,
           0,
           0.12109375,
           0.1468505859375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.115478515625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1998291015625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0921630859375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.08489990234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.06512451171875,
           0,
           0,
           0.229248046875,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1588134765625,
           0.2337646484375,
           0,
           0,
           0,
           0.1361083984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.197021484375,
           0,
           0,
           0,
           0,
           0,
           0.0980224609375,
           0,
           0,
           0,
           0,
           0.190673828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1361083984375,
           0.11163330078125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1572265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1092529296875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.22998046875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.147216796875,
           0,
           0,
           0,
           0.1953125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1048583984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10406494140625,
           0.1043701171875,
           0,
           0,
           0,
           0,
           0.11419677734375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1409912109375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1455078125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1640625,
           0,
           0.1441650390625,
           0,
           0,
           0.12890625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1571044921875,
           0,
           0,
           0,
           0,
           0,
           0.11920166015625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11669921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.118896484375,
           0.11358642578125,
           0,
           0,
           0,
           0,
           0,
           0.11199951171875,
           0,
           0,
           0.0953369140625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.342041015625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10137939453125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10308837890625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.149658203125,
           0.14208984375,
           0.137939453125,
           0,
           0,
           0,
           0.21435546875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12286376953125,
           0,
           0,
           0,
           0.1300048828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11712646484375,
           0,
           0.1341552734375,
           0,
           0,
           0,
           0.28076171875,
           0,
           0,
           0,
           0.12481689453125,
           0,
           0,
           0.10540771484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.131591796875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10626220703125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.165771484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1422119140625,
           0,
           0,
           0.111083984375,
           0,
           0.11846923828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1361083984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.169921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1563720703125,
           0,
           0,
           0,
           0,
           0,
           0.141845703125,
           0,
           0.134521484375,
           0,
           0,
           0,
           0.10870361328125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1197509765625,
           0,
           0,
           0,
           0.196044921875,
           0,
           0,
           0,
           0,
           0.19970703125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.099365234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1568603515625,
           0.11834716796875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.152099609375,
           0,
           0,
           0.14599609375,
           0.1156005859375,
           0,
           0,
           0.176513671875,
           0,
           0,
           0,
           0,
           0,
           0,
           0.134521484375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1397705078125,
           0,
           0,
           0.1434326171875,
           0,
           0,
           0.130859375,
           0,
           0,
           0,
           0,
           0,
           0,
           0.166259765625,
           0,
           0,
           0,
           0.1307373046875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1392822265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1495361328125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0966796875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.21826171875,
           0,
           0,
           0.095947265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.15673828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1405029296875,
           0,
           0,
           0.08709716796875,
           0,
           0.204833984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11334228515625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10272216796875,
           0,
           0,
           0,
           0,
           0,
           0.10797119140625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11431884765625,
           0,
           0.11334228515625,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1937255859375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.254638671875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1298828125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13916015625,
           0,
           0.13330078125,
           0.12457275390625,
           0,
           0,
           0,
           0.1239013671875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2078857421875,
           0,
           0,
           0,
           0,
           0,
           0,
           0.141357421875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12646484375,
           0,
           0,
           0.139404296875,
           0,
           0,
           0,
           0.1751708984375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1292724609375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10614013671875,
           0,
           0,
           0,
           0,
           0,
           0.1712646484375,
           0,
           0,
           0,
           0,
           0.15234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1663818359375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1112060546875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1419677734375,
           0.109619140625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11810302734375,
           0.11724853515625,
           0.235595703125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12457275390625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2332763671875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1041259765625,
           0,
           0,
           0,
           0.11163330078125,
           0,
           0.1221923828125,
           0,
           0.2022705078125,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1019287109375,
           0,
           0,
           0,
           0.11102294921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.177978515625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1175537109375,
           0,
           0.1314697265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12274169921875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2149658203125,
           0.12432861328125,
           0,
           0,
           0,
           0,
           0.13037109375,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12152099609375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.299072265625,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0728759765625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1241455078125,
           0,
           0,
           0,
           0,
           0.0859375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.166259765625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1510009765625,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.115234375,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11669921875,
           0,
           0,
           0,
           0,
           0,
           0.1531982421875,
           0,
           0,
           0,
           0,
           0.154296875,
           0.138671875,
           0.1707763671875,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          "colorbar": {
           "dtick": 0.2,
           "tick0": 0,
           "tickmode": "linear",
           "title": {
            "text": "Weight"
           }
          },
          "colorscale": [
           [
            0,
            "rgba(24, 21, 23, 0.8)"
           ],
           [
            0.0001,
            "rgb(68,1,84)"
           ],
           [
            1,
            "rgb(253,231,37)"
           ]
          ],
          "showscale": true,
          "size": 9
         },
         "mode": "markers",
         "text": [
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 5<br>Weight: 0.214<br>Top tokens:<br> наука: 0.216<br>зви: 0.206<br>landa: 0.200<br>нав: 0.194<br>стъпва: 0.184",
          null,
          null,
          "Layer: 1<br>Expert: 8<br>Weight: 0.091<br>Top tokens:<br>nora: 0.227<br>ursal: 0.217<br>襟: 0.190<br>shal: 0.188<br>CEPT: 0.177",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 26<br>Weight: 0.102<br>Top tokens:<br>eqno: 0.219<br>mmode: 0.201<br> \"': 0.197<br>��: 0.192<br> Selva: 0.192",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 34<br>Weight: 0.088<br>Top tokens:<br>迫: 0.253<br>8: 0.194<br>4: 0.186<br>9: 0.184<br> Breton: 0.183",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 59<br>Weight: 0.183<br>Top tokens:<br>сква: 0.227<br>aring: 0.218<br>ared: 0.191<br>疡: 0.183<br>可想: 0.181",
          null,
          "Layer: 1<br>Expert: 61<br>Weight: 0.148<br>Top tokens:<br>javase: 0.212<br>yte: 0.208<br>oyo: 0.207<br>obox: 0.187<br> censats: 0.185",
          null,
          "Layer: 1<br>Expert: 63<br>Weight: 0.173<br>Top tokens:<br>oldre: 0.219<br>ა: 0.205<br>nacl: 0.201<br>icast: 0.191<br>рали: 0.184",
          null,
          "Layer: 2<br>Expert: 1<br>Weight: 0.129<br>Top tokens:<br> Vars: 0.225<br>栓: 0.203<br>设: 0.198<br> <<<: 0.187<br>tains: 0.187",
          null,
          null,
          "Layer: 2<br>Expert: 4<br>Weight: 0.302<br>Top tokens:<br>arf: 0.211<br>adera: 0.200<br>ader: 0.200<br>enti: 0.198<br>iedo: 0.190",
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 9<br>Weight: 0.109<br>Top tokens:<br>rels: 0.228<br>rel: 0.228<br>ie: 0.187<br>ract: 0.180<br>REL: 0.177",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 23<br>Weight: 0.113<br>Top tokens:<br>ollers: 0.206<br> invent: 0.204<br> trap: 0.199<br>indeer: 0.199<br>反转: 0.193",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 30<br>Weight: 0.097<br>Top tokens:<br>灌: 0.215<br>opin: 0.212<br>ogc: 0.196<br> dice: 0.190<br>湃: 0.187",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 43<br>Weight: 0.114<br>Top tokens:<br>�: 0.245<br>swick: 0.227<br>OD: 0.183<br>acom: 0.180<br>icode: 0.165",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 51<br>Weight: 0.137<br>Top tokens:<br>ouri: 0.234<br>ор: 0.199<br>rido: 0.199<br>държа: 0.185<br>aturally: 0.184",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 9<br>Weight: 0.544<br>Top tokens:<br>ogie: 0.209<br> PT: 0.207<br>aiser: 0.196<br>undial: 0.194<br>ettle: 0.193",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 16<br>Weight: 0.059<br>Top tokens:<br>estres: 0.244<br>estes: 0.216<br>поле: 0.189<br>itzerland: 0.176<br>attribute: 0.175",
          null,
          "Layer: 3<br>Expert: 18<br>Weight: 0.110<br>Top tokens:<br>备: 0.226<br>ager: 0.214<br> syll: 0.191<br>lab: 0.185<br>粮: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 33<br>Weight: 0.073<br>Top tokens:<br>egraphics: 0.257<br>ifax: 0.191<br>usercontent: 0.189<br>initely: 0.182<br>helf: 0.181",
          "Layer: 3<br>Expert: 34<br>Weight: 0.108<br>Top tokens:<br>intilla: 0.221<br>вле: 0.218<br>rero: 0.191<br> отношение: 0.186<br>ENCES: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 53<br>Weight: 0.048<br>Top tokens:<br> pref: 0.238<br>Inflater: 0.198<br>uan: 0.191<br> null: 0.188<br>inc: 0.186",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 62<br>Weight: 0.057<br>Top tokens:<br>翼翼: 0.246<br>batim: 0.204<br>筋: 0.203<br>ndar: 0.195<br>禧: 0.152",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 8<br>Weight: 0.143<br>Top tokens:<br>itons: 0.240<br>itchen: 0.223<br>chism: 0.180<br>](/: 0.179<br>uites: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 32<br>Weight: 0.110<br>Top tokens:<br>ус: 0.227<br>�: 0.224<br>нати: 0.188<br>chitz: 0.183<br>estan: 0.178",
          null,
          null,
          null,
          "Layer: 4<br>Expert: 36<br>Weight: 0.110<br>Top tokens:<br>0: 0.216<br>8: 0.203<br>aval: 0.196<br>лета: 0.193<br>psy: 0.192",
          null,
          null,
          "Layer: 4<br>Expert: 39<br>Weight: 0.175<br>Top tokens:<br>widetext: 0.224<br>ад: 0.203<br> Кън: 0.195<br>汇: 0.189<br>вена: 0.189",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 47<br>Weight: 0.205<br>Top tokens:<br>igator: 0.219<br>oline: 0.203<br>eno: 0.195<br>idual: 0.193<br>phinx: 0.190",
          null,
          null,
          null,
          "Layer: 4<br>Expert: 51<br>Weight: 0.111<br>Top tokens:<br>apter: 0.211<br>ети: 0.211<br>ite: 0.201<br>ей: 0.194<br>itekt: 0.183",
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 57<br>Weight: 0.145<br>Top tokens:<br> @}: 0.267<br>.(*: 0.199<br>olins: 0.184<br> предава: 0.176<br> ([]: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 13<br>Weight: 0.260<br>Top tokens:<br> Кън: 0.210<br>ъри: 0.206<br>arreg: 0.200<br>unknownFields: 0.197<br>tessa: 0.187",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 22<br>Weight: 0.089<br>Top tokens:<br>way: 0.227<br>abis: 0.195<br>acht: 0.195<br>seg: 0.192<br>oring: 0.191",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 31<br>Weight: 0.054<br>Top tokens:<br>候: 0.251<br>lements: 0.199<br>insic: 0.184<br>ussa: 0.184<br>ulsions: 0.181",
          "Layer: 5<br>Expert: 32<br>Weight: 0.187<br>Top tokens:<br>intilla: 0.250<br> Republicana: 0.200<br>chroot: 0.187<br>闭: 0.185<br>懿: 0.177",
          null,
          null,
          "Layer: 5<br>Expert: 35<br>Weight: 0.054<br>Top tokens:<br>restant: 0.266<br>dust: 0.194<br>писани: 0.187<br>quio: 0.182<br>ACY: 0.171",
          "Layer: 5<br>Expert: 36<br>Weight: 0.293<br>Top tokens:<br>步: 0.241<br>��: 0.204<br> избира: 0.200<br>ilot: 0.181<br>ade: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 50<br>Weight: 0.063<br>Top tokens:<br>umnos: 0.231<br>errat: 0.218<br> part: 0.195<br> PACKAGE: 0.178<br>ernel: 0.178",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 9<br>Weight: 0.198<br>Top tokens:<br>��: 0.266<br>iars: 0.225<br>enni: 0.176<br>exper: 0.169<br>uner: 0.164",
          null,
          null,
          null,
          "Layer: 6<br>Expert: 13<br>Weight: 0.183<br>Top tokens:<br>ancel: 0.219<br> <<<: 0.212<br>theless: 0.200<br>сберг: 0.198<br> капи: 0.172",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 27<br>Weight: 0.132<br>Top tokens:<br>istat: 0.351<br>spe: 0.165<br>slug: 0.164<br>ɔ: 0.162<br>ksw: 0.158",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 37<br>Weight: 0.091<br>Top tokens:<br>连: 0.241<br> бре: 0.229<br>ени: 0.195<br>堰: 0.184<br>крат: 0.151",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 48<br>Weight: 0.079<br>Top tokens:<br>havia: 0.251<br>�: 0.197<br>чина: 0.197<br>ishments: 0.177<br>�: 0.177",
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 54<br>Weight: 0.198<br>Top tokens:<br>ic: 0.277<br>xies: 0.212<br>�: 0.175<br>弹: 0.168<br>ISS: 0.168",
          null,
          null,
          null,
          "Layer: 6<br>Expert: 58<br>Weight: 0.119<br>Top tokens:<br>acerb: 0.214<br>EMENT: 0.208<br>alada: 0.206<br>assada: 0.190<br>inada: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 11<br>Weight: 0.202<br>Top tokens:<br>ouver: 0.219<br>inherited: 0.208<br>niques: 0.197<br>dics: 0.193<br>nesday: 0.184",
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 17<br>Weight: 0.110<br>Top tokens:<br>itely: 0.220<br>��: 0.209<br>resso: 0.197<br>assol: 0.190<br> Него: 0.184",
          null,
          null,
          null,
          "Layer: 7<br>Expert: 21<br>Weight: 0.106<br>Top tokens:<br>ancourt: 0.207<br>lada: 0.205<br>adoc: 0.200<br>ianes: 0.198<br>uns: 0.189",
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 26<br>Weight: 0.121<br>Top tokens:<br>taw: 0.273<br>texts: 0.199<br>TEXT: 0.192<br>lood: 0.173<br>的人: 0.162",
          "Layer: 7<br>Expert: 27<br>Weight: 0.147<br>Top tokens:<br>�: 0.228<br>odef: 0.209<br>VARIABLE: 0.197<br>Indexed: 0.186<br>oman: 0.180",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 35<br>Weight: 0.115<br>Top tokens:<br>taf: 0.217<br>格: 0.212<br>亲: 0.194<br>лова: 0.191<br>itx: 0.186",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 46<br>Weight: 0.200<br>Top tokens:<br>еди: 0.240<br>quare: 0.222<br>ationals: 0.213<br>\"]=>: 0.168<br>pides: 0.156",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 0<br>Weight: 0.092<br>Top tokens:<br>9: 0.242<br>复印: 0.201<br>8: 0.192<br>;%: 0.183<br>arquia: 0.181",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 16<br>Weight: 0.085<br>Top tokens:<br>g: 0.221<br>ляр: 0.210<br>x: 0.203<br>sh: 0.187<br>GIN: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 32<br>Weight: 0.065<br>Top tokens:<br>ois: 0.412<br>大楼: 0.156<br>if: 0.155<br>тис: 0.141<br>侧面: 0.136",
          null,
          null,
          "Layer: 8<br>Expert: 35<br>Weight: 0.229<br>Top tokens:<br>venin: 0.238<br>vnc: 0.196<br>surprise: 0.195<br>icast: 0.187<br> Budd: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 42<br>Weight: 0.159<br>Top tokens:<br>adera: 0.278<br>readLine: 0.242<br>arcelon: 0.166<br>wildfly: 0.163<br>retes: 0.151",
          "Layer: 8<br>Expert: 43<br>Weight: 0.234<br>Top tokens:<br>пен: 0.270<br>ixen: 0.207<br>enties: 0.188<br>кор: 0.175<br>esfor: 0.160",
          null,
          null,
          null,
          "Layer: 8<br>Expert: 47<br>Weight: 0.136<br>Top tokens:<br>awan: 0.238<br>quel: 0.206<br>Library: 0.189<br> служба: 0.185<br>read: 0.183",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 4<br>Weight: 0.197<br>Top tokens:<br>well: 0.216<br>лко: 0.215<br>ек: 0.190<br>uders: 0.190<br>oga: 0.189",
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 10<br>Weight: 0.098<br>Top tokens:<br>3: 0.325<br>8: 0.180<br>2: 0.175<br>4: 0.164<br>9: 0.156",
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 15<br>Weight: 0.191<br>Top tokens:<br>__':: 0.336<br>etes: 0.218<br>\"?>: 0.198<br>装的: 0.128<br>IEW: 0.120",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 23<br>Weight: 0.136<br>Top tokens:<br>engo: 0.246<br>хът: 0.212<br> Collections: 0.192<br>landa: 0.178<br>reta: 0.172",
          "Layer: 9<br>Expert: 24<br>Weight: 0.112<br>Top tokens:<br>ifice: 0.407<br>ifies: 0.199<br>itatively: 0.142<br>kered: 0.138<br>嗽: 0.114",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 37<br>Weight: 0.157<br>Top tokens:<br>lectric: 0.232<br> Mouth: 0.200<br> богат: 0.200<br> mouth: 0.185<br> местообитание: 0.183",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 50<br>Weight: 0.109<br>Top tokens:<br>estown: 0.286<br>lations: 0.191<br>挛: 0.182<br>odot: 0.177<br> fal: 0.165",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 4<br>Weight: 0.230<br>Top tokens:<br>st: 0.232<br>蜂: 0.195<br>ly: 0.193<br>ios: 0.191<br>k: 0.190",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 19<br>Weight: 0.147<br>Top tokens:<br>IEEEeqnarray: 0.272<br>如有关于: 0.242<br>istani: 0.171<br>istan: 0.165<br>etano: 0.150",
          null,
          null,
          null,
          "Layer: 10<br>Expert: 23<br>Weight: 0.195<br>Top tokens:<br>onar: 0.243<br>пер: 0.238<br>мври: 0.178<br>贝: 0.171<br>Вън: 0.170",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 45<br>Weight: 0.105<br>Top tokens:<br>i: 0.312<br>4: 0.205<br>u: 0.182<br>6: 0.150<br>bull: 0.150",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 57<br>Weight: 0.104<br>Top tokens:<br>em: 0.274<br>l: 0.199<br>待: 0.194<br> em: 0.183<br>[: 0.150",
          "Layer: 10<br>Expert: 58<br>Weight: 0.104<br>Top tokens:<br> -: 0.255<br>—: 0.216<br> : 0.187<br>3: 0.184<br>–: 0.158",
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 63<br>Weight: 0.114<br>Top tokens:<br>ource: 0.318<br>lip: 0.187<br>周: 0.181<br>mar: 0.170<br>ку: 0.145",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 11<br>Weight: 0.141<br>Top tokens:<br>andria: 0.234<br>glomer: 0.221<br>zca: 0.193<br>ycler: 0.181<br>ес: 0.172",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 21<br>Weight: 0.146<br>Top tokens:<br> Basc: 0.243<br>reford: 0.229<br>KHR: 0.192<br>rances: 0.178<br>ropolit: 0.158",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 32<br>Weight: 0.164<br>Top tokens:<br>mits: 0.236<br>orb: 0.220<br>湃: 0.207<br>n: 0.173<br>others: 0.164",
          null,
          "Layer: 11<br>Expert: 34<br>Weight: 0.144<br>Top tokens:<br>esper: 0.227<br>rmi: 0.219<br>aque: 0.190<br>肢: 0.184<br>恺: 0.179",
          null,
          null,
          "Layer: 11<br>Expert: 37<br>Weight: 0.129<br>Top tokens:<br>irie: 0.244<br>iada: 0.208<br>psfrag: 0.188<br>Населе: 0.183<br> lectors: 0.177",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 56<br>Weight: 0.157<br>Top tokens:<br>lete: 0.227<br>dear: 0.207<br> otherwise: 0.200<br>лист: 0.193<br>Camel: 0.172",
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 62<br>Weight: 0.119<br>Top tokens:<br>lds: 0.239<br>lood: 0.212<br>��: 0.210<br>imoto: 0.175<br>sofs: 0.164",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 9<br>Weight: 0.117<br>Top tokens:<br>cert: 0.235<br>oldt: 0.203<br>Bench: 0.200<br>lapse: 0.197<br>odel: 0.165",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 18<br>Weight: 0.119<br>Top tokens:<br>matical: 0.273<br>spect: 0.186<br>rein: 0.185<br>amet: 0.184<br>eder: 0.172",
          "Layer: 12<br>Expert: 19<br>Weight: 0.114<br>Top tokens:<br>dif: 0.235<br>adi: 0.212<br>гер: 0.197<br>特: 0.181<br> Ni: 0.176",
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 25<br>Weight: 0.112<br>Top tokens:<br>ulum: 0.236<br>encil: 0.222<br>她们的: 0.187<br>ENT: 0.180<br>rices: 0.176",
          null,
          null,
          "Layer: 12<br>Expert: 28<br>Weight: 0.095<br>Top tokens:<br>holst: 0.331<br>tesi: 0.185<br>ux: 0.165<br>ud: 0.164<br>builtin: 0.155",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 36<br>Weight: 0.342<br>Top tokens:<br>modelVersion: 0.257<br>ведени: 0.204<br>iterr: 0.191<br>дрих: 0.175<br>�: 0.173",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 50<br>Weight: 0.101<br>Top tokens:<br>upost: 0.365<br>цбург: 0.215<br>uum: 0.146<br>处: 0.139<br>希: 0.135",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 5<br>Weight: 0.103<br>Top tokens:<br>渠道: 0.294<br>eks: 0.217<br>�: 0.178<br>ulated: 0.161<br>ил: 0.151",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 21<br>Weight: 0.150<br>Top tokens:<br>isto: 0.213<br>fico: 0.208<br>书记: 0.198<br>чия: 0.191<br> проекти: 0.190",
          "Layer: 13<br>Expert: 22<br>Weight: 0.142<br>Top tokens:<br>��: 0.258<br>动: 0.205<br>alsk: 0.198<br> обла: 0.193<br> xif: 0.147",
          "Layer: 13<br>Expert: 23<br>Weight: 0.138<br>Top tokens:<br>ru: 0.241<br>rog: 0.204<br>est: 0.193<br>Written: 0.188<br>土地: 0.174",
          null,
          null,
          null,
          "Layer: 13<br>Expert: 27<br>Weight: 0.214<br>Top tokens:<br>rime: 0.258<br>��: 0.210<br>亲: 0.195<br>шни: 0.169<br>antro: 0.168",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 38<br>Weight: 0.123<br>Top tokens:<br> tribus: 0.248<br> Entries: 0.219<br>conc: 0.209<br>cede: 0.164<br>Integration: 0.161",
          null,
          null,
          null,
          "Layer: 13<br>Expert: 42<br>Weight: 0.130<br>Top tokens:<br>�: 0.237<br>swered: 0.206<br> Горно: 0.206<br>片: 0.198<br>yset: 0.151",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 3<br>Weight: 0.117<br>Top tokens:<br>alum: 0.282<br>ongue: 0.238<br>ОН: 0.174<br>umber: 0.157<br>burg: 0.148",
          null,
          "Layer: 14<br>Expert: 5<br>Weight: 0.134<br>Top tokens:<br>тиран: 0.310<br>)]{: 0.184<br>plectic: 0.170<br>мино: 0.169<br>ръз: 0.167",
          null,
          null,
          null,
          "Layer: 14<br>Expert: 9<br>Weight: 0.281<br>Top tokens:<br>Pu: 0.211<br> коре: 0.210<br>MER: 0.202<br>WW: 0.190<br>ilio: 0.187",
          null,
          null,
          null,
          "Layer: 14<br>Expert: 13<br>Weight: 0.125<br>Top tokens:<br>ening: 0.232<br>nings: 0.204<br>abouts: 0.195<br>ката: 0.185<br>oric: 0.184",
          null,
          null,
          "Layer: 14<br>Expert: 16<br>Weight: 0.105<br>Top tokens:<br>0: 0.320<br>8: 0.180<br>7: 0.178<br>3: 0.164<br>9: 0.159",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 24<br>Weight: 0.132<br>Top tokens:<br>amba: 0.237<br>�: 0.205<br>2: 0.194<br>anteria: 0.183<br>广: 0.181",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 34<br>Weight: 0.106<br>Top tokens:<br>ufact: 0.276<br> herself: 0.218<br>ublic: 0.190<br>istocr: 0.169<br>跟鞋: 0.146",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 3<br>Weight: 0.166<br>Top tokens:<br>ifax: 0.294<br>aways: 0.196<br>缘: 0.172<br>пла: 0.170<br> Peabody: 0.169",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 16<br>Weight: 0.142<br>Top tokens:<br>ascend: 0.236<br>oice: 0.212<br>hei: 0.193<br>cita: 0.181<br>aring: 0.177",
          null,
          null,
          "Layer: 15<br>Expert: 19<br>Weight: 0.111<br>Top tokens:<br>2: 0.260<br>1: 0.218<br>3: 0.215<br>5: 0.178<br>yl: 0.129",
          null,
          "Layer: 15<br>Expert: 21<br>Weight: 0.118<br>Top tokens:<br>$^\\: 0.237<br>heid: 0.220<br>nable: 0.197<br>�: 0.186<br>αν: 0.160",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 30<br>Weight: 0.136<br>Top tokens:<br> rollers: 0.251<br>edn: 0.214<br> y: 0.186<br>пят: 0.176<br>气管: 0.173",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 44<br>Weight: 0.170<br>Top tokens:<br>�乐: 0.233<br>ampp: 0.216<br>稣: 0.200<br>Dumper: 0.183<br>enu: 0.168",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 61<br>Weight: 0.156<br>Top tokens:<br>Mid: 0.256<br>mid: 0.208<br>营业执照: 0.190<br>肢体: 0.179<br>ammed: 0.168",
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 3<br>Weight: 0.142<br>Top tokens:<br> bottom: 0.221<br>ilus: 0.215<br> import: 0.202<br>avell: 0.184<br> BIO: 0.179",
          null,
          "Layer: 16<br>Expert: 5<br>Weight: 0.135<br>Top tokens:<br>�: 0.545<br> &: 0.157<br>&: 0.123<br>ayne: 0.094<br>enstein: 0.081",
          null,
          null,
          null,
          "Layer: 16<br>Expert: 9<br>Weight: 0.109<br>Top tokens:<br>urant: 0.256<br>key: 0.221<br>g: 0.181<br>dig: 0.173<br>Key: 0.170",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 23<br>Weight: 0.120<br>Top tokens:<br>优: 0.249<br>ennes: 0.197<br>APTER: 0.187<br>垃: 0.184<br>бран: 0.183",
          null,
          null,
          null,
          "Layer: 16<br>Expert: 27<br>Weight: 0.196<br>Top tokens:<br>urt: 0.283<br>Machine: 0.205<br>nu: 0.178<br>machine: 0.167<br> lov: 0.167",
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 32<br>Weight: 0.200<br>Top tokens:<br>生: 0.282<br>нен: 0.219<br>chin: 0.177<br>rnia: 0.173<br>bil: 0.148",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 46<br>Weight: 0.099<br>Top tokens:<br> избу: 0.212<br>idencia: 0.206<br>бва: 0.205<br> {&: 0.197<br>idera: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 12<br>Weight: 0.157<br>Top tokens:<br>сис: 0.272<br>耐: 0.215<br>副: 0.196<br>ADER: 0.167<br>ader: 0.151",
          "Layer: 17<br>Expert: 13<br>Weight: 0.118<br>Top tokens:<br>noma: 0.290<br>ейнт: 0.190<br>]-->: 0.176<br>ACION: 0.173<br>erir: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 41<br>Weight: 0.152<br>Top tokens:<br>хау: 0.279<br>копа: 0.252<br>лна: 0.165<br> Buen: 0.155<br>silence: 0.150",
          null,
          null,
          "Layer: 17<br>Expert: 44<br>Weight: 0.146<br>Top tokens:<br>imales: 0.224<br>iew: 0.224<br>aturday: 0.218<br>anship: 0.170<br>SNAP: 0.164",
          "Layer: 17<br>Expert: 45<br>Weight: 0.116<br>Top tokens:<br>udi: 0.349<br>uls: 0.179<br>休: 0.163<br>inear: 0.156<br>ANI: 0.153",
          null,
          null,
          "Layer: 17<br>Expert: 48<br>Weight: 0.177<br>Top tokens:<br>所未: 0.313<br> host: 0.236<br>\t         : 0.186<br>hine: 0.137<br> tar: 0.128",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 55<br>Weight: 0.135<br>Top tokens:<br>igo: 0.258<br>⇒: 0.219<br> pitjor: 0.194<br>:<: 0.164<br>——: 0.164",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 15<br>Weight: 0.140<br>Top tokens:<br> ghast: 0.252<br>agma: 0.198<br>稻: 0.194<br>gles: 0.180<br>бъ: 0.175",
          null,
          null,
          "Layer: 18<br>Expert: 18<br>Weight: 0.143<br>Top tokens:<br>ancial: 0.260<br> certain: 0.236<br>onos: 0.223<br>enes: 0.141<br>ftp: 0.141",
          null,
          null,
          "Layer: 18<br>Expert: 21<br>Weight: 0.131<br>Top tokens:<br>iments: 0.292<br>ados: 0.241<br>走: 0.172<br>illas: 0.150<br> post: 0.145",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 28<br>Weight: 0.166<br>Top tokens:<br> lif: 0.235<br>apore: 0.228<br>ферен: 0.213<br>воре: 0.175<br>еруса: 0.149",
          null,
          null,
          null,
          "Layer: 18<br>Expert: 32<br>Weight: 0.131<br>Top tokens:<br> inactives: 0.301<br>pedia: 0.214<br>ב: 0.176<br>ESA: 0.173<br>ickr: 0.136",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 43<br>Weight: 0.139<br>Top tokens:<br>”: 0.336<br>\": 0.189<br> c: 0.161<br>仁: 0.159<br>」: 0.154",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 55<br>Weight: 0.150<br>Top tokens:<br>moid: 0.322<br>дем: 0.217<br>roid: 0.161<br>ever: 0.156<br>тели: 0.146",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 2<br>Weight: 0.097<br>Top tokens:<br> h: 0.273<br>лес: 0.232<br>ardin: 0.173<br>isoft: 0.165<br>5: 0.158",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 22<br>Weight: 0.218<br>Top tokens:<br>спа: 0.280<br>rots: 0.243<br>ISAM: 0.169<br>udes: 0.155<br>лица: 0.153",
          null,
          null,
          "Layer: 19<br>Expert: 25<br>Weight: 0.096<br>Top tokens:<br>tically: 0.223<br>quei: 0.214<br>tega: 0.198<br>paramname: 0.184<br> cle: 0.181",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 38<br>Weight: 0.157<br>Top tokens:<br>anship: 0.220<br>бива: 0.213<br> classificat: 0.210<br>尽致: 0.189<br>два: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 49<br>Weight: 0.141<br>Top tokens:<br>shw: 0.314<br>psia: 0.237<br>__(: 0.151<br>eeper: 0.151<br>oscana: 0.146",
          null,
          null,
          "Layer: 19<br>Expert: 52<br>Weight: 0.087<br>Top tokens:<br>止: 0.492<br>实体: 0.180<br>wani: 0.114<br>igo: 0.113<br>зани: 0.101",
          null,
          "Layer: 19<br>Expert: 54<br>Weight: 0.205<br>Top tokens:<br>LOCKS: 0.225<br>сиони: 0.223<br>interopRequireDefault: 0.196<br> Jehov: 0.183<br>лец: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 4<br>Weight: 0.113<br>Top tokens:<br>——: 0.764<br>—: 0.090<br> -: 0.056<br>$--: 0.047<br>–: 0.044",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 12<br>Weight: 0.103<br>Top tokens:<br>号: 0.353<br>际: 0.350<br>迹: 0.121<br>件: 0.120<br>号的: 0.057",
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 18<br>Weight: 0.108<br>Top tokens:<br>最长: 0.351<br>最高: 0.252<br>每: 0.199<br>SB: 0.102<br> променя: 0.095",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 34<br>Weight: 0.114<br>Top tokens:<br> Rollo: 0.230<br>itty: 0.230<br>市公安局: 0.208<br>elessly: 0.178<br>estock: 0.154",
          null,
          "Layer: 20<br>Expert: 36<br>Weight: 0.113<br>Top tokens:<br>著: 0.686<br>闻: 0.262<br>形成: 0.019<br>而出: 0.018<br>而: 0.014",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 43<br>Weight: 0.194<br>Top tokens:<br>约: 0.399<br>quesos: 0.292<br>��: 0.121<br>思: 0.096<br>drom: 0.091",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 56<br>Weight: 0.255<br>Top tokens:<br>under: 0.263<br> Under: 0.206<br>slant: 0.204<br>Under: 0.168<br>лес: 0.159",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 6<br>Weight: 0.130<br>Top tokens:<br>规划: 0.430<br>室: 0.195<br>室的: 0.165<br>bey: 0.110<br>�: 0.099",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 20<br>Weight: 0.139<br>Top tokens:<br>CONNE: 0.334<br>embar: 0.197<br>aira: 0.163<br> вул: 0.154<br>рича: 0.152",
          null,
          "Layer: 21<br>Expert: 22<br>Weight: 0.133<br>Top tokens:<br>opro: 0.364<br>牺: 0.182<br>inci: 0.159<br>裁: 0.148<br>�: 0.147",
          "Layer: 21<br>Expert: 23<br>Weight: 0.125<br>Top tokens:<br>失: 0.308<br>емон: 0.243<br>ront: 0.158<br>耗: 0.158<br>scrit: 0.134",
          null,
          null,
          null,
          "Layer: 21<br>Expert: 27<br>Weight: 0.124<br>Top tokens:<br>cils: 0.380<br>ION: 0.256<br>ioni: 0.124<br>bigarray: 0.120<br>4: 0.120",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 49<br>Weight: 0.208<br>Top tokens:<br>等的: 0.357<br>等: 0.185<br>这样的: 0.166<br>sem: 0.159<br>outs: 0.133",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 56<br>Weight: 0.141<br>Top tokens:<br>тари: 0.327<br> пролет: 0.229<br>WP: 0.204<br> Writ: 0.126<br> Runn: 0.114",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 2<br>Weight: 0.126<br>Top tokens:<br>oard: 0.263<br>odox: 0.245<br>motion: 0.199<br>effect: 0.161<br> Movement: 0.132",
          null,
          null,
          "Layer: 22<br>Expert: 5<br>Weight: 0.139<br>Top tokens:<br> : 0.451<br>��: 0.273<br>esides: 0.099<br>oners: 0.094<br>crits: 0.083",
          null,
          null,
          null,
          "Layer: 22<br>Expert: 9<br>Weight: 0.175<br>Top tokens:<br>讯: 0.442<br>se: 0.246<br>态: 0.132<br>ya: 0.100<br>sing: 0.081",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 19<br>Weight: 0.129<br>Top tokens:<br>2: 0.307<br>7: 0.216<br>3: 0.168<br>0: 0.163<br>1: 0.146",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 46<br>Weight: 0.106<br>Top tokens:<br>modelVersion: 0.564<br>enp: 0.157<br>�: 0.130<br>obles: 0.080<br>服务业: 0.069",
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 52<br>Weight: 0.171<br>Top tokens:<br> wire: 0.269<br>бло: 0.192<br>楼的: 0.191<br>�: 0.182<br>FilterChain: 0.166",
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 57<br>Weight: 0.152<br>Top tokens:<br>menuitem: 0.309<br>rcits: 0.215<br>aust: 0.172<br>视镜: 0.170<br>ndex: 0.133",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 1<br>Weight: 0.166<br>Top tokens:<br>heric: 0.238<br>bells: 0.198<br>peri: 0.192<br>accept: 0.186<br>原: 0.184",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 14<br>Weight: 0.111<br>Top tokens:<br>ring: 0.376<br>烤箱: 0.159<br>钩: 0.158<br>inars: 0.154<br>pher: 0.152",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 28<br>Weight: 0.142<br>Top tokens:<br>__':: 0.516<br>ected: 0.161<br>NOSCRIPT: 0.124<br>manifest: 0.105<br>左右: 0.094",
          "Layer: 23<br>Expert: 29<br>Weight: 0.110<br>Top tokens:<br> been: 0.403<br> остават: 0.190<br> Mean: 0.146<br> fallen: 0.135<br>hog: 0.126",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 37<br>Weight: 0.118<br>Top tokens:<br>MLElement: 0.298<br>eway: 0.206<br>ipte: 0.198<br>embar: 0.152<br>inistic: 0.146",
          "Layer: 23<br>Expert: 38<br>Weight: 0.117<br>Top tokens:<br>吸: 0.400<br>Strunz: 0.185<br>ername: 0.156<br>除: 0.131<br> numerus: 0.128",
          "Layer: 23<br>Expert: 39<br>Weight: 0.236<br>Top tokens:<br>ariidae: 0.340<br> ompl: 0.185<br>ogu: 0.182<br> сериали: 0.157<br>encion: 0.137",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 8<br>Weight: 0.125<br>Top tokens:<br>s: 1.000<br>es: 0.000<br>sj: 0.000<br>d: 0.000<br>mes: 0.000",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 19<br>Weight: 0.233<br>Top tokens:<br>LOPT: 0.259<br>ieu: 0.219<br>pson: 0.181<br>汉: 0.172<br>ложение: 0.168",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 45<br>Weight: 0.104<br>Top tokens:<br>oto: 0.329<br>rizz: 0.200<br>бори: 0.188<br>rale: 0.160<br>usher: 0.123",
          null,
          null,
          null,
          "Layer: 24<br>Expert: 49<br>Weight: 0.112<br>Top tokens:<br> Good: 0.232<br>lemany: 0.219<br> GOOD: 0.194<br> good: 0.189<br>apunov: 0.166",
          null,
          "Layer: 24<br>Expert: 51<br>Weight: 0.122<br>Top tokens:<br>ipus: 0.289<br>lique: 0.202<br>IFIED: 0.189<br>icated: 0.161<br>alta: 0.159",
          null,
          "Layer: 24<br>Expert: 53<br>Weight: 0.202<br>Top tokens:<br>�: 0.999<br>客: 0.001<br>�: 0.000<br>面: 0.000<br>节: 0.000",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 61<br>Weight: 0.102<br>Top tokens:<br>atmosfera: 0.483<br>ndia: 0.161<br> експе: 0.133<br>FieldLocation: 0.123<br>SHADOW: 0.100",
          null,
          null,
          null,
          "Layer: 25<br>Expert: 1<br>Weight: 0.111<br>Top tokens:<br> взи: 0.388<br>stal: 0.161<br>ymes: 0.159<br>ross: 0.158<br>�: 0.135",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 20<br>Weight: 0.178<br>Top tokens:<br>申: 0.980<br>收: 0.013<br>�: 0.004<br>抵: 0.002<br>�: 0.000",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 28<br>Weight: 0.118<br>Top tokens:<br>agossa: 0.303<br>ikip: 0.222<br>ideos: 0.204<br>行: 0.151<br>ει: 0.120",
          null,
          "Layer: 25<br>Expert: 30<br>Weight: 0.131<br>Top tokens:<br>逍: 0.451<br>IENT: 0.201<br>源头: 0.131<br>不对: 0.113<br>thon: 0.105",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 40<br>Weight: 0.123<br>Top tokens:<br>enda: 0.688<br>ques: 0.109<br>ета: 0.073<br>etric: 0.070<br>ert: 0.059",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 60<br>Weight: 0.215<br>Top tokens:<br>edas: 0.344<br>usercontent: 0.279<br>^*,: 0.143<br> «: 0.130<br>udisks: 0.105",
          "Layer: 25<br>Expert: 61<br>Weight: 0.124<br>Top tokens:<br> THEN: 0.346<br>毛: 0.327<br>then: 0.117<br>quette: 0.105<br> then: 0.105",
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 2<br>Weight: 0.130<br>Top tokens:<br>illas: 0.367<br>iza: 0.195<br>uum: 0.179<br>izaci: 0.135<br>iller: 0.123",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 9<br>Weight: 0.122<br>Top tokens:<br>IMP: 0.293<br>ливо: 0.247<br>щем: 0.177<br>же: 0.142<br>Mpc: 0.140",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 18<br>Weight: 0.299<br>Top tokens:<br>�: 0.483<br>脱: 0.193<br>rex: 0.192<br>iest: 0.070<br>esment: 0.062",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 25<br>Weight: 0.073<br>Top tokens:<br>endres: 0.291<br>escan: 0.218<br>aign: 0.184<br>++-: 0.166<br>ologne: 0.142",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 39<br>Weight: 0.124<br>Top tokens:<br>段: 0.721<br>段的: 0.084<br>�: 0.073<br>lands: 0.062<br>orts: 0.059",
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 44<br>Weight: 0.086<br>Top tokens:<br> Sut: 0.247<br>ont: 0.226<br> dimit: 0.192<br>ige: 0.173<br>amm: 0.162",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 59<br>Weight: 0.166<br>Top tokens:<br>lo: 0.228<br>me: 0.224<br>zz: 0.193<br>zza: 0.192<br> e: 0.164",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 5<br>Weight: 0.151<br>Top tokens:<br> l: 0.263<br> e: 0.193<br>阿: 0.185<br>扑: 0.179<br> k: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 26<br>Weight: 0.115<br>Top tokens:<br>ale: 0.237<br>eret: 0.216<br>erella: 0.195<br>avit: 0.187<br>ank: 0.165",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 38<br>Weight: 0.117<br>Top tokens:<br>缺: 0.336<br>ne: 0.173<br> condici: 0.171<br>ounters: 0.170<br>弱: 0.151",
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 44<br>Weight: 0.153<br>Top tokens:<br>全: 0.326<br>ffer: 0.204<br>ally: 0.167<br> Монте: 0.154<br>ren: 0.149",
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 49<br>Weight: 0.154<br>Top tokens:<br>/: 0.390<br>ed: 0.163<br>ing: 0.161<br>/[: 0.147<br>e: 0.140",
          "Layer: 27<br>Expert: 50<br>Weight: 0.139<br>Top tokens:<br>�: 1.000<br>园: 0.000<br>国: 0.000<br>国的: 0.000<br> coll: 0.000",
          "Layer: 27<br>Expert: 51<br>Weight: 0.171<br>Top tokens:<br> : 0.266<br>—: 0.199<br>外: 0.197<br> (: 0.171<br> -: 0.166",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63
         ],
         "y": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27
         ]
        }
       ],
       "layout": {
        "height": 800,
        "paper_bgcolor": "black",
        "plot_bgcolor": "black",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Expert Activations for Token \" fox\" at Position 4"
        },
        "width": 1200,
        "xaxis": {
         "gridcolor": "rgba(128, 128, 128, 0.2)",
         "gridwidth": 1,
         "range": [
          -1,
          64
         ],
         "showgrid": true,
         "title": {
          "text": "Expert ID"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "gridcolor": "rgba(128, 128, 128, 0.2)",
         "gridwidth": 1,
         "showgrid": true,
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_layer_analysis(tokenizer, results, token_position=0, input_text=text)\n",
    "# visualize_layer_analysis(tokenizer, results, token_position=1, input_text=text)\n",
    "visualize_layer_analysis(tokenizer, results, token_position=4, input_text=text)\n",
    "# visualize_layer_analysis(tokenizer, results, token_position=5, input_text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = out.logits[0,5]\n",
    "torch.argmax(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs.to(model.device), max_new_tokens=100)\n",
    "\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([6])\n",
      " jumps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = \"the quick brown fox\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.forward(**inputs.to(model.device))\n",
    "# print(outputs)\n",
    "x = outputs.logits[0, -1]\n",
    "x = torch.argmax(x)\n",
    "\n",
    "\n",
    "output2 = model.generate(**inputs.to(model.device), max_new_tokens=1)\n",
    "\n",
    "y = output2[0]\n",
    "# torch.argmax(x)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "result = tokenizer.decode(x)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\">:\n",
      "es\n",
      "es\n",
      "croft\n",
      "croft\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "issin\n",
      "IEEEeqnarray\n",
      "estrat\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "=\"../_\n",
      " rejo\n",
      " r\n",
      "Jump\n",
      "Jump\n",
      "Jump\n",
      "Jump\n",
      "Jump\n"
     ]
    }
   ],
   "source": [
    "outputs = model.forward(**inputs.to(model.device), output_hidden_states=True)\n",
    "for i in range(1, 27):\n",
    "    x = outputs.hidden_states[i]\n",
    "    y = x[0, -1]\n",
    "    z = model.lm_head(y)\n",
    "    z = torch.argmax(z)\n",
    "    result = tokenizer.decode(z)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (27,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create both visualizations\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m logit_fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_enhanced_logit_lens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m expert_fig \u001b[38;5;241m=\u001b[39m plot_expert_contributions(results, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display the figures\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 178\u001b[0m, in \u001b[0;36mplot_enhanced_logit_lens\u001b[0;34m(model_outputs, tokenizer, input_text, position)\u001b[0m\n\u001b[1;32m    175\u001b[0m     logits\u001b[38;5;241m.\u001b[39mappend(layer_logits)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Convert to numpy array for easier manipulation\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m logit_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Create figure\u001b[39;00m\n\u001b[1;32m    181\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(data\u001b[38;5;241m=\u001b[39mgo\u001b[38;5;241m.\u001b[39mHeatmap(\n\u001b[1;32m    182\u001b[0m     z\u001b[38;5;241m=\u001b[39mlogit_matrix,\n\u001b[1;32m    183\u001b[0m     x\u001b[38;5;241m=\u001b[39mtokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    203\u001b[0m ))\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (27,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Create both visualizations\n",
    "logit_fig = plot_enhanced_logit_lens(results, tokenizer, text, position=0)\n",
    "expert_fig = plot_expert_contributions(results, position=0)\n",
    "\n",
    "# Display the figures\n",
    "logit_fig.show()\n",
    "expert_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (27,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create both visualizations\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m logit_fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_enhanced_logit_lens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m expert_fig \u001b[38;5;241m=\u001b[39m plot_expert_contributions(results, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display the figures\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 178\u001b[0m, in \u001b[0;36mplot_enhanced_logit_lens\u001b[0;34m(model_outputs, tokenizer, input_text, position)\u001b[0m\n\u001b[1;32m    175\u001b[0m     logits\u001b[38;5;241m.\u001b[39mappend(layer_logits)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Convert to numpy array for easier manipulation\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m logit_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Create figure\u001b[39;00m\n\u001b[1;32m    181\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(data\u001b[38;5;241m=\u001b[39mgo\u001b[38;5;241m.\u001b[39mHeatmap(\n\u001b[1;32m    182\u001b[0m     z\u001b[38;5;241m=\u001b[39mlogit_matrix,\n\u001b[1;32m    183\u001b[0m     x\u001b[38;5;241m=\u001b[39mtokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    203\u001b[0m ))\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (27,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Create both visualizations\n",
    "logit_fig = plot_enhanced_logit_lens(results, tokenizer, text, position=1)\n",
    "expert_fig = plot_expert_contributions(results, position=1)\n",
    "\n",
    "# Display the figures\n",
    "logit_fig.show()\n",
    "expert_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
