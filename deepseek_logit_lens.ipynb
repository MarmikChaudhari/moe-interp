{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Tuple, List\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the optimal available device\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        # Enable TF32 for better performance on Ampere GPUs (A100, A6000, etc)\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        # Set memory allocation settings\n",
    "        torch.cuda.empty_cache()\n",
    "        # Enable CUDNN benchmarking for better performance\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d506f07bbb94cecb9a4ff7b131fd729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DeepseekForCausalLM(\n",
       "  (model): DeepseekModel(\n",
       "    (embed_tokens): Embedding(102400, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0): DeepseekDecoderLayer(\n",
       "        (self_attn): DeepseekSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): DeepseekRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): DeepseekMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=10944, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=10944, bias=False)\n",
       "          (down_proj): Linear(in_features=10944, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): DeepseekRMSNorm()\n",
       "        (post_attention_layernorm): DeepseekRMSNorm()\n",
       "      )\n",
       "      (1-27): 27 x DeepseekDecoderLayer(\n",
       "        (self_attn): DeepseekSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): DeepseekRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): DeepseekMoE(\n",
       "          (experts): ModuleList(\n",
       "            (0-63): 64 x DeepseekMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
       "              (down_proj): Linear(in_features=1408, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (gate): MoEGate()\n",
       "          (shared_experts): DeepseekMLP(\n",
       "            (gate_proj): Linear(in_features=2048, out_features=2816, bias=False)\n",
       "            (up_proj): Linear(in_features=2048, out_features=2816, bias=False)\n",
       "            (down_proj): Linear(in_features=2816, out_features=2048, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): DeepseekRMSNorm()\n",
       "        (post_attention_layernorm): DeepseekRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): DeepseekRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=102400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-moe-16b-base\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-moe-16b-base\", trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOEExpertLens:\n",
    "    def __init__(self, state_dict: Dict[str, torch.Tensor], tokenizer, device=None):\n",
    "        \"\"\"Initialize the MoE Expert analyzer.\"\"\"\n",
    "        self.device = device if device is not None else get_device()\n",
    "        self.state_dict = {k: v.to(self.device) for k, v in state_dict.items()}\n",
    "        self.tokenizer = tokenizer\n",
    "        self.hidden_size = self.state_dict[\"model.embed_tokens.weight\"].shape[1]\n",
    "        self.vocab_size = self.state_dict[\"model.embed_tokens.weight\"].shape[0]\n",
    "\n",
    "    def _process_expert(self, layer_idx: int, expert_idx: int, hidden_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Process hidden state through an expert's weights.\"\"\"\n",
    "        # Get expert weights\n",
    "        gate_proj = self.state_dict[f\"model.layers.{layer_idx}.mlp.experts.{expert_idx}.gate_proj.weight\"]\n",
    "        up_proj = self.state_dict[f\"model.layers.{layer_idx}.mlp.experts.{expert_idx}.up_proj.weight\"]\n",
    "        down_proj = self.state_dict[f\"model.layers.{layer_idx}.mlp.experts.{expert_idx}.down_proj.weight\"]\n",
    "\n",
    "        # Apply MLPs sequentially\n",
    "        # First gate projection and activation\n",
    "        gate_output = F.silu(F.linear(hidden_state, gate_proj))\n",
    "        \n",
    "        # Second up projection and activation \n",
    "        up_output = F.linear(hidden_state, up_proj)\n",
    "        \n",
    "        # Multiply gate and up projections then down project\n",
    "        x = gate_output * up_output\n",
    "        x = F.linear(x, down_proj)\n",
    "        return x\n",
    "\n",
    "    # def _get_router_output(self, layer_idx: int, hidden_state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    #     router_weights = self.state_dict[f\"model.layers.{layer_idx}.mlp.gate.weight\"]\n",
    "    #     logits = F.linear(hidden_state, router_weights)\n",
    "    #     topk_values, topk_indices = torch.topk(logits, k=7, dim=-1)  # Select top-k experts\n",
    "    #     normalized_weights = F.softmax(topk_values, dim=-1)  # Normalize gate weights\n",
    "    #     return normalized_weights\n",
    "\n",
    "    def _get_router_output(self, layer_idx: int, hidden_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get router logits for a layer.\"\"\"\n",
    "        router_weights = self.state_dict[f\"model.layers.{layer_idx}.mlp.gate.weight\"]\n",
    "        return F.linear(hidden_state, router_weights)\n",
    "    \n",
    "    def _process_attention(self, layer_idx: int, hidden_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Process hidden state through self-attention.\"\"\"\n",
    "        q_proj = self.state_dict[f\"model.layers.{layer_idx}.self_attn.q_proj.weight\"]\n",
    "        k_proj = self.state_dict[f\"model.layers.{layer_idx}.self_attn.k_proj.weight\"]\n",
    "        v_proj = self.state_dict[f\"model.layers.{layer_idx}.self_attn.v_proj.weight\"]\n",
    "        o_proj = self.state_dict[f\"model.layers.{layer_idx}.self_attn.o_proj.weight\"]\n",
    "\n",
    "        # Compute QKV\n",
    "        q = F.linear(hidden_state, q_proj)\n",
    "        k = F.linear(hidden_state, k_proj)\n",
    "        v = F.linear(hidden_state, v_proj)\n",
    "\n",
    "        # Compute attention and output projection\n",
    "        attn = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(self.hidden_size)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = torch.matmul(attn, v)\n",
    "        return F.linear(out, o_proj)\n",
    "\n",
    "    def _project_to_vocab(self, hidden_state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Project hidden state to vocabulary space.\"\"\"\n",
    "        # Ensure hidden state has the right shape for projection\n",
    "        if hidden_state.dim() == 3:\n",
    "            # If [batch, seq_len, hidden_dim], keep as is\n",
    "            pass\n",
    "        elif hidden_state.dim() == 2:\n",
    "            # If [batch, hidden_dim], add sequence dimension\n",
    "            hidden_state = hidden_state.unsqueeze(1)\n",
    "        \n",
    "        # Get lm_head weights instead of embedding weights for projection\n",
    "        lm_head_weights = self.state_dict[\"lm_head.weight\"]\n",
    "        \n",
    "        # Project to vocab space: [batch, seq_len, hidden_dim] x [vocab_size, hidden_dim]^T\n",
    "        return F.linear(hidden_state, lm_head_weights)\n",
    "\n",
    "    def analyze_text(self, input_ids: torch.Tensor) -> Dict:\n",
    "        \"\"\"Analyze text through expert lens.\"\"\"\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        hidden_states = self.state_dict[\"model.embed_tokens.weight\"][input_ids]\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for layer_idx in range(1, 28):  # Layers 1-27\n",
    "            # Apply layer normalization\n",
    "            if f\"model.layers.{layer_idx}.input_layernorm.weight\" in self.state_dict:\n",
    "                norm_weight = self.state_dict[f\"model.layers.{layer_idx}.input_layernorm.weight\"]\n",
    "                hidden_states = F.layer_norm(hidden_states, (self.hidden_size,), weight=norm_weight)\n",
    "            \n",
    "            layer_results = {\"tokens\": {}}\n",
    "            \n",
    "            # Process attention\n",
    "            hidden_states = self._process_attention(layer_idx, hidden_states)\n",
    "            \n",
    "            # Post-attention layer norm\n",
    "            if f\"model.layers.{layer_idx}.post_attention_layernorm.weight\" in self.state_dict:\n",
    "                norm_weight = self.state_dict[f\"model.layers.{layer_idx}.post_attention_layernorm.weight\"]\n",
    "                hidden_states = F.layer_norm(hidden_states, (self.hidden_size,), weight=norm_weight)\n",
    "            \n",
    "            # Get router decisions\n",
    "            router_logits = self._get_router_output(layer_idx, hidden_states)\n",
    "            top_k_experts = torch.topk(router_logits, k=7, dim=-1)\n",
    "            expert_weights = F.softmax(top_k_experts.values, dim=-1)\n",
    "            \n",
    "            # Process through selected experts\n",
    "            for pos in range(seq_len):\n",
    "                token = self.tokenizer.decode([input_ids[0, pos].item()])\n",
    "                token_state = hidden_states[:, pos:pos+1]\n",
    "                \n",
    "                expert_outputs = []\n",
    "                for idx, expert_idx in enumerate(top_k_experts.indices[0, pos]):\n",
    "                    expert_output = self._process_expert(layer_idx, expert_idx.item(), token_state)\n",
    "                    weight = expert_weights[0, pos, idx].item()\n",
    "                    \n",
    "                    # Project expert output to vocab space\n",
    "                    logits = self._project_to_vocab(expert_output)\n",
    "                    top_tokens = torch.topk(logits.squeeze(1), k=5)\n",
    "                    \n",
    "                    expert_outputs.append({\n",
    "                        \"expert_id\": expert_idx.item(),\n",
    "                        \"weight\": weight,\n",
    "                        \"top_tokens\": [\n",
    "                            (self.tokenizer.decode([idx.item()]), prob.item())\n",
    "                            for idx, prob in zip(top_tokens.indices[0], F.softmax(top_tokens.values[0], dim=-1))\n",
    "                        ]\n",
    "                    })\n",
    "                \n",
    "                layer_results[\"tokens\"][token] = {\n",
    "                    \"position\": pos,\n",
    "                    \"expert_outputs\": expert_outputs\n",
    "                }\n",
    "                # print(pos)\n",
    "                # print(expert_outputs)\n",
    "                # print(\"--------------------------------\")\n",
    "            \n",
    "            results[f\"layer_{layer_idx}\"] = layer_results\n",
    "            \n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_layer_analysis(tokenizer, results: Dict, token_position: int, input_text: str):\n",
    "    \"\"\"\n",
    "    Creates a plotly visualization of expert activations across layers for a specific token.\n",
    "    Shows all 64 experts with zero weights for non-selected experts.\n",
    "    \"\"\"\n",
    "    # Create lists to store data \n",
    "    layer_nums = []\n",
    "    expert_ids = []\n",
    "    weights = []\n",
    "    hover_texts = []\n",
    "    \n",
    "    total_experts = 64  # Total number of experts in the model\n",
    "    \n",
    "    # Extract token we're visualizing by tokenizing input text first\n",
    "    tokens = tokenizer.encode(input_text)\n",
    "    token = tokenizer.decode([tokens[token_position]])  # Get tokenized token\n",
    "    print(f\"Visualizing token: {token}\")\n",
    "        \n",
    "    for layer_idx in range(1, 28):  # Layers 1-27\n",
    "        layer_data = results[f\"layer_{layer_idx}\"]\n",
    "        token_data = [data for data in layer_data[\"tokens\"].values() \n",
    "                     if data[\"position\"] == token_position][0]\n",
    "        \n",
    "        # Create a mapping of expert_id to its data for this layer\n",
    "        expert_map = {exp[\"expert_id\"]: exp for exp in token_data[\"expert_outputs\"]}\n",
    "        \n",
    "        # Go through all possible experts\n",
    "        for expert_id in range(total_experts):\n",
    "            layer_nums.append(layer_idx)\n",
    "            expert_ids.append(expert_id)\n",
    "            \n",
    "            if expert_id in expert_map:\n",
    "                # Expert was selected\n",
    "                expert_data = expert_map[expert_id]\n",
    "                weight = expert_data[\"weight\"]\n",
    "                top_tokens_text = \"<br>\".join([\n",
    "                    f\"{token}: {prob:.3f}\" \n",
    "                    for token, prob in expert_data[\"top_tokens\"][:5]\n",
    "                ])\n",
    "                hover_text = f\"Layer: {layer_idx}<br>Expert: {expert_id}<br>Weight: {weight:.3f}<br>Top tokens:<br>{top_tokens_text}\"\n",
    "                hover_texts.append(hover_text)\n",
    "            else:\n",
    "                # Expert was not selected\n",
    "                weight = 0\n",
    "                hover_texts.append(None)  # No hover text for unselected experts\n",
    "            \n",
    "            weights.append(weight)\n",
    "    \n",
    "    # Create plotly heatmap\n",
    "    fig = go.Figure(data=go.Scatter(\n",
    "        x=expert_ids,\n",
    "        y=layer_nums,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=9,\n",
    "            color=weights,\n",
    "            colorscale=[\n",
    "                [0, 'rgba(24, 21, 23, 0.8)'],  # Very dark/transparent for zero weights\n",
    "                [0.0001, 'rgb(68,1,84)'],  # Start of Viridis colorscale\n",
    "                [1, 'rgb(253,231,37)']  # End of Viridis colorscale\n",
    "            ],\n",
    "            showscale=True,\n",
    "            colorbar=dict(title='Weight'),\n",
    "        ),\n",
    "        text=hover_texts,\n",
    "        hoverinfo='text',\n",
    "        hovertemplate='%{text}<extra></extra>',  # Only show hover when text exists\n",
    "    ))\n",
    "    \n",
    "    # Update layout with dark theme\n",
    "    fig.update_layout(\n",
    "        template='plotly_dark',\n",
    "        title=f'Expert Activations for Token \"{token}\" at Position {token_position}',\n",
    "        xaxis_title='Expert ID',\n",
    "        yaxis_title='Layer',\n",
    "        yaxis=dict(autorange='reversed'),  # Reverse y-axis to have layer 1 at top\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        showlegend=False,\n",
    "        plot_bgcolor='black',\n",
    "        paper_bgcolor='black'\n",
    "    )\n",
    "    \n",
    "    # Add grid lines\n",
    "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='rgba(128, 128, 128, 0.2)', \n",
    "                     range=[-1, total_experts])\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='rgba(128, 128, 128, 0.2)')\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_moe_logit_lens_with_active_expert_outputs(model, inputs, tokenizer, num_active_experts=7):\n",
    "    model.eval()\n",
    "\n",
    "    # Initial embedding\n",
    "    x = model.model.embed_tokens(inputs)\n",
    "\n",
    "    # Process each layer\n",
    "    for layer_idx, layer in enumerate(model.model.layers):\n",
    "        print(f\"Layer {layer_idx + 1}\")\n",
    "        x = layer.input_layernorm(x)\n",
    "\n",
    "        # Self-attention output\n",
    "        # Remove the position_ids argument here, let the model handle it internally\n",
    "        attn_output = layer.self_attn(x, x, x)\n",
    "        x = attn_output + x  # Residual connection\n",
    "        x = layer.post_attention_layernorm(x)\n",
    "\n",
    "        # MoE Layer\n",
    "        moe_output = layer.mlp(x)\n",
    "        gate_values = moe_output[\"gate_values\"]\n",
    "        expert_outputs = moe_output[\"expert_outputs\"]\n",
    "\n",
    "        # Extract active experts\n",
    "        for batch_idx, gates in enumerate(gate_values):\n",
    "            active_experts = gates.argsort(descending=True)[:num_active_experts]\n",
    "            print(f\"  Batch {batch_idx + 1}:\")\n",
    "            for expert_idx in active_experts:\n",
    "                expert_weight = gates[expert_idx].item()\n",
    "                expert_output = expert_outputs[batch_idx, :, expert_idx]\n",
    "                top_tokens = expert_output.topk(5, dim=-1)\n",
    "                top_indices = top_tokens.indices\n",
    "                top_scores = top_tokens.values\n",
    "                decoded_tokens = tokenizer.decode(top_indices.tolist())\n",
    "                print(f\"    Expert {expert_idx}: Weight: {expert_weight:.4f}, Tokens: {decoded_tokens}, Scores: {top_scores.tolist()}\")\n",
    "\n",
    "    # Final logits\n",
    "    logits = model.lm_head(x)\n",
    "    top_tokens = logits.topk(5, dim=-1)\n",
    "    decoded_final_tokens = tokenizer.decode(top_tokens.indices.tolist())\n",
    "    print(f\"Final Layer: Tokens: {decoded_final_tokens}, Scores: {top_tokens.values.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the optimal available device\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        # Enable TF32 for better performance on Ampere GPUs (A100, A6000, etc)\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        # Set memory allocation settings\n",
    "        torch.cuda.empty_cache()\n",
    "        # Enable CUDNN benchmarking for better performance\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_moe_logit_lens_with_active_expert_outputs(model, inputs, tokenizer, num_active_experts=7):\n",
    "    model.eval()\n",
    "\n",
    "    # Initial embedding\n",
    "    x = model.model.embed_tokens(inputs)\n",
    "\n",
    "    # Process each layer\n",
    "    for layer_idx, layer in enumerate(model.model.layers):\n",
    "        print(f\"Layer {layer_idx + 1}\")\n",
    "        x = layer.input_layernorm(x)\n",
    "\n",
    "        # Self-attention output\n",
    "        # Remove the position_ids argument here, let the model handle it internally\n",
    "        attn_output = layer.self_attn(x, x, x)\n",
    "        x = attn_output + x  # Residual connection\n",
    "        x = layer.post_attention_layernorm(x)\n",
    "\n",
    "        # MoE Layer\n",
    "        moe_output = layer.mlp(x)\n",
    "        gate_values = moe_output[\"gate_values\"]\n",
    "        expert_outputs = moe_output[\"expert_outputs\"]\n",
    "\n",
    "        # Extract active experts\n",
    "        for batch_idx, gates in enumerate(gate_values):\n",
    "            active_experts = gates.argsort(descending=True)[:num_active_experts]\n",
    "            print(f\"  Batch {batch_idx + 1}:\")\n",
    "            for expert_idx in active_experts:\n",
    "                expert_weight = gates[expert_idx].item()\n",
    "                expert_output = expert_outputs[batch_idx, :, expert_idx]\n",
    "                top_tokens = expert_output.topk(5, dim=-1)\n",
    "                top_indices = top_tokens.indices\n",
    "                top_scores = top_tokens.values\n",
    "                decoded_tokens = tokenizer.decode(top_indices.tolist())\n",
    "                print(f\"    Expert {expert_idx}: Weight: {expert_weight:.4f}, Tokens: {decoded_tokens}, Scores: {top_scores.tolist()}\")\n",
    "\n",
    "    # Final logits\n",
    "    logits = model.lm_head(x)\n",
    "    top_tokens = logits.topk(5, dim=-1)\n",
    "    decoded_final_tokens = tokenizer.decode(top_tokens.indices.tolist())\n",
    "    print(f\"Final Layer: Tokens: {decoded_final_tokens}, Scores: {top_tokens.values.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_lens(model, input_tokens):\n",
    "    \"\"\"\n",
    "    Applies a logit lens to each layer of a mixture of experts (MoE) model for specific input tokens.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The MoE model.\n",
    "        input_tokens (torch.Tensor): Input tensor with token embeddings, shape [batch_size, seq_len].\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the logit lens outputs for each token at each layer.\n",
    "    \"\"\"\n",
    "    logit_outputs = {}\n",
    "\n",
    "    # Pass the input tokens through the embedding layer\n",
    "    embedding_output = model.embed_tokens(input_tokens)  # Shape: [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "    # Process tokens through each layer\n",
    "    for layer_idx, layer in enumerate(model.layers):\n",
    "        # Apply the layer and get its output\n",
    "        layer_outputs = layer(embedding_output)  # Shape: [batch_size, seq_len, feature_dim]\n",
    "\n",
    "        # Extract the mixture of experts (MoE) components for this layer\n",
    "        if hasattr(layer.mlp, \"experts\"):\n",
    "            gate_outputs = layer.mlp.gate(embedding_output)  # Shape: [batch_size, seq_len, num_experts]\n",
    "            expert_outputs = []\n",
    "\n",
    "            # Process each token separately to extract expert-specific outputs\n",
    "            for token_idx in range(input_tokens.shape[1]):\n",
    "                token_expert_outputs = []\n",
    "\n",
    "                for expert_idx, expert in enumerate(layer.mlp.experts):\n",
    "                    token_input = embedding_output[:, token_idx, :]  # Shape: [batch_size, embedding_dim]\n",
    "                    expert_output = expert(token_input)  # Shape: [batch_size, feature_dim]\n",
    "                    token_expert_outputs.append(expert_output)\n",
    "\n",
    "                # Stack expert outputs and apply gating\n",
    "                token_expert_outputs = torch.stack(token_expert_outputs, dim=1)  # Shape: [batch_size, num_experts, feature_dim]\n",
    "                token_gate_weights = gate_outputs[:, token_idx, :].unsqueeze(-1)  # Shape: [batch_size, num_experts, 1]\n",
    "                activated_experts_output = torch.sum(token_expert_outputs * token_gate_weights, dim=1)  # Shape: [batch_size, feature_dim]\n",
    "\n",
    "                # Save activated expert outputs for this token\n",
    "                logit_outputs[f\"layer_{layer_idx}_token_{token_idx}_activated_experts\"] = activated_experts_output\n",
    "\n",
    "        # Update the embedding for the next layer\n",
    "        embedding_output = layer_outputs\n",
    "\n",
    "    return logit_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing token: The\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertemplate": "%{text}<extra></extra>",
         "marker": {
          "color": [
           0,
           0,
           0.00717683881521225,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.00892392173409462,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.054928939789533615,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.005585566163063049,
           0,
           0,
           0,
           0,
           0,
           0,
           0.006941183935850859,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.648349940776825,
           0,
           0,
           0,
           0.26809364557266235,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10812234878540039,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10702115297317505,
           0,
           0,
           0,
           0,
           0,
           0.1863333284854889,
           0,
           0,
           0,
           0.2174638956785202,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1284273862838745,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13749834895133972,
           0.11513348668813705,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18799206614494324,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1168036088347435,
           0.0911179631948471,
           0,
           0,
           0.0878542810678482,
           0,
           0,
           0,
           0,
           0.09758366644382477,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09220506250858307,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.32644325494766235,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.07799221575260162,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13901269435882568,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.21015317738056183,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2012322098016739,
           0,
           0.19251304864883423,
           0,
           0,
           0,
           0,
           0.09936502575874329,
           0,
           0,
           0,
           0,
           0.07973165065050125,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18065129220485687,
           0,
           0,
           0.11359081417322159,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1931973695755005,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12084542959928513,
           0,
           0.15899664163589478,
           0,
           0,
           0.11700213700532913,
           0,
           0,
           0.11571629345417023,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0999702662229538,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.37697336077690125,
           0,
           0,
           0,
           0.10815970599651337,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09741824865341187,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12239108234643936,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09736444801092148,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09772297739982605,
           0,
           0,
           0.12851081788539886,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10639643669128418,
           0,
           0,
           0.19215549528598785,
           0.15260010957717896,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.17775027453899384,
           0,
           0.14453475177288055,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09805221855640411,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12603503465652466,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12340118736028671,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.20518861711025238,
           0,
           0.14370515942573547,
           0,
           0,
           0.12508700788021088,
           0,
           0,
           0.13431066274642944,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14227229356765747,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12574805319309235,
           0,
           0,
           0,
           0,
           0,
           0,
           0.20744648575782776,
           0,
           0,
           0,
           0.11486721783876419,
           0.12031704187393188,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12427373230457306,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11917087435722351,
           0,
           0,
           0,
           0,
           0.18817652761936188,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13561558723449707,
           0,
           0.13709698617458344,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.15742698311805725,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11129108816385269,
           0,
           0,
           0,
           0,
           0,
           0.1400081366300583,
           0,
           0,
           0.14346222579479218,
           0,
           0,
           0.17509907484054565,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1181708574295044,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18911021947860718,
           0,
           0,
           0,
           0,
           0,
           0.13919728994369507,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14600124955177307,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.164143905043602,
           0,
           0.12194253504276276,
           0,
           0,
           0,
           0,
           0.12143383175134659,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1345495879650116,
           0,
           0,
           0.1081666424870491,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1541944295167923,
           0,
           0,
           0,
           0.21175627410411835,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14529503881931305,
           0.1037786602973938,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14225925505161285,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12933333218097687,
           0,
           0,
           0.1759272813796997,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13087522983551025,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.17461678385734558,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13170376420021057,
           0,
           0.1271468549966812,
           0,
           0,
           0,
           0,
           0,
           0,
           0.130396768450737,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12766580283641815,
           0,
           0,
           0.1640755832195282,
           0,
           0,
           0,
           0,
           0.1360434591770172,
           0,
           0,
           0,
           0.14733821153640747,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12330792844295502,
           0,
           0.1414686143398285,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.16010046005249023,
           0,
           0,
           0,
           0,
           0,
           0.15414899587631226,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18334589898586273,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11464234441518784,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1292155534029007,
           0,
           0,
           0.15630733966827393,
           0,
           0.12155171483755112,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1407882124185562,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1526760756969452,
           0,
           0,
           0.14337585866451263,
           0,
           0,
           0,
           0,
           0,
           0.14532266557216644,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12497209757566452,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.16377507150173187,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13161297142505646,
           0,
           0,
           0,
           0.13826529681682587,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10311529040336609,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11361655592918396,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10474615544080734,
           0,
           0,
           0.11578399688005447,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18309038877487183,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12973396480083466,
           0.2499135434627533,
           0,
           0.10827406495809555,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11296753585338593,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14693661034107208,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2540176510810852,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12403011322021484,
           0,
           0.1430576592683792,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11071635037660599,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12141107022762299,
           0,
           0.2715848386287689,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1366465836763382,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12027571350336075,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09781248867511749,
           0,
           0.14426249265670776,
           0,
           0,
           0,
           0,
           0.10800686478614807,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.161209374666214,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18258807063102722,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13970965147018433,
           0,
           0,
           0.16528283059597015,
           0,
           0,
           0,
           0.15038414299488068,
           0,
           0,
           0.08672109246253967,
           0.11410479992628098,
           0,
           0,
           0.138899564743042,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1647755652666092,
           0,
           0,
           0,
           0,
           0,
           0.11576560139656067,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.24631650745868683,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1000259518623352,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11071924865245819,
           0,
           0,
           0.12349757552146912,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11867068707942963,
           0,
           0,
           0.15688884258270264,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.23425613343715668,
           0,
           0.15127520263195038,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10987535864114761,
           0.1128414049744606,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11619237810373306,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10245984047651291,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14062243700027466,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11794473975896835,
           0,
           0.18173177540302277,
           0,
           0,
           0,
           0.10538255423307419,
           0,
           0,
           0,
           0.13220998644828796,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.21964862942695618,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.20139539241790771,
           0,
           0,
           0,
           0.11778736859560013,
           0,
           0,
           0,
           0.11779333651065826,
           0,
           0,
           0,
           0,
           0.1296749711036682,
           0,
           0,
           0,
           0,
           0.12220108509063721,
           0,
           0,
           0.12894918024539948,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18219859898090363,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10349902510643005,
           0,
           0.1293671876192093,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13312962651252747,
           0,
           0,
           0,
           0,
           0,
           0.1106809452176094,
           0,
           0,
           0,
           0,
           0.0990399718284607,
           0,
           0.1341702938079834,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2901129424571991,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2748919427394867,
           0,
           0,
           0,
           0.3511528968811035,
           0,
           0,
           0.069233238697052,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.08542267233133316,
           0,
           0.08714677393436432,
           0,
           0.06097190082073212,
           0,
           0.07118060439825058,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1081043928861618,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13378286361694336,
           0,
           0,
           0,
           0,
           0,
           0.1283576786518097,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13694006204605103,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18013468384742737,
           0,
           0.1039455309510231,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.20873484015464783
          ],
          "colorbar": {
           "title": {
            "text": "Weight"
           }
          },
          "colorscale": [
           [
            0,
            "rgba(24, 21, 23, 0.8)"
           ],
           [
            0.0001,
            "rgb(68,1,84)"
           ],
           [
            1,
            "rgb(253,231,37)"
           ]
          ],
          "showscale": true,
          "size": 9
         },
         "mode": "markers",
         "text": [
          null,
          null,
          "Layer: 1<br>Expert: 2<br>Weight: 0.007<br>Top tokens:<br>advert: 0.241<br>: 0.213<br>: 0.189<br>fir: 0.183<br>vig: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 14<br>Weight: 0.009<br>Top tokens:<br>nqu: 0.216<br>: 0.212<br> Status: 0.194<br> Hi: 0.192<br>onite: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 23<br>Weight: 0.055<br>Top tokens:<br>lot: 0.219<br>poles: 0.210<br>clou: 0.196<br>bserv: 0.195<br>: 0.180",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 40<br>Weight: 0.006<br>Top tokens:<br>Park: 0.212<br>: 0.211<br>hola: 0.204<br> Park: 0.190<br>: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 47<br>Weight: 0.007<br>Top tokens:<br>: 0.239<br> o: 0.227<br> bu: 0.196<br>opters: 0.171<br> PM: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 59<br>Weight: 0.648<br>Top tokens:<br>: 0.274<br>enses: 0.186<br>ens: 0.184<br>: 0.180<br>: 0.176",
          null,
          null,
          null,
          "Layer: 1<br>Expert: 63<br>Weight: 0.268<br>Top tokens:<br>: 0.227<br>: 0.201<br> constitucional: 0.201<br> [_: 0.198<br> : 0.172",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 8<br>Weight: 0.108<br>Top tokens:<br>: 0.216<br>: 0.212<br>apsed: 0.206<br>iterr: 0.185<br> : 0.181",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 18<br>Weight: 0.107<br>Top tokens:<br>essee: 0.229<br>eni: 0.208<br> : 0.205<br>ianes: 0.192<br>oud: 0.166",
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 24<br>Weight: 0.186<br>Top tokens:<br>enas: 0.248<br>: 0.208<br>KY: 0.188<br>: 0.178<br> Charac: 0.178",
          null,
          null,
          null,
          "Layer: 2<br>Expert: 28<br>Weight: 0.217<br>Top tokens:<br>: 0.226<br>ling: 0.218<br>@: 0.195<br>coni: 0.182<br>BUS: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 38<br>Weight: 0.128<br>Top tokens:<br>: 0.231<br>throwing: 0.217<br>: 0.200<br>: 0.185<br>Throw: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 48<br>Weight: 0.137<br>Top tokens:<br>opin: 0.216<br>: 0.214<br>: 0.191<br>Evoluci: 0.190<br> followed: 0.189",
          "Layer: 2<br>Expert: 49<br>Weight: 0.115<br>Top tokens:<br>0: 0.275<br>oan: 0.195<br> p: 0.187<br>gad: 0.172<br>1: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 9<br>Weight: 0.188<br>Top tokens:<br>acant: 0.236<br> sorra: 0.227<br>onstr: 0.184<br>PREC: 0.179<br>uges: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 25<br>Weight: 0.117<br>Top tokens:<br>: 0.247<br> scrut: 0.210<br>itures: 0.188<br>geries: 0.180<br>: 0.175",
          "Layer: 3<br>Expert: 26<br>Weight: 0.091<br>Top tokens:<br>Habitants: 0.304<br>abilitat: 0.202<br> : 0.170<br>perf: 0.162<br>rely: 0.161",
          null,
          null,
          "Layer: 3<br>Expert: 29<br>Weight: 0.088<br>Top tokens:<br>herits: 0.288<br>: 0.187<br>CODEGEN: 0.181<br>balena: 0.176<br>ificador: 0.167",
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 34<br>Weight: 0.098<br>Top tokens:<br>: 0.203<br>strat: 0.200<br> seix: 0.200<br>ingut: 0.199<br> propor: 0.197",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 42<br>Weight: 0.092<br>Top tokens:<br>_{_: 0.249<br>uelen: 0.190<br>xfce: 0.189<br> coneixen: 0.187<br>cke: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 60<br>Weight: 0.326<br>Top tokens:<br>0: 0.240<br>2: 0.210<br>9: 0.200<br>1: 0.176<br>8: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 13<br>Weight: 0.078<br>Top tokens:<br>: 0.223<br>: 0.218<br>pad: 0.201<br>.: 0.179<br>Gen: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 25<br>Weight: 0.139<br>Top tokens:<br>ather: 0.255<br>._\": 0.190<br>COMPONENT: 0.189<br>ume: 0.187<br>ynchronously: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 41<br>Weight: 0.210<br>Top tokens:<br>companion: 0.246<br>: 0.197<br> Candidate: 0.193<br> Engine: 0.189<br>enso: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 48<br>Weight: 0.201<br>Top tokens:<br>istre: 0.229<br>:///: 0.213<br>: 0.194<br>elf: 0.182<br>rief: 0.182",
          null,
          "Layer: 4<br>Expert: 50<br>Weight: 0.193<br>Top tokens:<br>oven: 0.324<br>lus: 0.197<br>:///: 0.180<br> built: 0.152<br> Loric: 0.147",
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 55<br>Weight: 0.099<br>Top tokens:<br>malink: 0.280<br>: 0.204<br>estan: 0.178<br> : 0.169<br>sst: 0.169",
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 60<br>Weight: 0.080<br>Top tokens:<br>estrat: 0.210<br>: 0.210<br>atron: 0.205<br>/__: 0.192<br>acor: 0.184",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 3<br>Weight: 0.181<br>Top tokens:<br>ivia: 0.241<br>: 0.194<br>warz: 0.192<br> City: 0.189<br>iform: 0.184",
          null,
          null,
          "Layer: 5<br>Expert: 6<br>Weight: 0.114<br>Top tokens:<br>: 0.210<br>anyes: 0.207<br> : 0.199<br>cades: 0.199<br>oldt: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 32<br>Weight: 0.193<br>Top tokens:<br> : 0.227<br>: 0.209<br> Senat: 0.202<br>elic: 0.186<br>: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 44<br>Weight: 0.121<br>Top tokens:<br>: 0.216<br>udes: 0.212<br>: 0.205<br>ude: 0.185<br>: 0.182",
          null,
          "Layer: 5<br>Expert: 46<br>Weight: 0.159<br>Top tokens:<br> _: 0.231<br>: 0.204<br>inches: 0.194<br>: 0.186<br> IO: 0.185",
          null,
          null,
          "Layer: 5<br>Expert: 49<br>Weight: 0.117<br>Top tokens:<br>: 0.392<br> dispos: 0.169<br>: 0.165<br> Peabody: 0.139<br>ulo: 0.135",
          null,
          null,
          "Layer: 5<br>Expert: 52<br>Weight: 0.116<br>Top tokens:<br>: 0.219<br>enginy: 0.208<br>oguera: 0.201<br>Equador: 0.190<br>ilitat: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 5<br>Weight: 0.100<br>Top tokens:<br> cercle: 0.211<br>ript: 0.209<br>nora: 0.198<br>blr: 0.193<br>>-->: 0.190",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 21<br>Weight: 0.377<br>Top tokens:<br>otip: 0.530<br>thon: 0.130<br>pher: 0.123<br>scor: 0.119<br>: 0.098",
          null,
          null,
          null,
          "Layer: 6<br>Expert: 25<br>Weight: 0.108<br>Top tokens:<br>arb: 0.221<br>ake: 0.213<br>: 0.211<br> : 0.180<br>icken: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 35<br>Weight: 0.097<br>Top tokens:<br>6: 0.238<br>9: 0.222<br>7: 0.194<br>4: 0.185<br>8: 0.162",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 43<br>Weight: 0.122<br>Top tokens:<br>ARE: 0.288<br> extrems: 0.189<br>wolves: 0.181<br>: 0.176<br>arena: 0.165",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 50<br>Weight: 0.097<br>Top tokens:<br> pocs: 0.233<br>}$': 0.221<br>: 0.189<br>antine: 0.185<br>ssia: 0.172",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 63<br>Weight: 0.098<br>Top tokens:<br>resco: 0.228<br> Cortes: 0.206<br>: 0.192<br>CPP: 0.188<br> diferencia: 0.186",
          null,
          null,
          "Layer: 7<br>Expert: 2<br>Weight: 0.129<br>Top tokens:<br>orat: 0.345<br>ajes: 0.176<br>hyde: 0.161<br>liter: 0.159<br>facet: 0.158",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 10<br>Weight: 0.106<br>Top tokens:<br>istable: 0.257<br>anell: 0.241<br>: 0.194<br>ocada: 0.186<br>ocell: 0.121",
          null,
          null,
          "Layer: 7<br>Expert: 13<br>Weight: 0.192<br>Top tokens:<br>akespeare: 0.211<br>alp: 0.208<br>ateful: 0.196<br>ugal: 0.195<br> turb: 0.189",
          "Layer: 7<br>Expert: 14<br>Weight: 0.153<br>Top tokens:<br>RAW: 0.230<br>$~\\: 0.207<br>GiB: 0.195<br>APER: 0.186<br>obrir: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 26<br>Weight: 0.178<br>Top tokens:<br>: 0.256<br>anet: 0.226<br>: 0.198<br>: 0.167<br>arant: 0.153",
          null,
          "Layer: 7<br>Expert: 28<br>Weight: 0.145<br>Top tokens:<br>omla: 0.232<br>: 0.215<br>oulder: 0.194<br>equals: 0.181<br>uita: 0.178",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 51<br>Weight: 0.098<br>Top tokens:<br> optar: 0.222<br>lady: 0.200<br>offee: 0.200<br>itas: 0.194<br>Issue: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 6<br>Weight: 0.126<br>Top tokens:<br>: 0.321<br>: 0.187<br>ish: 0.176<br>: 0.160<br>Inst: 0.156",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 25<br>Weight: 0.123<br>Top tokens:<br>8: 0.235<br>1: 0.225<br>hana: 0.185<br>6: 0.178<br>4: 0.177",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 41<br>Weight: 0.205<br>Top tokens:<br>ilitat: 0.255<br>: 0.217<br>ALES: 0.191<br>letes: 0.184<br>boxt: 0.153",
          null,
          "Layer: 8<br>Expert: 43<br>Weight: 0.144<br>Top tokens:<br>: 0.208<br>: 0.206<br>: 0.200<br>: 0.194<br>: 0.191",
          null,
          null,
          "Layer: 8<br>Expert: 46<br>Weight: 0.125<br>Top tokens:<br>9: 0.223<br>=\"../_: 0.210<br>1: 0.204<br>: 0.188<br>8: 0.175",
          null,
          null,
          "Layer: 8<br>Expert: 49<br>Weight: 0.134<br>Top tokens:<br>: 0.234<br>CDF: 0.224<br>ilst: 0.192<br>romy: 0.180<br> shifter: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 63<br>Weight: 0.142<br>Top tokens:<br>: 0.350<br>nicamente: 0.188<br>bic: 0.162<br>uta: 0.157<br>: 0.142",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 8<br>Weight: 0.126<br>Top tokens:<br>: 0.263<br>ATERIAL: 0.213<br>: 0.183<br>gence: 0.177<br> apreciar: 0.163",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 15<br>Weight: 0.207<br>Top tokens:<br> der: 0.232<br> Fort: 0.212<br>itty: 0.206<br> fits: 0.179<br> rather: 0.171",
          null,
          null,
          null,
          "Layer: 9<br>Expert: 19<br>Weight: 0.115<br>Top tokens:<br>: 0.265<br>LASS: 0.193<br>: 0.192<br>pee: 0.178<br>: 0.172",
          "Layer: 9<br>Expert: 20<br>Weight: 0.120<br>Top tokens:<br>: 0.268<br>: 0.215<br>ISTER: 0.193<br>: 0.165<br>: 0.159",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 42<br>Weight: 0.124<br>Top tokens:<br>moor: 0.248<br> Rouge: 0.218<br>elessly: 0.190<br>: 0.177<br> : 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 50<br>Weight: 0.119<br>Top tokens:<br>v: 0.375<br>olla: 0.169<br>: 0.162<br>odec: 0.150<br>end: 0.144",
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 55<br>Weight: 0.188<br>Top tokens:<br>: 0.252<br>: 0.218<br>: 0.195<br>sonian: 0.171<br>bology: 0.163",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 5<br>Weight: 0.136<br>Top tokens:<br>East: 0.370<br> East: 0.166<br>: 0.163<br>eln: 0.153<br>tect: 0.147",
          null,
          "Layer: 10<br>Expert: 7<br>Weight: 0.137<br>Top tokens:<br>miral: 0.282<br>part: 0.201<br>: 0.182<br>matical: 0.173<br>rode: 0.162",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 18<br>Weight: 0.157<br>Top tokens:<br>: 0.236<br>x: 0.210<br>terminal: 0.199<br>iaci: 0.180<br>icus: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 36<br>Weight: 0.111<br>Top tokens:<br>: 0.251<br>itat: 0.208<br>forter: 0.182<br>EVER: 0.182<br>: 0.178",
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 42<br>Weight: 0.140<br>Top tokens:<br>3: 0.248<br>0: 0.229<br>1: 0.227<br>6: 0.148<br>2: 0.148",
          null,
          null,
          "Layer: 10<br>Expert: 45<br>Weight: 0.143<br>Top tokens:<br>fog: 0.210<br>ock: 0.209<br>ig: 0.200<br>: 0.199<br>pires: 0.182",
          null,
          null,
          "Layer: 10<br>Expert: 48<br>Weight: 0.175<br>Top tokens:<br>inette: 0.333<br>vature: 0.195<br>: 0.180<br>rame: 0.162<br>ANCE: 0.130",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 4<br>Weight: 0.118<br>Top tokens:<br>8: 0.310<br>6: 0.234<br>3: 0.205<br>: 0.129<br>0: 0.122",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 13<br>Weight: 0.189<br>Top tokens:<br>Compan: 0.250<br> : 0.244<br>util: 0.211<br>: 0.162<br>: 0.133",
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 19<br>Weight: 0.139<br>Top tokens:<br>isure: 0.319<br> Served: 0.198<br>akr: 0.176<br> : 0.155<br>ALOG: 0.152",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 28<br>Weight: 0.146<br>Top tokens:<br>reys: 0.360<br>: 0.207<br>: 0.164<br>: 0.162<br>elines: 0.107",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 40<br>Weight: 0.164<br>Top tokens:<br>: 0.277<br>0: 0.225<br>odder: 0.175<br>aband: 0.164<br>9: 0.159",
          null,
          "Layer: 11<br>Expert: 42<br>Weight: 0.122<br>Top tokens:<br>ROID: 0.402<br>7: 0.172<br>8: 0.165<br> Tolosa: 0.136<br> Madge: 0.125",
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 47<br>Weight: 0.121<br>Top tokens:<br>ist: 0.340<br>m: 0.205<br>b: 0.174<br>burg: 0.142<br>: 0.140",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 0<br>Weight: 0.135<br>Top tokens:<br> part: 0.240<br>: 0.202<br>tery: 0.197<br>inx: 0.184<br>: 0.177",
          null,
          null,
          "Layer: 12<br>Expert: 3<br>Weight: 0.108<br>Top tokens:<br>oide: 0.379<br>uated: 0.262<br>ified: 0.131<br>: 0.128<br>ensem: 0.100",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 13<br>Weight: 0.154<br>Top tokens:<br>broad: 0.217<br>Broad: 0.215<br>: 0.199<br>hof: 0.187<br>RECT: 0.182",
          null,
          null,
          null,
          "Layer: 12<br>Expert: 17<br>Weight: 0.212<br>Top tokens:<br>veh: 0.272<br> col: 0.236<br>: 0.170<br>AT: 0.162<br>escl: 0.160",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 30<br>Weight: 0.145<br>Top tokens:<br>rena: 0.216<br>zca: 0.205<br>: 0.198<br>ths: 0.195<br>: 0.186",
          "Layer: 12<br>Expert: 31<br>Weight: 0.104<br>Top tokens:<br>arque: 0.466<br>rength: 0.147<br>: 0.137<br>iddy: 0.125<br> : 0.125",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 39<br>Weight: 0.142<br>Top tokens:<br>ccane: 0.235<br>CFT: 0.229<br>GR: 0.197<br>itons: 0.187<br>gia: 0.152",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 7<br>Weight: 0.129<br>Top tokens:<br>olas: 0.427<br>stream: 0.154<br>builder: 0.149<br>: 0.139<br>wisdom: 0.131",
          null,
          null,
          "Layer: 13<br>Expert: 10<br>Weight: 0.176<br>Top tokens:<br>MethodName: 0.218<br>Etapa: 0.214<br>scribe: 0.206<br>$/.: 0.190<br>estany: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 17<br>Weight: 0.131<br>Top tokens:<br>;=: 0.234<br>ournals: 0.200<br>: 0.195<br>iture: 0.193<br>ermost: 0.178",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 41<br>Weight: 0.175<br>Top tokens:<br>=\"__: 0.492<br>: 0.216<br>: 0.119<br>: 0.088<br>: 0.085",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 50<br>Weight: 0.132<br>Top tokens:<br>: 0.508<br>: 0.161<br>: 0.129<br>: 0.115<br>odot: 0.086",
          null,
          "Layer: 13<br>Expert: 52<br>Weight: 0.127<br>Top tokens:<br>PROTOBUF: 0.285<br>rary: 0.229<br>rate: 0.192<br>rates: 0.151<br>: 0.143",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 59<br>Weight: 0.130<br>Top tokens:<br>hetical: 0.217<br>: 0.214<br>ruce: 0.200<br>picker: 0.189<br>leted: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 14<br>Weight: 0.128<br>Top tokens:<br>0: 0.344<br>1: 0.222<br>2: 0.162<br>3: 0.143<br>5: 0.129",
          null,
          null,
          "Layer: 14<br>Expert: 17<br>Weight: 0.164<br>Top tokens:<br> calci: 0.277<br>iod: 0.246<br>: 0.172<br>: 0.159<br> constitution: 0.146",
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 22<br>Weight: 0.136<br>Top tokens:<br>i: 0.238<br>: 0.204<br> Edicions: 0.196<br>: 0.181<br>: 0.180",
          null,
          null,
          null,
          "Layer: 14<br>Expert: 26<br>Weight: 0.147<br>Top tokens:<br>: 0.291<br> tr: 0.203<br> l: 0.171<br>glob: 0.168<br>end: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 38<br>Weight: 0.123<br>Top tokens:<br> Pow: 0.309<br>: 0.299<br>ahler: 0.158<br>Pow: 0.117<br>eppel: 0.117",
          null,
          "Layer: 14<br>Expert: 40<br>Weight: 0.141<br>Top tokens:<br>acant: 0.323<br>: 0.206<br>ITED: 0.180<br>inberg: 0.157<br>uxley: 0.133",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 63<br>Weight: 0.160<br>Top tokens:<br>IZED: 0.303<br>anine: 0.191<br> Rocks: 0.179<br>edn: 0.166<br>ANGLE: 0.161",
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 5<br>Weight: 0.154<br>Top tokens:<br>refn: 0.307<br>:///: 0.189<br>illac: 0.172<br>fortunes: 0.170<br>GNU: 0.161",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 15<br>Weight: 0.183<br>Top tokens:<br>: 0.278<br>atem: 0.215<br>formed: 0.177<br>: 0.168<br>erves: 0.162",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 33<br>Weight: 0.115<br>Top tokens:<br>issin: 0.250<br>: 0.245<br>: 0.218<br>: 0.146<br>orthand: 0.141",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 40<br>Weight: 0.129<br>Top tokens:<br>hea: 0.278<br>ing: 0.194<br>: 0.189<br>sal: 0.171<br>: 0.169",
          null,
          null,
          "Layer: 15<br>Expert: 43<br>Weight: 0.156<br>Top tokens:<br>: 0.271<br>: 0.250<br>tofore: 0.180<br>).__: 0.153<br>lessness: 0.146",
          null,
          "Layer: 15<br>Expert: 45<br>Weight: 0.122<br>Top tokens:<br> fuster: 0.242<br>jades: 0.223<br>rivacy: 0.180<br>restant: 0.180<br>recci: 0.176",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 54<br>Weight: 0.141<br>Top tokens:<br> : 0.276<br>laz: 0.198<br>ament: 0.186<br>ogeneity: 0.173<br>ceil: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 0<br>Weight: 0.153<br>Top tokens:<br>: 0.212<br>imales: 0.209<br>ild: 0.205<br>: 0.203<br>opi: 0.172",
          null,
          null,
          "Layer: 16<br>Expert: 3<br>Weight: 0.143<br>Top tokens:<br>urats: 0.285<br>plets: 0.204<br>: 0.198<br>\"><![: 0.168<br>rbia: 0.144",
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 9<br>Weight: 0.145<br>Top tokens:<br>: 0.277<br> : 0.253<br>: 0.177<br>: 0.148<br>: 0.143",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 29<br>Weight: 0.125<br>Top tokens:<br>agena: 0.311<br>nids: 0.226<br>>.<: 0.215<br>avens: 0.124<br>: 0.124",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 40<br>Weight: 0.164<br>Top tokens:<br> who: 0.518<br> whom: 0.156<br>whom: 0.119<br>who: 0.112<br> things: 0.096",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 51<br>Weight: 0.132<br>Top tokens:<br> mill: 0.269<br> versa: 0.190<br>: 0.188<br>rpre: 0.179<br>: 0.174",
          null,
          null,
          null,
          "Layer: 16<br>Expert: 55<br>Weight: 0.138<br>Top tokens:<br>enery: 0.247<br>enance: 0.199<br>imize: 0.193<br>visi: 0.180<br> Tremp: 0.180",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 10<br>Weight: 0.103<br>Top tokens:<br> per: 0.302<br> each: 0.212<br>per: 0.178<br>atu: 0.172<br>each: 0.135",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 21<br>Weight: 0.114<br>Top tokens:<br> : 0.395<br> or: 0.356<br>urname: 0.094<br>odox: 0.082<br> nor: 0.073",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 40<br>Weight: 0.105<br>Top tokens:<br> fre: 0.244<br>: 0.219<br>: 0.211<br>enal: 0.164<br>: 0.163",
          null,
          null,
          "Layer: 17<br>Expert: 43<br>Weight: 0.116<br>Top tokens:<br>2: 0.284<br>3: 0.217<br>9: 0.179<br>1: 0.166<br>6: 0.155",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 52<br>Weight: 0.183<br>Top tokens:<br>again: 0.343<br>Again: 0.232<br>igneur: 0.163<br> Again: 0.132<br> again: 0.129",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 62<br>Weight: 0.130<br>Top tokens:<br>: 0.262<br>balls: 0.221<br> Po: 0.197<br>part: 0.161<br> Balls: 0.159",
          "Layer: 17<br>Expert: 63<br>Weight: 0.250<br>Top tokens:<br>zzle: 0.279<br>itti: 0.223<br>angelog: 0.173<br>estock: 0.170<br>itors: 0.155",
          null,
          "Layer: 18<br>Expert: 1<br>Weight: 0.108<br>Top tokens:<br>: 0.218<br>WAY: 0.214<br>WAYS: 0.213<br>doxygen: 0.182<br>agut: 0.173",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 9<br>Weight: 0.113<br>Top tokens:<br>odge: 0.261<br>: 0.213<br>: 0.181<br>ein: 0.176<br>kip: 0.169",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 18<br>Weight: 0.147<br>Top tokens:<br>ks: 0.224<br>pers: 0.204<br>im: 0.197<br>ithe: 0.188<br>ora: 0.186",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 25<br>Weight: 0.254<br>Top tokens:<br>: 0.367<br>wards: 0.192<br>blr: 0.174<br>ection: 0.142<br>roma: 0.126",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 47<br>Weight: 0.124<br>Top tokens:<br>: 0.407<br>: 0.197<br>zes: 0.164<br>ual: 0.120<br>ented: 0.112",
          null,
          "Layer: 18<br>Expert: 49<br>Weight: 0.143<br>Top tokens:<br> : 0.487<br>igna: 0.232<br> Foix: 0.096<br> drogues: 0.096<br> : 0.089",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 59<br>Weight: 0.111<br>Top tokens:<br>orden: 0.240<br>: 0.213<br>: 0.193<br>enched: 0.190<br>encar: 0.164",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 4<br>Weight: 0.121<br>Top tokens:<br>,: 0.428<br> or: 0.234<br>business: 0.154<br> our: 0.093<br> business: 0.092",
          null,
          "Layer: 19<br>Expert: 6<br>Weight: 0.272<br>Top tokens:<br>: 0.300<br>odium: 0.189<br>: 0.184<br>: 0.163<br> head: 0.163",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 14<br>Weight: 0.137<br>Top tokens:<br> in: 0.246<br> between: 0.196<br>: 0.195<br>: 0.192<br>ota: 0.170",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 23<br>Weight: 0.120<br>Top tokens:<br>only: 0.527<br>Only: 0.194<br>ONLY: 0.099<br>by: 0.095<br> only: 0.084",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 54<br>Weight: 0.098<br>Top tokens:<br>both: 0.409<br>: 0.221<br>: 0.134<br>: 0.118<br> Both: 0.118",
          null,
          "Layer: 19<br>Expert: 56<br>Weight: 0.144<br>Top tokens:<br>take: 0.337<br> take: 0.197<br> took: 0.188<br>taking: 0.146<br> taking: 0.131",
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 61<br>Weight: 0.108<br>Top tokens:<br> thing: 0.446<br>idean: 0.193<br>)$-: 0.173<br>avant: 0.099<br>: 0.090",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 5<br>Weight: 0.161<br>Top tokens:<br>-: 0.254<br>: 0.228<br> : 0.182<br>: 0.170<br> _: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 20<br>Weight: 0.183<br>Top tokens:<br> Asiatic: 0.459<br>iat: 0.309<br>: 0.111<br>: 0.085<br>: 0.037",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 50<br>Weight: 0.140<br>Top tokens:<br>: 0.340<br>pep: 0.208<br>: 0.162<br>: 0.150<br>: 0.140",
          null,
          null,
          "Layer: 20<br>Expert: 53<br>Weight: 0.165<br>Top tokens:<br>: 0.213<br> Climent: 0.211<br>: 0.211<br>: 0.194<br>ingui: 0.171",
          null,
          null,
          null,
          "Layer: 20<br>Expert: 57<br>Weight: 0.150<br>Top tokens:<br>nds: 0.235<br>: 0.211<br> r: 0.195<br>: 0.188<br>: 0.171",
          null,
          null,
          "Layer: 20<br>Expert: 60<br>Weight: 0.087<br>Top tokens:<br>cs: 0.236<br>m: 0.227<br>: 0.201<br>po: 0.181<br>0: 0.155",
          "Layer: 20<br>Expert: 61<br>Weight: 0.114<br>Top tokens:<br>poch: 0.245<br>rici: 0.224<br>Bound: 0.194<br>blocked: 0.169<br>: 0.168",
          null,
          null,
          "Layer: 21<br>Expert: 0<br>Weight: 0.139<br>Top tokens:<br>ifi: 0.354<br>sofs: 0.225<br>ium: 0.220<br>zing: 0.104<br>amping: 0.098",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 8<br>Weight: 0.165<br>Top tokens:<br>: 0.275<br> cell: 0.238<br> Cell: 0.188<br>})$-: 0.154<br> loopback: 0.145",
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 14<br>Weight: 0.116<br>Top tokens:<br>adona: 0.392<br>rable: 0.176<br>ctree: 0.146<br>}$),: 0.144<br>arcy: 0.142",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 33<br>Weight: 0.246<br>Top tokens:<br>obres: 0.304<br>: 0.209<br>alesa: 0.177<br> parabolic: 0.160<br>ossible: 0.149",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 40<br>Weight: 0.100<br>Top tokens:<br>: 0.383<br>icional: 0.187<br>rien: 0.158<br> jet: 0.148<br> l: 0.124",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 59<br>Weight: 0.111<br>Top tokens:<br>5: 0.582<br>1: 0.188<br>2: 0.122<br>8: 0.077<br>6: 0.032",
          null,
          null,
          "Layer: 21<br>Expert: 62<br>Weight: 0.123<br>Top tokens:<br>rowColor: 0.318<br>cnics: 0.193<br>: 0.173<br>miral: 0.159<br>ndies: 0.157",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 5<br>Weight: 0.119<br>Top tokens:<br>planar: 0.729<br> -: 0.084<br>,.: 0.080<br>: 0.053<br>occidental: 0.053",
          null,
          null,
          "Layer: 22<br>Expert: 8<br>Weight: 0.157<br>Top tokens:<br>: 0.302<br> : 0.212<br>: 0.204<br>2: 0.159<br>: 0.124",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 26<br>Weight: 0.234<br>Top tokens:<br>4: 0.244<br>2: 0.237<br>7: 0.177<br>1: 0.174<br>9: 0.169",
          null,
          "Layer: 22<br>Expert: 28<br>Weight: 0.151<br>Top tokens:<br> : 0.216<br>acte: 0.213<br>: 0.198<br>mirrors: 0.191<br>ue: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 46<br>Weight: 0.110<br>Top tokens:<br>: 0.762<br>: 0.082<br>: 0.071<br>itch: 0.058<br>: 0.027",
          "Layer: 22<br>Expert: 47<br>Weight: 0.113<br>Top tokens:<br>ittest: 0.401<br>: 0.177<br>edas: 0.151<br>: 0.150<br>ugosl: 0.120",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 60<br>Weight: 0.116<br>Top tokens:<br> herself: 0.979<br> her: 0.020<br>herself: 0.000<br> she: 0.000<br> hers: 0.000",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 5<br>Weight: 0.102<br>Top tokens:<br> trade: 0.421<br> business: 0.198<br> trading: 0.134<br> Trade: 0.126<br>business: 0.120",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 14<br>Weight: 0.141<br>Top tokens:<br>eered: 0.339<br>ield: 0.221<br> yourselves: 0.186<br>plication: 0.127<br>ex: 0.127",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 31<br>Weight: 0.118<br>Top tokens:<br>atal: 0.282<br>: 0.200<br> PM: 0.186<br>: 0.181<br>eration: 0.150",
          null,
          "Layer: 23<br>Expert: 33<br>Weight: 0.182<br>Top tokens:<br>0: 0.304<br>outcome: 0.196<br>alus: 0.180<br> outcome: 0.163<br> r: 0.157",
          null,
          null,
          null,
          "Layer: 23<br>Expert: 37<br>Weight: 0.105<br>Top tokens:<br> : 0.634<br> Martorell: 0.129<br>issen: 0.091<br>onics: 0.076<br>osity: 0.069",
          null,
          null,
          null,
          "Layer: 23<br>Expert: 41<br>Weight: 0.132<br>Top tokens:<br>C: 0.503<br>M: 0.276<br>Sh: 0.111<br>D: 0.062<br>an: 0.049",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 57<br>Weight: 0.220<br>Top tokens:<br>ikipedia: 0.210<br>: 0.208<br>: 0.205<br>germ: 0.193<br>cet: 0.184",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 11<br>Weight: 0.201<br>Top tokens:<br>ly: 1.000<br>ing: 0.000<br>is: 0.000<br>led: 0.000<br>ed: 0.000",
          null,
          null,
          null,
          "Layer: 24<br>Expert: 15<br>Weight: 0.118<br>Top tokens:<br>ILED: 0.531<br>layer: 0.127<br>: 0.117<br>: 0.114<br>ILY: 0.111",
          null,
          null,
          null,
          "Layer: 24<br>Expert: 19<br>Weight: 0.118<br>Top tokens:<br>edly: 0.457<br>: 0.188<br>ermost: 0.154<br>iation: 0.101<br>: 0.100",
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 24<br>Weight: 0.130<br>Top tokens:<br>[...]: 0.278<br> press: 0.195<br>lix: 0.188<br>harmonic: 0.172<br>: 0.166",
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 29<br>Weight: 0.122<br>Top tokens:<br>icolon: 0.372<br>ple: 0.234<br>: 0.153<br>: 0.138<br>: 0.103",
          null,
          null,
          "Layer: 24<br>Expert: 32<br>Weight: 0.129<br>Top tokens:<br>\": 0.476<br>\"\\: 0.305<br>: 0.091<br>: 0.074<br>: 0.054",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 52<br>Weight: 0.182<br>Top tokens:<br>eck: 0.226<br>domen: 0.222<br>oda: 0.198<br> mano: 0.179<br>ZING: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 9<br>Weight: 0.103<br>Top tokens:<br>atur: 0.258<br>: 0.221<br>ilde: 0.181<br>atu: 0.175<br>hore: 0.165",
          null,
          "Layer: 25<br>Expert: 11<br>Weight: 0.129<br>Top tokens:<br>: 0.239<br>ohl: 0.233<br>\"><!--: 0.184<br>atol: 0.174<br>aty: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 19<br>Weight: 0.133<br>Top tokens:<br>: 0.514<br>lehem: 0.160<br>igraphy: 0.126<br>mbol: 0.105<br>bilt: 0.096",
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 25<br>Weight: 0.111<br>Top tokens:<br>: 0.471<br>ives: 0.211<br>ivell: 0.120<br>/~: 0.100<br>words: 0.098",
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 30<br>Weight: 0.099<br>Top tokens:<br>: 0.475<br>: 0.207<br>: 0.126<br>: 0.097<br> : 0.095",
          null,
          "Layer: 25<br>Expert: 32<br>Weight: 0.134<br>Top tokens:<br> : 0.367<br>Formatting: 0.225<br> inactius: 0.141<br>: 0.141<br>: 0.126",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 53<br>Weight: 0.290<br>Top tokens:<br> .../: 0.444<br>: 0.249<br>: 0.117<br> met: 0.107<br>: 0.083",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 29<br>Weight: 0.275<br>Top tokens:<br>artment: 0.286<br>odatabase: 0.194<br>: 0.190<br>ilets: 0.167<br>itudes: 0.163",
          null,
          null,
          null,
          "Layer: 26<br>Expert: 33<br>Weight: 0.351<br>Top tokens:<br>: 0.264<br>: 0.242<br>: 0.172<br>: 0.163<br>equence: 0.158",
          null,
          null,
          "Layer: 26<br>Expert: 36<br>Weight: 0.069<br>Top tokens:<br>: 0.226<br>: 0.204<br>: 0.202<br>: 0.194<br>: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 49<br>Weight: 0.085<br>Top tokens:<br>: 0.224<br>udar: 0.209<br>rores: 0.205<br> Diod: 0.193<br>: 0.169",
          null,
          "Layer: 26<br>Expert: 51<br>Weight: 0.087<br>Top tokens:<br>: 0.707<br>: 0.187<br>: 0.075<br>: 0.017<br>: 0.014",
          null,
          "Layer: 26<br>Expert: 53<br>Weight: 0.061<br>Top tokens:<br>...: 0.419<br>......: 0.312<br>'...: 0.240<br>,...: 0.023<br>...?: 0.005",
          null,
          "Layer: 26<br>Expert: 55<br>Weight: 0.071<br>Top tokens:<br> : 0.798<br> h: 0.112<br> (: 0.035<br> r: 0.031<br> m: 0.024",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 1<br>Weight: 0.108<br>Top tokens:<br>: 0.218<br> cryptocur: 0.216<br>: 0.196<br>: 0.185<br>ottest: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 20<br>Weight: 0.134<br>Top tokens:<br> theater: 0.219<br>Player: 0.211<br> Player: 0.208<br> Theater: 0.190<br> Entertainment: 0.171",
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 26<br>Weight: 0.128<br>Top tokens:<br>7: 0.247<br>3: 0.211<br>9: 0.186<br>4: 0.183<br>1: 0.173",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 33<br>Weight: 0.137<br>Top tokens:<br> m: 0.518<br>\tm: 0.153<br>m: 0.152<br> : 0.091<br> os: 0.086",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 53<br>Weight: 0.180<br>Top tokens:<br>a: 0.281<br>land: 0.204<br>: 0.203<br>: 0.160<br>: 0.152",
          null,
          "Layer: 27<br>Expert: 55<br>Weight: 0.104<br>Top tokens:<br> ,\\\\: 0.251<br> &=&\\: 0.218<br>\\!+\\!: 0.184<br>&=&\\: 0.181<br>DOCKED: 0.166",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 63<br>Weight: 0.209<br>Top tokens:<br> var: 0.351<br>vect: 0.183<br> vector: 0.168<br> const: 0.155<br>: 0.143"
         ],
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63
         ],
         "y": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27
         ]
        }
       ],
       "layout": {
        "height": 800,
        "paper_bgcolor": "black",
        "plot_bgcolor": "black",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Expert Activations for Token \"The\" at Position 1"
        },
        "width": 1200,
        "xaxis": {
         "gridcolor": "rgba(128, 128, 128, 0.2)",
         "gridwidth": 1,
         "range": [
          -1,
          64
         ],
         "showgrid": true,
         "title": {
          "text": "Expert ID"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "gridcolor": "rgba(128, 128, 128, 0.2)",
         "gridwidth": 1,
         "showgrid": true,
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = MOEExpertLens(state_dict, tokenizer)\n",
    "\n",
    "# Analyze text\n",
    "text = \"The quick brown fox\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(get_device())\n",
    "results = analyzer.analyze_text(input_ids)\n",
    "\n",
    "# Visualize specific layer/token\n",
    "visualize_layer_analysis(tokenizer, results, token_position=1, input_text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing token:  fox\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertemplate": "%{text}<extra></extra>",
         "marker": {
          "color": [
           0,
           0.08546809107065201,
           0,
           0,
           0,
           0.07005205005407333,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.19625729322433472,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.24429796636104584,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.07223766297101974,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10177560895681381,
           0,
           0,
           0,
           0,
           0.22991140186786652,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10730572789907455,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10519911348819733,
           0,
           0,
           0,
           0,
           0,
           0.18813660740852356,
           0,
           0,
           0,
           0.21834084391593933,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1295311450958252,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1363677978515625,
           0.11511877924203873,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.187992125749588,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11680327355861664,
           0.09111838042736053,
           0,
           0,
           0.08785426616668701,
           0,
           0,
           0,
           0,
           0.09758324921131134,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09220483154058456,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.3264438807964325,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.07799221575260162,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13901260495185852,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.21015313267707825,
           0,
           0,
           0,
           0,
           0,
           0,
           0.20123226940631866,
           0,
           0.19251306354999542,
           0,
           0,
           0,
           0,
           0.09936507046222687,
           0,
           0,
           0,
           0,
           0.07973163574934006,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1806512326002121,
           0,
           0,
           0.11359085887670517,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.19319750368595123,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12084534019231796,
           0,
           0.1589965671300888,
           0,
           0,
           0.11700212210416794,
           0,
           0,
           0.11571630835533142,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0999702662229538,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.3769732713699341,
           0,
           0,
           0,
           0.10815970599651337,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09741830825805664,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12239106744527817,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0973644033074379,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09772297739982605,
           0,
           0,
           0.12851077318191528,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10639635473489761,
           0,
           0,
           0.19215548038482666,
           0.15260009467601776,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.17775021493434906,
           0,
           0.14453476667404175,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.09805218130350113,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12603507936000824,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12340119481086731,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.20518849790096283,
           0,
           0.14370518922805786,
           0,
           0,
           0.12508702278137207,
           0,
           0,
           0.13431069254875183,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14227229356765747,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12574803829193115,
           0,
           0,
           0,
           0,
           0,
           0,
           0.20744644105434418,
           0,
           0,
           0,
           0.11486725509166718,
           0.1203170195221901,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12427380681037903,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1191709116101265,
           0,
           0,
           0,
           0,
           0.18817652761936188,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13561564683914185,
           0,
           0.13709695637226105,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.15742695331573486,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1112910658121109,
           0,
           0,
           0,
           0,
           0,
           0.14000803232192993,
           0,
           0,
           0.14346228539943695,
           0,
           0,
           0.17509904503822327,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11817091703414917,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18911029398441315,
           0,
           0,
           0,
           0,
           0,
           0.13919728994369507,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14600123465061188,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.16414397954940796,
           0,
           0.1219424307346344,
           0,
           0,
           0,
           0,
           0.12143389135599136,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13454961776733398,
           0,
           0,
           0.10816668719053268,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.15419448912143707,
           0,
           0,
           0,
           0.21175622940063477,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14529500901699066,
           0.1037786453962326,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14225925505161285,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12933333218097687,
           0,
           0,
           0.17592735588550568,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13087522983551025,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1746167242527008,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13170373439788818,
           0,
           0.1271468847990036,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1303967982530594,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12766581773757935,
           0,
           0,
           0.1640755832195282,
           0,
           0,
           0,
           0,
           0.1360434591770172,
           0,
           0,
           0,
           0.14733821153640747,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12330793589353561,
           0,
           0.1414686143398285,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.16010043025016785,
           0,
           0,
           0,
           0,
           0,
           0.15414899587631226,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1833459436893463,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11464231461286545,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1292155236005783,
           0,
           0,
           0.15630723536014557,
           0,
           0.12155172228813171,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1407882273197174,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.15267598628997803,
           0,
           0,
           0.14337582886219025,
           0,
           0,
           0,
           0,
           0,
           0.14532266557216644,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12497211992740631,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.16377511620521545,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13161292672157288,
           0,
           0,
           0,
           0.13826531171798706,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10311533510684967,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11361652612686157,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10474615544080734,
           0,
           0,
           0.11578400433063507,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18309049308300018,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12973393499851227,
           0.2499135434627533,
           0,
           0.1082739531993866,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11296757310628891,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14693662524223328,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2540176510810852,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12403015792369843,
           0,
           0.143057718873024,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11071635037660599,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12141107022762299,
           0,
           0.27158495783805847,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1366465538740158,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.12027576565742493,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.0978124588727951,
           0,
           0.14426232874393463,
           0,
           0,
           0,
           0,
           0.1080068051815033,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.16120944917201996,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1825883537530899,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1397094577550888,
           0,
           0,
           0.16528284549713135,
           0,
           0,
           0,
           0.15038403868675232,
           0,
           0,
           0.08672105520963669,
           0.11410477012395859,
           0,
           0,
           0.13889947533607483,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.16477558016777039,
           0,
           0,
           0,
           0,
           0,
           0.11576557159423828,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.24631661176681519,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10002592951059341,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11071930080652237,
           0,
           0,
           0.12349753826856613,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11867058277130127,
           0,
           0,
           0.15688879787921906,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.23425623774528503,
           0,
           0.15127524733543396,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1098753809928894,
           0.11284136772155762,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11619241535663605,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10245981812477112,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.14062243700027466,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.11794478446245193,
           0,
           0.18173174560070038,
           0,
           0,
           0,
           0.10538256168365479,
           0,
           0,
           0,
           0.13221001625061035,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.21964862942695618,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2013954371213913,
           0,
           0,
           0,
           0.11778737604618073,
           0,
           0,
           0,
           0.11779338866472244,
           0,
           0,
           0,
           0,
           0.12967495620250702,
           0,
           0,
           0,
           0,
           0.1222011148929596,
           0,
           0,
           0.12894921004772186,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.18219861388206482,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.10349902510643005,
           0,
           0.1293671429157257,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13312965631484985,
           0,
           0,
           0,
           0,
           0,
           0.11068091541528702,
           0,
           0,
           0,
           0,
           0.0990399718284607,
           0,
           0.13417033851146698,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2901129424571991,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.2748918831348419,
           0,
           0,
           0,
           0.35115310549736023,
           0,
           0,
           0.06923320144414902,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.08542262017726898,
           0,
           0.08714678883552551,
           0,
           0.06097188591957092,
           0,
           0.071180559694767,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1081044003367424,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13378268480300903,
           0,
           0,
           0,
           0,
           0,
           0.1283576935529709,
           0,
           0,
           0,
           0,
           0,
           0,
           0.13694003224372864,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.1801348775625229,
           0,
           0.10394532233476639,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.20873504877090454
          ],
          "colorbar": {
           "title": {
            "text": "Weight"
           }
          },
          "colorscale": [
           [
            0,
            "rgba(24, 21, 23, 0.8)"
           ],
           [
            0.0001,
            "rgb(68,1,84)"
           ],
           [
            1,
            "rgb(253,231,37)"
           ]
          ],
          "showscale": true,
          "size": 9
         },
         "mode": "markers",
         "text": [
          null,
          "Layer: 1<br>Expert: 1<br>Weight: 0.085<br>Top tokens:<br>: 0.256<br>trouble: 0.206<br>ifices: 0.199<br>: 0.172<br>oor: 0.168",
          null,
          null,
          null,
          "Layer: 1<br>Expert: 5<br>Weight: 0.070<br>Top tokens:<br>rsia: 0.227<br>__':: 0.211<br>stia: 0.192<br>substack: 0.188<br>urals: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 14<br>Weight: 0.196<br>Top tokens:<br>: 0.207<br>ailing: 0.205<br>: 0.199<br>: 0.195<br> : 0.194",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 34<br>Weight: 0.244<br>Top tokens:<br>: 0.214<br> : 0.201<br> auto: 0.197<br> : 0.194<br>[^: 0.194",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 43<br>Weight: 0.072<br>Top tokens:<br>ancel: 0.243<br>inafter: 0.219<br>ncies: 0.217<br>: 0.169<br>: 0.153",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 54<br>Weight: 0.102<br>Top tokens:<br>: 0.253<br>eger: 0.194<br>tered: 0.190<br>igiosos: 0.182<br>: 0.182",
          null,
          null,
          null,
          null,
          "Layer: 1<br>Expert: 59<br>Weight: 0.230<br>Top tokens:<br>: 0.220<br>: 0.206<br>: 0.198<br> : 0.191<br>oplan: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 8<br>Weight: 0.107<br>Top tokens:<br>: 0.214<br>: 0.214<br>apsed: 0.209<br>iterr: 0.184<br>: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 18<br>Weight: 0.105<br>Top tokens:<br>essee: 0.235<br> : 0.206<br>eni: 0.206<br>ianes: 0.187<br>oud: 0.165",
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 24<br>Weight: 0.188<br>Top tokens:<br>enas: 0.250<br>: 0.213<br>KY: 0.186<br>: 0.177<br> Charac: 0.174",
          null,
          null,
          null,
          "Layer: 2<br>Expert: 28<br>Weight: 0.218<br>Top tokens:<br>: 0.226<br>ling: 0.218<br>@: 0.194<br>coni: 0.183<br>BUS: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 38<br>Weight: 0.130<br>Top tokens:<br>: 0.230<br>throwing: 0.222<br>: 0.201<br>: 0.179<br>Throw: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 2<br>Expert: 48<br>Weight: 0.136<br>Top tokens:<br>opin: 0.217<br>: 0.212<br>Evoluci: 0.194<br> followed: 0.188<br>: 0.188",
          "Layer: 2<br>Expert: 49<br>Weight: 0.115<br>Top tokens:<br>0: 0.271<br>oan: 0.193<br> p: 0.189<br>gad: 0.176<br> b: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 9<br>Weight: 0.188<br>Top tokens:<br>acant: 0.236<br> sorra: 0.227<br>onstr: 0.184<br>PREC: 0.179<br>uges: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 25<br>Weight: 0.117<br>Top tokens:<br>: 0.247<br> scrut: 0.210<br>itures: 0.188<br>geries: 0.180<br>: 0.175",
          "Layer: 3<br>Expert: 26<br>Weight: 0.091<br>Top tokens:<br>Habitants: 0.304<br>abilitat: 0.202<br> : 0.170<br>perf: 0.162<br>rely: 0.161",
          null,
          null,
          "Layer: 3<br>Expert: 29<br>Weight: 0.088<br>Top tokens:<br>herits: 0.288<br>: 0.187<br>CODEGEN: 0.181<br>balena: 0.176<br>ificador: 0.167",
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 34<br>Weight: 0.098<br>Top tokens:<br>: 0.203<br>strat: 0.200<br> seix: 0.200<br>ingut: 0.199<br> propor: 0.197",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 42<br>Weight: 0.092<br>Top tokens:<br>_{_: 0.249<br>uelen: 0.190<br>xfce: 0.189<br> coneixen: 0.187<br>cke: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 3<br>Expert: 60<br>Weight: 0.326<br>Top tokens:<br>0: 0.240<br>2: 0.210<br>9: 0.200<br>1: 0.176<br>8: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 13<br>Weight: 0.078<br>Top tokens:<br>: 0.223<br>: 0.218<br>pad: 0.201<br>.: 0.179<br>Gen: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 25<br>Weight: 0.139<br>Top tokens:<br>ather: 0.255<br>._\": 0.190<br>COMPONENT: 0.189<br>ume: 0.187<br>ynchronously: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 41<br>Weight: 0.210<br>Top tokens:<br>companion: 0.246<br>: 0.197<br> Candidate: 0.193<br> Engine: 0.189<br>enso: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 48<br>Weight: 0.201<br>Top tokens:<br>istre: 0.229<br>:///: 0.213<br>: 0.194<br>elf: 0.182<br>rief: 0.182",
          null,
          "Layer: 4<br>Expert: 50<br>Weight: 0.193<br>Top tokens:<br>oven: 0.324<br>lus: 0.197<br>:///: 0.180<br> built: 0.152<br> Loric: 0.147",
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 55<br>Weight: 0.099<br>Top tokens:<br>malink: 0.280<br>: 0.204<br>estan: 0.178<br> : 0.169<br>sst: 0.169",
          null,
          null,
          null,
          null,
          "Layer: 4<br>Expert: 60<br>Weight: 0.080<br>Top tokens:<br>estrat: 0.210<br>: 0.210<br>atron: 0.205<br>/__: 0.192<br>acor: 0.184",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 3<br>Weight: 0.181<br>Top tokens:<br>ivia: 0.241<br>: 0.194<br>warz: 0.192<br> City: 0.189<br>iform: 0.184",
          null,
          null,
          "Layer: 5<br>Expert: 6<br>Weight: 0.114<br>Top tokens:<br>: 0.210<br>anyes: 0.207<br> : 0.199<br>cades: 0.199<br>oldt: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 32<br>Weight: 0.193<br>Top tokens:<br> : 0.227<br>: 0.209<br> Senat: 0.202<br>elic: 0.186<br>: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 5<br>Expert: 44<br>Weight: 0.121<br>Top tokens:<br>: 0.216<br>udes: 0.212<br>: 0.205<br>ude: 0.185<br>: 0.182",
          null,
          "Layer: 5<br>Expert: 46<br>Weight: 0.159<br>Top tokens:<br> _: 0.231<br>: 0.204<br>inches: 0.194<br>: 0.186<br> IO: 0.185",
          null,
          null,
          "Layer: 5<br>Expert: 49<br>Weight: 0.117<br>Top tokens:<br>: 0.392<br> dispos: 0.169<br>: 0.165<br> Peabody: 0.139<br>ulo: 0.135",
          null,
          null,
          "Layer: 5<br>Expert: 52<br>Weight: 0.116<br>Top tokens:<br>: 0.219<br>enginy: 0.208<br>oguera: 0.201<br>Equador: 0.190<br>ilitat: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 5<br>Weight: 0.100<br>Top tokens:<br> cercle: 0.211<br>ript: 0.209<br>nora: 0.198<br>blr: 0.193<br>>-->: 0.190",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 21<br>Weight: 0.377<br>Top tokens:<br>otip: 0.530<br>thon: 0.130<br>pher: 0.123<br>scor: 0.119<br>: 0.098",
          null,
          null,
          null,
          "Layer: 6<br>Expert: 25<br>Weight: 0.108<br>Top tokens:<br>arb: 0.221<br>ake: 0.213<br>: 0.211<br> : 0.180<br>icken: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 35<br>Weight: 0.097<br>Top tokens:<br>6: 0.238<br>9: 0.222<br>7: 0.194<br>4: 0.185<br>8: 0.162",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 43<br>Weight: 0.122<br>Top tokens:<br>ARE: 0.288<br> extrems: 0.189<br>wolves: 0.181<br>: 0.176<br>arena: 0.165",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 50<br>Weight: 0.097<br>Top tokens:<br> pocs: 0.233<br>}$': 0.221<br>: 0.189<br>antine: 0.185<br>ssia: 0.172",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 6<br>Expert: 63<br>Weight: 0.098<br>Top tokens:<br>resco: 0.228<br> Cortes: 0.206<br>: 0.192<br>CPP: 0.188<br> diferencia: 0.186",
          null,
          null,
          "Layer: 7<br>Expert: 2<br>Weight: 0.129<br>Top tokens:<br>orat: 0.345<br>ajes: 0.176<br>hyde: 0.161<br>liter: 0.159<br>facet: 0.158",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 10<br>Weight: 0.106<br>Top tokens:<br>istable: 0.257<br>anell: 0.241<br>: 0.194<br>ocada: 0.186<br>ocell: 0.121",
          null,
          null,
          "Layer: 7<br>Expert: 13<br>Weight: 0.192<br>Top tokens:<br>akespeare: 0.211<br>alp: 0.208<br>ateful: 0.196<br>ugal: 0.195<br> turb: 0.189",
          "Layer: 7<br>Expert: 14<br>Weight: 0.153<br>Top tokens:<br>RAW: 0.230<br>$~\\: 0.207<br>GiB: 0.195<br>APER: 0.186<br>obrir: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 26<br>Weight: 0.178<br>Top tokens:<br>: 0.256<br>anet: 0.226<br>: 0.198<br>: 0.167<br>arant: 0.153",
          null,
          "Layer: 7<br>Expert: 28<br>Weight: 0.145<br>Top tokens:<br>omla: 0.232<br>: 0.215<br>oulder: 0.194<br>equals: 0.181<br>uita: 0.178",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 7<br>Expert: 51<br>Weight: 0.098<br>Top tokens:<br> optar: 0.222<br>lady: 0.200<br>offee: 0.200<br>itas: 0.194<br>Issue: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 6<br>Weight: 0.126<br>Top tokens:<br>: 0.321<br>: 0.187<br>ish: 0.176<br>: 0.160<br>Inst: 0.156",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 25<br>Weight: 0.123<br>Top tokens:<br>8: 0.235<br>1: 0.225<br>hana: 0.185<br>6: 0.178<br>4: 0.177",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 41<br>Weight: 0.205<br>Top tokens:<br>ilitat: 0.255<br>: 0.217<br>ALES: 0.191<br>letes: 0.184<br>boxt: 0.153",
          null,
          "Layer: 8<br>Expert: 43<br>Weight: 0.144<br>Top tokens:<br>: 0.208<br>: 0.206<br>: 0.200<br>: 0.194<br>: 0.191",
          null,
          null,
          "Layer: 8<br>Expert: 46<br>Weight: 0.125<br>Top tokens:<br>9: 0.223<br>=\"../_: 0.210<br>1: 0.204<br>: 0.188<br>8: 0.175",
          null,
          null,
          "Layer: 8<br>Expert: 49<br>Weight: 0.134<br>Top tokens:<br>: 0.234<br>CDF: 0.224<br>ilst: 0.192<br>romy: 0.180<br> shifter: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 8<br>Expert: 63<br>Weight: 0.142<br>Top tokens:<br>: 0.350<br>nicamente: 0.188<br>bic: 0.162<br>uta: 0.157<br>: 0.142",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 8<br>Weight: 0.126<br>Top tokens:<br>: 0.263<br>ATERIAL: 0.213<br>: 0.183<br>gence: 0.177<br> apreciar: 0.163",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 15<br>Weight: 0.207<br>Top tokens:<br> der: 0.232<br> Fort: 0.212<br>itty: 0.206<br> fits: 0.179<br> rather: 0.171",
          null,
          null,
          null,
          "Layer: 9<br>Expert: 19<br>Weight: 0.115<br>Top tokens:<br>: 0.265<br>LASS: 0.193<br>: 0.192<br>pee: 0.178<br>: 0.172",
          "Layer: 9<br>Expert: 20<br>Weight: 0.120<br>Top tokens:<br>: 0.268<br>: 0.215<br>ISTER: 0.193<br>: 0.165<br>: 0.159",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 42<br>Weight: 0.124<br>Top tokens:<br>moor: 0.248<br> Rouge: 0.218<br>elessly: 0.190<br>: 0.177<br> : 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 50<br>Weight: 0.119<br>Top tokens:<br>v: 0.375<br>olla: 0.169<br>: 0.162<br>odec: 0.150<br>end: 0.144",
          null,
          null,
          null,
          null,
          "Layer: 9<br>Expert: 55<br>Weight: 0.188<br>Top tokens:<br>: 0.252<br>: 0.218<br>: 0.195<br>sonian: 0.171<br>bology: 0.163",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 5<br>Weight: 0.136<br>Top tokens:<br>East: 0.370<br> East: 0.166<br>: 0.163<br>eln: 0.153<br>tect: 0.147",
          null,
          "Layer: 10<br>Expert: 7<br>Weight: 0.137<br>Top tokens:<br>miral: 0.282<br>part: 0.201<br>: 0.182<br>matical: 0.173<br>rode: 0.162",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 18<br>Weight: 0.157<br>Top tokens:<br>: 0.236<br>x: 0.210<br>terminal: 0.199<br>iaci: 0.180<br>icus: 0.175",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 36<br>Weight: 0.111<br>Top tokens:<br>: 0.251<br>itat: 0.208<br>forter: 0.182<br>EVER: 0.182<br>: 0.178",
          null,
          null,
          null,
          null,
          null,
          "Layer: 10<br>Expert: 42<br>Weight: 0.140<br>Top tokens:<br>3: 0.248<br>0: 0.229<br>1: 0.227<br>6: 0.148<br>2: 0.148",
          null,
          null,
          "Layer: 10<br>Expert: 45<br>Weight: 0.143<br>Top tokens:<br>fog: 0.210<br>ock: 0.209<br>ig: 0.200<br>: 0.199<br>pires: 0.182",
          null,
          null,
          "Layer: 10<br>Expert: 48<br>Weight: 0.175<br>Top tokens:<br>inette: 0.333<br>vature: 0.195<br>: 0.180<br>rame: 0.162<br>ANCE: 0.130",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 4<br>Weight: 0.118<br>Top tokens:<br>8: 0.310<br>6: 0.234<br>3: 0.205<br>: 0.129<br>0: 0.122",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 13<br>Weight: 0.189<br>Top tokens:<br>Compan: 0.250<br> : 0.244<br>util: 0.211<br>: 0.162<br>: 0.133",
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 19<br>Weight: 0.139<br>Top tokens:<br>isure: 0.319<br> Served: 0.198<br>akr: 0.176<br> : 0.155<br>ALOG: 0.152",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 28<br>Weight: 0.146<br>Top tokens:<br>reys: 0.360<br>: 0.207<br>: 0.164<br>: 0.162<br>elines: 0.107",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 40<br>Weight: 0.164<br>Top tokens:<br>: 0.277<br>0: 0.225<br>odder: 0.175<br>aband: 0.164<br>9: 0.159",
          null,
          "Layer: 11<br>Expert: 42<br>Weight: 0.122<br>Top tokens:<br>ROID: 0.402<br>7: 0.172<br>8: 0.165<br> Tolosa: 0.136<br> Madge: 0.125",
          null,
          null,
          null,
          null,
          "Layer: 11<br>Expert: 47<br>Weight: 0.121<br>Top tokens:<br>ist: 0.340<br>m: 0.205<br>b: 0.174<br>burg: 0.142<br>: 0.140",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 0<br>Weight: 0.135<br>Top tokens:<br> part: 0.240<br>: 0.202<br>tery: 0.197<br>inx: 0.184<br>: 0.177",
          null,
          null,
          "Layer: 12<br>Expert: 3<br>Weight: 0.108<br>Top tokens:<br>oide: 0.379<br>uated: 0.262<br>ified: 0.131<br>: 0.128<br>ensem: 0.100",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 13<br>Weight: 0.154<br>Top tokens:<br>broad: 0.217<br>Broad: 0.215<br>: 0.199<br>hof: 0.187<br>RECT: 0.182",
          null,
          null,
          null,
          "Layer: 12<br>Expert: 17<br>Weight: 0.212<br>Top tokens:<br>veh: 0.272<br> col: 0.236<br>: 0.170<br>AT: 0.162<br>escl: 0.160",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 30<br>Weight: 0.145<br>Top tokens:<br>rena: 0.216<br>zca: 0.205<br>: 0.198<br>ths: 0.195<br>: 0.186",
          "Layer: 12<br>Expert: 31<br>Weight: 0.104<br>Top tokens:<br>arque: 0.466<br>rength: 0.147<br>: 0.137<br>iddy: 0.125<br> : 0.125",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 12<br>Expert: 39<br>Weight: 0.142<br>Top tokens:<br>ccane: 0.235<br>CFT: 0.229<br>GR: 0.197<br>itons: 0.187<br>gia: 0.152",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 7<br>Weight: 0.129<br>Top tokens:<br>olas: 0.427<br>stream: 0.154<br>builder: 0.149<br>: 0.139<br>wisdom: 0.131",
          null,
          null,
          "Layer: 13<br>Expert: 10<br>Weight: 0.176<br>Top tokens:<br>MethodName: 0.218<br>Etapa: 0.214<br>scribe: 0.206<br>$/.: 0.190<br>estany: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 17<br>Weight: 0.131<br>Top tokens:<br>;=: 0.234<br>ournals: 0.200<br>: 0.195<br>iture: 0.193<br>ermost: 0.178",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 41<br>Weight: 0.175<br>Top tokens:<br>=\"__: 0.492<br>: 0.216<br>: 0.119<br>: 0.088<br>: 0.085",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 50<br>Weight: 0.132<br>Top tokens:<br>: 0.508<br>: 0.161<br>: 0.129<br>: 0.115<br>odot: 0.086",
          null,
          "Layer: 13<br>Expert: 52<br>Weight: 0.127<br>Top tokens:<br>PROTOBUF: 0.285<br>rary: 0.229<br>rate: 0.192<br>rates: 0.151<br>: 0.143",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 13<br>Expert: 59<br>Weight: 0.130<br>Top tokens:<br>hetical: 0.217<br>: 0.214<br>ruce: 0.200<br>picker: 0.189<br>leted: 0.179",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 14<br>Weight: 0.128<br>Top tokens:<br>0: 0.344<br>1: 0.222<br>2: 0.162<br>3: 0.143<br>5: 0.129",
          null,
          null,
          "Layer: 14<br>Expert: 17<br>Weight: 0.164<br>Top tokens:<br> calci: 0.277<br>iod: 0.246<br>: 0.172<br>: 0.159<br> constitution: 0.146",
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 22<br>Weight: 0.136<br>Top tokens:<br>i: 0.238<br>: 0.204<br> Edicions: 0.196<br>: 0.181<br>: 0.180",
          null,
          null,
          null,
          "Layer: 14<br>Expert: 26<br>Weight: 0.147<br>Top tokens:<br>: 0.291<br> tr: 0.203<br> l: 0.171<br>glob: 0.168<br>end: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 38<br>Weight: 0.123<br>Top tokens:<br> Pow: 0.309<br>: 0.299<br>ahler: 0.158<br>Pow: 0.117<br>eppel: 0.117",
          null,
          "Layer: 14<br>Expert: 40<br>Weight: 0.141<br>Top tokens:<br>acant: 0.323<br>: 0.206<br>ITED: 0.180<br>inberg: 0.157<br>uxley: 0.133",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 14<br>Expert: 63<br>Weight: 0.160<br>Top tokens:<br>IZED: 0.303<br>anine: 0.191<br> Rocks: 0.179<br>edn: 0.166<br>ANGLE: 0.161",
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 5<br>Weight: 0.154<br>Top tokens:<br>refn: 0.307<br>:///: 0.189<br>illac: 0.172<br>fortunes: 0.170<br>GNU: 0.161",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 15<br>Weight: 0.183<br>Top tokens:<br>: 0.278<br>atem: 0.215<br>formed: 0.177<br>: 0.168<br>erves: 0.162",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 33<br>Weight: 0.115<br>Top tokens:<br>issin: 0.250<br>: 0.245<br>: 0.218<br>: 0.146<br>orthand: 0.141",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 40<br>Weight: 0.129<br>Top tokens:<br>hea: 0.278<br>ing: 0.194<br>: 0.189<br>sal: 0.171<br>: 0.169",
          null,
          null,
          "Layer: 15<br>Expert: 43<br>Weight: 0.156<br>Top tokens:<br>: 0.271<br>: 0.250<br>tofore: 0.180<br>).__: 0.153<br>lessness: 0.146",
          null,
          "Layer: 15<br>Expert: 45<br>Weight: 0.122<br>Top tokens:<br> fuster: 0.242<br>jades: 0.223<br>rivacy: 0.180<br>restant: 0.180<br>recci: 0.176",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 15<br>Expert: 54<br>Weight: 0.141<br>Top tokens:<br> : 0.276<br>laz: 0.198<br>ament: 0.186<br>ogeneity: 0.173<br>ceil: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 0<br>Weight: 0.153<br>Top tokens:<br>: 0.212<br>imales: 0.209<br>ild: 0.205<br>: 0.203<br>opi: 0.172",
          null,
          null,
          "Layer: 16<br>Expert: 3<br>Weight: 0.143<br>Top tokens:<br>urats: 0.285<br>plets: 0.204<br>: 0.198<br>\"><![: 0.168<br>rbia: 0.144",
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 9<br>Weight: 0.145<br>Top tokens:<br>: 0.277<br> : 0.253<br>: 0.177<br>: 0.148<br>: 0.143",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 29<br>Weight: 0.125<br>Top tokens:<br>agena: 0.311<br>nids: 0.226<br>>.<: 0.215<br>avens: 0.124<br>: 0.124",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 40<br>Weight: 0.164<br>Top tokens:<br> who: 0.518<br> whom: 0.156<br>whom: 0.119<br>who: 0.112<br> things: 0.096",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 16<br>Expert: 51<br>Weight: 0.132<br>Top tokens:<br> mill: 0.269<br> versa: 0.190<br>: 0.188<br>rpre: 0.179<br>: 0.174",
          null,
          null,
          null,
          "Layer: 16<br>Expert: 55<br>Weight: 0.138<br>Top tokens:<br>enery: 0.247<br>enance: 0.199<br>imize: 0.193<br>visi: 0.180<br> Tremp: 0.180",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 10<br>Weight: 0.103<br>Top tokens:<br> per: 0.302<br> each: 0.212<br>per: 0.178<br>atu: 0.172<br>each: 0.135",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 21<br>Weight: 0.114<br>Top tokens:<br> : 0.395<br> or: 0.356<br>urname: 0.094<br>odox: 0.082<br> nor: 0.073",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 40<br>Weight: 0.105<br>Top tokens:<br> fre: 0.244<br>: 0.219<br>: 0.211<br>enal: 0.164<br>: 0.163",
          null,
          null,
          "Layer: 17<br>Expert: 43<br>Weight: 0.116<br>Top tokens:<br>2: 0.284<br>3: 0.217<br>9: 0.179<br>1: 0.166<br>6: 0.155",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 52<br>Weight: 0.183<br>Top tokens:<br>again: 0.343<br>Again: 0.232<br>igneur: 0.163<br> Again: 0.132<br> again: 0.129",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 17<br>Expert: 62<br>Weight: 0.130<br>Top tokens:<br>: 0.262<br>balls: 0.221<br> Po: 0.197<br>part: 0.161<br> Balls: 0.159",
          "Layer: 17<br>Expert: 63<br>Weight: 0.250<br>Top tokens:<br>zzle: 0.279<br>itti: 0.223<br>angelog: 0.173<br>estock: 0.170<br>itors: 0.155",
          null,
          "Layer: 18<br>Expert: 1<br>Weight: 0.108<br>Top tokens:<br>: 0.218<br>WAY: 0.214<br>WAYS: 0.213<br>doxygen: 0.182<br>agut: 0.173",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 9<br>Weight: 0.113<br>Top tokens:<br>odge: 0.261<br>: 0.213<br>: 0.181<br>ein: 0.176<br>kip: 0.169",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 18<br>Weight: 0.147<br>Top tokens:<br>ks: 0.224<br>pers: 0.204<br>im: 0.197<br>ithe: 0.188<br>ora: 0.186",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 25<br>Weight: 0.254<br>Top tokens:<br>: 0.367<br>wards: 0.192<br>blr: 0.174<br>ection: 0.142<br>roma: 0.126",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 47<br>Weight: 0.124<br>Top tokens:<br>: 0.407<br>: 0.197<br>zes: 0.164<br>ual: 0.120<br>ented: 0.112",
          null,
          "Layer: 18<br>Expert: 49<br>Weight: 0.143<br>Top tokens:<br> : 0.487<br>igna: 0.232<br> Foix: 0.096<br> drogues: 0.096<br> : 0.089",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 18<br>Expert: 59<br>Weight: 0.111<br>Top tokens:<br>orden: 0.240<br>: 0.213<br>: 0.193<br>enched: 0.190<br>encar: 0.164",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 4<br>Weight: 0.121<br>Top tokens:<br>,: 0.428<br> or: 0.234<br>business: 0.154<br> our: 0.093<br> business: 0.092",
          null,
          "Layer: 19<br>Expert: 6<br>Weight: 0.272<br>Top tokens:<br>: 0.300<br>odium: 0.189<br>: 0.184<br>: 0.163<br> head: 0.163",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 14<br>Weight: 0.137<br>Top tokens:<br> in: 0.246<br> between: 0.196<br>: 0.195<br>: 0.192<br>ota: 0.170",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 23<br>Weight: 0.120<br>Top tokens:<br>only: 0.527<br>Only: 0.194<br>ONLY: 0.099<br>by: 0.095<br> only: 0.084",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 54<br>Weight: 0.098<br>Top tokens:<br>both: 0.409<br>: 0.221<br>: 0.134<br>: 0.118<br> Both: 0.118",
          null,
          "Layer: 19<br>Expert: 56<br>Weight: 0.144<br>Top tokens:<br>take: 0.337<br> take: 0.197<br> took: 0.188<br>taking: 0.146<br> taking: 0.131",
          null,
          null,
          null,
          null,
          "Layer: 19<br>Expert: 61<br>Weight: 0.108<br>Top tokens:<br> thing: 0.446<br>idean: 0.193<br>)$-: 0.173<br>avant: 0.099<br>: 0.090",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 5<br>Weight: 0.161<br>Top tokens:<br>-: 0.254<br>: 0.228<br> : 0.182<br>: 0.170<br> _: 0.167",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 20<br>Weight: 0.183<br>Top tokens:<br> Asiatic: 0.459<br>iat: 0.309<br>: 0.111<br>: 0.085<br>: 0.037",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 20<br>Expert: 50<br>Weight: 0.140<br>Top tokens:<br>: 0.340<br>pep: 0.208<br>: 0.162<br>: 0.150<br>: 0.140",
          null,
          null,
          "Layer: 20<br>Expert: 53<br>Weight: 0.165<br>Top tokens:<br>: 0.213<br> Climent: 0.211<br>: 0.211<br>: 0.194<br>ingui: 0.171",
          null,
          null,
          null,
          "Layer: 20<br>Expert: 57<br>Weight: 0.150<br>Top tokens:<br>nds: 0.235<br>: 0.211<br> r: 0.195<br>: 0.188<br>: 0.171",
          null,
          null,
          "Layer: 20<br>Expert: 60<br>Weight: 0.087<br>Top tokens:<br>cs: 0.236<br>m: 0.227<br>: 0.201<br>po: 0.181<br>0: 0.155",
          "Layer: 20<br>Expert: 61<br>Weight: 0.114<br>Top tokens:<br>poch: 0.245<br>rici: 0.224<br>Bound: 0.194<br>blocked: 0.169<br>: 0.168",
          null,
          null,
          "Layer: 21<br>Expert: 0<br>Weight: 0.139<br>Top tokens:<br>ifi: 0.354<br>sofs: 0.225<br>ium: 0.220<br>zing: 0.104<br>amping: 0.098",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 8<br>Weight: 0.165<br>Top tokens:<br>: 0.275<br> cell: 0.238<br> Cell: 0.188<br>})$-: 0.154<br> loopback: 0.145",
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 14<br>Weight: 0.116<br>Top tokens:<br>adona: 0.392<br>rable: 0.176<br>ctree: 0.146<br>}$),: 0.144<br>arcy: 0.142",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 33<br>Weight: 0.246<br>Top tokens:<br>obres: 0.304<br>: 0.209<br>alesa: 0.177<br> parabolic: 0.160<br>ossible: 0.149",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 40<br>Weight: 0.100<br>Top tokens:<br>: 0.383<br>icional: 0.187<br>rien: 0.158<br> jet: 0.148<br> l: 0.124",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 21<br>Expert: 59<br>Weight: 0.111<br>Top tokens:<br>5: 0.582<br>1: 0.188<br>2: 0.122<br>8: 0.077<br>6: 0.032",
          null,
          null,
          "Layer: 21<br>Expert: 62<br>Weight: 0.123<br>Top tokens:<br>rowColor: 0.318<br>cnics: 0.193<br>: 0.173<br>miral: 0.159<br>ndies: 0.157",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 5<br>Weight: 0.119<br>Top tokens:<br>planar: 0.729<br> -: 0.084<br>,.: 0.080<br>: 0.053<br>occidental: 0.053",
          null,
          null,
          "Layer: 22<br>Expert: 8<br>Weight: 0.157<br>Top tokens:<br>: 0.302<br> : 0.212<br>: 0.204<br>2: 0.159<br>: 0.124",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 26<br>Weight: 0.234<br>Top tokens:<br>4: 0.244<br>2: 0.237<br>7: 0.177<br>1: 0.174<br>9: 0.169",
          null,
          "Layer: 22<br>Expert: 28<br>Weight: 0.151<br>Top tokens:<br> : 0.216<br>acte: 0.213<br>: 0.198<br>mirrors: 0.191<br>ue: 0.182",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 46<br>Weight: 0.110<br>Top tokens:<br>: 0.762<br>: 0.082<br>: 0.071<br>itch: 0.058<br>: 0.027",
          "Layer: 22<br>Expert: 47<br>Weight: 0.113<br>Top tokens:<br>ittest: 0.401<br>: 0.177<br>edas: 0.151<br>: 0.150<br>ugosl: 0.120",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 22<br>Expert: 60<br>Weight: 0.116<br>Top tokens:<br> herself: 0.979<br> her: 0.020<br>herself: 0.000<br> she: 0.000<br> hers: 0.000",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 5<br>Weight: 0.102<br>Top tokens:<br> trade: 0.421<br> business: 0.198<br> trading: 0.134<br> Trade: 0.126<br>business: 0.120",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 14<br>Weight: 0.141<br>Top tokens:<br>eered: 0.339<br>ield: 0.221<br> yourselves: 0.186<br>plication: 0.127<br>ex: 0.127",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 31<br>Weight: 0.118<br>Top tokens:<br>atal: 0.282<br>: 0.200<br> PM: 0.186<br>: 0.181<br>eration: 0.150",
          null,
          "Layer: 23<br>Expert: 33<br>Weight: 0.182<br>Top tokens:<br>0: 0.304<br>outcome: 0.196<br>alus: 0.180<br> outcome: 0.163<br> r: 0.157",
          null,
          null,
          null,
          "Layer: 23<br>Expert: 37<br>Weight: 0.105<br>Top tokens:<br> : 0.634<br> Martorell: 0.129<br>issen: 0.091<br>onics: 0.076<br>osity: 0.069",
          null,
          null,
          null,
          "Layer: 23<br>Expert: 41<br>Weight: 0.132<br>Top tokens:<br>C: 0.503<br>M: 0.276<br>Sh: 0.111<br>D: 0.062<br>an: 0.049",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 23<br>Expert: 57<br>Weight: 0.220<br>Top tokens:<br>ikipedia: 0.210<br>: 0.208<br>: 0.205<br>germ: 0.193<br>cet: 0.184",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 11<br>Weight: 0.201<br>Top tokens:<br>ly: 1.000<br>ing: 0.000<br>is: 0.000<br>led: 0.000<br>ed: 0.000",
          null,
          null,
          null,
          "Layer: 24<br>Expert: 15<br>Weight: 0.118<br>Top tokens:<br>ILED: 0.531<br>layer: 0.127<br>: 0.117<br>: 0.114<br>ILY: 0.111",
          null,
          null,
          null,
          "Layer: 24<br>Expert: 19<br>Weight: 0.118<br>Top tokens:<br>edly: 0.457<br>: 0.188<br>ermost: 0.154<br>iation: 0.101<br>: 0.100",
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 24<br>Weight: 0.130<br>Top tokens:<br>[...]: 0.278<br> press: 0.195<br>lix: 0.188<br>harmonic: 0.172<br>: 0.166",
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 29<br>Weight: 0.122<br>Top tokens:<br>icolon: 0.372<br>ple: 0.234<br>: 0.153<br>: 0.138<br>: 0.103",
          null,
          null,
          "Layer: 24<br>Expert: 32<br>Weight: 0.129<br>Top tokens:<br>\": 0.476<br>\"\\: 0.305<br>: 0.091<br>: 0.074<br>: 0.054",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 24<br>Expert: 52<br>Weight: 0.182<br>Top tokens:<br>eck: 0.226<br>domen: 0.222<br>oda: 0.198<br> mano: 0.179<br>ZING: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 9<br>Weight: 0.103<br>Top tokens:<br>atur: 0.258<br>: 0.221<br>ilde: 0.181<br>atu: 0.175<br>hore: 0.165",
          null,
          "Layer: 25<br>Expert: 11<br>Weight: 0.129<br>Top tokens:<br>: 0.239<br>ohl: 0.233<br>\"><!--: 0.184<br>atol: 0.174<br>aty: 0.171",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 19<br>Weight: 0.133<br>Top tokens:<br>: 0.514<br>lehem: 0.160<br>igraphy: 0.126<br>mbol: 0.105<br>bilt: 0.096",
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 25<br>Weight: 0.111<br>Top tokens:<br>: 0.471<br>ives: 0.211<br>ivell: 0.120<br>/~: 0.100<br>words: 0.098",
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 30<br>Weight: 0.099<br>Top tokens:<br>: 0.475<br>: 0.207<br>: 0.126<br>: 0.097<br> : 0.095",
          null,
          "Layer: 25<br>Expert: 32<br>Weight: 0.134<br>Top tokens:<br> : 0.367<br>Formatting: 0.225<br> inactius: 0.141<br>: 0.141<br>: 0.126",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 25<br>Expert: 53<br>Weight: 0.290<br>Top tokens:<br> .../: 0.444<br>: 0.249<br>: 0.117<br> met: 0.107<br>: 0.083",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 29<br>Weight: 0.275<br>Top tokens:<br>artment: 0.286<br>odatabase: 0.194<br>: 0.190<br>ilets: 0.167<br>itudes: 0.163",
          null,
          null,
          null,
          "Layer: 26<br>Expert: 33<br>Weight: 0.351<br>Top tokens:<br>: 0.264<br>: 0.242<br>: 0.172<br>: 0.163<br>equence: 0.158",
          null,
          null,
          "Layer: 26<br>Expert: 36<br>Weight: 0.069<br>Top tokens:<br>: 0.226<br>: 0.204<br>: 0.202<br>: 0.194<br>: 0.174",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 26<br>Expert: 49<br>Weight: 0.085<br>Top tokens:<br>: 0.224<br>udar: 0.209<br>rores: 0.205<br> Diod: 0.193<br>: 0.169",
          null,
          "Layer: 26<br>Expert: 51<br>Weight: 0.087<br>Top tokens:<br>: 0.707<br>: 0.187<br>: 0.075<br>: 0.017<br>: 0.014",
          null,
          "Layer: 26<br>Expert: 53<br>Weight: 0.061<br>Top tokens:<br>...: 0.419<br>......: 0.312<br>'...: 0.240<br>,...: 0.023<br>...?: 0.005",
          null,
          "Layer: 26<br>Expert: 55<br>Weight: 0.071<br>Top tokens:<br> : 0.798<br> h: 0.112<br> (: 0.035<br> r: 0.031<br> m: 0.024",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 1<br>Weight: 0.108<br>Top tokens:<br>: 0.218<br> cryptocur: 0.216<br>: 0.196<br>: 0.185<br>ottest: 0.185",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 20<br>Weight: 0.134<br>Top tokens:<br> theater: 0.219<br>Player: 0.211<br> Player: 0.208<br> Theater: 0.190<br> Entertainment: 0.171",
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 26<br>Weight: 0.128<br>Top tokens:<br>7: 0.247<br>3: 0.211<br>9: 0.186<br>4: 0.183<br>1: 0.173",
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 33<br>Weight: 0.137<br>Top tokens:<br> m: 0.518<br>\tm: 0.153<br>m: 0.152<br> : 0.091<br> os: 0.086",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 53<br>Weight: 0.180<br>Top tokens:<br>a: 0.281<br>land: 0.204<br>: 0.203<br>: 0.160<br>: 0.152",
          null,
          "Layer: 27<br>Expert: 55<br>Weight: 0.104<br>Top tokens:<br> ,\\\\: 0.251<br> &=&\\: 0.218<br>\\!+\\!: 0.184<br>&=&\\: 0.181<br>DOCKED: 0.166",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "Layer: 27<br>Expert: 63<br>Weight: 0.209<br>Top tokens:<br> var: 0.351<br>vect: 0.183<br> vector: 0.168<br> const: 0.155<br>: 0.143"
         ],
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63
         ],
         "y": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27
         ]
        }
       ],
       "layout": {
        "height": 800,
        "paper_bgcolor": "black",
        "plot_bgcolor": "black",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Expert Activations for Token \" fox\" at Position 4"
        },
        "width": 1200,
        "xaxis": {
         "gridcolor": "rgba(128, 128, 128, 0.2)",
         "gridwidth": 1,
         "range": [
          -1,
          64
         ],
         "showgrid": true,
         "title": {
          "text": "Expert ID"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "gridcolor": "rgba(128, 128, 128, 0.2)",
         "gridwidth": 1,
         "showgrid": true,
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_layer_analysis(tokenizer, results, token_position=4, input_text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 59,\n",
       "      'weight': 0.5422781109809875,\n",
       "      'top_tokens': [('', 0.26229143142700195),\n",
       "       ('', 0.1976265162229538),\n",
       "       ('', 0.19655679166316986),\n",
       "       ('', 0.17411065101623535),\n",
       "       ('', 0.1694146692752838)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.34705036878585815,\n",
       "      'top_tokens': [(' [_', 0.27444252371788025),\n",
       "       (' constitucional', 0.20918963849544525),\n",
       "       ('[_', 0.1754363775253296),\n",
       "       (' ', 0.17200511693954468),\n",
       "       ('', 0.16892629861831665)]},\n",
       "     {'expert_id': 23,\n",
       "      'weight': 0.07234028726816177,\n",
       "      'top_tokens': [('owered', 0.23469220101833344),\n",
       "       ('lim', 0.20719026029109955),\n",
       "       ('lot', 0.1996721774339676),\n",
       "       ('', 0.1882195621728897),\n",
       "       ('ilitat', 0.17022579908370972)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.012752970680594444,\n",
       "      'top_tokens': [('', 0.21719421446323395),\n",
       "       ('agall', 0.208298921585083),\n",
       "       (\"$''\", 0.1963340938091278),\n",
       "       ('', 0.19402463734149933),\n",
       "       ('', 0.1841481626033783)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.010810106061398983,\n",
       "      'top_tokens': [('', 0.28242960572242737),\n",
       "       ('opters', 0.2290925830602646),\n",
       "       ('Bu', 0.19766855239868164),\n",
       "       ('', 0.14630207419395447),\n",
       "       (' Bu', 0.14450713992118835)]},\n",
       "     {'expert_id': 2,\n",
       "      'weight': 0.008401017636060715,\n",
       "      'top_tokens': [('y', 0.2235429435968399),\n",
       "       ('vig', 0.21381869912147522),\n",
       "       (' ', 0.1942390650510788),\n",
       "       (' darrer', 0.1859326809644699),\n",
       "       ('', 0.18246665596961975)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.006367169786244631,\n",
       "      'top_tokens': [('inada', 0.23952563107013702),\n",
       "       ('snia', 0.21524962782859802),\n",
       "       ('herself', 0.18646679818630219),\n",
       "       ('aturday', 0.18497459590435028),\n",
       "       ('resar', 0.17378337681293488)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 59,\n",
       "      'weight': 0.648349940776825,\n",
       "      'top_tokens': [('', 0.27430105209350586),\n",
       "       ('enses', 0.18568933010101318),\n",
       "       ('ens', 0.18435636162757874),\n",
       "       ('', 0.1799972504377365),\n",
       "       ('', 0.17565594613552094)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.26809364557266235,\n",
       "      'top_tokens': [('', 0.22718271613121033),\n",
       "       ('', 0.2014033943414688),\n",
       "       (' constitucional', 0.20129120349884033),\n",
       "       (' [_', 0.19800399243831635),\n",
       "       (' ', 0.17211870849132538)]},\n",
       "     {'expert_id': 23,\n",
       "      'weight': 0.054928939789533615,\n",
       "      'top_tokens': [('lot', 0.21935667097568512),\n",
       "       ('poles', 0.21002988517284393),\n",
       "       ('clou', 0.19561085104942322),\n",
       "       ('bserv', 0.19490985572338104),\n",
       "       ('', 0.1800927072763443)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.00892392173409462,\n",
       "      'top_tokens': [('nqu', 0.21636120975017548),\n",
       "       ('', 0.21238046884536743),\n",
       "       (' Status', 0.19390840828418732),\n",
       "       (' Hi', 0.19240738451480865),\n",
       "       ('onite', 0.18494248390197754)]},\n",
       "     {'expert_id': 2,\n",
       "      'weight': 0.00717683881521225,\n",
       "      'top_tokens': [('advert', 0.24053077399730682),\n",
       "       ('', 0.21282726526260376),\n",
       "       ('', 0.1888037770986557),\n",
       "       ('fir', 0.1825062483549118),\n",
       "       ('vig', 0.1753319352865219)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.006941183935850859,\n",
       "      'top_tokens': [('', 0.2392541915178299),\n",
       "       (' o', 0.2269427478313446),\n",
       "       (' bu', 0.19562284648418427),\n",
       "       ('opters', 0.17123089730739594),\n",
       "       (' PM', 0.1669493466615677)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.005585566163063049,\n",
       "      'top_tokens': [('Park', 0.2120777815580368),\n",
       "       ('', 0.21122492849826813),\n",
       "       ('hola', 0.2044585794210434),\n",
       "       (' Park', 0.1900998055934906),\n",
       "       ('', 0.18213894963264465)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 37,\n",
       "      'weight': 0.2106364369392395,\n",
       "      'top_tokens': [('', 0.21593423187732697),\n",
       "       ('Me', 0.20405377447605133),\n",
       "       ('', 0.20106026530265808),\n",
       "       ('fal', 0.19317184388637543),\n",
       "       (' Me', 0.18577982485294342)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.18099966645240784,\n",
       "      'top_tokens': [('matically', 0.27018117904663086),\n",
       "       ('tofore', 0.21545714139938354),\n",
       "       ('bilt', 0.17655232548713684),\n",
       "       ('eligible', 0.17218182981014252),\n",
       "       ('apad', 0.16562747955322266)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.14927397668361664,\n",
       "      'top_tokens': [('enga', 0.2179756909608841),\n",
       "       ('endor', 0.20440255105495453),\n",
       "       ('', 0.1956755518913269),\n",
       "       ('sy', 0.19492048025131226),\n",
       "       (' prest', 0.18702568113803864)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.12988506257534027,\n",
       "      'top_tokens': [('orum', 0.21381394565105438),\n",
       "       ('imo', 0.20579952001571655),\n",
       "       ('', 0.1957436203956604),\n",
       "       (' ', 0.19479839503765106),\n",
       "       ('grown', 0.18984442949295044)]},\n",
       "     {'expert_id': 34,\n",
       "      'weight': 0.12482861429452896,\n",
       "      'top_tokens': [('', 0.21616585552692413),\n",
       "       ('NNs', 0.2106262594461441),\n",
       "       ('exion', 0.20024798810482025),\n",
       "       ('thems', 0.19655320048332214),\n",
       "       ('', 0.17640680074691772)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.10971280187368393,\n",
       "      'top_tokens': [('ramfs', 0.23967401683330536),\n",
       "       (' ', 0.1973721832036972),\n",
       "       (' pleg', 0.19487594068050385),\n",
       "       ('tsd', 0.18469452857971191),\n",
       "       ('CALLBACK', 0.1833832710981369)]},\n",
       "     {'expert_id': 23,\n",
       "      'weight': 0.09466341882944107,\n",
       "      'top_tokens': [(' R', 0.2243160903453827),\n",
       "       (' -', 0.20269952714443207),\n",
       "       (' P', 0.1970166563987732),\n",
       "       (' W', 0.19267484545707703),\n",
       "       (' B', 0.18329288065433502)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 14,\n",
       "      'weight': 0.23837876319885254,\n",
       "      'top_tokens': [('imum', 0.2665138244628906),\n",
       "       ('ules', 0.19132594764232635),\n",
       "       ('', 0.19081410765647888),\n",
       "       ('nides', 0.1844564527273178),\n",
       "       ('', 0.1668897122144699)]},\n",
       "     {'expert_id': 34,\n",
       "      'weight': 0.19359219074249268,\n",
       "      'top_tokens': [('', 0.23210670053958893),\n",
       "       ('', 0.2138218730688095),\n",
       "       (' item', 0.19692356884479523),\n",
       "       ('<', 0.1807197630405426),\n",
       "       ('', 0.17642813920974731)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.1775868535041809,\n",
       "      'top_tokens': [('OTH', 0.2372646927833557),\n",
       "       (' ', 0.19416576623916626),\n",
       "       ('arum', 0.19256284832954407),\n",
       "       ('', 0.19245724380016327),\n",
       "       ('lo', 0.18354950845241547)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.1288904994726181,\n",
       "      'top_tokens': [('**', 0.22271893918514252),\n",
       "       ('ive', 0.21905553340911865),\n",
       "       ('9', 0.20557542145252228),\n",
       "       ('ne', 0.18440060317516327),\n",
       "       ('ifices', 0.16824960708618164)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.08985757827758789,\n",
       "      'top_tokens': [('', 0.22307127714157104),\n",
       "       (' Segon', 0.21415841579437256),\n",
       "       (' Ngram', 0.19924838840961456),\n",
       "       ('sies', 0.18267889320850372),\n",
       "       ('umen', 0.1808430254459381)]},\n",
       "     {'expert_id': 23,\n",
       "      'weight': 0.08764449506998062,\n",
       "      'top_tokens': [('', 0.21472540497779846),\n",
       "       ('', 0.2100004255771637),\n",
       "       ('onomic', 0.20472556352615356),\n",
       "       ('', 0.19110862910747528),\n",
       "       ('pant', 0.1794399470090866)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.08404956012964249,\n",
       "      'top_tokens': [('', 0.25121477246284485),\n",
       "       ('cies', 0.21940621733665466),\n",
       "       ('rsia', 0.20969721674919128),\n",
       "       ('haps', 0.16227756440639496),\n",
       "       ('', 0.15740419924259186)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 34,\n",
       "      'weight': 0.24429796636104584,\n",
       "      'top_tokens': [('', 0.21391865611076355),\n",
       "       (' ', 0.20109923183918),\n",
       "       (' auto', 0.19708019495010376),\n",
       "       (' ', 0.19427408277988434),\n",
       "       ('[^', 0.19362777471542358)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.22991140186786652,\n",
       "      'top_tokens': [('', 0.21976007521152496),\n",
       "       ('\\x97', 0.2063876837491989),\n",
       "       ('', 0.19831088185310364),\n",
       "       (' ', 0.19081483781337738),\n",
       "       ('oplan', 0.18472646176815033)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.19625729322433472,\n",
       "      'top_tokens': [('', 0.20670829713344574),\n",
       "       ('ailing', 0.20518091320991516),\n",
       "       ('', 0.1989390105009079),\n",
       "       ('', 0.19546835124492645),\n",
       "       (' ', 0.19370344281196594)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.10177560895681381,\n",
       "      'top_tokens': [('', 0.25250789523124695),\n",
       "       ('eger', 0.1937604695558548),\n",
       "       ('tered', 0.19040855765342712),\n",
       "       ('igiosos', 0.18171265721321106),\n",
       "       ('', 0.1816103607416153)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.08546809107065201,\n",
       "      'top_tokens': [('', 0.25588512420654297),\n",
       "       ('trouble', 0.20574676990509033),\n",
       "       ('ifices', 0.1987714320421219),\n",
       "       ('', 0.1715618073940277),\n",
       "       ('oor', 0.16803491115570068)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.07223766297101974,\n",
       "      'top_tokens': [('ancel', 0.24275825917720795),\n",
       "       ('inafter', 0.2185574471950531),\n",
       "       ('ncies', 0.21683263778686523),\n",
       "       ('', 0.16922660171985626),\n",
       "       ('', 0.1526249796152115)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.07005205005407333,\n",
       "      'top_tokens': [('rsia', 0.22689472138881683),\n",
       "       (\"__':\", 0.21114441752433777),\n",
       "       ('stia', 0.19183097779750824),\n",
       "       ('substack', 0.18763944506645203),\n",
       "       ('urals', 0.18249040842056274)]}]}}},\n",
       " 'layer_2': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 28,\n",
       "      'weight': 0.212108314037323,\n",
       "      'top_tokens': [('', 0.22110116481781006),\n",
       "       ('ling', 0.21001999080181122),\n",
       "       ('@', 0.19741657376289368),\n",
       "       ('coni', 0.1942194402217865),\n",
       "       ('BUS', 0.17724283039569855)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.20216335356235504,\n",
       "      'top_tokens': [('enas', 0.2429412603378296),\n",
       "       ('', 0.2068275660276413),\n",
       "       ('KY', 0.1907801777124405),\n",
       "       ('', 0.18570496141910553),\n",
       "       ('otine', 0.17374606430530548)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.1276846081018448,\n",
       "      'top_tokens': [('opin', 0.21568281948566437),\n",
       "       ('', 0.2030358761548996),\n",
       "       ('Evoluci', 0.19664311408996582),\n",
       "       ('', 0.19396927952766418),\n",
       "       ('', 0.19066894054412842)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.12651965022087097,\n",
       "      'top_tokens': [('', 0.23227520287036896),\n",
       "       ('throwing', 0.2244611531496048),\n",
       "       ('', 0.18720363080501556),\n",
       "       ('', 0.1852608323097229),\n",
       "       ('', 0.17079922556877136)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11990782618522644,\n",
       "      'top_tokens': [('0', 0.24658501148223877),\n",
       "       (' p', 0.20226295292377472),\n",
       "       ('oan', 0.19520431756973267),\n",
       "       (' b', 0.17860813438892365),\n",
       "       ('asso', 0.17733953893184662)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.10875479131937027,\n",
       "      'top_tokens': [('', 0.21780608594417572),\n",
       "       ('', 0.21110288798809052),\n",
       "       ('apsed', 0.20095963776111603),\n",
       "       (' ', 0.1865939199924469),\n",
       "       ('iterr', 0.1835375279188156)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.10286140441894531,\n",
       "      'top_tokens': [('essee', 0.2295614778995514),\n",
       "       (' ', 0.2142419070005417),\n",
       "       ('eni', 0.1979420781135559),\n",
       "       ('ianes', 0.18101662397384644),\n",
       "       ('oud', 0.17723795771598816)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 28,\n",
       "      'weight': 0.2174638956785202,\n",
       "      'top_tokens': [('', 0.22584892809391022),\n",
       "       ('ling', 0.21773307025432587),\n",
       "       ('@', 0.19471494853496552),\n",
       "       ('coni', 0.18238309025764465),\n",
       "       ('BUS', 0.17931999266147614)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.1863333284854889,\n",
       "      'top_tokens': [('enas', 0.2476702481508255),\n",
       "       ('', 0.2081713080406189),\n",
       "       ('KY', 0.1884322315454483),\n",
       "       ('', 0.1780640035867691),\n",
       "       (' Charac', 0.17766223847866058)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.13749834895133972,\n",
       "      'top_tokens': [('opin', 0.21617759764194489),\n",
       "       ('', 0.2136438935995102),\n",
       "       ('', 0.19101113080978394),\n",
       "       ('Evoluci', 0.19034190475940704),\n",
       "       (' followed', 0.18882548809051514)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.1284273862838745,\n",
       "      'top_tokens': [('', 0.23073598742485046),\n",
       "       ('throwing', 0.21725644171237946),\n",
       "       ('', 0.19959202408790588),\n",
       "       ('', 0.185410276055336),\n",
       "       ('Throw', 0.1670052856206894)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11513348668813705,\n",
       "      'top_tokens': [('0', 0.27460813522338867),\n",
       "       ('oan', 0.19488605856895447),\n",
       "       (' p', 0.18699806928634644),\n",
       "       ('gad', 0.17236457765102386),\n",
       "       ('1', 0.17114317417144775)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.10812234878540039,\n",
       "      'top_tokens': [('', 0.2161523401737213),\n",
       "       ('', 0.2118929624557495),\n",
       "       ('apsed', 0.2055821418762207),\n",
       "       ('iterr', 0.18516698479652405),\n",
       "       (' ', 0.18120552599430084)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.10702115297317505,\n",
       "      'top_tokens': [('essee', 0.2290526032447815),\n",
       "       ('eni', 0.20838522911071777),\n",
       "       (' ', 0.20508673787117004),\n",
       "       ('ianes', 0.19181865453720093),\n",
       "       ('oud', 0.16565683484077454)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 28,\n",
       "      'weight': 0.21960829198360443,\n",
       "      'top_tokens': [('', 0.22632798552513123),\n",
       "       ('ling', 0.2173021137714386),\n",
       "       ('@', 0.1935383528470993),\n",
       "       ('coni', 0.18240799009799957),\n",
       "       ('BUS', 0.1804235577583313)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.18804514408111572,\n",
       "      'top_tokens': [('enas', 0.25075680017471313),\n",
       "       ('', 0.21271289885044098),\n",
       "       ('KY', 0.18671835958957672),\n",
       "       ('', 0.176494762301445),\n",
       "       ('onat', 0.17331720888614655)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.135304257273674,\n",
       "      'top_tokens': [('opin', 0.218521386384964),\n",
       "       ('', 0.21186988055706024),\n",
       "       ('Evoluci', 0.1934482455253601),\n",
       "       (' followed', 0.189187154173851),\n",
       "       ('', 0.18697327375411987)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.1297418624162674,\n",
       "      'top_tokens': [('', 0.23186126351356506),\n",
       "       ('throwing', 0.22072122991085052),\n",
       "       ('', 0.19961702823638916),\n",
       "       ('', 0.18100649118423462),\n",
       "       ('Throw', 0.16679394245147705)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11530417948961258,\n",
       "      'top_tokens': [('0', 0.2702641189098358),\n",
       "       ('oan', 0.1959334760904312),\n",
       "       (' p', 0.18793171644210815),\n",
       "       ('gad', 0.17616413533687592),\n",
       "       (' b', 0.1697065830230713)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.10709045827388763,\n",
       "      'top_tokens': [('', 0.21506457030773163),\n",
       "       ('', 0.21367351710796356),\n",
       "       ('apsed', 0.20891347527503967),\n",
       "       ('iterr', 0.18467220664024353),\n",
       "       (' ', 0.1776762157678604)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.10490582883358002,\n",
       "      'top_tokens': [('essee', 0.23699985444545746),\n",
       "       (' ', 0.20575784146785736),\n",
       "       ('eni', 0.2036736160516739),\n",
       "       ('ianes', 0.18858937919139862),\n",
       "       ('oud', 0.16497932374477386)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 28,\n",
       "      'weight': 0.21894454956054688,\n",
       "      'top_tokens': [('', 0.22731292247772217),\n",
       "       ('ling', 0.22039265930652618),\n",
       "       ('@', 0.19355176389217377),\n",
       "       ('coni', 0.1811782717704773),\n",
       "       ('BUS', 0.177564337849617)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.18672247231006622,\n",
       "      'top_tokens': [('enas', 0.2530355155467987),\n",
       "       ('', 0.217863529920578),\n",
       "       ('KY', 0.1826300323009491),\n",
       "       ('', 0.1753576397895813),\n",
       "       (' Charac', 0.1711132824420929)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.13710732758045197,\n",
       "      'top_tokens': [('opin', 0.21450306475162506),\n",
       "       ('', 0.21221747994422913),\n",
       "       ('Evoluci', 0.19627422094345093),\n",
       "       ('', 0.1902225911617279),\n",
       "       (' followed', 0.1867826282978058)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.13116128742694855,\n",
       "      'top_tokens': [('', 0.22690345346927643),\n",
       "       ('throwing', 0.22604772448539734),\n",
       "       ('', 0.20661750435829163),\n",
       "       ('', 0.171791210770607),\n",
       "       ('', 0.16864003241062164)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11450088769197464,\n",
       "      'top_tokens': [('0', 0.2745046317577362),\n",
       "       ('oan', 0.18969452381134033),\n",
       "       (' p', 0.18579435348510742),\n",
       "       ('gad', 0.17723068594932556),\n",
       "       ('1', 0.1727757602930069)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.10663460940122604,\n",
       "      'top_tokens': [('', 0.2136158049106598),\n",
       "       ('apsed', 0.21309131383895874),\n",
       "       ('', 0.21019141376018524),\n",
       "       ('', 0.18309728801250458),\n",
       "       ('iterr', 0.18000413477420807)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.10492899268865585,\n",
       "      'top_tokens': [('essee', 0.2405618131160736),\n",
       "       ('eni', 0.20722422003746033),\n",
       "       (' ', 0.20452062785625458),\n",
       "       ('ianes', 0.1848209947347641),\n",
       "       ('oud', 0.16287225484848022)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 28,\n",
       "      'weight': 0.21834084391593933,\n",
       "      'top_tokens': [('', 0.22638249397277832),\n",
       "       ('ling', 0.2179001122713089),\n",
       "       ('@', 0.1939702033996582),\n",
       "       ('coni', 0.18299049139022827),\n",
       "       ('BUS', 0.1787566840648651)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.18813660740852356,\n",
       "      'top_tokens': [('enas', 0.2504522502422333),\n",
       "       ('', 0.21301798522472382),\n",
       "       ('KY', 0.18598297238349915),\n",
       "       ('', 0.1770305037498474),\n",
       "       (' Charac', 0.17351625859737396)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.1363677978515625,\n",
       "      'top_tokens': [('opin', 0.21709886193275452),\n",
       "       ('', 0.21243925392627716),\n",
       "       ('Evoluci', 0.19405673444271088),\n",
       "       (' followed', 0.18832847476005554),\n",
       "       ('', 0.1880767047405243)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.1295311450958252,\n",
       "      'top_tokens': [('', 0.23029950261116028),\n",
       "       ('throwing', 0.22241422533988953),\n",
       "       ('', 0.20076005160808563),\n",
       "       ('', 0.1790333241224289),\n",
       "       ('Throw', 0.16749294102191925)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11511877924203873,\n",
       "      'top_tokens': [('0', 0.2710464298725128),\n",
       "       ('oan', 0.19323745369911194),\n",
       "       (' p', 0.1889808177947998),\n",
       "       ('gad', 0.17590893805027008),\n",
       "       (' b', 0.17082636058330536)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.10730572789907455,\n",
       "      'top_tokens': [('', 0.21435903012752533),\n",
       "       ('', 0.21358509361743927),\n",
       "       ('apsed', 0.20912878215312958),\n",
       "       ('iterr', 0.18365728855133057),\n",
       "       ('', 0.17926977574825287)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.10519911348819733,\n",
       "      'top_tokens': [('essee', 0.23544643819332123),\n",
       "       (' ', 0.20618590712547302),\n",
       "       ('eni', 0.205690398812294),\n",
       "       ('ianes', 0.1874808371067047),\n",
       "       ('oud', 0.1651964783668518)]}]}}},\n",
       " 'layer_3': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 60,\n",
       "      'weight': 0.3264475166797638,\n",
       "      'top_tokens': [('0', 0.24006234109401703),\n",
       "       ('2', 0.20976649224758148),\n",
       "       ('9', 0.19982819259166718),\n",
       "       ('1', 0.17551255226135254),\n",
       "       ('8', 0.1748303920030594)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.18798989057540894,\n",
       "      'top_tokens': [('acant', 0.23620326817035675),\n",
       "       (' sorra', 0.2265186756849289),\n",
       "       ('onstr', 0.18383845686912537),\n",
       "       ('PREC', 0.1793421059846878),\n",
       "       ('uges', 0.17409740388393402)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.11680374294519424,\n",
       "      'top_tokens': [('', 0.24677172303199768),\n",
       "       (' scrut', 0.20962561666965485),\n",
       "       ('itures', 0.18791748583316803),\n",
       "       ('geries', 0.1804109662771225),\n",
       "       ('', 0.17527423799037933)]},\n",
       "     {'expert_id': 34,\n",
       "      'weight': 0.09758022427558899,\n",
       "      'top_tokens': [('', 0.20320716500282288),\n",
       "       ('strat', 0.2002408504486084),\n",
       "       (' seix', 0.1998496651649475),\n",
       "       ('ingut', 0.1992482841014862),\n",
       "       (' propor', 0.19745397567749023)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.09220528602600098,\n",
       "      'top_tokens': [('_{_', 0.2491385042667389),\n",
       "       ('uelen', 0.1895952671766281),\n",
       "       ('xfce', 0.1889694482088089),\n",
       "       (' coneixen', 0.1872185617685318),\n",
       "       ('cke', 0.18507817387580872)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.0911206379532814,\n",
       "      'top_tokens': [('Habitants', 0.30437159538269043),\n",
       "       ('abilitat', 0.20189803838729858),\n",
       "       (' ', 0.1703868955373764),\n",
       "       ('perf', 0.16216258704662323),\n",
       "       ('rely', 0.16118083894252777)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.08785265684127808,\n",
       "      'top_tokens': [('herits', 0.2881675362586975),\n",
       "       ('', 0.18721376359462738),\n",
       "       ('CODEGEN', 0.18105433881282806),\n",
       "       ('balena', 0.17635704576969147),\n",
       "       ('ificador', 0.1672072559595108)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 60,\n",
       "      'weight': 0.32644325494766235,\n",
       "      'top_tokens': [('0', 0.24005891382694244),\n",
       "       ('2', 0.2097710371017456),\n",
       "       ('9', 0.19982552528381348),\n",
       "       ('1', 0.17551206052303314),\n",
       "       ('8', 0.17483246326446533)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.18799206614494324,\n",
       "      'top_tokens': [('acant', 0.23618364334106445),\n",
       "       (' sorra', 0.2265295684337616),\n",
       "       ('onstr', 0.18385416269302368),\n",
       "       ('PREC', 0.17934152483940125),\n",
       "       ('uges', 0.17409111559391022)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.1168036088347435,\n",
       "      'top_tokens': [('', 0.24679960310459137),\n",
       "       (' scrut', 0.20960940420627594),\n",
       "       ('itures', 0.18792487680912018),\n",
       "       ('geries', 0.1804015189409256),\n",
       "       ('', 0.17526455223560333)]},\n",
       "     {'expert_id': 34,\n",
       "      'weight': 0.09758366644382477,\n",
       "      'top_tokens': [('', 0.2032119333744049),\n",
       "       ('strat', 0.2002360075712204),\n",
       "       (' seix', 0.19983737170696259),\n",
       "       ('ingut', 0.19925394654273987),\n",
       "       (' propor', 0.19746069610118866)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.09220506250858307,\n",
       "      'top_tokens': [('_{_', 0.24911805987358093),\n",
       "       ('uelen', 0.189592182636261),\n",
       "       ('xfce', 0.18899232149124146),\n",
       "       (' coneixen', 0.18721319735050201),\n",
       "       ('cke', 0.18508420884609222)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.0911179631948471,\n",
       "      'top_tokens': [('Habitants', 0.3043617010116577),\n",
       "       ('abilitat', 0.20190703868865967),\n",
       "       (' ', 0.17039453983306885),\n",
       "       ('perf', 0.16216032207012177),\n",
       "       ('rely', 0.16117632389068604)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.0878542810678482,\n",
       "      'top_tokens': [('herits', 0.2881585657596588),\n",
       "       ('', 0.18721996247768402),\n",
       "       ('CODEGEN', 0.18104007840156555),\n",
       "       ('balena', 0.17636547982692719),\n",
       "       ('ificador', 0.16721591353416443)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 60,\n",
       "      'weight': 0.3264440596103668,\n",
       "      'top_tokens': [('0', 0.24005940556526184),\n",
       "       ('2', 0.20977047085762024),\n",
       "       ('9', 0.19982627034187317),\n",
       "       ('1', 0.17551195621490479),\n",
       "       ('8', 0.17483194172382355)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.1879919469356537,\n",
       "      'top_tokens': [('acant', 0.23618687689304352),\n",
       "       (' sorra', 0.22652752697467804),\n",
       "       ('onstr', 0.1838516741991043),\n",
       "       ('PREC', 0.1793411672115326),\n",
       "       ('uges', 0.17409266531467438)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.116803377866745,\n",
       "      'top_tokens': [('', 0.24679595232009888),\n",
       "       (' scrut', 0.20961152017116547),\n",
       "       ('itures', 0.18792389333248138),\n",
       "       ('geries', 0.18040259182453156),\n",
       "       ('', 0.17526613175868988)]},\n",
       "     {'expert_id': 34,\n",
       "      'weight': 0.09758318960666656,\n",
       "      'top_tokens': [('', 0.20321165025234222),\n",
       "       ('strat', 0.20023655891418457),\n",
       "       (' seix', 0.1998380422592163),\n",
       "       ('ingut', 0.1992526352405548),\n",
       "       (' propor', 0.19746112823486328)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.09220486134290695,\n",
       "      'top_tokens': [('_{_', 0.2491205334663391),\n",
       "       ('uelen', 0.18959344923496246),\n",
       "       ('xfce', 0.18898896872997284),\n",
       "       (' coneixen', 0.1872139424085617),\n",
       "       ('cke', 0.1850830465555191)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.09111838042736053,\n",
       "      'top_tokens': [('Habitants', 0.30436381697654724),\n",
       "       ('abilitat', 0.20190617442131042),\n",
       "       (' ', 0.17039327323436737),\n",
       "       ('perf', 0.1621604561805725),\n",
       "       ('rely', 0.16117633879184723)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.08785416185855865,\n",
       "      'top_tokens': [('herits', 0.2881592810153961),\n",
       "       ('', 0.18721917271614075),\n",
       "       ('CODEGEN', 0.18104298412799835),\n",
       "       ('balena', 0.1763637363910675),\n",
       "       ('ificador', 0.16721485555171967)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 60,\n",
       "      'weight': 0.3264440596103668,\n",
       "      'top_tokens': [('0', 0.24005860090255737),\n",
       "       ('2', 0.20977148413658142),\n",
       "       ('9', 0.19982655346393585),\n",
       "       ('1', 0.17551152408123016),\n",
       "       ('8', 0.17483186721801758)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.18799246847629547,\n",
       "      'top_tokens': [('acant', 0.23618663847446442),\n",
       "       (' sorra', 0.2265274077653885),\n",
       "       ('onstr', 0.18385271728038788),\n",
       "       ('PREC', 0.17933975160121918),\n",
       "       ('uges', 0.17409341037273407)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.11680301278829575,\n",
       "      'top_tokens': [('', 0.24679945409297943),\n",
       "       (' scrut', 0.20960889756679535),\n",
       "       ('itures', 0.1879248172044754),\n",
       "       ('geries', 0.18040180206298828),\n",
       "       ('', 0.17526507377624512)]},\n",
       "     {'expert_id': 34,\n",
       "      'weight': 0.09758369624614716,\n",
       "      'top_tokens': [('', 0.2032131552696228),\n",
       "       ('strat', 0.20023567974567413),\n",
       "       (' seix', 0.19983479380607605),\n",
       "       ('ingut', 0.1992524415254593),\n",
       "       (' propor', 0.1974639594554901)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.09220445901155472,\n",
       "      'top_tokens': [('_{_', 0.24911737442016602),\n",
       "       ('uelen', 0.1895943433046341),\n",
       "       ('xfce', 0.1889917552471161),\n",
       "       (' coneixen', 0.1872132569551468),\n",
       "       ('cke', 0.1850832849740982)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.09111784398555756,\n",
       "      'top_tokens': [('Habitants', 0.30436447262763977),\n",
       "       ('abilitat', 0.2019079029560089),\n",
       "       (' ', 0.17039412260055542),\n",
       "       ('perf', 0.16215944290161133),\n",
       "       ('rely', 0.16117405891418457)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.08785459399223328,\n",
       "      'top_tokens': [('herits', 0.28815749287605286),\n",
       "       ('', 0.18722015619277954),\n",
       "       ('CODEGEN', 0.18104241788387299),\n",
       "       ('balena', 0.17636388540267944),\n",
       "       ('ificador', 0.16721613705158234)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 60,\n",
       "      'weight': 0.3264438807964325,\n",
       "      'top_tokens': [('0', 0.24005931615829468),\n",
       "       ('2', 0.2097705900669098),\n",
       "       ('9', 0.19982634484767914),\n",
       "       ('1', 0.17551189661026),\n",
       "       ('8', 0.17483185231685638)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.187992125749588,\n",
       "      'top_tokens': [('acant', 0.2361874133348465),\n",
       "       (' sorra', 0.22652718424797058),\n",
       "       ('onstr', 0.18385165929794312),\n",
       "       ('PREC', 0.17934063076972961),\n",
       "       ('uges', 0.1740930676460266)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.11680327355861664,\n",
       "      'top_tokens': [('', 0.24679602682590485),\n",
       "       (' scrut', 0.20961137115955353),\n",
       "       ('itures', 0.187923863530159),\n",
       "       ('geries', 0.18040268123149872),\n",
       "       ('', 0.17526598274707794)]},\n",
       "     {'expert_id': 34,\n",
       "      'weight': 0.09758324921131134,\n",
       "      'top_tokens': [('', 0.20321181416511536),\n",
       "       ('strat', 0.20023636519908905),\n",
       "       (' seix', 0.19983774423599243),\n",
       "       ('ingut', 0.19925251603126526),\n",
       "       (' propor', 0.19746148586273193)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.09220483154058456,\n",
       "      'top_tokens': [('_{_', 0.2491205334663391),\n",
       "       ('uelen', 0.18959367275238037),\n",
       "       ('xfce', 0.18898896872997284),\n",
       "       (' coneixen', 0.1872139424085617),\n",
       "       ('cke', 0.18508295714855194)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.09111838042736053,\n",
       "      'top_tokens': [('Habitants', 0.3043641746044159),\n",
       "       ('abilitat', 0.2019062042236328),\n",
       "       (' ', 0.17039327323436737),\n",
       "       ('perf', 0.1621602475643158),\n",
       "       ('rely', 0.16117613017559052)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.08785426616668701,\n",
       "      'top_tokens': [('herits', 0.2881591022014618),\n",
       "       ('', 0.18721923232078552),\n",
       "       ('CODEGEN', 0.18104325234889984),\n",
       "       ('balena', 0.1763635277748108),\n",
       "       ('ificador', 0.1672147959470749)]}]}}},\n",
       " 'layer_4': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.21015313267707825,\n",
       "      'top_tokens': [('companion', 0.2463497817516327),\n",
       "       ('', 0.19662369787693024),\n",
       "       (' Candidate', 0.19308537244796753),\n",
       "       (' Engine', 0.1886574923992157),\n",
       "       ('enso', 0.17528373003005981)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.20123212039470673,\n",
       "      'top_tokens': [('istre', 0.2292436957359314),\n",
       "       (':///', 0.21347014605998993),\n",
       "       ('', 0.19412216544151306),\n",
       "       ('elf', 0.18161842226982117),\n",
       "       ('rief', 0.18154560029506683)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.19251319766044617,\n",
       "      'top_tokens': [('oven', 0.32441118359565735),\n",
       "       ('lus', 0.19673441350460052),\n",
       "       (':///', 0.18028803169727325),\n",
       "       (' built', 0.15197061002254486),\n",
       "       (' Loric', 0.14659574627876282)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.1390126645565033,\n",
       "      'top_tokens': [('ather', 0.25473326444625854),\n",
       "       ('._\"', 0.18983817100524902),\n",
       "       ('COMPONENT', 0.18922777473926544),\n",
       "       ('ume', 0.18732014298439026),\n",
       "       ('ynchronously', 0.17888063192367554)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.0993649959564209,\n",
       "      'top_tokens': [('malink', 0.28021377325057983),\n",
       "       ('', 0.20394185185432434),\n",
       "       ('estan', 0.17751151323318481),\n",
       "       (' ', 0.16939781606197357),\n",
       "       ('sst', 0.16893506050109863)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.07973163574934006,\n",
       "      'top_tokens': [('estrat', 0.21034254133701324),\n",
       "       ('', 0.20968210697174072),\n",
       "       ('atron', 0.20469930768013),\n",
       "       ('/__', 0.19157962501049042),\n",
       "       ('acor', 0.18369638919830322)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.07799217849969864,\n",
       "      'top_tokens': [('', 0.22267556190490723),\n",
       "       ('', 0.21825219690799713),\n",
       "       ('pad', 0.20113889873027802),\n",
       "       ('.', 0.17937961220741272),\n",
       "       ('Gen', 0.17855370044708252)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.21015317738056183,\n",
       "      'top_tokens': [('companion', 0.24634972214698792),\n",
       "       ('', 0.196623757481575),\n",
       "       (' Candidate', 0.1930854171514511),\n",
       "       (' Engine', 0.1886574625968933),\n",
       "       ('enso', 0.17528368532657623)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.2012322098016739,\n",
       "      'top_tokens': [('istre', 0.22924381494522095),\n",
       "       (':///', 0.21347016096115112),\n",
       "       ('', 0.19412218034267426),\n",
       "       ('elf', 0.181618332862854),\n",
       "       ('rief', 0.18154557049274445)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.19251304864883423,\n",
       "      'top_tokens': [('oven', 0.32441121339797974),\n",
       "       ('lus', 0.1967344880104065),\n",
       "       (':///', 0.18028801679611206),\n",
       "       (' built', 0.15197062492370605),\n",
       "       (' Loric', 0.14659570157527924)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.13901269435882568,\n",
       "      'top_tokens': [('ather', 0.25473326444625854),\n",
       "       ('._\"', 0.1898382604122162),\n",
       "       ('COMPONENT', 0.18922768533229828),\n",
       "       ('ume', 0.18732017278671265),\n",
       "       ('ynchronously', 0.17888067662715912)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.09936502575874329,\n",
       "      'top_tokens': [('malink', 0.2802138030529022),\n",
       "       ('', 0.20394188165664673),\n",
       "       ('estan', 0.17751146852970123),\n",
       "       (' ', 0.16939777135849),\n",
       "       ('sst', 0.16893509030342102)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.07973165065050125,\n",
       "      'top_tokens': [('estrat', 0.21034257113933563),\n",
       "       ('', 0.20968209207057953),\n",
       "       ('atron', 0.2046992927789688),\n",
       "       ('/__', 0.19157961010932922),\n",
       "       ('acor', 0.1836964190006256)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.07799221575260162,\n",
       "      'top_tokens': [('', 0.22267554700374603),\n",
       "       ('', 0.2182522416114807),\n",
       "       ('pad', 0.20113879442214966),\n",
       "       ('.', 0.17937959730625153),\n",
       "       ('Gen', 0.17855378985404968)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.2101532220840454,\n",
       "      'top_tokens': [('companion', 0.2463497817516327),\n",
       "       ('', 0.19662368297576904),\n",
       "       (' Candidate', 0.1930854320526123),\n",
       "       (' Engine', 0.1886575073003769),\n",
       "       ('enso', 0.17528370022773743)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.20123212039470673,\n",
       "      'top_tokens': [('istre', 0.2292437106370926),\n",
       "       (':///', 0.21347016096115112),\n",
       "       ('', 0.19412213563919067),\n",
       "       ('elf', 0.18161839246749878),\n",
       "       ('rief', 0.18154552578926086)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.1925130933523178,\n",
       "      'top_tokens': [('oven', 0.32441118359565735),\n",
       "       ('lus', 0.1967344731092453),\n",
       "       (':///', 0.18028795719146729),\n",
       "       (' built', 0.15197061002254486),\n",
       "       (' Loric', 0.14659574627876282)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.13901259005069733,\n",
       "      'top_tokens': [('ather', 0.2547333240509033),\n",
       "       ('._\"', 0.1898382157087326),\n",
       "       ('COMPONENT', 0.18922770023345947),\n",
       "       ('ume', 0.18732014298439026),\n",
       "       ('ynchronously', 0.17888067662715912)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.09936506301164627,\n",
       "      'top_tokens': [('malink', 0.2802138030529022),\n",
       "       ('', 0.20394188165664673),\n",
       "       ('estan', 0.17751145362854004),\n",
       "       (' ', 0.16939781606197357),\n",
       "       ('sst', 0.16893507540225983)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.07973165065050125,\n",
       "      'top_tokens': [('estrat', 0.21034258604049683),\n",
       "       ('', 0.20968204736709595),\n",
       "       ('atron', 0.20469930768013),\n",
       "       ('/__', 0.1915796548128128),\n",
       "       ('acor', 0.18369634449481964)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.07799217104911804,\n",
       "      'top_tokens': [('', 0.2226756513118744),\n",
       "       ('', 0.21825207769870758),\n",
       "       ('pad', 0.20113883912563324),\n",
       "       ('.', 0.17937959730625153),\n",
       "       ('Gen', 0.17855381965637207)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.21015307307243347,\n",
       "      'top_tokens': [('companion', 0.24634969234466553),\n",
       "       ('', 0.19662374258041382),\n",
       "       (' Candidate', 0.19308538734912872),\n",
       "       (' Engine', 0.18865752220153809),\n",
       "       ('enso', 0.17528365552425385)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.20123225450515747,\n",
       "      'top_tokens': [('istre', 0.22924374043941498),\n",
       "       (':///', 0.2134702503681183),\n",
       "       ('', 0.19412212073802948),\n",
       "       ('elf', 0.1816183179616928),\n",
       "       ('rief', 0.18154551088809967)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.1925130933523178,\n",
       "      'top_tokens': [('oven', 0.3244112432003021),\n",
       "       ('lus', 0.1967344433069229),\n",
       "       (':///', 0.18028803169727325),\n",
       "       (' built', 0.15197056531906128),\n",
       "       (' Loric', 0.14659571647644043)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.13901261985301971,\n",
       "      'top_tokens': [('ather', 0.25473329424858093),\n",
       "       ('._\"', 0.18983818590641022),\n",
       "       ('COMPONENT', 0.18922770023345947),\n",
       "       ('ume', 0.18732020258903503),\n",
       "       ('ynchronously', 0.1788807064294815)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.09936506301164627,\n",
       "      'top_tokens': [('malink', 0.28021368384361267),\n",
       "       ('', 0.20394189655780792),\n",
       "       ('estan', 0.17751148343086243),\n",
       "       (' ', 0.16939780116081238),\n",
       "       ('sst', 0.16893509030342102)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.07973168790340424,\n",
       "      'top_tokens': [('estrat', 0.2103426456451416),\n",
       "       ('', 0.20968201756477356),\n",
       "       ('atron', 0.20469926297664642),\n",
       "       ('/__', 0.19157962501049042),\n",
       "       ('acor', 0.18369640409946442)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.07799216359853745,\n",
       "      'top_tokens': [('', 0.22267554700374603),\n",
       "       ('', 0.2182522416114807),\n",
       "       ('pad', 0.20113888382911682),\n",
       "       ('.', 0.17937959730625153),\n",
       "       ('Gen', 0.17855378985404968)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.21015313267707825,\n",
       "      'top_tokens': [('companion', 0.24634972214698792),\n",
       "       ('', 0.19662372767925262),\n",
       "       (' Candidate', 0.19308540225028992),\n",
       "       (' Engine', 0.1886574923992157),\n",
       "       ('enso', 0.17528368532657623)]},\n",
       "     {'expert_id': 48,\n",
       "      'weight': 0.20123226940631866,\n",
       "      'top_tokens': [('istre', 0.22924374043941498),\n",
       "       (':///', 0.2134701907634735),\n",
       "       ('', 0.19412215054035187),\n",
       "       ('elf', 0.1816183626651764),\n",
       "       ('rief', 0.18154558539390564)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.19251306354999542,\n",
       "      'top_tokens': [('oven', 0.3244112432003021),\n",
       "       ('lus', 0.19673441350460052),\n",
       "       (':///', 0.18028803169727325),\n",
       "       (' built', 0.15197056531906128),\n",
       "       (' Loric', 0.14659574627876282)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.13901260495185852,\n",
       "      'top_tokens': [('ather', 0.25473323464393616),\n",
       "       ('._\"', 0.1898382157087326),\n",
       "       ('COMPONENT', 0.18922774493694305),\n",
       "       ('ume', 0.18732015788555145),\n",
       "       ('ynchronously', 0.17888066172599792)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.09936507046222687,\n",
       "      'top_tokens': [('malink', 0.2802136540412903),\n",
       "       ('', 0.20394186675548553),\n",
       "       ('estan', 0.17751151323318481),\n",
       "       (' ', 0.16939783096313477),\n",
       "       ('sst', 0.16893510520458221)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.07973163574934006,\n",
       "      'top_tokens': [('estrat', 0.21034252643585205),\n",
       "       ('', 0.20968209207057953),\n",
       "       ('atron', 0.2046992927789688),\n",
       "       ('/__', 0.19157961010932922),\n",
       "       ('acor', 0.1836964339017868)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.07799221575260162,\n",
       "      'top_tokens': [('', 0.22267559170722961),\n",
       "       ('', 0.21825212240219116),\n",
       "       ('pad', 0.20113888382911682),\n",
       "       ('.', 0.1793796420097351),\n",
       "       ('Gen', 0.1785537749528885)]}]}}},\n",
       " 'layer_5': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 32,\n",
       "      'weight': 0.19319741427898407,\n",
       "      'top_tokens': [(' ', 0.22730523347854614),\n",
       "       ('', 0.20926998555660248),\n",
       "       (' Senat', 0.20207978785037994),\n",
       "       ('elic', 0.18613941967487335),\n",
       "       ('', 0.17520557343959808)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.18065118789672852,\n",
       "      'top_tokens': [('ivia', 0.24106641113758087),\n",
       "       ('', 0.1940903216600418),\n",
       "       ('warz', 0.19159814715385437),\n",
       "       (' City', 0.18921156227588654),\n",
       "       ('iform', 0.18403345346450806)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.15899664163589478,\n",
       "      'top_tokens': [(' _', 0.2308569848537445),\n",
       "       ('', 0.20440198481082916),\n",
       "       ('inches', 0.1938582956790924),\n",
       "       ('', 0.1857730746269226),\n",
       "       (' IO', 0.18510961532592773)]},\n",
       "     {'expert_id': 44,\n",
       "      'weight': 0.12084544450044632,\n",
       "      'top_tokens': [('', 0.21588875353336334),\n",
       "       ('udes', 0.21212106943130493),\n",
       "       ('', 0.20521153509616852),\n",
       "       ('ude', 0.1852206587791443),\n",
       "       ('', 0.18155798316001892)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11700212955474854,\n",
       "      'top_tokens': [('', 0.39210760593414307),\n",
       "       (' dispos', 0.16864868998527527),\n",
       "       ('', 0.1648591011762619),\n",
       "       (' Peabody', 0.13890404999256134),\n",
       "       ('ulo', 0.135480597615242)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.11571630090475082,\n",
       "      'top_tokens': [('', 0.21918925642967224),\n",
       "       ('enginy', 0.2076326608657837),\n",
       "       ('oguera', 0.20118847489356995),\n",
       "       ('Equador', 0.19045449793338776),\n",
       "       ('ilitat', 0.18153508007526398)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.11359088867902756,\n",
       "      'top_tokens': [('', 0.2099156677722931),\n",
       "       ('anyes', 0.20664387941360474),\n",
       "       (' ', 0.19932147860527039),\n",
       "       ('cades', 0.19887326657772064),\n",
       "       ('oldt', 0.18524564802646637)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 32,\n",
       "      'weight': 0.1931973695755005,\n",
       "      'top_tokens': [(' ', 0.22730515897274017),\n",
       "       ('', 0.2092699557542801),\n",
       "       (' Senat', 0.20207983255386353),\n",
       "       ('elic', 0.18613938987255096),\n",
       "       ('', 0.17520557343959808)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.18065129220485687,\n",
       "      'top_tokens': [('ivia', 0.24106644093990326),\n",
       "       ('', 0.194090336561203),\n",
       "       ('warz', 0.19159817695617676),\n",
       "       (' City', 0.18921151757240295),\n",
       "       ('iform', 0.18403342366218567)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.15899664163589478,\n",
       "      'top_tokens': [(' _', 0.23085719347000122),\n",
       "       ('', 0.20440202951431274),\n",
       "       ('inches', 0.19385823607444763),\n",
       "       ('', 0.18577297031879425),\n",
       "       (' IO', 0.18510966002941132)]},\n",
       "     {'expert_id': 44,\n",
       "      'weight': 0.12084542959928513,\n",
       "      'top_tokens': [('', 0.21588869392871857),\n",
       "       ('udes', 0.21212106943130493),\n",
       "       ('', 0.2052115797996521),\n",
       "       ('ude', 0.18522068858146667),\n",
       "       ('', 0.1815580129623413)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11700213700532913,\n",
       "      'top_tokens': [('', 0.39210760593414307),\n",
       "       (' dispos', 0.16864868998527527),\n",
       "       ('', 0.16485904157161713),\n",
       "       (' Peabody', 0.13890409469604492),\n",
       "       ('ulo', 0.13548055291175842)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.11571629345417023,\n",
       "      'top_tokens': [('', 0.2191893309354782),\n",
       "       ('enginy', 0.20763257145881653),\n",
       "       ('oguera', 0.20118854939937592),\n",
       "       ('Equador', 0.1904544234275818),\n",
       "       ('ilitat', 0.18153515458106995)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.11359081417322159,\n",
       "      'top_tokens': [('', 0.20991572737693787),\n",
       "       ('anyes', 0.20664389431476593),\n",
       "       (' ', 0.19932138919830322),\n",
       "       ('cades', 0.19887323677539825),\n",
       "       ('oldt', 0.18524569272994995)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 32,\n",
       "      'weight': 0.1931973099708557,\n",
       "      'top_tokens': [(' ', 0.22730518877506256),\n",
       "       ('', 0.20927007496356964),\n",
       "       (' Senat', 0.20207974314689636),\n",
       "       ('elic', 0.18613943457603455),\n",
       "       ('', 0.17520558834075928)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.1806512027978897,\n",
       "      'top_tokens': [('ivia', 0.24106644093990326),\n",
       "       ('', 0.1940903216600418),\n",
       "       ('warz', 0.19159817695617676),\n",
       "       (' City', 0.18921157717704773),\n",
       "       ('iform', 0.18403342366218567)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.15899670124053955,\n",
       "      'top_tokens': [(' _', 0.2308569848537445),\n",
       "       ('', 0.20440204441547394),\n",
       "       ('inches', 0.19385825097560883),\n",
       "       ('', 0.1857731193304062),\n",
       "       (' IO', 0.18510957062244415)]},\n",
       "     {'expert_id': 44,\n",
       "      'weight': 0.12084541469812393,\n",
       "      'top_tokens': [('', 0.21588875353336334),\n",
       "       ('udes', 0.21212106943130493),\n",
       "       ('', 0.20521153509616852),\n",
       "       ('ude', 0.1852206587791443),\n",
       "       ('', 0.18155798316001892)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11700218915939331,\n",
       "      'top_tokens': [('', 0.39210766553878784),\n",
       "       (' dispos', 0.16864871978759766),\n",
       "       ('', 0.16485895216464996),\n",
       "       (' Peabody', 0.13890403509140015),\n",
       "       ('ulo', 0.13548055291175842)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.11571629345417023,\n",
       "      'top_tokens': [('', 0.21918925642967224),\n",
       "       ('enginy', 0.20763269066810608),\n",
       "       ('oguera', 0.20118838548660278),\n",
       "       ('Equador', 0.19045445322990417),\n",
       "       ('ilitat', 0.18153512477874756)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.11359087377786636,\n",
       "      'top_tokens': [('', 0.20991557836532593),\n",
       "       ('anyes', 0.20664389431476593),\n",
       "       (' ', 0.19932149350643158),\n",
       "       ('cades', 0.19887328147888184),\n",
       "       ('oldt', 0.18524569272994995)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 32,\n",
       "      'weight': 0.19319747388362885,\n",
       "      'top_tokens': [(' ', 0.22730514407157898),\n",
       "       ('', 0.20927006006240845),\n",
       "       (' Senat', 0.20207977294921875),\n",
       "       ('elic', 0.18613941967487335),\n",
       "       ('', 0.17520561814308167)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.1806512027978897,\n",
       "      'top_tokens': [('ivia', 0.24106641113758087),\n",
       "       ('', 0.1940903514623642),\n",
       "       ('warz', 0.19159816205501556),\n",
       "       (' City', 0.18921156227588654),\n",
       "       ('iform', 0.18403339385986328)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.15899668633937836,\n",
       "      'top_tokens': [(' _', 0.23085711896419525),\n",
       "       ('', 0.20440199971199036),\n",
       "       ('inches', 0.19385823607444763),\n",
       "       ('', 0.18577304482460022),\n",
       "       (' IO', 0.18510963022708893)]},\n",
       "     {'expert_id': 44,\n",
       "      'weight': 0.12084543704986572,\n",
       "      'top_tokens': [('', 0.21588875353336334),\n",
       "       ('udes', 0.21212102472782135),\n",
       "       ('', 0.2052115947008133),\n",
       "       ('ude', 0.1852206587791443),\n",
       "       ('', 0.18155798316001892)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11700208485126495,\n",
       "      'top_tokens': [('', 0.39210760593414307),\n",
       "       (' dispos', 0.16864868998527527),\n",
       "       ('', 0.16485916078090668),\n",
       "       (' Peabody', 0.13890402019023895),\n",
       "       ('ulo', 0.135480597615242)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.11571632325649261,\n",
       "      'top_tokens': [('', 0.21918930113315582),\n",
       "       ('enginy', 0.20763258635997772),\n",
       "       ('oguera', 0.20118843019008636),\n",
       "       ('Equador', 0.19045454263687134),\n",
       "       ('ilitat', 0.18153508007526398)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.11359088122844696,\n",
       "      'top_tokens': [('', 0.2099156677722931),\n",
       "       ('anyes', 0.20664387941360474),\n",
       "       (' ', 0.1993214190006256),\n",
       "       ('cades', 0.19887332618236542),\n",
       "       ('oldt', 0.18524567782878876)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 32,\n",
       "      'weight': 0.19319750368595123,\n",
       "      'top_tokens': [(' ', 0.22730518877506256),\n",
       "       ('', 0.20926998555660248),\n",
       "       (' Senat', 0.20207983255386353),\n",
       "       ('elic', 0.18613941967487335),\n",
       "       ('', 0.17520557343959808)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.1806512326002121,\n",
       "      'top_tokens': [('ivia', 0.24106644093990326),\n",
       "       ('', 0.1940903663635254),\n",
       "       ('warz', 0.19159820675849915),\n",
       "       (' City', 0.18921154737472534),\n",
       "       ('iform', 0.18403343856334686)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.1589965671300888,\n",
       "      'top_tokens': [(' _', 0.23085704445838928),\n",
       "       ('', 0.20440199971199036),\n",
       "       ('inches', 0.1938583105802536),\n",
       "       ('', 0.18577302992343903),\n",
       "       (' IO', 0.18510957062244415)]},\n",
       "     {'expert_id': 44,\n",
       "      'weight': 0.12084534019231796,\n",
       "      'top_tokens': [('', 0.21588878333568573),\n",
       "       ('udes', 0.21212105453014374),\n",
       "       ('', 0.20521152019500732),\n",
       "       ('ude', 0.1852206289768219),\n",
       "       ('', 0.1815580427646637)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.11700212210416794,\n",
       "      'top_tokens': [('', 0.3921075463294983),\n",
       "       (' dispos', 0.16864866018295288),\n",
       "       ('', 0.1648590862751007),\n",
       "       (' Peabody', 0.13890400528907776),\n",
       "       ('ulo', 0.13548067212104797)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.11571630835533142,\n",
       "      'top_tokens': [('', 0.21918930113315582),\n",
       "       ('enginy', 0.20763270556926727),\n",
       "       ('oguera', 0.20118847489356995),\n",
       "       ('Equador', 0.19045445322990417),\n",
       "       ('ilitat', 0.18153516948223114)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.11359085887670517,\n",
       "      'top_tokens': [('', 0.20991560816764832),\n",
       "       ('anyes', 0.20664387941360474),\n",
       "       (' ', 0.19932152330875397),\n",
       "       ('cades', 0.198873370885849),\n",
       "       ('oldt', 0.18524567782878876)]}]}}},\n",
       " 'layer_6': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 21,\n",
       "      'weight': 0.37697339057922363,\n",
       "      'top_tokens': [('otip', 0.5296183228492737),\n",
       "       ('thon', 0.13031616806983948),\n",
       "       ('pher', 0.12294016778469086),\n",
       "       ('scor', 0.1193796694278717),\n",
       "       ('', 0.09774560481309891)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.12239104509353638,\n",
       "      'top_tokens': [('ARE', 0.2881486713886261),\n",
       "       (' extrems', 0.18942268192768097),\n",
       "       ('wolves', 0.18125414848327637),\n",
       "       ('', 0.17570814490318298),\n",
       "       ('arena', 0.16546638309955597)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.10815966874361038,\n",
       "      'top_tokens': [('arb', 0.2205713540315628),\n",
       "       ('ake', 0.21301376819610596),\n",
       "       ('', 0.21097707748413086),\n",
       "       (' ', 0.1802273690700531),\n",
       "       ('icken', 0.17521049082279205)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.0999702513217926,\n",
       "      'top_tokens': [(' cercle', 0.21068865060806274),\n",
       "       ('ript', 0.2087041437625885),\n",
       "       ('nora', 0.19791074097156525),\n",
       "       ('blr', 0.1929207742214203),\n",
       "       ('>-->', 0.18977569043636322)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.09772298485040665,\n",
       "      'top_tokens': [('resco', 0.22795671224594116),\n",
       "       (' Cortes', 0.20577087998390198),\n",
       "       ('', 0.1924014538526535),\n",
       "       ('CPP', 0.1879204660654068),\n",
       "       (' diferencia', 0.18595044314861298)]},\n",
       "     {'expert_id': 35,\n",
       "      'weight': 0.09741830080747604,\n",
       "      'top_tokens': [('6', 0.23783208429813385),\n",
       "       ('9', 0.22185556590557098),\n",
       "       ('7', 0.19382423162460327),\n",
       "       ('4', 0.18466152250766754),\n",
       "       ('8', 0.16182659566402435)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.09736441820859909,\n",
       "      'top_tokens': [(' pocs', 0.23288823664188385),\n",
       "       (\"}$'\", 0.22109277546405792),\n",
       "       ('', 0.18895664811134338),\n",
       "       ('antine', 0.1854797899723053),\n",
       "       ('ssia', 0.17158257961273193)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 21,\n",
       "      'weight': 0.37697336077690125,\n",
       "      'top_tokens': [('otip', 0.5296186208724976),\n",
       "       ('thon', 0.13031616806983948),\n",
       "       ('pher', 0.1229400634765625),\n",
       "       ('scor', 0.11937962472438812),\n",
       "       ('', 0.09774548560380936)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.12239108234643936,\n",
       "      'top_tokens': [('ARE', 0.28814879059791565),\n",
       "       (' extrems', 0.18942268192768097),\n",
       "       ('wolves', 0.18125402927398682),\n",
       "       ('', 0.1757081300020218),\n",
       "       ('arena', 0.16546638309955597)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.10815970599651337,\n",
       "      'top_tokens': [('arb', 0.22057129442691803),\n",
       "       ('ake', 0.21301387250423431),\n",
       "       ('', 0.21097707748413086),\n",
       "       (' ', 0.18022730946540833),\n",
       "       ('icken', 0.1752103865146637)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.0999702662229538,\n",
       "      'top_tokens': [(' cercle', 0.21068866550922394),\n",
       "       ('ript', 0.20870426297187805),\n",
       "       ('nora', 0.19791080057621002),\n",
       "       ('blr', 0.19292064011096954),\n",
       "       ('>-->', 0.18977564573287964)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.09772297739982605,\n",
       "      'top_tokens': [('resco', 0.2279566526412964),\n",
       "       (' Cortes', 0.2057708352804184),\n",
       "       ('', 0.19240149855613708),\n",
       "       ('CPP', 0.18792060017585754),\n",
       "       (' diferencia', 0.18595044314861298)]},\n",
       "     {'expert_id': 35,\n",
       "      'weight': 0.09741824865341187,\n",
       "      'top_tokens': [('6', 0.23783200979232788),\n",
       "       ('9', 0.22185565531253815),\n",
       "       ('7', 0.19382421672344208),\n",
       "       ('4', 0.18466155230998993),\n",
       "       ('8', 0.16182655096054077)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.09736444801092148,\n",
       "      'top_tokens': [(' pocs', 0.23288799822330475),\n",
       "       (\"}$'\", 0.22109271585941315),\n",
       "       ('', 0.18895670771598816),\n",
       "       ('antine', 0.18547990918159485),\n",
       "       ('ssia', 0.1715826839208603)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 21,\n",
       "      'weight': 0.37697339057922363,\n",
       "      'top_tokens': [('otip', 0.5296185612678528),\n",
       "       ('thon', 0.13031622767448425),\n",
       "       ('pher', 0.12294011563062668),\n",
       "       ('scor', 0.11937961727380753),\n",
       "       ('', 0.09774550795555115)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.12239105999469757,\n",
       "      'top_tokens': [('ARE', 0.28814882040023804),\n",
       "       (' extrems', 0.18942265212535858),\n",
       "       ('wolves', 0.181254044175148),\n",
       "       ('', 0.1757081001996994),\n",
       "       ('arena', 0.16546639800071716)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.10815959423780441,\n",
       "      'top_tokens': [('arb', 0.22057127952575684),\n",
       "       ('ake', 0.21301385760307312),\n",
       "       ('', 0.2109770029783249),\n",
       "       (' ', 0.1802273839712143),\n",
       "       ('icken', 0.17521043121814728)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.09997020661830902,\n",
       "      'top_tokens': [(' cercle', 0.21068857610225677),\n",
       "       ('ript', 0.20870427787303925),\n",
       "       ('nora', 0.19791077077388763),\n",
       "       ('blr', 0.19292065501213074),\n",
       "       ('>-->', 0.18977566063404083)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.09772296249866486,\n",
       "      'top_tokens': [('resco', 0.2279566377401352),\n",
       "       (' Cortes', 0.2057708203792572),\n",
       "       ('', 0.19240157306194305),\n",
       "       ('CPP', 0.18792054057121277),\n",
       "       (' diferencia', 0.18595047295093536)]},\n",
       "     {'expert_id': 35,\n",
       "      'weight': 0.09741827100515366,\n",
       "      'top_tokens': [('6', 0.23783200979232788),\n",
       "       ('9', 0.22185565531253815),\n",
       "       ('7', 0.19382426142692566),\n",
       "       ('4', 0.18466155230998993),\n",
       "       ('8', 0.16182656586170197)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.09736441820859909,\n",
       "      'top_tokens': [(' pocs', 0.23288807272911072),\n",
       "       (\"}$'\", 0.22109289467334747),\n",
       "       ('', 0.18895667791366577),\n",
       "       ('antine', 0.1854797899723053),\n",
       "       ('ssia', 0.17158262431621552)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 21,\n",
       "      'weight': 0.3769732713699341,\n",
       "      'top_tokens': [('otip', 0.5296183824539185),\n",
       "       ('thon', 0.13031630218029022),\n",
       "       ('pher', 0.1229400709271431),\n",
       "       ('scor', 0.11937957257032394),\n",
       "       ('', 0.0977456197142601)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.12239111959934235,\n",
       "      'top_tokens': [('ARE', 0.28814879059791565),\n",
       "       (' extrems', 0.18942268192768097),\n",
       "       ('wolves', 0.18125396966934204),\n",
       "       ('', 0.17570815980434418),\n",
       "       ('arena', 0.16546641290187836)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.10815964639186859,\n",
       "      'top_tokens': [('arb', 0.22057129442691803),\n",
       "       ('ake', 0.21301381289958954),\n",
       "       ('', 0.21097701787948608),\n",
       "       (' ', 0.18022727966308594),\n",
       "       ('icken', 0.17521056532859802)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.099970243871212,\n",
       "      'top_tokens': [(' cercle', 0.21068862080574036),\n",
       "       ('ript', 0.20870432257652283),\n",
       "       ('nora', 0.19791075587272644),\n",
       "       ('blr', 0.19292061030864716),\n",
       "       ('>-->', 0.189775750041008)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.09772299975156784,\n",
       "      'top_tokens': [('resco', 0.2279566079378128),\n",
       "       (' Cortes', 0.20577089488506317),\n",
       "       ('', 0.1924014538526535),\n",
       "       ('CPP', 0.18792057037353516),\n",
       "       (' diferencia', 0.18595048785209656)]},\n",
       "     {'expert_id': 35,\n",
       "      'weight': 0.09741828590631485,\n",
       "      'top_tokens': [('6', 0.2378319799900055),\n",
       "       ('9', 0.22185556590557098),\n",
       "       ('7', 0.19382423162460327),\n",
       "       ('4', 0.18466153740882874),\n",
       "       ('8', 0.16182659566402435)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.0973643884062767,\n",
       "      'top_tokens': [(' pocs', 0.23288804292678833),\n",
       "       (\"}$'\", 0.22109276056289673),\n",
       "       ('', 0.18895670771598816),\n",
       "       ('antine', 0.18547981977462769),\n",
       "       ('ssia', 0.17158262431621552)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 21,\n",
       "      'weight': 0.3769732713699341,\n",
       "      'top_tokens': [('otip', 0.5296186208724976),\n",
       "       ('thon', 0.1303161084651947),\n",
       "       ('pher', 0.12294013053178787),\n",
       "       ('scor', 0.11937962472438812),\n",
       "       ('', 0.09774548560380936)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.12239106744527817,\n",
       "      'top_tokens': [('ARE', 0.2881487011909485),\n",
       "       (' extrems', 0.1894226223230362),\n",
       "       ('wolves', 0.1812540590763092),\n",
       "       ('', 0.17570818960666656),\n",
       "       ('arena', 0.16546639800071716)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.10815970599651337,\n",
       "      'top_tokens': [('arb', 0.2205711305141449),\n",
       "       ('ake', 0.21301396191120148),\n",
       "       ('', 0.21097701787948608),\n",
       "       (' ', 0.1802273988723755),\n",
       "       ('icken', 0.17521047592163086)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.0999702662229538,\n",
       "      'top_tokens': [(' cercle', 0.21068866550922394),\n",
       "       ('ript', 0.20870426297187805),\n",
       "       ('nora', 0.19791071116924286),\n",
       "       ('blr', 0.19292064011096954),\n",
       "       ('>-->', 0.18977579474449158)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.09772297739982605,\n",
       "      'top_tokens': [('resco', 0.2279566377401352),\n",
       "       (' Cortes', 0.20577086508274078),\n",
       "       ('', 0.19240154325962067),\n",
       "       ('CPP', 0.18792054057121277),\n",
       "       (' diferencia', 0.18595051765441895)]},\n",
       "     {'expert_id': 35,\n",
       "      'weight': 0.09741830825805664,\n",
       "      'top_tokens': [('6', 0.2378319799900055),\n",
       "       ('9', 0.22185568511486053),\n",
       "       ('7', 0.19382423162460327),\n",
       "       ('4', 0.18466149270534515),\n",
       "       ('8', 0.16182664036750793)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.0973644033074379,\n",
       "      'top_tokens': [(' pocs', 0.2328881025314331),\n",
       "       (\"}$'\", 0.22109276056289673),\n",
       "       ('', 0.18895670771598816),\n",
       "       ('antine', 0.18547981977462769),\n",
       "       ('ssia', 0.1715826392173767)]}]}}},\n",
       " 'layer_7': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.1921554058790207,\n",
       "      'top_tokens': [('akespeare', 0.21104036271572113),\n",
       "       ('alp', 0.2084648460149765),\n",
       "       ('ateful', 0.19645698368549347),\n",
       "       ('ugal', 0.1948208212852478),\n",
       "       (' turb', 0.1892169862985611)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.17775024473667145,\n",
       "      'top_tokens': [('', 0.25600501894950867),\n",
       "       ('anet', 0.22582830488681793),\n",
       "       ('', 0.19766061007976532),\n",
       "       ('', 0.16705423593521118),\n",
       "       ('arant', 0.15345177054405212)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.15260006487369537,\n",
       "      'top_tokens': [('RAW', 0.23004859685897827),\n",
       "       ('$~\\\\', 0.20684795081615448),\n",
       "       ('GiB', 0.19544313848018646),\n",
       "       ('APER', 0.18609468638896942),\n",
       "       ('obrir', 0.18156571686267853)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.14453472197055817,\n",
       "      'top_tokens': [('omla', 0.23241262137889862),\n",
       "       ('', 0.21481271088123322),\n",
       "       ('oulder', 0.1942683458328247),\n",
       "       ('equals', 0.18063496053218842),\n",
       "       ('uita', 0.17787140607833862)]},\n",
       "     {'expert_id': 2,\n",
       "      'weight': 0.12851080298423767,\n",
       "      'top_tokens': [('orat', 0.3453294038772583),\n",
       "       ('ajes', 0.1762411892414093),\n",
       "       ('hyde', 0.16122159361839294),\n",
       "       ('liter', 0.15913328528404236),\n",
       "       ('facet', 0.15807460248470306)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10639645159244537,\n",
       "      'top_tokens': [('istable', 0.25743797421455383),\n",
       "       ('anell', 0.24131162464618683),\n",
       "       ('', 0.19417618215084076),\n",
       "       ('ocada', 0.18599581718444824),\n",
       "       ('ocell', 0.12107833474874496)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.0980522409081459,\n",
       "      'top_tokens': [(' optar', 0.22201253473758698),\n",
       "       ('lady', 0.19958588480949402),\n",
       "       ('offee', 0.19958098232746124),\n",
       "       ('itas', 0.19403107464313507),\n",
       "       ('Issue', 0.1847895085811615)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.19215549528598785,\n",
       "      'top_tokens': [('akespeare', 0.2110404670238495),\n",
       "       ('alp', 0.20846469700336456),\n",
       "       ('ateful', 0.19645704329013824),\n",
       "       ('ugal', 0.1948208063840866),\n",
       "       (' turb', 0.18921694159507751)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.17775027453899384,\n",
       "      'top_tokens': [('', 0.2560049295425415),\n",
       "       ('anet', 0.22582823038101196),\n",
       "       ('', 0.1976606398820877),\n",
       "       ('', 0.16705426573753357),\n",
       "       ('arant', 0.15345193445682526)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.15260010957717896,\n",
       "      'top_tokens': [('RAW', 0.23004859685897827),\n",
       "       ('$~\\\\', 0.20684805512428284),\n",
       "       ('GiB', 0.19544309377670288),\n",
       "       ('APER', 0.18609464168548584),\n",
       "       ('obrir', 0.1815655529499054)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.14453475177288055,\n",
       "      'top_tokens': [('omla', 0.23241256177425385),\n",
       "       ('', 0.21481271088123322),\n",
       "       ('oulder', 0.19426821172237396),\n",
       "       ('equals', 0.18063491582870483),\n",
       "       ('uita', 0.17787154018878937)]},\n",
       "     {'expert_id': 2,\n",
       "      'weight': 0.12851081788539886,\n",
       "      'top_tokens': [('orat', 0.3453294038772583),\n",
       "       ('ajes', 0.17624109983444214),\n",
       "       ('hyde', 0.16122154891490936),\n",
       "       ('liter', 0.15913324058055878),\n",
       "       ('facet', 0.15807460248470306)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10639643669128418,\n",
       "      'top_tokens': [('istable', 0.257438063621521),\n",
       "       ('anell', 0.241311714053154),\n",
       "       ('', 0.1941760629415512),\n",
       "       ('ocada', 0.18599580228328705),\n",
       "       ('ocell', 0.12107831239700317)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.09805221855640411,\n",
       "      'top_tokens': [(' optar', 0.22201256453990936),\n",
       "       ('lady', 0.1995859146118164),\n",
       "       ('offee', 0.19958101212978363),\n",
       "       ('itas', 0.19403095543384552),\n",
       "       ('Issue', 0.18478956818580627)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.19215551018714905,\n",
       "      'top_tokens': [('akespeare', 0.21104034781455994),\n",
       "       ('alp', 0.20846472680568695),\n",
       "       ('ateful', 0.19645705819129944),\n",
       "       ('ugal', 0.1948208510875702),\n",
       "       (' turb', 0.1892169713973999)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.17775030434131622,\n",
       "      'top_tokens': [('', 0.25600484013557434),\n",
       "       ('anet', 0.2258283644914627),\n",
       "       ('', 0.19766075909137726),\n",
       "       ('', 0.16705411672592163),\n",
       "       ('arant', 0.15345187485218048)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.15260004997253418,\n",
       "      'top_tokens': [('RAW', 0.2300485223531723),\n",
       "       ('$~\\\\', 0.20684804022312164),\n",
       "       ('GiB', 0.19544321298599243),\n",
       "       ('APER', 0.18609458208084106),\n",
       "       ('obrir', 0.18156570196151733)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.14453472197055817,\n",
       "      'top_tokens': [('omla', 0.2324126660823822),\n",
       "       ('', 0.21481265127658844),\n",
       "       ('oulder', 0.19426825642585754),\n",
       "       ('equals', 0.18063491582870483),\n",
       "       ('uita', 0.1778714954853058)]},\n",
       "     {'expert_id': 2,\n",
       "      'weight': 0.12851077318191528,\n",
       "      'top_tokens': [('orat', 0.3453294634819031),\n",
       "       ('ajes', 0.17624108493328094),\n",
       "       ('hyde', 0.16122150421142578),\n",
       "       ('liter', 0.15913331508636475),\n",
       "       ('facet', 0.15807458758354187)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10639642924070358,\n",
       "      'top_tokens': [('istable', 0.2574380040168762),\n",
       "       ('anell', 0.24131177365779877),\n",
       "       ('', 0.1941761076450348),\n",
       "       ('ocada', 0.18599575757980347),\n",
       "       ('ocell', 0.12107828259468079)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.09805222600698471,\n",
       "      'top_tokens': [(' optar', 0.22201259434223175),\n",
       "       ('lady', 0.1995859444141388),\n",
       "       ('offee', 0.19958090782165527),\n",
       "       ('itas', 0.1940309852361679),\n",
       "       ('Issue', 0.18478959798812866)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.19215548038482666,\n",
       "      'top_tokens': [('akespeare', 0.2110404521226883),\n",
       "       ('alp', 0.2084648311138153),\n",
       "       ('ateful', 0.19645696878433228),\n",
       "       ('ugal', 0.1948208063840866),\n",
       "       (' turb', 0.1892169862985611)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.17775022983551025,\n",
       "      'top_tokens': [('', 0.25600478053092957),\n",
       "       ('anet', 0.22582821547985077),\n",
       "       ('', 0.19766071438789368),\n",
       "       ('', 0.16705432534217834),\n",
       "       ('arant', 0.15345199406147003)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.15260010957717896,\n",
       "      'top_tokens': [('RAW', 0.23004856705665588),\n",
       "       ('$~\\\\', 0.2068479210138321),\n",
       "       ('GiB', 0.1954430639743805),\n",
       "       ('APER', 0.18609470129013062),\n",
       "       ('obrir', 0.18156570196151733)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.14453473687171936,\n",
       "      'top_tokens': [('omla', 0.23241256177425385),\n",
       "       ('', 0.21481262147426605),\n",
       "       ('oulder', 0.19426830112934113),\n",
       "       ('equals', 0.180635005235672),\n",
       "       ('uita', 0.1778714507818222)]},\n",
       "     {'expert_id': 2,\n",
       "      'weight': 0.12851081788539886,\n",
       "      'top_tokens': [('orat', 0.3453294634819031),\n",
       "       ('ajes', 0.1762411743402481),\n",
       "       ('hyde', 0.16122162342071533),\n",
       "       ('liter', 0.15913327038288116),\n",
       "       ('facet', 0.1580745428800583)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10639643669128418,\n",
       "      'top_tokens': [('istable', 0.2574380040168762),\n",
       "       ('anell', 0.24131165444850922),\n",
       "       ('', 0.19417619705200195),\n",
       "       ('ocada', 0.18599575757980347),\n",
       "       ('ocell', 0.12107834964990616)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.09805219620466232,\n",
       "      'top_tokens': [(' optar', 0.22201251983642578),\n",
       "       ('lady', 0.19958588480949402),\n",
       "       ('offee', 0.19958096742630005),\n",
       "       ('itas', 0.1940310001373291),\n",
       "       ('Issue', 0.18478958308696747)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.19215548038482666,\n",
       "      'top_tokens': [('akespeare', 0.21104039251804352),\n",
       "       ('alp', 0.20846477150917053),\n",
       "       ('ateful', 0.19645710289478302),\n",
       "       ('ugal', 0.19482079148292542),\n",
       "       (' turb', 0.1892169862985611)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.17775021493434906,\n",
       "      'top_tokens': [('', 0.25600484013557434),\n",
       "       ('anet', 0.2258283644914627),\n",
       "       ('', 0.1976606696844101),\n",
       "       ('', 0.16705422103405),\n",
       "       ('arant', 0.15345194935798645)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.15260009467601776,\n",
       "      'top_tokens': [('RAW', 0.23004870116710663),\n",
       "       ('$~\\\\', 0.20684804022312164),\n",
       "       ('GiB', 0.19544309377670288),\n",
       "       ('APER', 0.18609455227851868),\n",
       "       ('obrir', 0.18156567215919495)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.14453476667404175,\n",
       "      'top_tokens': [('omla', 0.23241262137889862),\n",
       "       ('', 0.21481266617774963),\n",
       "       ('oulder', 0.19426831603050232),\n",
       "       ('equals', 0.18063496053218842),\n",
       "       ('uita', 0.17787154018878937)]},\n",
       "     {'expert_id': 2,\n",
       "      'weight': 0.12851077318191528,\n",
       "      'top_tokens': [('orat', 0.34532925486564636),\n",
       "       ('ajes', 0.1762411892414093),\n",
       "       ('hyde', 0.16122159361839294),\n",
       "       ('liter', 0.15913328528404236),\n",
       "       ('facet', 0.15807464718818665)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10639635473489761,\n",
       "      'top_tokens': [('istable', 0.25743791460990906),\n",
       "       ('anell', 0.2413119226694107),\n",
       "       ('', 0.19417613744735718),\n",
       "       ('ocada', 0.1859956979751587),\n",
       "       ('ocell', 0.12107830494642258)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.09805218130350113,\n",
       "      'top_tokens': [(' optar', 0.22201260924339294),\n",
       "       ('lady', 0.1995859593153),\n",
       "       ('offee', 0.19958095252513885),\n",
       "       ('itas', 0.19403095543384552),\n",
       "       ('Issue', 0.18478959798812866)]}]}}},\n",
       " 'layer_8': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.2051885575056076,\n",
       "      'top_tokens': [('ilitat', 0.25535979866981506),\n",
       "       ('', 0.21678176522254944),\n",
       "       ('ALES', 0.19088797271251678),\n",
       "       ('letes', 0.18402087688446045),\n",
       "       ('boxt', 0.15294955670833588)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.14370518922805786,\n",
       "      'top_tokens': [('', 0.20841291546821594),\n",
       "       ('', 0.206244558095932),\n",
       "       ('', 0.20020073652267456),\n",
       "       ('', 0.19446511566638947),\n",
       "       ('', 0.19067664444446564)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.14227233827114105,\n",
       "      'top_tokens': [('', 0.3503228425979614),\n",
       "       ('nicamente', 0.18804097175598145),\n",
       "       ('bic', 0.16220149397850037),\n",
       "       ('uta', 0.15707756578922272),\n",
       "       ('', 0.14235709607601166)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.13431066274642944,\n",
       "      'top_tokens': [('', 0.23355916142463684),\n",
       "       ('CDF', 0.2236609309911728),\n",
       "       ('ilst', 0.191977858543396),\n",
       "       ('romy', 0.17962661385536194),\n",
       "       (' shifter', 0.17117547988891602)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.12603509426116943,\n",
       "      'top_tokens': [('', 0.32065045833587646),\n",
       "       ('', 0.1874198019504547),\n",
       "       ('ish', 0.17557866871356964),\n",
       "       ('', 0.15995678305625916),\n",
       "       ('Inst', 0.15639428794384003)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.12508703768253326,\n",
       "      'top_tokens': [('9', 0.22286273539066315),\n",
       "       ('=\"../_', 0.21002303063869476),\n",
       "       ('1', 0.2036331593990326),\n",
       "       ('', 0.18811720609664917),\n",
       "       ('8', 0.17536383867263794)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.12340118736028671,\n",
       "      'top_tokens': [('8', 0.23461057245731354),\n",
       "       ('1', 0.2246294915676117),\n",
       "       ('hana', 0.18547749519348145),\n",
       "       ('6', 0.17812874913215637),\n",
       "       ('4', 0.17715366184711456)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.20518861711025238,\n",
       "      'top_tokens': [('ilitat', 0.2553598880767822),\n",
       "       ('', 0.21678178012371063),\n",
       "       ('ALES', 0.190887913107872),\n",
       "       ('letes', 0.18402089178562164),\n",
       "       ('boxt', 0.1529495269060135)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.14370515942573547,\n",
       "      'top_tokens': [('', 0.20841294527053833),\n",
       "       ('', 0.20624451339244843),\n",
       "       ('', 0.20020069181919098),\n",
       "       ('', 0.19446517527103424),\n",
       "       ('', 0.19067667424678802)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.14227229356765747,\n",
       "      'top_tokens': [('', 0.3503227233886719),\n",
       "       ('nicamente', 0.188041090965271),\n",
       "       ('bic', 0.16220144927501678),\n",
       "       ('uta', 0.15707765519618988),\n",
       "       ('', 0.14235705137252808)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.13431066274642944,\n",
       "      'top_tokens': [('', 0.23355913162231445),\n",
       "       ('CDF', 0.2236609011888504),\n",
       "       ('ilst', 0.19197776913642883),\n",
       "       ('romy', 0.17962664365768433),\n",
       "       (' shifter', 0.1711754947900772)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.12603503465652466,\n",
       "      'top_tokens': [('', 0.320650577545166),\n",
       "       ('', 0.1874198615550995),\n",
       "       ('ish', 0.1755785197019577),\n",
       "       ('', 0.159956693649292),\n",
       "       ('Inst', 0.15639430284500122)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.12508700788021088,\n",
       "      'top_tokens': [('9', 0.2228628545999527),\n",
       "       ('=\"../_', 0.2100229114294052),\n",
       "       ('1', 0.203633114695549),\n",
       "       ('', 0.18811717629432678),\n",
       "       ('8', 0.17536388337612152)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.12340118736028671,\n",
       "      'top_tokens': [('8', 0.23461073637008667),\n",
       "       ('1', 0.22462943196296692),\n",
       "       ('hana', 0.18547748029232025),\n",
       "       ('6', 0.17812874913215637),\n",
       "       ('4', 0.17715364694595337)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.20518843829631805,\n",
       "      'top_tokens': [('ilitat', 0.25535982847213745),\n",
       "       ('', 0.21678173542022705),\n",
       "       ('ALES', 0.1908879578113556),\n",
       "       ('letes', 0.18402089178562164),\n",
       "       ('boxt', 0.15294954180717468)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.14370517432689667,\n",
       "      'top_tokens': [('', 0.20841294527053833),\n",
       "       ('', 0.20624451339244843),\n",
       "       ('', 0.200200617313385),\n",
       "       ('', 0.19446519017219543),\n",
       "       ('', 0.19067667424678802)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.14227230846881866,\n",
       "      'top_tokens': [('', 0.3503228425979614),\n",
       "       ('nicamente', 0.18804116547107697),\n",
       "       ('bic', 0.1622014343738556),\n",
       "       ('uta', 0.15707756578922272),\n",
       "       ('', 0.1423570215702057)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.13431069254875183,\n",
       "      'top_tokens': [('', 0.23355911672115326),\n",
       "       ('CDF', 0.22366082668304443),\n",
       "       ('ilst', 0.191977858543396),\n",
       "       ('romy', 0.17962665855884552),\n",
       "       (' shifter', 0.1711755096912384)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.12603510916233063,\n",
       "      'top_tokens': [('', 0.320650577545166),\n",
       "       ('', 0.1874198019504547),\n",
       "       ('ish', 0.17557865381240845),\n",
       "       ('', 0.159956693649292),\n",
       "       ('Inst', 0.1563943475484848)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.12508706748485565,\n",
       "      'top_tokens': [('9', 0.22286280989646912),\n",
       "       ('=\"../_', 0.21002306044101715),\n",
       "       ('1', 0.20363302528858185),\n",
       "       ('', 0.18811722099781036),\n",
       "       ('8', 0.17536380887031555)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.1234012246131897,\n",
       "      'top_tokens': [('8', 0.2346106320619583),\n",
       "       ('1', 0.2246294915676117),\n",
       "       ('hana', 0.1854773610830307),\n",
       "       ('6', 0.17812883853912354),\n",
       "       ('4', 0.17715370655059814)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.2051885724067688,\n",
       "      'top_tokens': [('ilitat', 0.25535979866981506),\n",
       "       ('', 0.2167818248271942),\n",
       "       ('ALES', 0.1908879280090332),\n",
       "       ('letes', 0.18402087688446045),\n",
       "       ('boxt', 0.15294958651065826)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.14370514452457428,\n",
       "      'top_tokens': [('', 0.20841294527053833),\n",
       "       ('', 0.2062445729970932),\n",
       "       ('', 0.20020075142383575),\n",
       "       ('', 0.19446514546871185),\n",
       "       ('', 0.19067656993865967)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.14227226376533508,\n",
       "      'top_tokens': [('', 0.3503226637840271),\n",
       "       ('nicamente', 0.1880410611629486),\n",
       "       ('bic', 0.1622014194726944),\n",
       "       ('uta', 0.1570776253938675),\n",
       "       ('', 0.14235715568065643)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.13431067764759064,\n",
       "      'top_tokens': [('', 0.2335590273141861),\n",
       "       ('CDF', 0.22366085648536682),\n",
       "       ('ilst', 0.19197793304920197),\n",
       "       ('romy', 0.17962665855884552),\n",
       "       (' shifter', 0.1711754947900772)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.12603512406349182,\n",
       "      'top_tokens': [('', 0.320650577545166),\n",
       "       ('', 0.1874198019504547),\n",
       "       ('ish', 0.17557868361473083),\n",
       "       ('', 0.159956693649292),\n",
       "       ('Inst', 0.15639419853687286)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.12508706748485565,\n",
       "      'top_tokens': [('9', 0.22286291420459747),\n",
       "       ('=\"../_', 0.21002297103405),\n",
       "       ('1', 0.2036331295967102),\n",
       "       ('', 0.18811717629432678),\n",
       "       ('8', 0.17536385357379913)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.12340115755796432,\n",
       "      'top_tokens': [('8', 0.23461054265499115),\n",
       "       ('1', 0.2246294617652893),\n",
       "       ('hana', 0.18547751009464264),\n",
       "       ('6', 0.17812880873680115),\n",
       "       ('4', 0.17715366184711456)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 41,\n",
       "      'weight': 0.20518849790096283,\n",
       "      'top_tokens': [('ilitat', 0.2553597092628479),\n",
       "       ('', 0.2167818546295166),\n",
       "       ('ALES', 0.19088804721832275),\n",
       "       ('letes', 0.18402095139026642),\n",
       "       ('boxt', 0.1529495269060135)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.14370518922805786,\n",
       "      'top_tokens': [('', 0.20841294527053833),\n",
       "       ('', 0.20624449849128723),\n",
       "       ('', 0.20020069181919098),\n",
       "       ('', 0.19446517527103424),\n",
       "       ('', 0.19067661464214325)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.14227229356765747,\n",
       "      'top_tokens': [('', 0.350322961807251),\n",
       "       ('nicamente', 0.18804103136062622),\n",
       "       ('bic', 0.1622014045715332),\n",
       "       ('uta', 0.1570776253938675),\n",
       "       ('', 0.1423569917678833)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.13431069254875183,\n",
       "      'top_tokens': [('', 0.23355919122695923),\n",
       "       ('CDF', 0.22366084158420563),\n",
       "       ('ilst', 0.19197778403759003),\n",
       "       ('romy', 0.1796267181634903),\n",
       "       (' shifter', 0.17117547988891602)]},\n",
       "     {'expert_id': 6,\n",
       "      'weight': 0.12603507936000824,\n",
       "      'top_tokens': [('', 0.32065054774284363),\n",
       "       ('', 0.1874198466539383),\n",
       "       ('ish', 0.17557863891124725),\n",
       "       ('', 0.15995670855045319),\n",
       "       ('Inst', 0.15639428794384003)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.12508702278137207,\n",
       "      'top_tokens': [('9', 0.22286279499530792),\n",
       "       ('=\"../_', 0.21002314984798431),\n",
       "       ('1', 0.20363305509090424),\n",
       "       ('', 0.18811720609664917),\n",
       "       ('8', 0.17536383867263794)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.12340119481086731,\n",
       "      'top_tokens': [('8', 0.23461051285266876),\n",
       "       ('1', 0.22462943196296692),\n",
       "       ('hana', 0.18547753989696503),\n",
       "       ('6', 0.17812877893447876),\n",
       "       ('4', 0.17715373635292053)]}]}}},\n",
       " 'layer_9': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.20744650065898895,\n",
       "      'top_tokens': [(' der', 0.2315765619277954),\n",
       "       (' Fort', 0.2124544084072113),\n",
       "       ('itty', 0.20589511096477509),\n",
       "       (' fits', 0.17878274619579315),\n",
       "       (' rather', 0.17129118740558624)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.18817640841007233,\n",
       "      'top_tokens': [('', 0.2518880367279053),\n",
       "       ('', 0.2181910127401352),\n",
       "       ('', 0.19532792270183563),\n",
       "       ('sonian', 0.17142872512340546),\n",
       "       ('bology', 0.16316437721252441)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.12574800848960876,\n",
       "      'top_tokens': [('', 0.26313677430152893),\n",
       "       ('ATERIAL', 0.21329817175865173),\n",
       "       ('', 0.1830158829689026),\n",
       "       ('gence', 0.17748203873634338),\n",
       "       (' apreciar', 0.16306708753108978)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.12427380681037903,\n",
       "      'top_tokens': [('moor', 0.24750500917434692),\n",
       "       (' Rouge', 0.21790413558483124),\n",
       "       ('elessly', 0.19009850919246674),\n",
       "       ('', 0.1773131787776947),\n",
       "       (' ', 0.16717904806137085)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.12031704932451248,\n",
       "      'top_tokens': [('', 0.2681617736816406),\n",
       "       ('', 0.2148154228925705),\n",
       "       ('ISTER', 0.19339002668857574),\n",
       "       ('', 0.16468144953250885),\n",
       "       ('', 0.1589512974023819)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.11917091906070709,\n",
       "      'top_tokens': [('v', 0.3746193051338196),\n",
       "       ('olla', 0.16851985454559326),\n",
       "       ('', 0.16245576739311218),\n",
       "       ('odec', 0.15014955401420593),\n",
       "       ('end', 0.1442556083202362)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11486726254224777,\n",
       "      'top_tokens': [('', 0.2652546167373657),\n",
       "       ('LASS', 0.1926749348640442),\n",
       "       ('', 0.1916273534297943),\n",
       "       ('pee', 0.1780584752559662),\n",
       "       ('', 0.17238469421863556)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.20744648575782776,\n",
       "      'top_tokens': [(' der', 0.23157641291618347),\n",
       "       (' Fort', 0.2124544382095337),\n",
       "       ('itty', 0.20589527487754822),\n",
       "       (' fits', 0.17878270149230957),\n",
       "       (' rather', 0.17129118740558624)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.18817652761936188,\n",
       "      'top_tokens': [('', 0.25188809633255005),\n",
       "       ('', 0.21819084882736206),\n",
       "       ('', 0.19532787799835205),\n",
       "       ('sonian', 0.17142868041992188),\n",
       "       ('bology', 0.163164421916008)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.12574805319309235,\n",
       "      'top_tokens': [('', 0.2631368339061737),\n",
       "       ('ATERIAL', 0.21329791843891144),\n",
       "       ('', 0.1830160915851593),\n",
       "       ('gence', 0.1774819940328598),\n",
       "       (' apreciar', 0.16306720674037933)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.12427373230457306,\n",
       "      'top_tokens': [('moor', 0.24750494956970215),\n",
       "       (' Rouge', 0.21790418028831482),\n",
       "       ('elessly', 0.19009865820407867),\n",
       "       ('', 0.17731305956840515),\n",
       "       (' ', 0.16717924177646637)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.12031704187393188,\n",
       "      'top_tokens': [('', 0.2681618928909302),\n",
       "       ('', 0.21481551229953766),\n",
       "       ('ISTER', 0.19339001178741455),\n",
       "       ('', 0.1646813601255417),\n",
       "       ('', 0.1589512825012207)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.11917087435722351,\n",
       "      'top_tokens': [('v', 0.3746195435523987),\n",
       "       ('olla', 0.1685197353363037),\n",
       "       ('', 0.1624557077884674),\n",
       "       ('odec', 0.15014943480491638),\n",
       "       ('end', 0.144255593419075)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11486721783876419,\n",
       "      'top_tokens': [('', 0.26525455713272095),\n",
       "       ('LASS', 0.1926749348640442),\n",
       "       ('', 0.19162721931934357),\n",
       "       ('pee', 0.1780584454536438),\n",
       "       ('', 0.1723848134279251)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.20744645595550537,\n",
       "      'top_tokens': [(' der', 0.2315765917301178),\n",
       "       (' Fort', 0.21245449781417847),\n",
       "       ('itty', 0.2058950811624527),\n",
       "       (' fits', 0.1787826418876648),\n",
       "       (' rather', 0.17129115760326385)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.18817655742168427,\n",
       "      'top_tokens': [('', 0.25188785791397095),\n",
       "       ('', 0.21819128096103668),\n",
       "       ('', 0.1953277885913849),\n",
       "       ('sonian', 0.17142868041992188),\n",
       "       ('bology', 0.16316434741020203)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.12574803829193115,\n",
       "      'top_tokens': [('', 0.2631366550922394),\n",
       "       ('ATERIAL', 0.21329817175865173),\n",
       "       ('', 0.18301579356193542),\n",
       "       ('gence', 0.17748194932937622),\n",
       "       (' apreciar', 0.16306732594966888)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.12427376210689545,\n",
       "      'top_tokens': [('moor', 0.24750500917434692),\n",
       "       (' Rouge', 0.21790434420108795),\n",
       "       ('elessly', 0.19009824097156525),\n",
       "       ('', 0.1773131787776947),\n",
       "       (' ', 0.1671791970729828)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.1203170120716095,\n",
       "      'top_tokens': [('', 0.2681620121002197),\n",
       "       ('', 0.21481530368328094),\n",
       "       ('ISTER', 0.1933899223804474),\n",
       "       ('', 0.16468143463134766),\n",
       "       ('', 0.1589512825012207)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.1191708967089653,\n",
       "      'top_tokens': [('v', 0.3746193051338196),\n",
       "       ('olla', 0.1685197800397873),\n",
       "       ('', 0.16245591640472412),\n",
       "       ('odec', 0.15014947950839996),\n",
       "       ('end', 0.14425557851791382)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11486722528934479,\n",
       "      'top_tokens': [('', 0.2652546167373657),\n",
       "       ('LASS', 0.1926748901605606),\n",
       "       ('', 0.1916273832321167),\n",
       "       ('pee', 0.17805835604667664),\n",
       "       ('', 0.17238476872444153)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.20744650065898895,\n",
       "      'top_tokens': [(' der', 0.231576606631279),\n",
       "       (' Fort', 0.21245431900024414),\n",
       "       ('itty', 0.2058950960636139),\n",
       "       (' fits', 0.17878267168998718),\n",
       "       (' rather', 0.1712912619113922)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.18817658722400665,\n",
       "      'top_tokens': [('', 0.2518879175186157),\n",
       "       ('', 0.21819111704826355),\n",
       "       ('', 0.1953277438879013),\n",
       "       ('sonian', 0.17142872512340546),\n",
       "       ('bology', 0.16316445171833038)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.12574803829193115,\n",
       "      'top_tokens': [('', 0.2631366550922394),\n",
       "       ('ATERIAL', 0.21329817175865173),\n",
       "       ('', 0.1830156296491623),\n",
       "       ('gence', 0.17748212814331055),\n",
       "       (' apreciar', 0.16306740045547485)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.12427379190921783,\n",
       "      'top_tokens': [('moor', 0.2475050687789917),\n",
       "       (' Rouge', 0.21790418028831482),\n",
       "       ('elessly', 0.19009821116924286),\n",
       "       ('', 0.17731331288814545),\n",
       "       (' ', 0.1671791672706604)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.12031695246696472,\n",
       "      'top_tokens': [('', 0.26816174387931824),\n",
       "       ('', 0.2148153930902481),\n",
       "       ('ISTER', 0.19338999688625336),\n",
       "       ('', 0.16468150913715363),\n",
       "       ('', 0.1589512825012207)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.11917084455490112,\n",
       "      'top_tokens': [('v', 0.3746192455291748),\n",
       "       ('olla', 0.1685197502374649),\n",
       "       ('', 0.16245590150356293),\n",
       "       ('odec', 0.15014953911304474),\n",
       "       ('end', 0.1442556530237198)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11486724019050598,\n",
       "      'top_tokens': [('', 0.2652546465396881),\n",
       "       ('LASS', 0.1926749050617218),\n",
       "       ('', 0.19162721931934357),\n",
       "       ('pee', 0.178058460354805),\n",
       "       ('', 0.17238475382328033)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.20744644105434418,\n",
       "      'top_tokens': [(' der', 0.23157666623592377),\n",
       "       (' Fort', 0.21245451271533966),\n",
       "       ('itty', 0.2058950513601303),\n",
       "       (' fits', 0.17878255248069763),\n",
       "       (' rather', 0.17129121720790863)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.18817652761936188,\n",
       "      'top_tokens': [('', 0.2518879473209381),\n",
       "       ('', 0.21819114685058594),\n",
       "       ('', 0.1953277736902237),\n",
       "       ('sonian', 0.17142866551876068),\n",
       "       ('bology', 0.1631644070148468)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.12574803829193115,\n",
       "      'top_tokens': [('', 0.26313671469688416),\n",
       "       ('ATERIAL', 0.213298037648201),\n",
       "       ('', 0.183015838265419),\n",
       "       ('gence', 0.17748217284679413),\n",
       "       (' apreciar', 0.16306720674037933)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.12427380681037903,\n",
       "      'top_tokens': [('moor', 0.24750518798828125),\n",
       "       (' Rouge', 0.21790409088134766),\n",
       "       ('elessly', 0.19009838998317719),\n",
       "       ('', 0.17731313407421112),\n",
       "       (' ', 0.1671791672706604)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.1203170195221901,\n",
       "      'top_tokens': [('', 0.2681618928909302),\n",
       "       ('', 0.21481530368328094),\n",
       "       ('ISTER', 0.19339001178741455),\n",
       "       ('', 0.1646815985441208),\n",
       "       ('', 0.1589512825012207)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.1191709116101265,\n",
       "      'top_tokens': [('v', 0.37461933493614197),\n",
       "       ('olla', 0.1685197949409485),\n",
       "       ('', 0.16245593130588531),\n",
       "       ('odec', 0.15014949440956116),\n",
       "       ('end', 0.14425547420978546)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11486725509166718,\n",
       "      'top_tokens': [('', 0.2652547061443329),\n",
       "       ('LASS', 0.1926749050617218),\n",
       "       ('', 0.19162726402282715),\n",
       "       ('pee', 0.17805832624435425),\n",
       "       ('', 0.1723848283290863)]}]}}},\n",
       " 'layer_10': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 48,\n",
       "      'weight': 0.1750989407300949,\n",
       "      'top_tokens': [('inette', 0.33339470624923706),\n",
       "       ('vature', 0.19470103085041046),\n",
       "       ('', 0.18047653138637543),\n",
       "       ('rame', 0.16156627237796783),\n",
       "       ('ANCE', 0.129861518740654)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.1574268937110901,\n",
       "      'top_tokens': [('', 0.2358732670545578),\n",
       "       ('x', 0.20991170406341553),\n",
       "       ('terminal', 0.1989423632621765),\n",
       "       ('iaci', 0.18046128749847412),\n",
       "       ('icus', 0.17481134831905365)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.1434623748064041,\n",
       "      'top_tokens': [('fog', 0.20990726351737976),\n",
       "       ('ock', 0.20871815085411072),\n",
       "       ('ig', 0.2002314031124115),\n",
       "       ('', 0.19941364228725433),\n",
       "       ('pires', 0.1817295104265213)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.14000815153121948,\n",
       "      'top_tokens': [('3', 0.24771392345428467),\n",
       "       ('0', 0.22945018112659454),\n",
       "       ('1', 0.22735919058322906),\n",
       "       ('6', 0.1478009670972824),\n",
       "       ('2', 0.14767581224441528)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.13709700107574463,\n",
       "      'top_tokens': [('miral', 0.28177374601364136),\n",
       "       ('\\xa0part', 0.20063363015651703),\n",
       "       ('', 0.1823395937681198),\n",
       "       ('matical', 0.17343434691429138),\n",
       "       ('rode', 0.1618186980485916)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.13561564683914185,\n",
       "      'top_tokens': [('East', 0.36967939138412476),\n",
       "       (' East', 0.16649594902992249),\n",
       "       ('', 0.1634090542793274),\n",
       "       ('eln', 0.15326522290706635),\n",
       "       ('tect', 0.14715039730072021)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.11129108816385269,\n",
       "      'top_tokens': [('', 0.2507205903530121),\n",
       "       ('itat', 0.2076670378446579),\n",
       "       ('forter', 0.1824243813753128),\n",
       "       ('EVER', 0.18152563273906708),\n",
       "       ('', 0.17766231298446655)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 48,\n",
       "      'weight': 0.17509907484054565,\n",
       "      'top_tokens': [('inette', 0.33339476585388184),\n",
       "       ('vature', 0.19470103085041046),\n",
       "       ('', 0.18047651648521423),\n",
       "       ('rame', 0.1615661382675171),\n",
       "       ('ANCE', 0.12986153364181519)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.15742698311805725,\n",
       "      'top_tokens': [('', 0.235873281955719),\n",
       "       ('x', 0.20991192758083344),\n",
       "       ('terminal', 0.19894246757030487),\n",
       "       ('iaci', 0.18046128749847412),\n",
       "       ('icus', 0.17481102049350739)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.14346222579479218,\n",
       "      'top_tokens': [('fog', 0.20990724861621857),\n",
       "       ('ock', 0.20871798694133759),\n",
       "       ('ig', 0.20023134350776672),\n",
       "       ('', 0.1994137167930603),\n",
       "       ('pires', 0.18172967433929443)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.1400081366300583,\n",
       "      'top_tokens': [('3', 0.24771398305892944),\n",
       "       ('0', 0.2294500172138214),\n",
       "       ('1', 0.22735914587974548),\n",
       "       ('6', 0.1478009968996048),\n",
       "       ('2', 0.14767590165138245)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.13709698617458344,\n",
       "      'top_tokens': [('miral', 0.28177356719970703),\n",
       "       ('\\xa0part', 0.20063388347625732),\n",
       "       ('', 0.1823394000530243),\n",
       "       ('matical', 0.173434317111969),\n",
       "       ('rode', 0.16181883215904236)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.13561558723449707,\n",
       "      'top_tokens': [('East', 0.3696792423725128),\n",
       "       (' East', 0.16649596393108368),\n",
       "       ('', 0.16340894997119904),\n",
       "       ('eln', 0.15326526761054993),\n",
       "       ('tect', 0.14715059101581573)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.11129108816385269,\n",
       "      'top_tokens': [('', 0.25072041153907776),\n",
       "       ('itat', 0.20766699314117432),\n",
       "       ('forter', 0.1824243813753128),\n",
       "       ('EVER', 0.1815258413553238),\n",
       "       ('', 0.17766225337982178)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 48,\n",
       "      'weight': 0.17509903013706207,\n",
       "      'top_tokens': [('inette', 0.3333945572376251),\n",
       "       ('vature', 0.19470104575157166),\n",
       "       ('', 0.18047656118869781),\n",
       "       ('rame', 0.16156627237796783),\n",
       "       ('ANCE', 0.129861518740654)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.15742695331573486,\n",
       "      'top_tokens': [('', 0.23587317764759064),\n",
       "       ('x', 0.20991173386573792),\n",
       "       ('terminal', 0.1989426612854004),\n",
       "       ('iaci', 0.18046121299266815),\n",
       "       ('icus', 0.17481110990047455)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.1434621661901474,\n",
       "      'top_tokens': [('fog', 0.20990729331970215),\n",
       "       ('ock', 0.20871803164482117),\n",
       "       ('ig', 0.20023134350776672),\n",
       "       ('', 0.19941367208957672),\n",
       "       ('pires', 0.18172967433929443)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.14000798761844635,\n",
       "      'top_tokens': [('3', 0.24771395325660706),\n",
       "       ('0', 0.22945009171962738),\n",
       "       ('1', 0.2273591160774231),\n",
       "       ('6', 0.14780105650424957),\n",
       "       ('2', 0.14767587184906006)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.13709698617458344,\n",
       "      'top_tokens': [('miral', 0.2817736566066742),\n",
       "       ('\\xa0part', 0.20063376426696777),\n",
       "       ('', 0.1823393553495407),\n",
       "       ('matical', 0.17343436181545258),\n",
       "       ('rode', 0.16181887686252594)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.13561567664146423,\n",
       "      'top_tokens': [('East', 0.36967918276786804),\n",
       "       (' East', 0.16649602353572845),\n",
       "       ('', 0.16340896487236023),\n",
       "       ('eln', 0.15326520800590515),\n",
       "       ('tect', 0.14715056121349335)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.1112910807132721,\n",
       "      'top_tokens': [('', 0.2507205307483673),\n",
       "       ('itat', 0.20766709744930267),\n",
       "       ('forter', 0.1824243664741516),\n",
       "       ('EVER', 0.18152575194835663),\n",
       "       ('', 0.17766226828098297)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 48,\n",
       "      'weight': 0.17509903013706207,\n",
       "      'top_tokens': [('inette', 0.33339473605155945),\n",
       "       ('vature', 0.19470097124576569),\n",
       "       ('', 0.18047654628753662),\n",
       "       ('rame', 0.1615661233663559),\n",
       "       ('ANCE', 0.12986162304878235)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.1574268639087677,\n",
       "      'top_tokens': [('', 0.235873281955719),\n",
       "       ('x', 0.20991192758083344),\n",
       "       ('terminal', 0.19894246757030487),\n",
       "       ('iaci', 0.18046121299266815),\n",
       "       ('icus', 0.17481110990047455)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.14346225559711456,\n",
       "      'top_tokens': [('fog', 0.20990724861621857),\n",
       "       ('ock', 0.20871809124946594),\n",
       "       ('ig', 0.2002314031124115),\n",
       "       ('', 0.19941364228725433),\n",
       "       ('pires', 0.18172967433929443)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.1400081366300583,\n",
       "      'top_tokens': [('3', 0.24771398305892944),\n",
       "       ('0', 0.22945012152194977),\n",
       "       ('1', 0.22735914587974548),\n",
       "       ('6', 0.1478009968996048),\n",
       "       ('2', 0.1476757526397705)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.1370970457792282,\n",
       "      'top_tokens': [('miral', 0.28177371621131897),\n",
       "       ('\\xa0part', 0.20063380897045135),\n",
       "       ('', 0.1823393851518631),\n",
       "       ('matical', 0.1734343320131302),\n",
       "       ('rode', 0.1618187576532364)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.13561563193798065,\n",
       "      'top_tokens': [('East', 0.3696793019771576),\n",
       "       (' East', 0.1664959043264389),\n",
       "       ('', 0.1634090542793274),\n",
       "       ('eln', 0.15326519310474396),\n",
       "       ('tect', 0.14715054631233215)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.11129105091094971,\n",
       "      'top_tokens': [('', 0.25072041153907776),\n",
       "       ('itat', 0.20766699314117432),\n",
       "       ('forter', 0.18242447078227997),\n",
       "       ('EVER', 0.1815258413553238),\n",
       "       ('', 0.1776621788740158)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 48,\n",
       "      'weight': 0.17509904503822327,\n",
       "      'top_tokens': [('inette', 0.3333946764469147),\n",
       "       ('vature', 0.19470107555389404),\n",
       "       ('', 0.1804765909910202),\n",
       "       ('rame', 0.1615661382675171),\n",
       "       ('ANCE', 0.12986159324645996)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.15742695331573486,\n",
       "      'top_tokens': [('', 0.2358732372522354),\n",
       "       ('x', 0.2099119871854782),\n",
       "       ('terminal', 0.19894243776798248),\n",
       "       ('iaci', 0.1804610937833786),\n",
       "       ('icus', 0.1748112440109253)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.14346228539943695,\n",
       "      'top_tokens': [('fog', 0.20990721881389618),\n",
       "       ('ock', 0.2087179571390152),\n",
       "       ('ig', 0.20023122429847717),\n",
       "       ('', 0.19941379129886627),\n",
       "       ('pires', 0.18172968924045563)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.14000803232192993,\n",
       "      'top_tokens': [('3', 0.24771395325660706),\n",
       "       ('0', 0.22945009171962738),\n",
       "       ('1', 0.2273591160774231),\n",
       "       ('6', 0.14780105650424957),\n",
       "       ('2', 0.14767584204673767)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.13709695637226105,\n",
       "      'top_tokens': [('miral', 0.28177347779273987),\n",
       "       ('\\xa0part', 0.20063400268554688),\n",
       "       ('', 0.18233941495418549),\n",
       "       ('matical', 0.17343425750732422),\n",
       "       ('rode', 0.16181892156600952)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.13561564683914185,\n",
       "      'top_tokens': [('East', 0.36967939138412476),\n",
       "       (' East', 0.16649603843688965),\n",
       "       ('', 0.16340890526771545),\n",
       "       ('eln', 0.15326517820358276),\n",
       "       ('tect', 0.14715050160884857)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.1112910658121109,\n",
       "      'top_tokens': [('', 0.2507205009460449),\n",
       "       ('itat', 0.20766696333885193),\n",
       "       ('forter', 0.18242435157299042),\n",
       "       ('EVER', 0.1815258264541626),\n",
       "       ('', 0.1776624172925949)]}]}}},\n",
       " 'layer_11': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.18911026418209076,\n",
       "      'top_tokens': [('Compan', 0.24964813888072968),\n",
       "       (' ', 0.24443258345127106),\n",
       "       ('util', 0.21138662099838257),\n",
       "       ('', 0.16168037056922913),\n",
       "       ('', 0.1328522264957428)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.16414403915405273,\n",
       "      'top_tokens': [('', 0.2771160304546356),\n",
       "       ('0', 0.22492985427379608),\n",
       "       ('odder', 0.17522592842578888),\n",
       "       ('aband', 0.1640932261943817),\n",
       "       ('9', 0.15863491594791412)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.1460012048482895,\n",
       "      'top_tokens': [('reys', 0.360251784324646),\n",
       "       ('', 0.2067854404449463),\n",
       "       ('', 0.16381187736988068),\n",
       "       ('', 0.1622428297996521),\n",
       "       ('elines', 0.10690813511610031)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.1391972452402115,\n",
       "      'top_tokens': [('isure', 0.3188073933124542),\n",
       "       (' Served', 0.1977597326040268),\n",
       "       ('akr', 0.1763450652360916),\n",
       "       (' ', 0.15469057857990265),\n",
       "       ('ALOG', 0.15239723026752472)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.12194251269102097,\n",
       "      'top_tokens': [('ROID', 0.40249085426330566),\n",
       "       ('7', 0.1715630292892456),\n",
       "       ('8', 0.16478580236434937),\n",
       "       (' Tolosa', 0.13596320152282715),\n",
       "       (' Madge', 0.1251971423625946)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12143387645483017,\n",
       "      'top_tokens': [('ist', 0.3396996557712555),\n",
       "       ('m', 0.20501451194286346),\n",
       "       ('b', 0.1737368106842041),\n",
       "       ('burg', 0.14189013838768005),\n",
       "       ('', 0.1396588385105133)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.11817088723182678,\n",
       "      'top_tokens': [('8', 0.30991384387016296),\n",
       "       ('6', 0.233934685587883),\n",
       "       ('3', 0.20491459965705872),\n",
       "       ('', 0.12909185886383057),\n",
       "       ('0', 0.12214498966932297)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.18911021947860718,\n",
       "      'top_tokens': [('Compan', 0.24964787065982819),\n",
       "       (' ', 0.24443268775939941),\n",
       "       ('util', 0.21138699352741241),\n",
       "       ('', 0.161680206656456),\n",
       "       ('', 0.1328522264957428)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.164143905043602,\n",
       "      'top_tokens': [('', 0.2771160900592804),\n",
       "       ('0', 0.2249297946691513),\n",
       "       ('odder', 0.17522604763507843),\n",
       "       ('aband', 0.16409318149089813),\n",
       "       ('9', 0.1586349457502365)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.14600124955177307,\n",
       "      'top_tokens': [('reys', 0.360251784324646),\n",
       "       ('', 0.2067856341600418),\n",
       "       ('', 0.1638118028640747),\n",
       "       ('', 0.16224268078804016),\n",
       "       ('elines', 0.10690813511610031)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.13919728994369507,\n",
       "      'top_tokens': [('isure', 0.3188073933124542),\n",
       "       (' Served', 0.19775955379009247),\n",
       "       ('akr', 0.17634513974189758),\n",
       "       (' ', 0.15469065308570862),\n",
       "       ('ALOG', 0.1523972898721695)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.12194253504276276,\n",
       "      'top_tokens': [('ROID', 0.40249109268188477),\n",
       "       ('7', 0.17156288027763367),\n",
       "       ('8', 0.16478559374809265),\n",
       "       (' Tolosa', 0.13596323132514954),\n",
       "       (' Madge', 0.12519721686840057)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12143383175134659,\n",
       "      'top_tokens': [('ist', 0.33969950675964355),\n",
       "       ('m', 0.20501463115215302),\n",
       "       ('b', 0.17373697459697723),\n",
       "       ('burg', 0.14189007878303528),\n",
       "       ('', 0.1396588385105133)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.1181708574295044,\n",
       "      'top_tokens': [('8', 0.3099139928817749),\n",
       "       ('6', 0.23393458127975464),\n",
       "       ('3', 0.20491470396518707),\n",
       "       ('', 0.1290917992591858),\n",
       "       ('0', 0.12214498966932297)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.18911035358905792,\n",
       "      'top_tokens': [('Compan', 0.24964796006679535),\n",
       "       (' ', 0.24443253874778748),\n",
       "       ('util', 0.21138687431812286),\n",
       "       ('', 0.16168026626110077),\n",
       "       ('', 0.13285233080387115)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.16414402425289154,\n",
       "      'top_tokens': [('', 0.27711594104766846),\n",
       "       ('0', 0.22492998838424683),\n",
       "       ('odder', 0.17522594332695007),\n",
       "       ('aband', 0.1640930026769638),\n",
       "       ('9', 0.15863509476184845)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.14600121974945068,\n",
       "      'top_tokens': [('reys', 0.36025184392929077),\n",
       "       ('', 0.2067856788635254),\n",
       "       ('', 0.16381174325942993),\n",
       "       ('', 0.16224278509616852),\n",
       "       ('elines', 0.10690805315971375)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.1391972005367279,\n",
       "      'top_tokens': [('isure', 0.3188074231147766),\n",
       "       (' Served', 0.19775956869125366),\n",
       "       ('akr', 0.17634524405002594),\n",
       "       (' ', 0.15469059348106384),\n",
       "       ('ALOG', 0.1523972451686859)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.1219424158334732,\n",
       "      'top_tokens': [('ROID', 0.4024909734725952),\n",
       "       ('7', 0.17156291007995605),\n",
       "       ('8', 0.16478554904460907),\n",
       "       (' Tolosa', 0.13596318662166595),\n",
       "       (' Madge', 0.1251973658800125)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12143388390541077,\n",
       "      'top_tokens': [('ist', 0.33969953656196594),\n",
       "       ('m', 0.20501454174518585),\n",
       "       ('b', 0.1737368404865265),\n",
       "       ('burg', 0.14189022779464722),\n",
       "       ('', 0.1396588534116745)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.11817086488008499,\n",
       "      'top_tokens': [('8', 0.3099139630794525),\n",
       "       ('6', 0.23393477499485016),\n",
       "       ('3', 0.20491456985473633),\n",
       "       ('', 0.12909166514873505),\n",
       "       ('0', 0.12214497476816177)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.1891101896762848,\n",
       "      'top_tokens': [('Compan', 0.24964813888072968),\n",
       "       (' ', 0.2444324642419815),\n",
       "       ('util', 0.21138691902160645),\n",
       "       ('', 0.1616802215576172),\n",
       "       ('', 0.13285228610038757)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.16414403915405273,\n",
       "      'top_tokens': [('', 0.2771160900592804),\n",
       "       ('0', 0.22492991387844086),\n",
       "       ('odder', 0.17522604763507843),\n",
       "       ('aband', 0.1640930324792862),\n",
       "       ('9', 0.15863488614559174)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.14600126445293427,\n",
       "      'top_tokens': [('reys', 0.3602515757083893),\n",
       "       ('', 0.20678570866584778),\n",
       "       ('', 0.16381169855594635),\n",
       "       ('', 0.1622428148984909),\n",
       "       ('elines', 0.10690807551145554)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.13919733464717865,\n",
       "      'top_tokens': [('isure', 0.3188073933124542),\n",
       "       (' Served', 0.1977597326040268),\n",
       "       ('akr', 0.17634513974189758),\n",
       "       (' ', 0.15469065308570862),\n",
       "       ('ALOG', 0.15239715576171875)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.12194247543811798,\n",
       "      'top_tokens': [('ROID', 0.4024909734725952),\n",
       "       ('7', 0.17156291007995605),\n",
       "       ('8', 0.16478562355041504),\n",
       "       (' Tolosa', 0.13596324622631073),\n",
       "       (' Madge', 0.125197172164917)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12143384665250778,\n",
       "      'top_tokens': [('ist', 0.33969947695732117),\n",
       "       ('m', 0.20501461625099182),\n",
       "       ('b', 0.17373688519001007),\n",
       "       ('burg', 0.14189019799232483),\n",
       "       ('', 0.1396588236093521)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.11817090958356857,\n",
       "      'top_tokens': [('8', 0.3099140524864197),\n",
       "       ('6', 0.23393462598323822),\n",
       "       ('3', 0.20491474866867065),\n",
       "       ('', 0.1290915161371231),\n",
       "       ('0', 0.12214507162570953)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 13,\n",
       "      'weight': 0.18911029398441315,\n",
       "      'top_tokens': [('Compan', 0.2496480494737625),\n",
       "       (' ', 0.24443261325359344),\n",
       "       ('util', 0.21138684451580048),\n",
       "       ('', 0.16168032586574554),\n",
       "       ('', 0.132852241396904)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.16414397954940796,\n",
       "      'top_tokens': [('', 0.27711600065231323),\n",
       "       ('0', 0.2249300330877304),\n",
       "       ('odder', 0.1752258986234665),\n",
       "       ('aband', 0.1640930473804474),\n",
       "       ('9', 0.1586349904537201)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.14600123465061188,\n",
       "      'top_tokens': [('reys', 0.36025187373161316),\n",
       "       ('', 0.20678550004959106),\n",
       "       ('', 0.16381190717220306),\n",
       "       ('', 0.16224272549152374),\n",
       "       ('elines', 0.10690800845623016)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.13919728994369507,\n",
       "      'top_tokens': [('isure', 0.318807452917099),\n",
       "       (' Served', 0.1977596879005432),\n",
       "       ('akr', 0.17634516954421997),\n",
       "       (' ', 0.15469053387641907),\n",
       "       ('ALOG', 0.15239718556404114)]},\n",
       "     {'expert_id': 42,\n",
       "      'weight': 0.1219424307346344,\n",
       "      'top_tokens': [('ROID', 0.4024910032749176),\n",
       "       ('7', 0.17156283557415009),\n",
       "       ('8', 0.1647857129573822),\n",
       "       (' Tolosa', 0.13596320152282715),\n",
       "       (' Madge', 0.12519724667072296)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12143389135599136,\n",
       "      'top_tokens': [('ist', 0.3396996259689331),\n",
       "       ('m', 0.20501460134983063),\n",
       "       ('b', 0.1737367957830429),\n",
       "       ('burg', 0.14189013838768005),\n",
       "       ('', 0.1396588236093521)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.11817091703414917,\n",
       "      'top_tokens': [('8', 0.3099140226840973),\n",
       "       ('6', 0.23393471539020538),\n",
       "       ('3', 0.20491452515125275),\n",
       "       ('', 0.12909169495105743),\n",
       "       ('0', 0.12214506417512894)]}]}}},\n",
       " 'layer_12': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.21175627410411835,\n",
       "      'top_tokens': [('veh', 0.2723914384841919),\n",
       "       (' col', 0.23556463420391083),\n",
       "       ('', 0.1703389286994934),\n",
       "       ('AT', 0.16189999878406525),\n",
       "       ('escl', 0.15980495512485504)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.1541944295167923,\n",
       "      'top_tokens': [('broad', 0.21709832549095154),\n",
       "       ('Broad', 0.21519099175930023),\n",
       "       ('', 0.19895964860916138),\n",
       "       ('hof', 0.18717022240161896),\n",
       "       ('RECT', 0.1815807819366455)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.14529500901699066,\n",
       "      'top_tokens': [('rena', 0.2156786322593689),\n",
       "       ('zca', 0.2048909217119217),\n",
       "       ('', 0.19781556725502014),\n",
       "       ('ths', 0.19522127509117126),\n",
       "       ('', 0.1863936483860016)]},\n",
       "     {'expert_id': 39,\n",
       "      'weight': 0.14225924015045166,\n",
       "      'top_tokens': [('ccane', 0.235338032245636),\n",
       "       ('CFT', 0.22872501611709595),\n",
       "       ('GR', 0.197450652718544),\n",
       "       ('itons', 0.1866486668586731),\n",
       "       ('gia', 0.15183758735656738)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.13454964756965637,\n",
       "      'top_tokens': [(' part', 0.240480437874794),\n",
       "       ('', 0.20186804234981537),\n",
       "       ('tery', 0.1965402513742447),\n",
       "       ('inx', 0.1843384951353073),\n",
       "       ('', 0.17677272856235504)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.1081666573882103,\n",
       "      'top_tokens': [('oide', 0.37930068373680115),\n",
       "       ('uated', 0.26216360926628113),\n",
       "       ('ified', 0.13095836341381073),\n",
       "       ('', 0.1279289275407791),\n",
       "       ('ensem', 0.0996483713388443)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.1037786602973938,\n",
       "      'top_tokens': [('arque', 0.4657338857650757),\n",
       "       ('rength', 0.1473575383424759),\n",
       "       ('', 0.13702769577503204),\n",
       "       ('iddy', 0.12522472441196442),\n",
       "       (' ', 0.12465611100196838)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.21175627410411835,\n",
       "      'top_tokens': [('veh', 0.2723913788795471),\n",
       "       (' col', 0.23556461930274963),\n",
       "       ('', 0.170338973402977),\n",
       "       ('AT', 0.1618998795747757),\n",
       "       ('escl', 0.15980514883995056)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.1541944295167923,\n",
       "      'top_tokens': [('broad', 0.21709834039211273),\n",
       "       ('Broad', 0.21519100666046143),\n",
       "       ('', 0.19895966351032257),\n",
       "       ('hof', 0.18717019259929657),\n",
       "       ('RECT', 0.18158076703548431)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.14529503881931305,\n",
       "      'top_tokens': [('rena', 0.21567858755588531),\n",
       "       ('zca', 0.2048908770084381),\n",
       "       ('', 0.19781556725502014),\n",
       "       ('ths', 0.19522136449813843),\n",
       "       ('', 0.18639366328716278)]},\n",
       "     {'expert_id': 39,\n",
       "      'weight': 0.14225925505161285,\n",
       "      'top_tokens': [('ccane', 0.23533804714679718),\n",
       "       ('CFT', 0.2287251353263855),\n",
       "       ('GR', 0.19745056331157684),\n",
       "       ('itons', 0.18664859235286713),\n",
       "       ('gia', 0.15183760225772858)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.1345495879650116,\n",
       "      'top_tokens': [(' part', 0.24048052728176117),\n",
       "       ('', 0.2018679678440094),\n",
       "       ('tery', 0.19654043018817902),\n",
       "       ('inx', 0.1843382865190506),\n",
       "       ('', 0.1767728477716446)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.1081666424870491,\n",
       "      'top_tokens': [('oide', 0.3793005049228668),\n",
       "       ('uated', 0.26216375827789307),\n",
       "       ('ified', 0.13095839321613312),\n",
       "       ('', 0.1279289275407791),\n",
       "       ('ensem', 0.09964829683303833)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.1037786602973938,\n",
       "      'top_tokens': [('arque', 0.4657338857650757),\n",
       "       ('rength', 0.14735756814479828),\n",
       "       ('', 0.13702766597270966),\n",
       "       ('iddy', 0.12522481381893158),\n",
       "       (' ', 0.124656081199646)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.21175625920295715,\n",
       "      'top_tokens': [('veh', 0.27239149808883667),\n",
       "       (' col', 0.23556461930274963),\n",
       "       ('', 0.17033883929252625),\n",
       "       ('AT', 0.16189992427825928),\n",
       "       ('escl', 0.15980510413646698)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.15419445931911469,\n",
       "      'top_tokens': [('broad', 0.21709828078746796),\n",
       "       ('Broad', 0.21519090235233307),\n",
       "       ('', 0.19895966351032257),\n",
       "       ('hof', 0.18717019259929657),\n",
       "       ('RECT', 0.18158100545406342)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.14529505372047424,\n",
       "      'top_tokens': [('rena', 0.21567855775356293),\n",
       "       ('zca', 0.20489108562469482),\n",
       "       ('', 0.19781555235385895),\n",
       "       ('ths', 0.19522126019001007),\n",
       "       ('', 0.1863935887813568)]},\n",
       "     {'expert_id': 39,\n",
       "      'weight': 0.14225924015045166,\n",
       "      'top_tokens': [('ccane', 0.23533816635608673),\n",
       "       ('CFT', 0.22872503101825714),\n",
       "       ('GR', 0.1974506676197052),\n",
       "       ('itons', 0.18664860725402832),\n",
       "       ('gia', 0.1518375426530838)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.13454961776733398,\n",
       "      'top_tokens': [(' part', 0.24048066139221191),\n",
       "       ('', 0.20186789333820343),\n",
       "       ('tery', 0.1965404748916626),\n",
       "       ('inx', 0.1843383014202118),\n",
       "       ('', 0.17677272856235504)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.10816667228937149,\n",
       "      'top_tokens': [('oide', 0.3793003261089325),\n",
       "       ('uated', 0.2621638774871826),\n",
       "       ('ified', 0.1309584528207779),\n",
       "       ('', 0.1279289871454239),\n",
       "       ('ensem', 0.09964834153652191)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.10377869755029678,\n",
       "      'top_tokens': [('arque', 0.46573406457901),\n",
       "       ('rength', 0.1473575383424759),\n",
       "       ('', 0.13702765107154846),\n",
       "       ('iddy', 0.12522464990615845),\n",
       "       (' ', 0.12465620785951614)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.21175622940063477,\n",
       "      'top_tokens': [('veh', 0.27239152789115906),\n",
       "       (' col', 0.23556454479694366),\n",
       "       ('', 0.1703389436006546),\n",
       "       ('AT', 0.16189993917942047),\n",
       "       ('escl', 0.1598050892353058)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.1541944146156311,\n",
       "      'top_tokens': [('broad', 0.21709834039211273),\n",
       "       ('Broad', 0.2151910662651062),\n",
       "       ('', 0.19895966351032257),\n",
       "       ('hof', 0.1871701031923294),\n",
       "       ('RECT', 0.18158076703548431)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.14529500901699066,\n",
       "      'top_tokens': [('rena', 0.21567858755588531),\n",
       "       ('zca', 0.2048908770084381),\n",
       "       ('', 0.19781552255153656),\n",
       "       ('ths', 0.19522131979465485),\n",
       "       ('', 0.18639370799064636)]},\n",
       "     {'expert_id': 39,\n",
       "      'weight': 0.14225925505161285,\n",
       "      'top_tokens': [('ccane', 0.23533816635608673),\n",
       "       ('CFT', 0.22872492671012878),\n",
       "       ('GR', 0.19745056331157684),\n",
       "       ('itons', 0.18664869666099548),\n",
       "       ('gia', 0.15183760225772858)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.13454966247081757,\n",
       "      'top_tokens': [(' part', 0.24048066139221191),\n",
       "       ('', 0.2018679976463318),\n",
       "       ('tery', 0.19654038548469543),\n",
       "       ('inx', 0.18433834612369537),\n",
       "       ('', 0.17677269876003265)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.1081666499376297,\n",
       "      'top_tokens': [('oide', 0.3793005049228668),\n",
       "       ('uated', 0.26216375827789307),\n",
       "       ('ified', 0.13095839321613312),\n",
       "       ('', 0.1279289573431015),\n",
       "       ('ensem', 0.09964834153652191)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.10377863794565201,\n",
       "      'top_tokens': [('arque', 0.46573400497436523),\n",
       "       ('rength', 0.14735756814479828),\n",
       "       ('', 0.13702763617038727),\n",
       "       ('iddy', 0.12522467970848083),\n",
       "       (' ', 0.1246560662984848)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.21175622940063477,\n",
       "      'top_tokens': [('veh', 0.2723912298679352),\n",
       "       (' col', 0.23556476831436157),\n",
       "       ('', 0.17033891379833221),\n",
       "       ('AT', 0.16189983487129211),\n",
       "       ('escl', 0.15980525314807892)]},\n",
       "     {'expert_id': 13,\n",
       "      'weight': 0.15419448912143707,\n",
       "      'top_tokens': [('broad', 0.21709832549095154),\n",
       "       ('Broad', 0.21519088745117188),\n",
       "       ('', 0.19895970821380615),\n",
       "       ('hof', 0.1871700882911682),\n",
       "       ('RECT', 0.18158091604709625)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.14529500901699066,\n",
       "      'top_tokens': [('rena', 0.21567855775356293),\n",
       "       ('zca', 0.20489095151424408),\n",
       "       ('', 0.1978154480457306),\n",
       "       ('ths', 0.19522134959697723),\n",
       "       ('', 0.18639372289180756)]},\n",
       "     {'expert_id': 39,\n",
       "      'weight': 0.14225925505161285,\n",
       "      'top_tokens': [('ccane', 0.23533828556537628),\n",
       "       ('CFT', 0.22872503101825714),\n",
       "       ('GR', 0.1974506676197052),\n",
       "       ('itons', 0.18664851784706116),\n",
       "       ('gia', 0.15183745324611664)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.13454961776733398,\n",
       "      'top_tokens': [(' part', 0.24048049747943878),\n",
       "       ('', 0.201867938041687),\n",
       "       ('tery', 0.19654040038585663),\n",
       "       ('inx', 0.18433845043182373),\n",
       "       ('', 0.17677272856235504)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.10816668719053268,\n",
       "      'top_tokens': [('oide', 0.3793005049228668),\n",
       "       ('uated', 0.26216360926628113),\n",
       "       ('ified', 0.13095839321613312),\n",
       "       ('', 0.12792907655239105),\n",
       "       ('ensem', 0.09964840859174728)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.1037786453962326,\n",
       "      'top_tokens': [('arque', 0.46573421359062195),\n",
       "       ('rength', 0.14735746383666992),\n",
       "       ('', 0.1370275318622589),\n",
       "       ('iddy', 0.12522466480731964),\n",
       "       (' ', 0.12465612590312958)]}]}}},\n",
       " 'layer_13': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 10,\n",
       "      'weight': 0.17592734098434448,\n",
       "      'top_tokens': [('MethodName', 0.21845479309558868),\n",
       "       ('Etapa', 0.21429620683193207),\n",
       "       ('scribe', 0.20633994042873383),\n",
       "       ('$/.', 0.190128892660141),\n",
       "       ('estany', 0.17078015208244324)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.1746167540550232,\n",
       "      'top_tokens': [('=\"__', 0.4921577274799347),\n",
       "       ('', 0.21577727794647217),\n",
       "       ('', 0.11896141618490219),\n",
       "       ('', 0.08778627961874008),\n",
       "       ('', 0.08531727641820908)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.1317036896944046,\n",
       "      'top_tokens': [('', 0.5081015229225159),\n",
       "       ('', 0.16139203310012817),\n",
       "       ('', 0.12928663194179535),\n",
       "       ('', 0.11512058228254318),\n",
       "       ('odot', 0.08609927445650101)]},\n",
       "     {'expert_id': 17,\n",
       "      'weight': 0.13087518513202667,\n",
       "      'top_tokens': [(';=', 0.2343875616788864),\n",
       "       ('ournals', 0.20020726323127747),\n",
       "       ('', 0.19459645450115204),\n",
       "       ('iture', 0.1930130571126938),\n",
       "       ('ermost', 0.1777956485748291)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.13039670884609222,\n",
       "      'top_tokens': [('hetical', 0.21694226562976837),\n",
       "       ('', 0.21421445906162262),\n",
       "       ('ruce', 0.20021913945674896),\n",
       "       ('picker', 0.18934646248817444),\n",
       "       ('leted', 0.17927773296833038)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.12933333218097687,\n",
       "      'top_tokens': [('olas', 0.4270103871822357),\n",
       "       ('stream', 0.15404175221920013),\n",
       "       ('builder', 0.14921508729457855),\n",
       "       ('', 0.1387653648853302),\n",
       "       ('wisdom', 0.1309674233198166)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.1271468698978424,\n",
       "      'top_tokens': [('PROTOBUF', 0.28473761677742004),\n",
       "       ('rary', 0.22896729409694672),\n",
       "       ('rate', 0.19224078953266144),\n",
       "       ('rates', 0.15137998759746552),\n",
       "       ('', 0.1426742821931839)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 10,\n",
       "      'weight': 0.1759272813796997,\n",
       "      'top_tokens': [('MethodName', 0.21845461428165436),\n",
       "       ('Etapa', 0.21429623663425446),\n",
       "       ('scribe', 0.20634007453918457),\n",
       "       ('$/.', 0.19012881815433502),\n",
       "       ('estany', 0.1707802563905716)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.17461678385734558,\n",
       "      'top_tokens': [('=\"__', 0.49215731024742126),\n",
       "       ('', 0.21577750146389008),\n",
       "       ('', 0.11896131187677383),\n",
       "       ('', 0.08778653293848038),\n",
       "       ('', 0.08531736582517624)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.13170376420021057,\n",
       "      'top_tokens': [('', 0.5081017017364502),\n",
       "       ('', 0.16139209270477295),\n",
       "       ('', 0.1292862892150879),\n",
       "       ('', 0.11512050777673721),\n",
       "       ('odot', 0.08609934151172638)]},\n",
       "     {'expert_id': 17,\n",
       "      'weight': 0.13087522983551025,\n",
       "      'top_tokens': [(';=', 0.23438763618469238),\n",
       "       ('ournals', 0.20020724833011627),\n",
       "       ('', 0.19459642469882965),\n",
       "       ('iture', 0.19301311671733856),\n",
       "       ('ermost', 0.17779555916786194)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.130396768450737,\n",
       "      'top_tokens': [('hetical', 0.21694231033325195),\n",
       "       ('', 0.2142145037651062),\n",
       "       ('ruce', 0.20021900534629822),\n",
       "       ('picker', 0.18934644758701324),\n",
       "       ('leted', 0.17927777767181396)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.12933333218097687,\n",
       "      'top_tokens': [('olas', 0.4270104765892029),\n",
       "       ('stream', 0.15404164791107178),\n",
       "       ('builder', 0.14921505749225616),\n",
       "       ('', 0.13876532018184662),\n",
       "       ('wisdom', 0.13096748292446136)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.1271468549966812,\n",
       "      'top_tokens': [('PROTOBUF', 0.2847379148006439),\n",
       "       ('rary', 0.2289673089981079),\n",
       "       ('rate', 0.1922406256198883),\n",
       "       ('rates', 0.1513800173997879),\n",
       "       ('', 0.14267416298389435)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 10,\n",
       "      'weight': 0.17592734098434448,\n",
       "      'top_tokens': [('MethodName', 0.21845479309558868),\n",
       "       ('Etapa', 0.2142961025238037),\n",
       "       ('scribe', 0.20634004473686218),\n",
       "       ('$/.', 0.190128892660141),\n",
       "       ('estany', 0.1707802414894104)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.17461688816547394,\n",
       "      'top_tokens': [('=\"__', 0.49215760827064514),\n",
       "       ('', 0.21577763557434082),\n",
       "       ('', 0.1189611554145813),\n",
       "       ('', 0.08778641372919083),\n",
       "       ('', 0.08531725406646729)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.131703719496727,\n",
       "      'top_tokens': [('', 0.5081014633178711),\n",
       "       ('', 0.16139216721057892),\n",
       "       ('', 0.12928661704063416),\n",
       "       ('', 0.11512056738138199),\n",
       "       ('odot', 0.08609925955533981)]},\n",
       "     {'expert_id': 17,\n",
       "      'weight': 0.13087521493434906,\n",
       "      'top_tokens': [(';=', 0.2343875914812088),\n",
       "       ('ournals', 0.20020724833011627),\n",
       "       ('', 0.19459643959999084),\n",
       "       ('iture', 0.19301313161849976),\n",
       "       ('ermost', 0.1777956187725067)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.13039669394493103,\n",
       "      'top_tokens': [('hetical', 0.21694210171699524),\n",
       "       ('', 0.21421460807323456),\n",
       "       ('ruce', 0.20021918416023254),\n",
       "       ('picker', 0.18934635818004608),\n",
       "       ('leted', 0.17927773296833038)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.1293332725763321,\n",
       "      'top_tokens': [('olas', 0.4270102083683014),\n",
       "       ('stream', 0.1540418267250061),\n",
       "       ('builder', 0.14921505749225616),\n",
       "       ('', 0.1387653648853302),\n",
       "       ('wisdom', 0.13096746802330017)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.1271468698978424,\n",
       "      'top_tokens': [('PROTOBUF', 0.28473761677742004),\n",
       "       ('rary', 0.22896794974803925),\n",
       "       ('rate', 0.19224043190479279),\n",
       "       ('rates', 0.15137985348701477),\n",
       "       ('', 0.14267414808273315)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 10,\n",
       "      'weight': 0.1759273260831833,\n",
       "      'top_tokens': [('MethodName', 0.21845456957817078),\n",
       "       ('Etapa', 0.21429620683193207),\n",
       "       ('scribe', 0.206340029835701),\n",
       "       ('$/.', 0.1901288777589798),\n",
       "       ('estany', 0.17078031599521637)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.17461691796779633,\n",
       "      'top_tokens': [('=\"__', 0.4921577274799347),\n",
       "       ('', 0.21577727794647217),\n",
       "       ('', 0.11896141618490219),\n",
       "       ('', 0.08778627961874008),\n",
       "       ('', 0.08531727641820908)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.1317037045955658,\n",
       "      'top_tokens': [('', 0.5081018209457397),\n",
       "       ('', 0.16139213740825653),\n",
       "       ('', 0.12928631901741028),\n",
       "       ('', 0.11512043327093124),\n",
       "       ('odot', 0.08609919250011444)]},\n",
       "     {'expert_id': 17,\n",
       "      'weight': 0.13087517023086548,\n",
       "      'top_tokens': [(';=', 0.23438766598701477),\n",
       "       ('ournals', 0.2002071738243103),\n",
       "       ('', 0.19459645450115204),\n",
       "       ('iture', 0.19301313161849976),\n",
       "       ('ermost', 0.17779554426670074)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.13039670884609222,\n",
       "      'top_tokens': [('hetical', 0.21694205701351166),\n",
       "       ('', 0.21421466767787933),\n",
       "       ('ruce', 0.20021913945674896),\n",
       "       ('picker', 0.1893463134765625),\n",
       "       ('leted', 0.17927777767181396)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.1293332576751709,\n",
       "      'top_tokens': [('olas', 0.42701050639152527),\n",
       "       ('stream', 0.15404166281223297),\n",
       "       ('builder', 0.14921505749225616),\n",
       "       ('', 0.13876526057720184),\n",
       "       ('wisdom', 0.13096745312213898)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.127146914601326,\n",
       "      'top_tokens': [('PROTOBUF', 0.2847375273704529),\n",
       "       ('rary', 0.22896765172481537),\n",
       "       ('rate', 0.19224071502685547),\n",
       "       ('rates', 0.1513798087835312),\n",
       "       ('', 0.14267423748970032)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 10,\n",
       "      'weight': 0.17592735588550568,\n",
       "      'top_tokens': [('MethodName', 0.21845461428165436),\n",
       "       ('Etapa', 0.2142961323261261),\n",
       "       ('scribe', 0.20634016394615173),\n",
       "       ('$/.', 0.19012881815433502),\n",
       "       ('estany', 0.1707802563905716)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.1746167242527008,\n",
       "      'top_tokens': [('=\"__', 0.4921577274799347),\n",
       "       ('', 0.21577727794647217),\n",
       "       ('', 0.11896129697561264),\n",
       "       ('', 0.08778643608093262),\n",
       "       ('', 0.08531718701124191)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.13170373439788818,\n",
       "      'top_tokens': [('', 0.5081022381782532),\n",
       "       ('', 0.16139180958271027),\n",
       "       ('', 0.12928655743598938),\n",
       "       ('', 0.11512041091918945),\n",
       "       ('odot', 0.08609902113676071)]},\n",
       "     {'expert_id': 17,\n",
       "      'weight': 0.13087522983551025,\n",
       "      'top_tokens': [(';=', 0.2343875616788864),\n",
       "       ('ournals', 0.20020736753940582),\n",
       "       ('', 0.19459645450115204),\n",
       "       ('iture', 0.19301319122314453),\n",
       "       ('ermost', 0.17779549956321716)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.1303967982530594,\n",
       "      'top_tokens': [('hetical', 0.2169422209262848),\n",
       "       ('', 0.21421436965465546),\n",
       "       ('ruce', 0.20021915435791016),\n",
       "       ('picker', 0.18934641778469086),\n",
       "       ('leted', 0.17927782237529755)]},\n",
       "     {'expert_id': 7,\n",
       "      'weight': 0.12933333218097687,\n",
       "      'top_tokens': [('olas', 0.4270104467868805),\n",
       "       ('stream', 0.15404169261455536),\n",
       "       ('builder', 0.14921514689922333),\n",
       "       ('', 0.13876527547836304),\n",
       "       ('wisdom', 0.13096746802330017)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.1271468847990036,\n",
       "      'top_tokens': [('PROTOBUF', 0.28473779559135437),\n",
       "       ('rary', 0.22896765172481537),\n",
       "       ('rate', 0.19224035739898682),\n",
       "       ('rates', 0.15137995779514313),\n",
       "       ('', 0.14267423748970032)]}]}}},\n",
       " 'layer_14': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.1640755832195282,\n",
       "      'top_tokens': [(' calci', 0.2771672308444977),\n",
       "       ('iod', 0.2461281567811966),\n",
       "       ('', 0.171622633934021),\n",
       "       ('', 0.15875236690044403),\n",
       "       (' constitution', 0.1463296115398407)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.16010043025016785,\n",
       "      'top_tokens': [('IZED', 0.30287760496139526),\n",
       "       ('anine', 0.19105347990989685),\n",
       "       (' Rocks', 0.1791011244058609),\n",
       "       ('edn', 0.16553130745887756),\n",
       "       ('ANGLE', 0.1614365428686142)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.1473381072282791,\n",
       "      'top_tokens': [('', 0.291134238243103),\n",
       "       (' tr', 0.20327241718769073),\n",
       "       (' l', 0.17082278430461884),\n",
       "       ('glob', 0.16779573261737823),\n",
       "       ('end', 0.16697482764720917)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.1414685994386673,\n",
       "      'top_tokens': [('acant', 0.322517991065979),\n",
       "       ('', 0.20648866891860962),\n",
       "       ('ITED', 0.18034610152244568),\n",
       "       ('inberg', 0.15740908682346344),\n",
       "       ('uxley', 0.13323813676834106)]},\n",
       "     {'expert_id': 22,\n",
       "      'weight': 0.1360434740781784,\n",
       "      'top_tokens': [('i', 0.23813682794570923),\n",
       "       ('', 0.20404288172721863),\n",
       "       (' Edicions', 0.19631436467170715),\n",
       "       ('', 0.18106095492839813),\n",
       "       ('', 0.18044501543045044)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.12766578793525696,\n",
       "      'top_tokens': [('0', 0.34395232796669006),\n",
       "       ('1', 0.22157898545265198),\n",
       "       ('2', 0.1624698042869568),\n",
       "       ('3', 0.14347997307777405),\n",
       "       ('5', 0.12851892411708832)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.1233079582452774,\n",
       "      'top_tokens': [(' Pow', 0.308767706155777),\n",
       "       ('', 0.29914936423301697),\n",
       "       ('ahler', 0.15783166885375977),\n",
       "       ('Pow', 0.11718019843101501),\n",
       "       ('eppel', 0.11707106232643127)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.1640755832195282,\n",
       "      'top_tokens': [(' calci', 0.2771672308444977),\n",
       "       ('iod', 0.24612803757190704),\n",
       "       ('', 0.17162272334098816),\n",
       "       ('', 0.15875236690044403),\n",
       "       (' constitution', 0.14632967114448547)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.16010046005249023,\n",
       "      'top_tokens': [('IZED', 0.3028775751590729),\n",
       "       ('anine', 0.19105340540409088),\n",
       "       (' Rocks', 0.1791011542081833),\n",
       "       ('edn', 0.16553141176700592),\n",
       "       ('ANGLE', 0.16143648326396942)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.14733821153640747,\n",
       "      'top_tokens': [('', 0.2911341190338135),\n",
       "       (' tr', 0.20327241718769073),\n",
       "       (' l', 0.17082282900810242),\n",
       "       ('glob', 0.16779571771621704),\n",
       "       ('end', 0.1669749766588211)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.1414686143398285,\n",
       "      'top_tokens': [('acant', 0.3225177824497223),\n",
       "       ('', 0.20648853480815887),\n",
       "       ('ITED', 0.1803463250398636),\n",
       "       ('inberg', 0.15740928053855896),\n",
       "       ('uxley', 0.13323812186717987)]},\n",
       "     {'expert_id': 22,\n",
       "      'weight': 0.1360434591770172,\n",
       "      'top_tokens': [('i', 0.23813672363758087),\n",
       "       ('', 0.20404309034347534),\n",
       "       (' Edicions', 0.19631437957286835),\n",
       "       ('', 0.18106083571910858),\n",
       "       ('', 0.18044501543045044)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.12766580283641815,\n",
       "      'top_tokens': [('0', 0.34395235776901245),\n",
       "       ('1', 0.22157900035381317),\n",
       "       ('2', 0.16246981918811798),\n",
       "       ('3', 0.14347991347312927),\n",
       "       ('5', 0.1285189986228943)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.12330792844295502,\n",
       "      'top_tokens': [(' Pow', 0.30876749753952026),\n",
       "       ('', 0.2991493046283722),\n",
       "       ('ahler', 0.15783187747001648),\n",
       "       ('Pow', 0.11718028038740158),\n",
       "       ('eppel', 0.11707109212875366)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.16407561302185059,\n",
       "      'top_tokens': [(' calci', 0.27716705203056335),\n",
       "       ('iod', 0.24612835049629211),\n",
       "       ('', 0.1716226190328598),\n",
       "       ('', 0.15875238180160522),\n",
       "       (' constitution', 0.14632964134216309)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.16010037064552307,\n",
       "      'top_tokens': [('IZED', 0.30287742614746094),\n",
       "       ('anine', 0.1910535991191864),\n",
       "       (' Rocks', 0.17910116910934448),\n",
       "       ('edn', 0.16553136706352234),\n",
       "       ('ANGLE', 0.16143637895584106)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.1473381370306015,\n",
       "      'top_tokens': [('', 0.2911340594291687),\n",
       "       (' tr', 0.20327253639698029),\n",
       "       (' l', 0.17082270979881287),\n",
       "       ('glob', 0.16779574751853943),\n",
       "       ('end', 0.16697493195533752)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.14146855473518372,\n",
       "      'top_tokens': [('acant', 0.3225178122520447),\n",
       "       ('', 0.20648877322673798),\n",
       "       ('ITED', 0.18034625053405762),\n",
       "       ('inberg', 0.15740913152694702),\n",
       "       ('uxley', 0.1332380175590515)]},\n",
       "     {'expert_id': 22,\n",
       "      'weight': 0.1360434740781784,\n",
       "      'top_tokens': [('i', 0.23813679814338684),\n",
       "       ('', 0.20404274761676788),\n",
       "       (' Edicions', 0.19631443917751312),\n",
       "       ('', 0.18106094002723694),\n",
       "       ('', 0.18044507503509521)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.12766581773757935,\n",
       "      'top_tokens': [('0', 0.3439521789550781),\n",
       "       ('1', 0.22157898545265198),\n",
       "       ('2', 0.1624698042869568),\n",
       "       ('3', 0.14348004758358002),\n",
       "       ('5', 0.12851892411708832)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.12330798804759979,\n",
       "      'top_tokens': [(' Pow', 0.30876755714416504),\n",
       "       ('', 0.29914963245391846),\n",
       "       ('ahler', 0.1578315943479538),\n",
       "       ('Pow', 0.11718019843101501),\n",
       "       ('eppel', 0.11707106232643127)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.1640755832195282,\n",
       "      'top_tokens': [(' calci', 0.2771669626235962),\n",
       "       ('iod', 0.24612826108932495),\n",
       "       ('', 0.17162279784679413),\n",
       "       ('', 0.15875239670276642),\n",
       "       (' constitution', 0.14632956683635712)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.16010043025016785,\n",
       "      'top_tokens': [('IZED', 0.3028774559497833),\n",
       "       ('anine', 0.19105347990989685),\n",
       "       (' Rocks', 0.1791011542081833),\n",
       "       ('edn', 0.16553138196468353),\n",
       "       ('ANGLE', 0.16143646836280823)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.14733821153640747,\n",
       "      'top_tokens': [('', 0.29113417863845825),\n",
       "       (' tr', 0.20327241718769073),\n",
       "       (' l', 0.17082273960113525),\n",
       "       ('glob', 0.16779570281505585),\n",
       "       ('end', 0.1669750064611435)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.1414685994386673,\n",
       "      'top_tokens': [('acant', 0.3225175738334656),\n",
       "       ('', 0.20648880302906036),\n",
       "       ('ITED', 0.18034628033638),\n",
       "       ('inberg', 0.1574091762304306),\n",
       "       ('uxley', 0.13323816657066345)]},\n",
       "     {'expert_id': 22,\n",
       "      'weight': 0.1360435038805008,\n",
       "      'top_tokens': [('i', 0.23813672363758087),\n",
       "       ('', 0.20404279232025146),\n",
       "       (' Edicions', 0.1963144838809967),\n",
       "       ('', 0.18106098473072052),\n",
       "       ('', 0.18044501543045044)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.12766586244106293,\n",
       "      'top_tokens': [('0', 0.3439522683620453),\n",
       "       ('1', 0.22157904505729675),\n",
       "       ('2', 0.1624697744846344),\n",
       "       ('3', 0.14347994327545166),\n",
       "       ('5', 0.1285189539194107)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.12330794334411621,\n",
       "      'top_tokens': [(' Pow', 0.3087675869464874),\n",
       "       ('', 0.2991495430469513),\n",
       "       ('ahler', 0.15783153474330902),\n",
       "       ('Pow', 0.11718020588159561),\n",
       "       ('eppel', 0.11707112938165665)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 17,\n",
       "      'weight': 0.1640755832195282,\n",
       "      'top_tokens': [(' calci', 0.2771671414375305),\n",
       "       ('iod', 0.24612830579280853),\n",
       "       ('', 0.17162266373634338),\n",
       "       ('', 0.1587522029876709),\n",
       "       (' constitution', 0.14632965624332428)]},\n",
       "     {'expert_id': 63,\n",
       "      'weight': 0.16010043025016785,\n",
       "      'top_tokens': [('IZED', 0.30287760496139526),\n",
       "       ('anine', 0.19105353951454163),\n",
       "       (' Rocks', 0.17910107970237732),\n",
       "       ('edn', 0.16553130745887756),\n",
       "       ('ANGLE', 0.16143640875816345)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.14733821153640747,\n",
       "      'top_tokens': [('', 0.2911340296268463),\n",
       "       (' tr', 0.20327255129814148),\n",
       "       (' l', 0.17082269489765167),\n",
       "       ('glob', 0.16779573261737823),\n",
       "       ('end', 0.1669749617576599)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.1414686143398285,\n",
       "      'top_tokens': [('acant', 0.3225176930427551),\n",
       "       ('', 0.20648859441280365),\n",
       "       ('ITED', 0.18034628033638),\n",
       "       ('inberg', 0.1574091613292694),\n",
       "       ('uxley', 0.133238285779953)]},\n",
       "     {'expert_id': 22,\n",
       "      'weight': 0.1360434591770172,\n",
       "      'top_tokens': [('i', 0.2381366640329361),\n",
       "       ('', 0.20404283702373505),\n",
       "       (' Edicions', 0.19631442427635193),\n",
       "       ('', 0.18106088042259216),\n",
       "       ('', 0.18044513463974)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.12766581773757935,\n",
       "      'top_tokens': [('0', 0.34395238757133484),\n",
       "       ('1', 0.22157901525497437),\n",
       "       ('2', 0.16246981918811798),\n",
       "       ('3', 0.14347992837429047),\n",
       "       ('5', 0.1285189390182495)]},\n",
       "     {'expert_id': 38,\n",
       "      'weight': 0.12330793589353561,\n",
       "      'top_tokens': [(' Pow', 0.3087676763534546),\n",
       "       ('', 0.29914918541908264),\n",
       "       ('ahler', 0.15783172845840454),\n",
       "       ('Pow', 0.11718029528856277),\n",
       "       ('eppel', 0.11707104742527008)]}]}}},\n",
       " 'layer_15': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.18334592878818512,\n",
       "      'top_tokens': [('', 0.27788498997688293),\n",
       "       ('atem', 0.21527716517448425),\n",
       "       ('formed', 0.17725281417369843),\n",
       "       ('', 0.16759543120861053),\n",
       "       ('erves', 0.16198959946632385)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.15630725026130676,\n",
       "      'top_tokens': [('', 0.27088260650634766),\n",
       "       ('', 0.2501886785030365),\n",
       "       ('tofore', 0.17961633205413818),\n",
       "       (').__', 0.1530824601650238),\n",
       "       ('lessness', 0.14622989296913147)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.15414895117282867,\n",
       "      'top_tokens': [('refn', 0.3066905736923218),\n",
       "       (':///', 0.18948513269424438),\n",
       "       ('illac', 0.17212487757205963),\n",
       "       ('fortunes', 0.17037057876586914),\n",
       "       ('GNU', 0.16132880747318268)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.140788272023201,\n",
       "      'top_tokens': [(' ', 0.2764483094215393),\n",
       "       ('laz', 0.19800403714179993),\n",
       "       ('ament', 0.18638946115970612),\n",
       "       ('ogeneity', 0.17262570559978485),\n",
       "       ('ceil', 0.1665324866771698)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.12921550869941711,\n",
       "      'top_tokens': [('hea', 0.278130441904068),\n",
       "       ('ing', 0.19372668862342834),\n",
       "       ('', 0.1885811686515808),\n",
       "       ('sal', 0.17086239159107208),\n",
       "       ('', 0.16869929432868958)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.12155172228813171,\n",
       "      'top_tokens': [(' fuster', 0.24180737137794495),\n",
       "       ('jades', 0.22260825335979462),\n",
       "       ('rivacy', 0.18034854531288147),\n",
       "       ('restant', 0.179505854845047),\n",
       "       ('recci', 0.17573004961013794)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.11464232951402664,\n",
       "      'top_tokens': [('issin', 0.2496185153722763),\n",
       "       ('', 0.24513643980026245),\n",
       "       ('', 0.21811413764953613),\n",
       "       ('', 0.14615127444267273),\n",
       "       ('orthand', 0.14097960293293)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.18334589898586273,\n",
       "      'top_tokens': [('', 0.2778850197792053),\n",
       "       ('atem', 0.21527719497680664),\n",
       "       ('formed', 0.17725282907485962),\n",
       "       ('', 0.16759538650512695),\n",
       "       ('erves', 0.16198961436748505)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.15630733966827393,\n",
       "      'top_tokens': [('', 0.2708825469017029),\n",
       "       ('', 0.2501884996891022),\n",
       "       ('tofore', 0.17961637675762177),\n",
       "       (').__', 0.15308265388011932),\n",
       "       ('lessness', 0.1462298482656479)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.15414899587631226,\n",
       "      'top_tokens': [('refn', 0.3066904842853546),\n",
       "       (':///', 0.1894851177930832),\n",
       "       ('illac', 0.1721249371767044),\n",
       "       ('fortunes', 0.17037059366703033),\n",
       "       ('GNU', 0.16132886707782745)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.1407882124185562,\n",
       "      'top_tokens': [(' ', 0.27644822001457214),\n",
       "       ('laz', 0.1980040818452835),\n",
       "       ('ament', 0.18638953566551208),\n",
       "       ('ogeneity', 0.17262573540210724),\n",
       "       ('ceil', 0.16653242707252502)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.1292155534029007,\n",
       "      'top_tokens': [('hea', 0.27813032269477844),\n",
       "       ('ing', 0.1937267929315567),\n",
       "       ('', 0.18858127295970917),\n",
       "       ('sal', 0.17086215317249298),\n",
       "       ('', 0.16869939863681793)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.12155171483755112,\n",
       "      'top_tokens': [(' fuster', 0.24180738627910614),\n",
       "       ('jades', 0.22260814905166626),\n",
       "       ('rivacy', 0.1803484708070755),\n",
       "       ('restant', 0.1795058697462082),\n",
       "       ('recci', 0.17573006451129913)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.11464234441518784,\n",
       "      'top_tokens': [('issin', 0.24961866438388824),\n",
       "       ('', 0.24513636529445648),\n",
       "       ('', 0.21811385452747345),\n",
       "       ('', 0.14615128934383392),\n",
       "       ('orthand', 0.1409798264503479)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.18334585428237915,\n",
       "      'top_tokens': [('', 0.27788496017456055),\n",
       "       ('atem', 0.21527723968029022),\n",
       "       ('formed', 0.17725279927253723),\n",
       "       ('', 0.16759541630744934),\n",
       "       ('erves', 0.16198956966400146)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.15630728006362915,\n",
       "      'top_tokens': [('', 0.27088263630867004),\n",
       "       ('', 0.2501884698867798),\n",
       "       ('tofore', 0.17961643636226654),\n",
       "       (').__', 0.15308262407779694),\n",
       "       ('lessness', 0.1462298184633255)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.15414899587631226,\n",
       "      'top_tokens': [('refn', 0.3066905736923218),\n",
       "       (':///', 0.18948522210121155),\n",
       "       ('illac', 0.17212484776973724),\n",
       "       ('fortunes', 0.17037053406238556),\n",
       "       ('GNU', 0.1613287776708603)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.140788272023201,\n",
       "      'top_tokens': [(' ', 0.27644822001457214),\n",
       "       ('laz', 0.19800400733947754),\n",
       "       ('ament', 0.1863894760608673),\n",
       "       ('ogeneity', 0.17262578010559082),\n",
       "       ('ceil', 0.1665324568748474)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.1292155385017395,\n",
       "      'top_tokens': [('hea', 0.2781304717063904),\n",
       "       ('ing', 0.19372670352458954),\n",
       "       ('', 0.188581183552742),\n",
       "       ('sal', 0.17086242139339447),\n",
       "       ('', 0.1686992347240448)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.1215517669916153,\n",
       "      'top_tokens': [(' fuster', 0.24180731177330017),\n",
       "       ('jades', 0.2226082980632782),\n",
       "       ('rivacy', 0.1803485006093979),\n",
       "       ('restant', 0.17950581014156342),\n",
       "       ('recci', 0.17573009431362152)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.11464232206344604,\n",
       "      'top_tokens': [('issin', 0.2496183067560196),\n",
       "       ('', 0.24513646960258484),\n",
       "       ('', 0.21811425685882568),\n",
       "       ('', 0.1461513489484787),\n",
       "       ('orthand', 0.1409796178340912)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.18334592878818512,\n",
       "      'top_tokens': [('', 0.27788490056991577),\n",
       "       ('atem', 0.21527719497680664),\n",
       "       ('formed', 0.1772528439760208),\n",
       "       ('', 0.16759555041790009),\n",
       "       ('erves', 0.16198962926864624)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.15630730986595154,\n",
       "      'top_tokens': [('', 0.2708825469017029),\n",
       "       ('', 0.2501884996891022),\n",
       "       ('tofore', 0.17961646616458893),\n",
       "       (').__', 0.15308251976966858),\n",
       "       ('lessness', 0.14622992277145386)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.15414896607398987,\n",
       "      'top_tokens': [('refn', 0.30669036507606506),\n",
       "       (':///', 0.18948513269424438),\n",
       "       ('illac', 0.17212501168251038),\n",
       "       ('fortunes', 0.17037062346935272),\n",
       "       ('GNU', 0.16132888197898865)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.1407882571220398,\n",
       "      'top_tokens': [(' ', 0.27644839882850647),\n",
       "       ('laz', 0.19800400733947754),\n",
       "       ('ament', 0.18638941645622253),\n",
       "       ('ogeneity', 0.17262575030326843),\n",
       "       ('ceil', 0.1665324568748474)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.12921547889709473,\n",
       "      'top_tokens': [('hea', 0.2781303822994232),\n",
       "       ('ing', 0.1937265545129776),\n",
       "       ('', 0.1885812133550644),\n",
       "       ('sal', 0.1708623617887497),\n",
       "       ('', 0.16869942843914032)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.12155172228813171,\n",
       "      'top_tokens': [(' fuster', 0.24180760979652405),\n",
       "       ('jades', 0.2226080447435379),\n",
       "       ('rivacy', 0.18034829199314117),\n",
       "       ('restant', 0.17950594425201416),\n",
       "       ('recci', 0.1757301390171051)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.11464228481054306,\n",
       "      'top_tokens': [('issin', 0.2496185451745987),\n",
       "       ('', 0.24513636529445648),\n",
       "       ('', 0.21811404824256897),\n",
       "       ('', 0.14615128934383392),\n",
       "       ('orthand', 0.14097975194454193)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 15,\n",
       "      'weight': 0.1833459436893463,\n",
       "      'top_tokens': [('', 0.27788496017456055),\n",
       "       ('atem', 0.21527715027332306),\n",
       "       ('formed', 0.17725279927253723),\n",
       "       ('', 0.16759558022022247),\n",
       "       ('erves', 0.16198956966400146)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.15630723536014557,\n",
       "      'top_tokens': [('', 0.2708827555179596),\n",
       "       ('', 0.25018858909606934),\n",
       "       ('tofore', 0.17961634695529938),\n",
       "       (').__', 0.15308234095573425),\n",
       "       ('lessness', 0.14622996747493744)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.15414899587631226,\n",
       "      'top_tokens': [('refn', 0.306690514087677),\n",
       "       (':///', 0.189485102891922),\n",
       "       ('illac', 0.1721249669790268),\n",
       "       ('fortunes', 0.17037060856819153),\n",
       "       ('GNU', 0.16132888197898865)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.1407882273197174,\n",
       "      'top_tokens': [(' ', 0.27644822001457214),\n",
       "       ('laz', 0.1980040818452835),\n",
       "       ('ament', 0.1863894760608673),\n",
       "       ('ogeneity', 0.17262578010559082),\n",
       "       ('ceil', 0.1665324568748474)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.1292155236005783,\n",
       "      'top_tokens': [('hea', 0.27813053131103516),\n",
       "       ('ing', 0.19372674822807312),\n",
       "       ('', 0.18858122825622559),\n",
       "       ('sal', 0.17086219787597656),\n",
       "       ('', 0.16869927942752838)]},\n",
       "     {'expert_id': 45,\n",
       "      'weight': 0.12155172228813171,\n",
       "      'top_tokens': [(' fuster', 0.24180744588375092),\n",
       "       ('jades', 0.22260820865631104),\n",
       "       ('rivacy', 0.18034851551055908),\n",
       "       ('restant', 0.1795058250427246),\n",
       "       ('recci', 0.17573001980781555)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.11464231461286545,\n",
       "      'top_tokens': [('issin', 0.2496187835931778),\n",
       "       ('', 0.24513623118400574),\n",
       "       ('', 0.2181139588356018),\n",
       "       ('', 0.1461513489484787),\n",
       "       ('orthand', 0.14097967743873596)]}]}}},\n",
       " 'layer_16': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 40,\n",
       "      'weight': 0.16377514600753784,\n",
       "      'top_tokens': [(' who', 0.5176292061805725),\n",
       "       (' whom', 0.1563226282596588),\n",
       "       ('whom', 0.11851707100868225),\n",
       "       ('who', 0.11187142133712769),\n",
       "       (' things', 0.09565963596105576)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.15267600119113922,\n",
       "      'top_tokens': [('', 0.21190112829208374),\n",
       "       ('imales', 0.208678737282753),\n",
       "       ('ild', 0.20485442876815796),\n",
       "       ('', 0.20261335372924805),\n",
       "       ('opi', 0.1719522774219513)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.14532266557216644,\n",
       "      'top_tokens': [('', 0.2773520350456238),\n",
       "       (' ', 0.2534113824367523),\n",
       "       ('', 0.17746923863887787),\n",
       "       ('', 0.14835861325263977),\n",
       "       ('', 0.1434086561203003)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.14337585866451263,\n",
       "      'top_tokens': [('urats', 0.285367488861084),\n",
       "       ('plets', 0.20438171923160553),\n",
       "       ('', 0.19830790162086487),\n",
       "       ('\"><![', 0.16770270466804504),\n",
       "       ('rbia', 0.144240140914917)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.13826535642147064,\n",
       "      'top_tokens': [('enery', 0.24745407700538635),\n",
       "       ('enance', 0.19940321147441864),\n",
       "       ('imize', 0.19337016344070435),\n",
       "       ('visi', 0.18009553849697113),\n",
       "       (' Tremp', 0.1796770989894867)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.13161292672157288,\n",
       "      'top_tokens': [(' mill', 0.2688661515712738),\n",
       "       (' versa', 0.19014830887317657),\n",
       "       ('', 0.18805359303951263),\n",
       "       ('rpre', 0.17925311625003815),\n",
       "       ('', 0.17367888987064362)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.12497216463088989,\n",
       "      'top_tokens': [('agena', 0.3110204339027405),\n",
       "       ('nids', 0.22620539367198944),\n",
       "       ('>.<', 0.21481940150260925),\n",
       "       ('avens', 0.12399934232234955),\n",
       "       ('', 0.12395541369915009)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 40,\n",
       "      'weight': 0.16377507150173187,\n",
       "      'top_tokens': [(' who', 0.517629086971283),\n",
       "       (' whom', 0.1563226729631424),\n",
       "       ('whom', 0.11851704865694046),\n",
       "       ('who', 0.11187149584293365),\n",
       "       (' things', 0.09565979987382889)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.1526760756969452,\n",
       "      'top_tokens': [('', 0.21190112829208374),\n",
       "       ('imales', 0.20867884159088135),\n",
       "       ('ild', 0.20485442876815796),\n",
       "       ('', 0.2026132047176361),\n",
       "       ('opi', 0.17195239663124084)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.14532266557216644,\n",
       "      'top_tokens': [('', 0.27735239267349243),\n",
       "       (' ', 0.25341111421585083),\n",
       "       ('', 0.17746928334236145),\n",
       "       ('', 0.14835846424102783),\n",
       "       ('', 0.14340876042842865)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.14337585866451263,\n",
       "      'top_tokens': [('urats', 0.2853674590587616),\n",
       "       ('plets', 0.20438162982463837),\n",
       "       ('', 0.19830791652202606),\n",
       "       ('\"><![', 0.16770288348197937),\n",
       "       ('rbia', 0.1442400962114334)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.13826529681682587,\n",
       "      'top_tokens': [('enery', 0.24745404720306396),\n",
       "       ('enance', 0.19940327107906342),\n",
       "       ('imize', 0.1933700442314148),\n",
       "       ('visi', 0.18009541928768158),\n",
       "       (' Tremp', 0.17967717349529266)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.13161297142505646,\n",
       "      'top_tokens': [(' mill', 0.26886606216430664),\n",
       "       (' versa', 0.1901482194662094),\n",
       "       ('', 0.18805356323719025),\n",
       "       ('rpre', 0.17925317585468292),\n",
       "       ('', 0.17367900907993317)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.12497209757566452,\n",
       "      'top_tokens': [('agena', 0.31102028489112854),\n",
       "       ('nids', 0.226205512881279),\n",
       "       ('>.<', 0.2148195058107376),\n",
       "       ('avens', 0.12399928271770477),\n",
       "       ('', 0.12395535409450531)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 40,\n",
       "      'weight': 0.16377510130405426,\n",
       "      'top_tokens': [(' who', 0.5176287889480591),\n",
       "       (' whom', 0.15632280707359314),\n",
       "       ('whom', 0.11851714551448822),\n",
       "       ('who', 0.11187154054641724),\n",
       "       (' things', 0.09565974026918411)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.15267598628997803,\n",
       "      'top_tokens': [('', 0.21190117299556732),\n",
       "       ('imales', 0.20867863297462463),\n",
       "       ('ild', 0.20485447347164154),\n",
       "       ('', 0.20261339843273163),\n",
       "       ('opi', 0.17195230722427368)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.14532269537448883,\n",
       "      'top_tokens': [('', 0.27735236287117004),\n",
       "       (' ', 0.253411203622818),\n",
       "       ('', 0.17746920883655548),\n",
       "       ('', 0.1483585089445114),\n",
       "       ('', 0.14340868592262268)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.14337590336799622,\n",
       "      'top_tokens': [('urats', 0.28536751866340637),\n",
       "       ('plets', 0.20438174903392792),\n",
       "       ('', 0.1983078122138977),\n",
       "       ('\"><![', 0.1677028387784958),\n",
       "       ('rbia', 0.14424008131027222)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.13826525211334229,\n",
       "      'top_tokens': [('enery', 0.24745404720306396),\n",
       "       ('enance', 0.19940318167209625),\n",
       "       ('imize', 0.19337014853954315),\n",
       "       ('visi', 0.18009541928768158),\n",
       "       (' Tremp', 0.17967717349529266)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.1316128820180893,\n",
       "      'top_tokens': [(' mill', 0.2688661217689514),\n",
       "       (' versa', 0.19014818966388702),\n",
       "       ('', 0.18805360794067383),\n",
       "       ('rpre', 0.17925314605236053),\n",
       "       ('', 0.173678919672966)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.12497219443321228,\n",
       "      'top_tokens': [('agena', 0.3110203146934509),\n",
       "       ('nids', 0.22620552778244019),\n",
       "       ('>.<', 0.21481943130493164),\n",
       "       ('avens', 0.12399929761886597),\n",
       "       ('', 0.12395543605089188)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 40,\n",
       "      'weight': 0.16377514600753784,\n",
       "      'top_tokens': [(' who', 0.5176288485527039),\n",
       "       (' whom', 0.1563226729631424),\n",
       "       ('whom', 0.11851710081100464),\n",
       "       ('who', 0.11187144368886948),\n",
       "       (' things', 0.09565989673137665)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.15267594158649445,\n",
       "      'top_tokens': [('', 0.2119012176990509),\n",
       "       ('imales', 0.20867876708507538),\n",
       "       ('ild', 0.20485447347164154),\n",
       "       ('', 0.2026132345199585),\n",
       "       ('opi', 0.17195235192775726)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.14532269537448883,\n",
       "      'top_tokens': [('', 0.2773522734642029),\n",
       "       (' ', 0.2534112334251404),\n",
       "       ('', 0.17746920883655548),\n",
       "       ('', 0.1483585238456726),\n",
       "       ('', 0.14340879023075104)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.14337590336799622,\n",
       "      'top_tokens': [('urats', 0.2853674590587616),\n",
       "       ('plets', 0.20438183844089508),\n",
       "       ('', 0.19830778241157532),\n",
       "       ('\"><![', 0.16770285367965698),\n",
       "       ('rbia', 0.1442400962114334)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.13826531171798706,\n",
       "      'top_tokens': [('enery', 0.24745407700538635),\n",
       "       ('enance', 0.19940321147441864),\n",
       "       ('imize', 0.19337016344070435),\n",
       "       ('visi', 0.180095374584198),\n",
       "       (' Tremp', 0.17967718839645386)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.13161292672157288,\n",
       "      'top_tokens': [(' mill', 0.26886600255966187),\n",
       "       (' versa', 0.19014829397201538),\n",
       "       ('', 0.18805356323719025),\n",
       "       ('rpre', 0.1792532205581665),\n",
       "       ('', 0.17367888987064362)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.12497211992740631,\n",
       "      'top_tokens': [('agena', 0.31102028489112854),\n",
       "       ('nids', 0.226205512881279),\n",
       "       ('>.<', 0.2148195058107376),\n",
       "       ('avens', 0.12399928271770477),\n",
       "       ('', 0.12395542114973068)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 40,\n",
       "      'weight': 0.16377511620521545,\n",
       "      'top_tokens': [(' who', 0.517629086971283),\n",
       "       (' whom', 0.15632274746894836),\n",
       "       ('whom', 0.11851704865694046),\n",
       "       ('who', 0.11187145113945007),\n",
       "       (' things', 0.09565970301628113)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.15267598628997803,\n",
       "      'top_tokens': [('', 0.21190108358860016),\n",
       "       ('imales', 0.20867864787578583),\n",
       "       ('ild', 0.20485448837280273),\n",
       "       ('', 0.20261339843273163),\n",
       "       ('opi', 0.17195236682891846)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.14532266557216644,\n",
       "      'top_tokens': [('', 0.2773522138595581),\n",
       "       (' ', 0.25341129302978516),\n",
       "       ('', 0.17746910452842712),\n",
       "       ('', 0.14835849404335022),\n",
       "       ('', 0.14340876042842865)]},\n",
       "     {'expert_id': 3,\n",
       "      'weight': 0.14337582886219025,\n",
       "      'top_tokens': [('urats', 0.2853673994541168),\n",
       "       ('plets', 0.20438174903392792),\n",
       "       ('', 0.19830794632434845),\n",
       "       ('\"><![', 0.16770276427268982),\n",
       "       ('rbia', 0.1442400962114334)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.13826531171798706,\n",
       "      'top_tokens': [('enery', 0.24745410680770874),\n",
       "       ('enance', 0.19940312206745148),\n",
       "       ('imize', 0.19337019324302673),\n",
       "       ('visi', 0.18009555339813232),\n",
       "       (' Tremp', 0.17967703938484192)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.13161292672157288,\n",
       "      'top_tokens': [(' mill', 0.26886606216430664),\n",
       "       (' versa', 0.19014829397201538),\n",
       "       ('', 0.18805353343486786),\n",
       "       ('rpre', 0.17925310134887695),\n",
       "       ('', 0.17367896437644958)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.12497211992740631,\n",
       "      'top_tokens': [('agena', 0.3110203146934509),\n",
       "       ('nids', 0.22620552778244019),\n",
       "       ('>.<', 0.21481943130493164),\n",
       "       ('avens', 0.12399934977293015),\n",
       "       ('', 0.1239553689956665)]}]}}},\n",
       " 'layer_17': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.24991360306739807,\n",
       "      'top_tokens': [('zzle', 0.2788418233394623),\n",
       "       ('itti', 0.22290578484535217),\n",
       "       ('angelog', 0.17335499823093414),\n",
       "       ('estock', 0.17004068195819855),\n",
       "       ('itors', 0.15485674142837524)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.18309038877487183,\n",
       "      'top_tokens': [('again', 0.34345072507858276),\n",
       "       ('Again', 0.23235958814620972),\n",
       "       ('igneur', 0.16330291330814362),\n",
       "       (' Again', 0.13164618611335754),\n",
       "       (' again', 0.12924066185951233)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.12973394989967346,\n",
       "      'top_tokens': [('', 0.2619338035583496),\n",
       "       ('balls', 0.2213149219751358),\n",
       "       (' Po', 0.196824848651886),\n",
       "       ('part', 0.16056881844997406),\n",
       "       (' Balls', 0.15935760736465454)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.11578408628702164,\n",
       "      'top_tokens': [('2', 0.2839003801345825),\n",
       "       ('3', 0.21672125160694122),\n",
       "       ('9', 0.17894934117794037),\n",
       "       ('1', 0.16554418206214905),\n",
       "       ('6', 0.15488487482070923)]},\n",
       "     {'expert_id': 21,\n",
       "      'weight': 0.11361648142337799,\n",
       "      'top_tokens': [(' ', 0.3950646221637726),\n",
       "       (' or', 0.3555464744567871),\n",
       "       ('urname', 0.0941871702671051),\n",
       "       ('odox', 0.08193950355052948),\n",
       "       (' nor', 0.07326211780309677)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.10474617779254913,\n",
       "      'top_tokens': [(' fre', 0.24364995956420898),\n",
       "       ('', 0.21865056455135345),\n",
       "       ('', 0.21050813794136047),\n",
       "       ('enal', 0.1642048954963684),\n",
       "       ('', 0.1629863828420639)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10311531275510788,\n",
       "      'top_tokens': [(' per', 0.30195358395576477),\n",
       "       (' each', 0.2123759239912033),\n",
       "       ('per', 0.17798832058906555),\n",
       "       ('atu', 0.17224152386188507),\n",
       "       ('each', 0.13544072210788727)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.2499135434627533,\n",
       "      'top_tokens': [('zzle', 0.27884188294410706),\n",
       "       ('itti', 0.22290560603141785),\n",
       "       ('angelog', 0.17335495352745056),\n",
       "       ('estock', 0.17004063725471497),\n",
       "       ('itors', 0.15485692024230957)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.18309038877487183,\n",
       "      'top_tokens': [('again', 0.3434508740901947),\n",
       "       ('Again', 0.23235957324504852),\n",
       "       ('igneur', 0.16330274939537048),\n",
       "       (' Again', 0.13164611160755157),\n",
       "       (' again', 0.12924066185951233)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.12973396480083466,\n",
       "      'top_tokens': [('', 0.2619335651397705),\n",
       "       ('balls', 0.22131513059139252),\n",
       "       (' Po', 0.19682475924491882),\n",
       "       ('part', 0.1605687439441681),\n",
       "       (' Balls', 0.15935783088207245)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.11578399688005447,\n",
       "      'top_tokens': [('2', 0.28390026092529297),\n",
       "       ('3', 0.21672125160694122),\n",
       "       ('9', 0.17894935607910156),\n",
       "       ('1', 0.16554419696331024),\n",
       "       ('6', 0.15488487482070923)]},\n",
       "     {'expert_id': 21,\n",
       "      'weight': 0.11361655592918396,\n",
       "      'top_tokens': [(' ', 0.3950645923614502),\n",
       "       (' or', 0.355546772480011),\n",
       "       ('urname', 0.09418707340955734),\n",
       "       ('odox', 0.08193937689065933),\n",
       "       (' nor', 0.07326221466064453)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.10474615544080734,\n",
       "      'top_tokens': [(' fre', 0.24364988505840302),\n",
       "       ('', 0.2186506986618042),\n",
       "       ('', 0.21050837635993958),\n",
       "       ('enal', 0.16420480608940125),\n",
       "       ('', 0.16298627853393555)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10311529040336609,\n",
       "      'top_tokens': [(' per', 0.3019535541534424),\n",
       "       (' each', 0.21237590909004211),\n",
       "       ('per', 0.17798830568790436),\n",
       "       ('atu', 0.17224150896072388),\n",
       "       ('each', 0.13544078171253204)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.24991357326507568,\n",
       "      'top_tokens': [('zzle', 0.278842031955719),\n",
       "       ('itti', 0.22290562093257904),\n",
       "       ('angelog', 0.17335478961467743),\n",
       "       ('estock', 0.17004063725471497),\n",
       "       ('itors', 0.15485699474811554)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.18309040367603302,\n",
       "      'top_tokens': [('again', 0.34345054626464844),\n",
       "       ('Again', 0.23235967755317688),\n",
       "       ('igneur', 0.16330306231975555),\n",
       "       (' Again', 0.13164612650871277),\n",
       "       (' again', 0.12924060225486755)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.12973396480083466,\n",
       "      'top_tokens': [('', 0.2619335651397705),\n",
       "       ('balls', 0.22131502628326416),\n",
       "       (' Po', 0.19682475924491882),\n",
       "       ('part', 0.16056887805461884),\n",
       "       (' Balls', 0.15935775637626648)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.11578402668237686,\n",
       "      'top_tokens': [('2', 0.2839003801345825),\n",
       "       ('3', 0.2167213410139084),\n",
       "       ('9', 0.1789492517709732),\n",
       "       ('1', 0.16554409265518188),\n",
       "       ('6', 0.1548849493265152)]},\n",
       "     {'expert_id': 21,\n",
       "      'weight': 0.11361656337976456,\n",
       "      'top_tokens': [(' ', 0.39506471157073975),\n",
       "       (' or', 0.35554635524749756),\n",
       "       ('urname', 0.09418723732233047),\n",
       "       ('odox', 0.08193956315517426),\n",
       "       (' nor', 0.07326210290193558)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.10474618524312973,\n",
       "      'top_tokens': [(' fre', 0.24364979565143585),\n",
       "       ('', 0.2186507284641266),\n",
       "       ('', 0.2105080932378769),\n",
       "       ('enal', 0.16420498490333557),\n",
       "       ('', 0.16298645734786987)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10311531275510788,\n",
       "      'top_tokens': [(' per', 0.30195361375808716),\n",
       "       (' each', 0.2123759388923645),\n",
       "       ('per', 0.17798824608325958),\n",
       "       ('atu', 0.17224153876304626),\n",
       "       ('each', 0.13544073700904846)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.24991363286972046,\n",
       "      'top_tokens': [('zzle', 0.27884188294410706),\n",
       "       ('itti', 0.22290560603141785),\n",
       "       ('angelog', 0.1733548641204834),\n",
       "       ('estock', 0.17004071176052094),\n",
       "       ('itors', 0.1548568308353424)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.18309050798416138,\n",
       "      'top_tokens': [('again', 0.3434508740901947),\n",
       "       ('Again', 0.23235957324504852),\n",
       "       ('igneur', 0.16330282390117645),\n",
       "       (' Again', 0.13164611160755157),\n",
       "       (' again', 0.12924060225486755)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.1297338902950287,\n",
       "      'top_tokens': [('', 0.2619335353374481),\n",
       "       ('balls', 0.22131511569023132),\n",
       "       (' Po', 0.19682492315769196),\n",
       "       ('part', 0.1605687290430069),\n",
       "       (' Balls', 0.15935774147510529)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.11578401923179626,\n",
       "      'top_tokens': [('2', 0.2839002013206482),\n",
       "       ('3', 0.21672120690345764),\n",
       "       ('9', 0.17894940078258514),\n",
       "       ('1', 0.16554415225982666),\n",
       "       ('6', 0.15488506853580475)]},\n",
       "     {'expert_id': 21,\n",
       "      'weight': 0.11361642926931381,\n",
       "      'top_tokens': [(' ', 0.39506447315216064),\n",
       "       (' or', 0.35554665327072144),\n",
       "       ('urname', 0.09418713301420212),\n",
       "       ('odox', 0.08193947374820709),\n",
       "       (' nor', 0.07326215505599976)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.10474618524312973,\n",
       "      'top_tokens': [(' fre', 0.2436499297618866),\n",
       "       ('', 0.21865063905715942),\n",
       "       ('', 0.21050821244716644),\n",
       "       ('enal', 0.16420488059520721),\n",
       "       ('', 0.16298630833625793)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10311535745859146,\n",
       "      'top_tokens': [(' per', 0.30195367336273193),\n",
       "       (' each', 0.21237559616565704),\n",
       "       ('per', 0.177988201379776),\n",
       "       ('atu', 0.17224182188510895),\n",
       "       ('each', 0.1354406327009201)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.2499135434627533,\n",
       "      'top_tokens': [('zzle', 0.2788417935371399),\n",
       "       ('itti', 0.22290563583374023),\n",
       "       ('angelog', 0.17335480451583862),\n",
       "       ('estock', 0.17004083096981049),\n",
       "       ('itors', 0.15485693514347076)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.18309049308300018,\n",
       "      'top_tokens': [('again', 0.3434508740901947),\n",
       "       ('Again', 0.23235969245433807),\n",
       "       ('igneur', 0.16330274939537048),\n",
       "       (' Again', 0.13164611160755157),\n",
       "       (' again', 0.12924060225486755)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.12973393499851227,\n",
       "      'top_tokens': [('', 0.2619337737560272),\n",
       "       ('balls', 0.22131499648094177),\n",
       "       (' Po', 0.19682472944259644),\n",
       "       ('part', 0.16056877374649048),\n",
       "       (' Balls', 0.15935777127742767)]},\n",
       "     {'expert_id': 43,\n",
       "      'weight': 0.11578400433063507,\n",
       "      'top_tokens': [('2', 0.28390026092529297),\n",
       "       ('3', 0.21672125160694122),\n",
       "       ('9', 0.1789495199918747),\n",
       "       ('1', 0.16554410755634308),\n",
       "       ('6', 0.15488487482070923)]},\n",
       "     {'expert_id': 21,\n",
       "      'weight': 0.11361652612686157,\n",
       "      'top_tokens': [(' ', 0.39506468176841736),\n",
       "       (' or', 0.3555465340614319),\n",
       "       ('urname', 0.0941871777176857),\n",
       "       ('odox', 0.08193947374820709),\n",
       "       (' nor', 0.07326216250658035)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.10474615544080734,\n",
       "      'top_tokens': [(' fre', 0.24365004897117615),\n",
       "       ('', 0.21865063905715942),\n",
       "       ('', 0.21050810813903809),\n",
       "       ('enal', 0.1642049252986908),\n",
       "       ('', 0.16298632323741913)]},\n",
       "     {'expert_id': 10,\n",
       "      'weight': 0.10311533510684967,\n",
       "      'top_tokens': [(' per', 0.30195340514183044),\n",
       "       (' each', 0.21237580478191376),\n",
       "       ('per', 0.17798830568790436),\n",
       "       ('atu', 0.17224174737930298),\n",
       "       ('each', 0.13544076681137085)]}]}}},\n",
       " 'layer_18': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 25,\n",
       "      'weight': 0.25401782989501953,\n",
       "      'top_tokens': [('', 0.3670589327812195),\n",
       "       ('wards', 0.19183483719825745),\n",
       "       ('blr', 0.17359872162342072),\n",
       "       ('ection', 0.14154520630836487),\n",
       "       ('roma', 0.12596222758293152)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.1469365656375885,\n",
       "      'top_tokens': [('ks', 0.2244793176651001),\n",
       "       ('pers', 0.20393143594264984),\n",
       "       ('im', 0.19725707173347473),\n",
       "       ('ithe', 0.18831925094127655),\n",
       "       ('ora', 0.18601293861865997)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.14305764436721802,\n",
       "      'top_tokens': [(' ', 0.4865487217903137),\n",
       "       ('igna', 0.23222379386425018),\n",
       "       (' Foix', 0.09609628468751907),\n",
       "       (' drogues', 0.09590841829776764),\n",
       "       (' ', 0.08922276645898819)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12403015792369843,\n",
       "      'top_tokens': [('', 0.40726470947265625),\n",
       "       ('', 0.1967158019542694),\n",
       "       ('zes', 0.16400954127311707),\n",
       "       ('ual', 0.11984450370073318),\n",
       "       ('ented', 0.1121654063463211)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.11296751350164413,\n",
       "      'top_tokens': [('odge', 0.2607223093509674),\n",
       "       ('', 0.21328884363174438),\n",
       "       ('', 0.1813167780637741),\n",
       "       ('ein', 0.17564526200294495),\n",
       "       ('kip', 0.16902677714824677)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071628332138062,\n",
       "      'top_tokens': [('orden', 0.23973654210567474),\n",
       "       ('', 0.21268495917320251),\n",
       "       ('', 0.1930486261844635),\n",
       "       ('enched', 0.19020627439022064),\n",
       "       ('encar', 0.16432349383831024)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.10827405005693436,\n",
       "      'top_tokens': [('', 0.2178190052509308),\n",
       "       ('WAY', 0.21425336599349976),\n",
       "       ('WAYS', 0.21342934668064117),\n",
       "       ('doxygen', 0.18192951381206512),\n",
       "       ('agut', 0.17256876826286316)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 25,\n",
       "      'weight': 0.2540176510810852,\n",
       "      'top_tokens': [('', 0.36705851554870605),\n",
       "       ('wards', 0.1918351650238037),\n",
       "       ('blr', 0.17359869182109833),\n",
       "       ('ection', 0.14154525101184845),\n",
       "       ('roma', 0.1259623020887375)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.14693661034107208,\n",
       "      'top_tokens': [('ks', 0.22447927296161652),\n",
       "       ('pers', 0.20393139123916626),\n",
       "       ('im', 0.19725702702999115),\n",
       "       ('ithe', 0.18831931054592133),\n",
       "       ('ora', 0.18601304292678833)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.1430576592683792,\n",
       "      'top_tokens': [(' ', 0.4865490794181824),\n",
       "       ('igna', 0.23222362995147705),\n",
       "       (' Foix', 0.0960962250828743),\n",
       "       (' drogues', 0.09590843319892883),\n",
       "       (' ', 0.08922266215085983)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12403011322021484,\n",
       "      'top_tokens': [('', 0.4072647988796234),\n",
       "       ('', 0.1967158019542694),\n",
       "       ('zes', 0.1640094667673111),\n",
       "       ('ual', 0.11984444409608841),\n",
       "       ('ented', 0.1121654286980629)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.11296753585338593,\n",
       "      'top_tokens': [('odge', 0.2607223689556122),\n",
       "       ('', 0.2132887989282608),\n",
       "       ('', 0.18131674826145172),\n",
       "       ('ein', 0.17564526200294495),\n",
       "       ('kip', 0.1690267026424408)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071635037660599,\n",
       "      'top_tokens': [('orden', 0.23973676562309265),\n",
       "       ('', 0.21268504858016968),\n",
       "       ('', 0.19304834306240082),\n",
       "       ('enched', 0.1902063637971878),\n",
       "       ('encar', 0.16432350873947144)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.10827406495809555,\n",
       "      'top_tokens': [('', 0.21781902015209198),\n",
       "       ('WAY', 0.2142532765865326),\n",
       "       ('WAYS', 0.2134292721748352),\n",
       "       ('doxygen', 0.18192970752716064),\n",
       "       ('agut', 0.1725686937570572)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 25,\n",
       "      'weight': 0.25401771068573,\n",
       "      'top_tokens': [('', 0.36705881357192993),\n",
       "       ('wards', 0.191834956407547),\n",
       "       ('blr', 0.1735984981060028),\n",
       "       ('ection', 0.14154529571533203),\n",
       "       ('roma', 0.12596237659454346)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.14693665504455566,\n",
       "      'top_tokens': [('ks', 0.22447927296161652),\n",
       "       ('pers', 0.20393136143684387),\n",
       "       ('im', 0.1972571164369583),\n",
       "       ('ithe', 0.18831922113895416),\n",
       "       ('ora', 0.18601299822330475)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.1430576592683792,\n",
       "      'top_tokens': [(' ', 0.48654916882514954),\n",
       "       ('igna', 0.23222357034683228),\n",
       "       (' Foix', 0.09609614312648773),\n",
       "       (' drogues', 0.09590845555067062),\n",
       "       (' ', 0.08922267705202103)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12403006851673126,\n",
       "      'top_tokens': [('', 0.4072648584842682),\n",
       "       ('', 0.19671568274497986),\n",
       "       ('zes', 0.1640094518661499),\n",
       "       ('ual', 0.11984452605247498),\n",
       "       ('ented', 0.11216544359922409)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.11296756565570831,\n",
       "      'top_tokens': [('odge', 0.26072239875793457),\n",
       "       ('', 0.21328887343406677),\n",
       "       ('', 0.18131685256958008),\n",
       "       ('ein', 0.17564518749713898),\n",
       "       ('kip', 0.16902664303779602)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071640253067017,\n",
       "      'top_tokens': [('orden', 0.23973657190799713),\n",
       "       ('', 0.2126849889755249),\n",
       "       ('', 0.19304853677749634),\n",
       "       ('enched', 0.19020642340183258),\n",
       "       ('encar', 0.16432341933250427)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.10827399790287018,\n",
       "      'top_tokens': [('', 0.2178189605474472),\n",
       "       ('WAY', 0.21425342559814453),\n",
       "       ('WAYS', 0.2134293168783188),\n",
       "       ('doxygen', 0.1819295585155487),\n",
       "       ('agut', 0.17256872355937958)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 25,\n",
       "      'weight': 0.25401782989501953,\n",
       "      'top_tokens': [('', 0.3670588731765747),\n",
       "       ('wards', 0.19183480739593506),\n",
       "       ('blr', 0.17359869182109833),\n",
       "       ('ection', 0.14154532551765442),\n",
       "       ('roma', 0.1259622424840927)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.1469365507364273,\n",
       "      'top_tokens': [('ks', 0.22447924315929413),\n",
       "       ('pers', 0.20393136143684387),\n",
       "       ('im', 0.19725701212882996),\n",
       "       ('ithe', 0.18831928074359894),\n",
       "       ('ora', 0.18601305782794952)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.1430576890707016,\n",
       "      'top_tokens': [(' ', 0.48654860258102417),\n",
       "       ('igna', 0.2322237342596054),\n",
       "       (' Foix', 0.09609630703926086),\n",
       "       (' drogues', 0.09590847790241241),\n",
       "       (' ', 0.08922278136014938)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12403014302253723,\n",
       "      'top_tokens': [('', 0.40726491808891296),\n",
       "       ('', 0.196715846657753),\n",
       "       ('zes', 0.1640094369649887),\n",
       "       ('ual', 0.11984442174434662),\n",
       "       ('ented', 0.11216537654399872)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.11296751350164413,\n",
       "      'top_tokens': [('odge', 0.26072224974632263),\n",
       "       ('', 0.21328890323638916),\n",
       "       ('', 0.18131695687770844),\n",
       "       ('ein', 0.17564521729946136),\n",
       "       ('kip', 0.1690266728401184)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071629822254181,\n",
       "      'top_tokens': [('orden', 0.23973657190799713),\n",
       "       ('', 0.21268503367900848),\n",
       "       ('', 0.1930486410856247),\n",
       "       ('enched', 0.19020621478557587),\n",
       "       ('encar', 0.16432346403598785)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.10827402770519257,\n",
       "      'top_tokens': [('', 0.21781904995441437),\n",
       "       ('WAY', 0.21425341069698334),\n",
       "       ('WAYS', 0.21342919766902924),\n",
       "       ('doxygen', 0.18192946910858154),\n",
       "       ('agut', 0.17256879806518555)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 25,\n",
       "      'weight': 0.2540176510810852,\n",
       "      'top_tokens': [('', 0.36705881357192993),\n",
       "       ('wards', 0.19183486700057983),\n",
       "       ('blr', 0.17359866201877594),\n",
       "       ('ection', 0.14154529571533203),\n",
       "       ('roma', 0.12596234679222107)]},\n",
       "     {'expert_id': 18,\n",
       "      'weight': 0.14693662524223328,\n",
       "      'top_tokens': [('ks', 0.2244790941476822),\n",
       "       ('pers', 0.20393134653568268),\n",
       "       ('im', 0.19725719094276428),\n",
       "       ('ithe', 0.18831925094127655),\n",
       "       ('ora', 0.1860131174325943)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.143057718873024,\n",
       "      'top_tokens': [(' ', 0.48654884099960327),\n",
       "       ('igna', 0.23222385346889496),\n",
       "       (' Foix', 0.0960962176322937),\n",
       "       (' drogues', 0.09590844064950943),\n",
       "       (' ', 0.08922265470027924)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.12403015792369843,\n",
       "      'top_tokens': [('', 0.4072648584842682),\n",
       "       ('', 0.1967158317565918),\n",
       "       ('zes', 0.1640094518661499),\n",
       "       ('ual', 0.11984439939260483),\n",
       "       ('ented', 0.11216544359922409)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.11296757310628891,\n",
       "      'top_tokens': [('odge', 0.26072239875793457),\n",
       "       ('', 0.21328891813755035),\n",
       "       ('', 0.18131685256958008),\n",
       "       ('ein', 0.17564529180526733),\n",
       "       ('kip', 0.16902650892734528)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071635037660599,\n",
       "      'top_tokens': [('orden', 0.23973676562309265),\n",
       "       ('', 0.2126850187778473),\n",
       "       ('', 0.19304843246936798),\n",
       "       ('enched', 0.1902063935995102),\n",
       "       ('encar', 0.16432343423366547)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.1082739531993866,\n",
       "      'top_tokens': [('', 0.21781913936138153),\n",
       "       ('WAY', 0.21425318717956543),\n",
       "       ('WAYS', 0.21342918276786804),\n",
       "       ('doxygen', 0.1819295436143875),\n",
       "       ('agut', 0.17256887257099152)]}]}}},\n",
       " 'layer_19': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 6,\n",
       "      'weight': 0.2715849280357361,\n",
       "      'top_tokens': [('', 0.29995301365852356),\n",
       "       ('odium', 0.18949227035045624),\n",
       "       ('', 0.18444539606571198),\n",
       "       ('', 0.1631786972284317),\n",
       "       (' head', 0.16293060779571533)]},\n",
       "     {'expert_id': 56,\n",
       "      'weight': 0.14426234364509583,\n",
       "      'top_tokens': [('take', 0.3372780680656433),\n",
       "       (' take', 0.19693247973918915),\n",
       "       (' took', 0.1883307844400406),\n",
       "       ('taking', 0.1464547961950302),\n",
       "       (' taking', 0.13100390136241913)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.1366465985774994,\n",
       "      'top_tokens': [(' in', 0.24637199938297272),\n",
       "       (' between', 0.19634360074996948),\n",
       "       ('', 0.19533246755599976),\n",
       "       ('', 0.19217275083065033),\n",
       "       ('ota', 0.1697792410850525)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.12141115218400955,\n",
       "      'top_tokens': [(',', 0.4278882145881653),\n",
       "       (' or', 0.23387649655342102),\n",
       "       ('business', 0.15391038358211517),\n",
       "       (' our', 0.09262648969888687),\n",
       "       (' business', 0.09169843792915344)]},\n",
       "     {'expert_id': 23,\n",
       "      'weight': 0.12027572095394135,\n",
       "      'top_tokens': [('only', 0.5265964865684509),\n",
       "       ('Only', 0.19414635002613068),\n",
       "       ('ONLY', 0.09946759790182114),\n",
       "       ('by', 0.09535330533981323),\n",
       "       (' only', 0.08443629741668701)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.10800682008266449,\n",
       "      'top_tokens': [(' thing', 0.44575756788253784),\n",
       "       ('idean', 0.19299821555614471),\n",
       "       (')$-', 0.17258621752262115),\n",
       "       ('avant', 0.09875299036502838),\n",
       "       ('', 0.08990507572889328)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.09781251847743988,\n",
       "      'top_tokens': [('both', 0.4087163805961609),\n",
       "       ('', 0.22144244611263275),\n",
       "       ('', 0.13443362712860107),\n",
       "       ('', 0.11779723316431046),\n",
       "       (' Both', 0.11761033535003662)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 6,\n",
       "      'weight': 0.2715848386287689,\n",
       "      'top_tokens': [('', 0.2999528646469116),\n",
       "       ('odium', 0.1894923597574234),\n",
       "       ('', 0.1844453066587448),\n",
       "       ('', 0.16317878663539886),\n",
       "       (' head', 0.1629306823015213)]},\n",
       "     {'expert_id': 56,\n",
       "      'weight': 0.14426249265670776,\n",
       "      'top_tokens': [('take', 0.3372781276702881),\n",
       "       (' take', 0.19693230092525482),\n",
       "       (' took', 0.18833081424236298),\n",
       "       ('taking', 0.14645490050315857),\n",
       "       (' taking', 0.13100393116474152)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.1366465836763382,\n",
       "      'top_tokens': [(' in', 0.24637199938297272),\n",
       "       (' between', 0.19634369015693665),\n",
       "       ('', 0.19533254206180573),\n",
       "       ('', 0.1921725571155548),\n",
       "       ('ota', 0.16977916657924652)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.12141107022762299,\n",
       "      'top_tokens': [(',', 0.4278881251811981),\n",
       "       (' or', 0.23387645184993744),\n",
       "       ('business', 0.15391035377979279),\n",
       "       (' our', 0.09262665361166),\n",
       "       (' business', 0.09169841557741165)]},\n",
       "     {'expert_id': 23,\n",
       "      'weight': 0.12027571350336075,\n",
       "      'top_tokens': [('only', 0.5265969634056091),\n",
       "       ('Only', 0.1941462606191635),\n",
       "       ('ONLY', 0.09946764260530472),\n",
       "       ('by', 0.09535279870033264),\n",
       "       (' only', 0.08443637192249298)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.10800686478614807,\n",
       "      'top_tokens': [(' thing', 0.4457572102546692),\n",
       "       ('idean', 0.19299861788749695),\n",
       "       (')$-', 0.17258624732494354),\n",
       "       ('avant', 0.09875291585922241),\n",
       "       ('', 0.08990500867366791)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.09781248867511749,\n",
       "      'top_tokens': [('both', 0.4087163805961609),\n",
       "       ('', 0.22144213318824768),\n",
       "       ('', 0.13443374633789062),\n",
       "       ('', 0.11779734492301941),\n",
       "       (' Both', 0.11761027574539185)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 6,\n",
       "      'weight': 0.27158495783805847,\n",
       "      'top_tokens': [('', 0.2999528646469116),\n",
       "       ('odium', 0.18949227035045624),\n",
       "       ('', 0.18444539606571198),\n",
       "       ('', 0.1631789207458496),\n",
       "       (' head', 0.16293059289455414)]},\n",
       "     {'expert_id': 56,\n",
       "      'weight': 0.14426231384277344,\n",
       "      'top_tokens': [('take', 0.3372783064842224),\n",
       "       (' take', 0.19693240523338318),\n",
       "       (' took', 0.18833063542842865),\n",
       "       ('taking', 0.14645490050315857),\n",
       "       (' taking', 0.1310037523508072)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.1366465538740158,\n",
       "      'top_tokens': [(' in', 0.24637199938297272),\n",
       "       (' between', 0.1963437795639038),\n",
       "       ('', 0.19533246755599976),\n",
       "       ('', 0.1921725571155548),\n",
       "       ('ota', 0.16977916657924652)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.12141109257936478,\n",
       "      'top_tokens': [(',', 0.4278886914253235),\n",
       "       (' or', 0.2338767647743225),\n",
       "       ('business', 0.15390996634960175),\n",
       "       (' our', 0.09262650460004807),\n",
       "       (' business', 0.09169801324605942)]},\n",
       "     {'expert_id': 23,\n",
       "      'weight': 0.12027575820684433,\n",
       "      'top_tokens': [('only', 0.5265964865684509),\n",
       "       ('Only', 0.1941462606191635),\n",
       "       ('ONLY', 0.0994676947593689),\n",
       "       ('by', 0.09535316377878189),\n",
       "       (' only', 0.08443633466959)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.1080067977309227,\n",
       "      'top_tokens': [(' thing', 0.44575735926628113),\n",
       "       ('idean', 0.19299830496311188),\n",
       "       (')$-', 0.17258630692958832),\n",
       "       ('avant', 0.09875304251909256),\n",
       "       ('', 0.08990494906902313)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.09781243652105331,\n",
       "      'top_tokens': [('both', 0.4087163209915161),\n",
       "       ('', 0.22144241631031036),\n",
       "       ('', 0.13443367183208466),\n",
       "       ('', 0.11779726296663284),\n",
       "       (' Both', 0.11761031299829483)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 6,\n",
       "      'weight': 0.27158495783805847,\n",
       "      'top_tokens': [('', 0.29995307326316833),\n",
       "       ('odium', 0.18949231505393982),\n",
       "       ('', 0.1844453662633896),\n",
       "       ('', 0.16317866742610931),\n",
       "       (' head', 0.16293056309223175)]},\n",
       "     {'expert_id': 56,\n",
       "      'weight': 0.14426228404045105,\n",
       "      'top_tokens': [('take', 0.3372781276702881),\n",
       "       (' take', 0.19693230092525482),\n",
       "       (' took', 0.18833070993423462),\n",
       "       ('taking', 0.14645490050315857),\n",
       "       (' taking', 0.13100393116474152)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.13664661347866058,\n",
       "      'top_tokens': [(' in', 0.24637165665626526),\n",
       "       (' between', 0.19634407758712769),\n",
       "       ('', 0.19533245265483856),\n",
       "       ('', 0.19217248260974884),\n",
       "       ('ota', 0.16977933049201965)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.1214110404253006,\n",
       "      'top_tokens': [(',', 0.4278879463672638),\n",
       "       (' or', 0.23387634754180908),\n",
       "       ('business', 0.1539105921983719),\n",
       "       (' our', 0.09262643754482269),\n",
       "       (' business', 0.09169864654541016)]},\n",
       "     {'expert_id': 23,\n",
       "      'weight': 0.12027570605278015,\n",
       "      'top_tokens': [('only', 0.52659672498703),\n",
       "       ('Only', 0.1941462606191635),\n",
       "       ('ONLY', 0.09946755319833755),\n",
       "       ('by', 0.09535320848226547),\n",
       "       (' only', 0.08443629741668701)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.10800681263208389,\n",
       "      'top_tokens': [(' thing', 0.445757657289505),\n",
       "       ('idean', 0.19299843907356262),\n",
       "       (')$-', 0.1725860983133316),\n",
       "       ('avant', 0.09875292330980301),\n",
       "       ('', 0.08990492671728134)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.0978124812245369,\n",
       "      'top_tokens': [('both', 0.40871647000312805),\n",
       "       ('', 0.22144217789173126),\n",
       "       ('', 0.13443365693092346),\n",
       "       ('', 0.11779730767011642),\n",
       "       (' Both', 0.11761035770177841)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 6,\n",
       "      'weight': 0.27158495783805847,\n",
       "      'top_tokens': [('', 0.2999529540538788),\n",
       "       ('odium', 0.189492329955101),\n",
       "       ('', 0.18444529175758362),\n",
       "       ('', 0.16317883133888245),\n",
       "       (' head', 0.16293063759803772)]},\n",
       "     {'expert_id': 56,\n",
       "      'weight': 0.14426232874393463,\n",
       "      'top_tokens': [('take', 0.33727824687957764),\n",
       "       (' take', 0.1969323754310608),\n",
       "       (' took', 0.18833059072494507),\n",
       "       ('taking', 0.1464548110961914),\n",
       "       (' taking', 0.13100384175777435)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.1366465538740158,\n",
       "      'top_tokens': [(' in', 0.24637211859226227),\n",
       "       (' between', 0.1963433176279068),\n",
       "       ('', 0.1953323632478714),\n",
       "       ('', 0.19217264652252197),\n",
       "       ('ota', 0.16977949440479279)]},\n",
       "     {'expert_id': 4,\n",
       "      'weight': 0.12141107022762299,\n",
       "      'top_tokens': [(',', 0.4278884828090668),\n",
       "       (' or', 0.23387664556503296),\n",
       "       ('business', 0.15391018986701965),\n",
       "       (' our', 0.09262637048959732),\n",
       "       (' business', 0.09169831871986389)]},\n",
       "     {'expert_id': 23,\n",
       "      'weight': 0.12027576565742493,\n",
       "      'top_tokens': [('only', 0.5265966653823853),\n",
       "       ('Only', 0.19414614140987396),\n",
       "       ('ONLY', 0.0994676798582077),\n",
       "       ('by', 0.09535319358110428),\n",
       "       (' only', 0.0844363272190094)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.1080068051815033,\n",
       "      'top_tokens': [(' thing', 0.4457576870918274),\n",
       "       ('idean', 0.1929982602596283),\n",
       "       (')$-', 0.17258593440055847),\n",
       "       ('avant', 0.09875302016735077),\n",
       "       ('', 0.0899050161242485)]},\n",
       "     {'expert_id': 54,\n",
       "      'weight': 0.0978124588727951,\n",
       "      'top_tokens': [('both', 0.40871623158454895),\n",
       "       ('', 0.2214425653219223),\n",
       "       ('', 0.1344335824251175),\n",
       "       ('', 0.11779730021953583),\n",
       "       (' Both', 0.11761035025119781)]}]}}},\n",
       " 'layer_20': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 20,\n",
       "      'weight': 0.1825883388519287,\n",
       "      'top_tokens': [(' Asiatic', 0.4586283564567566),\n",
       "       ('iat', 0.3088378310203552),\n",
       "       ('', 0.11090447753667831),\n",
       "       ('', 0.08475959300994873),\n",
       "       ('', 0.03686976805329323)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.16528278589248657,\n",
       "      'top_tokens': [('', 0.2126113325357437),\n",
       "       (' Climent', 0.2114257514476776),\n",
       "       ('', 0.21097086369991302),\n",
       "       ('', 0.19361039996147156),\n",
       "       ('ingui', 0.1713816523551941)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.16120949387550354,\n",
       "      'top_tokens': [('-', 0.25402945280075073),\n",
       "       ('', 0.2275930792093277),\n",
       "       (' ', 0.1818588376045227),\n",
       "       ('', 0.16951294243335724),\n",
       "       (' _', 0.16700564324855804)]},\n",
       "     {'expert_id': 57,\n",
       "      'weight': 0.15038402378559113,\n",
       "      'top_tokens': [('nds', 0.23452383279800415),\n",
       "       ('', 0.21124131977558136),\n",
       "       (' r', 0.19484297931194305),\n",
       "       ('', 0.1879124641418457),\n",
       "       ('', 0.17147938907146454)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.13970957696437836,\n",
       "      'top_tokens': [('', 0.3397662937641144),\n",
       "       ('pep', 0.20818667113780975),\n",
       "       ('', 0.1621323823928833),\n",
       "       ('', 0.1495027244091034),\n",
       "       ('', 0.14041200280189514)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.11410478502511978,\n",
       "      'top_tokens': [('poch', 0.24471808969974518),\n",
       "       ('rici', 0.2243204265832901),\n",
       "       ('Bound', 0.19431842863559723),\n",
       "       ('blocked', 0.1690024882555008),\n",
       "       ('', 0.1676405966281891)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.0867210328578949,\n",
       "      'top_tokens': [('cs', 0.2361990362405777),\n",
       "       ('m', 0.22696071863174438),\n",
       "       ('', 0.20101018249988556),\n",
       "       ('po', 0.18129155039787292),\n",
       "       ('0', 0.15453851222991943)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 20,\n",
       "      'weight': 0.18258807063102722,\n",
       "      'top_tokens': [(' Asiatic', 0.45862826704978943),\n",
       "       ('iat', 0.30883777141571045),\n",
       "       ('', 0.11090446263551712),\n",
       "       ('', 0.08475973457098007),\n",
       "       ('', 0.03686979413032532)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.16528283059597015,\n",
       "      'top_tokens': [('', 0.21261143684387207),\n",
       "       (' Climent', 0.2114257663488388),\n",
       "       ('', 0.21097096800804138),\n",
       "       ('', 0.19361011683940887),\n",
       "       ('ingui', 0.17138174176216125)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.161209374666214,\n",
       "      'top_tokens': [('-', 0.2540295720100403),\n",
       "       ('', 0.2275930792093277),\n",
       "       (' ', 0.18185876309871674),\n",
       "       ('', 0.1695130169391632),\n",
       "       (' _', 0.16700555384159088)]},\n",
       "     {'expert_id': 57,\n",
       "      'weight': 0.15038414299488068,\n",
       "      'top_tokens': [('nds', 0.23452386260032654),\n",
       "       ('', 0.21124137938022614),\n",
       "       (' r', 0.1948428601026535),\n",
       "       ('', 0.18791253864765167),\n",
       "       ('', 0.17147937417030334)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.13970965147018433,\n",
       "      'top_tokens': [('', 0.3397662341594696),\n",
       "       ('pep', 0.20818673074245453),\n",
       "       ('', 0.16213244199752808),\n",
       "       ('', 0.14950276911258698),\n",
       "       ('', 0.1404118537902832)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.11410479992628098,\n",
       "      'top_tokens': [('poch', 0.24471816420555115),\n",
       "       ('rici', 0.22432050108909607),\n",
       "       ('Bound', 0.19431835412979126),\n",
       "       ('blocked', 0.1690024584531784),\n",
       "       ('', 0.16764050722122192)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.08672109246253967,\n",
       "      'top_tokens': [('cs', 0.23619896173477173),\n",
       "       ('m', 0.22696097195148468),\n",
       "       ('', 0.20101012289524078),\n",
       "       ('po', 0.18129131197929382),\n",
       "       ('0', 0.1545386165380478)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 20,\n",
       "      'weight': 0.18258850276470184,\n",
       "      'top_tokens': [(' Asiatic', 0.45862799882888794),\n",
       "       ('iat', 0.3088381886482239),\n",
       "       ('', 0.11090439558029175),\n",
       "       ('', 0.08475968986749649),\n",
       "       ('', 0.03686973825097084)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.1652827113866806,\n",
       "      'top_tokens': [('', 0.2126113474369049),\n",
       "       (' Climent', 0.2114255726337433),\n",
       "       ('', 0.21097107231616974),\n",
       "       ('', 0.19361048936843872),\n",
       "       ('ingui', 0.17138157784938812)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.1612095832824707,\n",
       "      'top_tokens': [('-', 0.25402960181236267),\n",
       "       ('', 0.22759321331977844),\n",
       "       (' ', 0.18185868859291077),\n",
       "       ('', 0.16951286792755127),\n",
       "       (' _', 0.16700565814971924)]},\n",
       "     {'expert_id': 57,\n",
       "      'weight': 0.1503840535879135,\n",
       "      'top_tokens': [('nds', 0.2345239669084549),\n",
       "       ('', 0.21124133467674255),\n",
       "       (' r', 0.1948428899049759),\n",
       "       ('', 0.18791243433952332),\n",
       "       ('', 0.17147940397262573)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.13970942795276642,\n",
       "      'top_tokens': [('', 0.33976641297340393),\n",
       "       ('pep', 0.208186537027359),\n",
       "       ('', 0.16213244199752808),\n",
       "       ('', 0.1495027095079422),\n",
       "       ('', 0.14041192829608917)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.11410477757453918,\n",
       "      'top_tokens': [('poch', 0.24471811950206757),\n",
       "       ('rici', 0.2243204563856125),\n",
       "       ('Bound', 0.19431839883327484),\n",
       "       ('blocked', 0.169002503156662),\n",
       "       ('', 0.16764047741889954)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.08672098070383072,\n",
       "      'top_tokens': [('cs', 0.23619893193244934),\n",
       "       ('m', 0.22696082293987274),\n",
       "       ('', 0.20100998878479004),\n",
       "       ('po', 0.1812916398048401),\n",
       "       ('0', 0.1545385867357254)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 20,\n",
       "      'weight': 0.18258842825889587,\n",
       "      'top_tokens': [(' Asiatic', 0.4586282968521118),\n",
       "       ('iat', 0.30883780121803284),\n",
       "       ('', 0.11090446263551712),\n",
       "       ('', 0.08475974202156067),\n",
       "       ('', 0.036869656294584274)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.16528278589248657,\n",
       "      'top_tokens': [('', 0.21261145174503326),\n",
       "       (' Climent', 0.21142567694187164),\n",
       "       ('', 0.21097077429294586),\n",
       "       ('', 0.19361059367656708),\n",
       "       ('ingui', 0.17138150334358215)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.16120947897434235,\n",
       "      'top_tokens': [('-', 0.25402963161468506),\n",
       "       ('', 0.22759312391281128),\n",
       "       (' ', 0.18185852468013763),\n",
       "       ('', 0.1695130616426468),\n",
       "       (' _', 0.16700568795204163)]},\n",
       "     {'expert_id': 57,\n",
       "      'weight': 0.15038396418094635,\n",
       "      'top_tokens': [('nds', 0.23452386260032654),\n",
       "       ('', 0.21124133467674255),\n",
       "       (' r', 0.19484280049800873),\n",
       "       ('', 0.18791261315345764),\n",
       "       ('', 0.17147941887378693)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.13970951735973358,\n",
       "      'top_tokens': [('', 0.33976632356643677),\n",
       "       ('pep', 0.20818668603897095),\n",
       "       ('', 0.16213248670101166),\n",
       "       ('', 0.14950266480445862),\n",
       "       ('', 0.1404118835926056)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.11410480737686157,\n",
       "      'top_tokens': [('poch', 0.24471800029277802),\n",
       "       ('rici', 0.22432056069374084),\n",
       "       ('Bound', 0.19431841373443604),\n",
       "       ('blocked', 0.169002503156662),\n",
       "       ('', 0.16764050722122192)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.08672107011079788,\n",
       "      'top_tokens': [('cs', 0.2361992597579956),\n",
       "       ('m', 0.2269607037305832),\n",
       "       ('', 0.20101018249988556),\n",
       "       ('po', 0.1812913715839386),\n",
       "       ('0', 0.15453849732875824)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 20,\n",
       "      'weight': 0.1825883537530899,\n",
       "      'top_tokens': [(' Asiatic', 0.4586280584335327),\n",
       "       ('iat', 0.30883821845054626),\n",
       "       ('', 0.11090441048145294),\n",
       "       ('', 0.08475953340530396),\n",
       "       ('', 0.03686971217393875)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.16528284549713135,\n",
       "      'top_tokens': [('', 0.21261148154735565),\n",
       "       (' Climent', 0.21142560243606567),\n",
       "       ('', 0.21097080409526825),\n",
       "       ('', 0.1936105340719223),\n",
       "       ('ingui', 0.1713816076517105)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.16120944917201996,\n",
       "      'top_tokens': [('-', 0.25402969121932983),\n",
       "       ('', 0.2275930792093277),\n",
       "       (' ', 0.18185874819755554),\n",
       "       ('', 0.1695127636194229),\n",
       "       (' _', 0.16700562834739685)]},\n",
       "     {'expert_id': 57,\n",
       "      'weight': 0.15038403868675232,\n",
       "      'top_tokens': [('nds', 0.2345239371061325),\n",
       "       ('', 0.21124126017093658),\n",
       "       (' r', 0.19484281539916992),\n",
       "       ('', 0.1879124939441681),\n",
       "       ('', 0.1714794635772705)]},\n",
       "     {'expert_id': 50,\n",
       "      'weight': 0.1397094577550888,\n",
       "      'top_tokens': [('', 0.33976614475250244),\n",
       "       ('pep', 0.20818668603897095),\n",
       "       ('', 0.1621323972940445),\n",
       "       ('', 0.1495027393102646),\n",
       "       ('', 0.1404120773077011)]},\n",
       "     {'expert_id': 61,\n",
       "      'weight': 0.11410477012395859,\n",
       "      'top_tokens': [('poch', 0.24471797049045563),\n",
       "       ('rici', 0.2243204414844513),\n",
       "       ('Bound', 0.19431856274604797),\n",
       "       ('blocked', 0.16900256276130676),\n",
       "       ('', 0.16764044761657715)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.08672105520963669,\n",
       "      'top_tokens': [('cs', 0.23619888722896576),\n",
       "       ('m', 0.2269608974456787),\n",
       "       ('', 0.20101025700569153),\n",
       "       ('po', 0.18129152059555054),\n",
       "       ('0', 0.15453848242759705)]}]}}},\n",
       " 'layer_21': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.24631647765636444,\n",
       "      'top_tokens': [('obres', 0.30442866683006287),\n",
       "       ('', 0.20925091207027435),\n",
       "       ('alesa', 0.1773073524236679),\n",
       "       (' parabolic', 0.16036802530288696),\n",
       "       ('ossible', 0.14864498376846313)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.16477568447589874,\n",
       "      'top_tokens': [('', 0.2747441530227661),\n",
       "       (' cell', 0.23822474479675293),\n",
       "       (' Cell', 0.18823179602622986),\n",
       "       ('})$-', 0.1536640077829361),\n",
       "       (' loopback', 0.1451352834701538)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.1388995498418808,\n",
       "      'top_tokens': [('ifi', 0.35353749990463257),\n",
       "       ('sofs', 0.225098118185997),\n",
       "       ('ium', 0.21959683299064636),\n",
       "       ('zing', 0.1038779467344284),\n",
       "       ('amping', 0.09788951277732849)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.12349756062030792,\n",
       "      'top_tokens': [('rowColor', 0.3183515965938568),\n",
       "       ('cnics', 0.19250769913196564),\n",
       "       ('', 0.17324413359165192),\n",
       "       ('miral', 0.15894469618797302),\n",
       "       ('ndies', 0.1569518744945526)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.11576550453901291,\n",
       "      'top_tokens': [('adona', 0.3920821249485016),\n",
       "       ('rable', 0.17556063830852509),\n",
       "       ('ctree', 0.14635440707206726),\n",
       "       ('}$),', 0.14361345767974854),\n",
       "       ('arcy', 0.14238935708999634)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071930825710297,\n",
       "      'top_tokens': [('5', 0.5821133255958557),\n",
       "       ('1', 0.18801075220108032),\n",
       "       ('2', 0.12177950143814087),\n",
       "       ('8', 0.07658126950263977),\n",
       "       ('6', 0.03151508793234825)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.10002591460943222,\n",
       "      'top_tokens': [('', 0.3828691840171814),\n",
       "       ('icional', 0.1872936189174652),\n",
       "       ('rien', 0.15786713361740112),\n",
       "       (' jet', 0.14809130132198334),\n",
       "       (' l', 0.12387877702713013)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.24631650745868683,\n",
       "      'top_tokens': [('obres', 0.3044290840625763),\n",
       "       ('', 0.2092507928609848),\n",
       "       ('alesa', 0.17730741202831268),\n",
       "       (' parabolic', 0.1603679358959198),\n",
       "       ('ossible', 0.14864476025104523)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.1647755652666092,\n",
       "      'top_tokens': [('', 0.2747447192668915),\n",
       "       (' cell', 0.2382243126630783),\n",
       "       (' Cell', 0.18823164701461792),\n",
       "       ('})$-', 0.15366403758525848),\n",
       "       (' loopback', 0.145135298371315)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.138899564743042,\n",
       "      'top_tokens': [('ifi', 0.35353779792785645),\n",
       "       ('sofs', 0.22509807348251343),\n",
       "       ('ium', 0.21959659457206726),\n",
       "       ('zing', 0.10387799143791199),\n",
       "       ('amping', 0.0978895053267479)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.12349757552146912,\n",
       "      'top_tokens': [('rowColor', 0.3183519244194031),\n",
       "       ('cnics', 0.19250769913196564),\n",
       "       ('', 0.17324364185333252),\n",
       "       ('miral', 0.15894471108913422),\n",
       "       ('ndies', 0.15695203840732574)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.11576560139656067,\n",
       "      'top_tokens': [('adona', 0.3920822739601135),\n",
       "       ('rable', 0.175560861825943),\n",
       "       ('ctree', 0.14635418355464935),\n",
       "       ('}$),', 0.14361311495304108),\n",
       "       ('arcy', 0.14238953590393066)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071924865245819,\n",
       "      'top_tokens': [('5', 0.5821137428283691),\n",
       "       ('1', 0.18801051378250122),\n",
       "       ('2', 0.12177947908639908),\n",
       "       ('8', 0.07658117264509201),\n",
       "       ('6', 0.03151505067944527)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.1000259518623352,\n",
       "      'top_tokens': [('', 0.3828693628311157),\n",
       "       ('icional', 0.1872934252023697),\n",
       "       ('rien', 0.15786728262901306),\n",
       "       (' jet', 0.14809122681617737),\n",
       "       (' l', 0.12387866526842117)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.24631653726100922,\n",
       "      'top_tokens': [('obres', 0.30442896485328674),\n",
       "       ('', 0.20925092697143555),\n",
       "       ('alesa', 0.1773073524236679),\n",
       "       (' parabolic', 0.16036787629127502),\n",
       "       ('ossible', 0.1486448347568512)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.16477562487125397,\n",
       "      'top_tokens': [('', 0.2747444808483124),\n",
       "       (' cell', 0.2382245659828186),\n",
       "       (' Cell', 0.1882316619157791),\n",
       "       ('})$-', 0.1536637544631958),\n",
       "       (' loopback', 0.14513544738292694)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.13889949023723602,\n",
       "      'top_tokens': [('ifi', 0.35353755950927734),\n",
       "       ('sofs', 0.2250981628894806),\n",
       "       ('ium', 0.21959686279296875),\n",
       "       ('zing', 0.10387786477804184),\n",
       "       ('amping', 0.09788943827152252)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.12349757552146912,\n",
       "      'top_tokens': [('rowColor', 0.3183515667915344),\n",
       "       ('cnics', 0.19250786304473877),\n",
       "       ('', 0.17324359714984894),\n",
       "       ('miral', 0.15894483029842377),\n",
       "       ('ndies', 0.1569521576166153)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.11576540768146515,\n",
       "      'top_tokens': [('adona', 0.39208245277404785),\n",
       "       ('rable', 0.17556044459342957),\n",
       "       ('ctree', 0.14635437726974487),\n",
       "       ('}$),', 0.1436133086681366),\n",
       "       ('arcy', 0.14238934218883514)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071930825710297,\n",
       "      'top_tokens': [('5', 0.5821133255958557),\n",
       "       ('1', 0.18801075220108032),\n",
       "       ('2', 0.12177950143814087),\n",
       "       ('8', 0.07658126950263977),\n",
       "       ('6', 0.03151508793234825)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.10002599656581879,\n",
       "      'top_tokens': [('', 0.38286957144737244),\n",
       "       ('icional', 0.18729326128959656),\n",
       "       ('rien', 0.15786714851856232),\n",
       "       (' jet', 0.14809131622314453),\n",
       "       (' l', 0.12387868016958237)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.24631661176681519,\n",
       "      'top_tokens': [('obres', 0.3044295012950897),\n",
       "       ('', 0.20925067365169525),\n",
       "       ('alesa', 0.1773071587085724),\n",
       "       (' parabolic', 0.16036801040172577),\n",
       "       ('ossible', 0.14864467084407806)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.16477558016777039,\n",
       "      'top_tokens': [('', 0.2747443914413452),\n",
       "       (' cell', 0.23822471499443054),\n",
       "       (' Cell', 0.18823160231113434),\n",
       "       ('})$-', 0.15366385877132416),\n",
       "       (' loopback', 0.14513540267944336)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.13889943063259125,\n",
       "      'top_tokens': [('ifi', 0.3535376489162445),\n",
       "       ('sofs', 0.22509820759296417),\n",
       "       ('ium', 0.2195965051651001),\n",
       "       ('zing', 0.10387799143791199),\n",
       "       ('amping', 0.09788960218429565)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.12349764257669449,\n",
       "      'top_tokens': [('rowColor', 0.3183515667915344),\n",
       "       ('cnics', 0.19250786304473877),\n",
       "       ('', 0.17324359714984894),\n",
       "       ('miral', 0.15894483029842377),\n",
       "       ('ndies', 0.1569521576166153)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.11576550453901291,\n",
       "      'top_tokens': [('adona', 0.3920823931694031),\n",
       "       ('rable', 0.17556025087833405),\n",
       "       ('ctree', 0.14635449647903442),\n",
       "       ('}$),', 0.14361342787742615),\n",
       "       ('arcy', 0.1423894464969635)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071929335594177,\n",
       "      'top_tokens': [('5', 0.5821136236190796),\n",
       "       ('1', 0.18801066279411316),\n",
       "       ('2', 0.12177956104278564),\n",
       "       ('8', 0.07658109068870544),\n",
       "       ('6', 0.03151507303118706)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.1000259667634964,\n",
       "      'top_tokens': [('', 0.38286909461021423),\n",
       "       ('icional', 0.18729348480701447),\n",
       "       ('rien', 0.1578674018383026),\n",
       "       (' jet', 0.14809125661849976),\n",
       "       (' l', 0.12387882173061371)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.24631661176681519,\n",
       "      'top_tokens': [('obres', 0.30442899465560913),\n",
       "       ('', 0.20925073325634003),\n",
       "       ('alesa', 0.1773073673248291),\n",
       "       (' parabolic', 0.16036789119243622),\n",
       "       ('ossible', 0.14864499866962433)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.16477558016777039,\n",
       "      'top_tokens': [('', 0.2747449278831482),\n",
       "       (' cell', 0.23822449147701263),\n",
       "       (' Cell', 0.18823160231113434),\n",
       "       ('})$-', 0.15366385877132416),\n",
       "       (' loopback', 0.14513513445854187)]},\n",
       "     {'expert_id': 0,\n",
       "      'weight': 0.13889947533607483,\n",
       "      'top_tokens': [('ifi', 0.3535376489162445),\n",
       "       ('sofs', 0.22509798407554626),\n",
       "       ('ium', 0.2195967137813568),\n",
       "       ('zing', 0.10387804359197617),\n",
       "       ('amping', 0.09788955748081207)]},\n",
       "     {'expert_id': 62,\n",
       "      'weight': 0.12349753826856613,\n",
       "      'top_tokens': [('rowColor', 0.3183513879776001),\n",
       "       ('cnics', 0.19250811636447906),\n",
       "       ('', 0.17324385046958923),\n",
       "       ('miral', 0.1589447408914566),\n",
       "       ('ndies', 0.1569519191980362)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.11576557159423828,\n",
       "      'top_tokens': [('adona', 0.3920823335647583),\n",
       "       ('rable', 0.17556023597717285),\n",
       "       ('ctree', 0.1463543325662613),\n",
       "       ('}$),', 0.14361314475536346),\n",
       "       ('arcy', 0.14238983392715454)]},\n",
       "     {'expert_id': 59,\n",
       "      'weight': 0.11071930080652237,\n",
       "      'top_tokens': [('5', 0.58211350440979),\n",
       "       ('1', 0.18801043927669525),\n",
       "       ('2', 0.12177965044975281),\n",
       "       ('8', 0.07658129185438156),\n",
       "       ('6', 0.03151515871286392)]},\n",
       "     {'expert_id': 40,\n",
       "      'weight': 0.10002592951059341,\n",
       "      'top_tokens': [('', 0.3828694522380829),\n",
       "       ('icional', 0.18729330599308014),\n",
       "       ('rien', 0.15786725282669067),\n",
       "       (' jet', 0.14809127151966095),\n",
       "       (' l', 0.12387869507074356)]}]}}},\n",
       " 'layer_22': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 26,\n",
       "      'weight': 0.23425617814064026,\n",
       "      'top_tokens': [('4', 0.24372559785842896),\n",
       "       ('2', 0.23650038242340088),\n",
       "       ('7', 0.17699332535266876),\n",
       "       ('1', 0.174033060669899),\n",
       "       ('9', 0.16874772310256958)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.1568889021873474,\n",
       "      'top_tokens': [('', 0.30184537172317505),\n",
       "       (' ', 0.21165241301059723),\n",
       "       ('', 0.20402173697948456),\n",
       "       ('2', 0.15885159373283386),\n",
       "       ('', 0.1236288920044899)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.15127521753311157,\n",
       "      'top_tokens': [(' ', 0.21636411547660828),\n",
       "       ('acte', 0.2132652997970581),\n",
       "       ('', 0.19800427556037903),\n",
       "       ('mirrors', 0.190765842795372),\n",
       "       ('ue', 0.18160055577754974)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.11867069453001022,\n",
       "      'top_tokens': [('planar', 0.7285929322242737),\n",
       "       (' -', 0.08446463197469711),\n",
       "       (',.', 0.08006390184164047),\n",
       "       ('', 0.05346579849720001),\n",
       "       ('occidental', 0.053412698209285736)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.1161923035979271,\n",
       "      'top_tokens': [(' herself', 0.9790613055229187),\n",
       "       (' her', 0.020424682646989822),\n",
       "       ('herself', 0.00048112921649590135),\n",
       "       (' she', 2.8992762963753194e-05),\n",
       "       (' hers', 3.954201019951142e-06)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.11284135282039642,\n",
       "      'top_tokens': [('ittest', 0.4013060927391052),\n",
       "       ('', 0.17694595456123352),\n",
       "       ('edas', 0.15117377042770386),\n",
       "       ('', 0.15040284395217896),\n",
       "       ('ugosl', 0.12017135322093964)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.10987530648708344,\n",
       "      'top_tokens': [('', 0.7620458602905273),\n",
       "       ('', 0.081598661839962),\n",
       "       ('', 0.07121371477842331),\n",
       "       ('itch', 0.05840064585208893),\n",
       "       ('', 0.02674107812345028)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 26,\n",
       "      'weight': 0.23425613343715668,\n",
       "      'top_tokens': [('4', 0.2437257319688797),\n",
       "       ('2', 0.23650029301643372),\n",
       "       ('7', 0.17699316143989563),\n",
       "       ('1', 0.17403298616409302),\n",
       "       ('9', 0.16874773800373077)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.15688884258270264,\n",
       "      'top_tokens': [('', 0.30184537172317505),\n",
       "       (' ', 0.21165232360363007),\n",
       "       ('', 0.20402191579341888),\n",
       "       ('2', 0.15885168313980103),\n",
       "       ('', 0.1236286535859108)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.15127520263195038,\n",
       "      'top_tokens': [(' ', 0.21636386215686798),\n",
       "       ('acte', 0.21326546370983124),\n",
       "       ('', 0.19800442457199097),\n",
       "       ('mirrors', 0.19076579809188843),\n",
       "       ('ue', 0.18160051107406616)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.11867068707942963,\n",
       "      'top_tokens': [('planar', 0.7285933494567871),\n",
       "       (' -', 0.08446411788463593),\n",
       "       (',.', 0.08006394654512405),\n",
       "       ('', 0.05346578359603882),\n",
       "       ('occidental', 0.053412675857543945)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.11619237810373306,\n",
       "      'top_tokens': [(' herself', 0.9790614247322083),\n",
       "       (' her', 0.020424606278538704),\n",
       "       ('herself', 0.00048112927470356226),\n",
       "       (' she', 2.8992766601732e-05),\n",
       "       (' hers', 3.954186468035914e-06)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.1128414049744606,\n",
       "      'top_tokens': [('ittest', 0.4013063907623291),\n",
       "       ('', 0.176945760846138),\n",
       "       ('edas', 0.15117402374744415),\n",
       "       ('', 0.15040266513824463),\n",
       "       ('ugosl', 0.12017115205526352)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.10987535864114761,\n",
       "      'top_tokens': [('', 0.7620460987091064),\n",
       "       ('', 0.0815986916422844),\n",
       "       ('', 0.07121360301971436),\n",
       "       ('itch', 0.058400608599185944),\n",
       "       ('', 0.026740986853837967)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 26,\n",
       "      'weight': 0.23425616323947906,\n",
       "      'top_tokens': [('4', 0.2437254786491394),\n",
       "       ('2', 0.23650038242340088),\n",
       "       ('7', 0.17699314653873444),\n",
       "       ('1', 0.17403315007686615),\n",
       "       ('9', 0.16874781250953674)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.15688887238502502,\n",
       "      'top_tokens': [('', 0.30184540152549744),\n",
       "       (' ', 0.21165254712104797),\n",
       "       ('', 0.20402194559574127),\n",
       "       ('2', 0.15885140001773834),\n",
       "       ('', 0.12362866848707199)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.151275172829628,\n",
       "      'top_tokens': [(' ', 0.21636411547660828),\n",
       "       ('acte', 0.2132652997970581),\n",
       "       ('', 0.1980043649673462),\n",
       "       ('mirrors', 0.19076593220233917),\n",
       "       ('ue', 0.18160036206245422)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.11867070198059082,\n",
       "      'top_tokens': [('planar', 0.7285929322242737),\n",
       "       (' -', 0.08446463197469711),\n",
       "       (',.', 0.08006390184164047),\n",
       "       ('', 0.05346579849720001),\n",
       "       ('occidental', 0.053412746638059616)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.11619234085083008,\n",
       "      'top_tokens': [(' herself', 0.9790615439414978),\n",
       "       (' her', 0.020424453541636467),\n",
       "       ('herself', 0.0004811274993699044),\n",
       "       (' she', 2.899265928135719e-05),\n",
       "       (' hers', 3.954186922783265e-06)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.11284139007329941,\n",
       "      'top_tokens': [('ittest', 0.40130600333213806),\n",
       "       ('', 0.17694592475891113),\n",
       "       ('edas', 0.15117402374744415),\n",
       "       ('', 0.15040279924869537),\n",
       "       ('ugosl', 0.12017126381397247)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.10987535864114761,\n",
       "      'top_tokens': [('', 0.7620458602905273),\n",
       "       ('', 0.08159874379634857),\n",
       "       ('', 0.07121364772319794),\n",
       "       ('itch', 0.05840064585208893),\n",
       "       ('', 0.02674105204641819)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 26,\n",
       "      'weight': 0.23425620794296265,\n",
       "      'top_tokens': [('4', 0.24372559785842896),\n",
       "       ('2', 0.23650048673152924),\n",
       "       ('7', 0.17699314653873444),\n",
       "       ('1', 0.17403297126293182),\n",
       "       ('9', 0.16874781250953674)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.15688881278038025,\n",
       "      'top_tokens': [('', 0.3018454611301422),\n",
       "       (' ', 0.211652472615242),\n",
       "       ('', 0.20402179658412933),\n",
       "       ('2', 0.15885180234909058),\n",
       "       ('', 0.1236284077167511)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.15127520263195038,\n",
       "      'top_tokens': [(' ', 0.2163638472557068),\n",
       "       ('acte', 0.21326524019241333),\n",
       "       ('', 0.19800469279289246),\n",
       "       ('mirrors', 0.19076569378376007),\n",
       "       ('ue', 0.18160058557987213)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.11867066472768784,\n",
       "      'top_tokens': [('planar', 0.7285929322242737),\n",
       "       (' -', 0.08446455001831055),\n",
       "       (',.', 0.08006405830383301),\n",
       "       ('', 0.053465958684682846),\n",
       "       ('occidental', 0.05341259762644768)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.11619236320257187,\n",
       "      'top_tokens': [(' herself', 0.9790614247322083),\n",
       "       (' her', 0.020424528047442436),\n",
       "       ('herself', 0.0004811274411622435),\n",
       "       (' she', 2.8992766601732e-05),\n",
       "       (' hers', 3.954186468035914e-06)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.1128414124250412,\n",
       "      'top_tokens': [('ittest', 0.4013068974018097),\n",
       "       ('', 0.17694546282291412),\n",
       "       ('edas', 0.1511736363172531),\n",
       "       ('', 0.1504027098417282),\n",
       "       ('ugosl', 0.1201711967587471)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.10987533628940582,\n",
       "      'top_tokens': [('', 0.7620458006858826),\n",
       "       ('', 0.08159873634576797),\n",
       "       ('', 0.07121370732784271),\n",
       "       ('itch', 0.05840064212679863),\n",
       "       ('', 0.02674107439815998)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 26,\n",
       "      'weight': 0.23425623774528503,\n",
       "      'top_tokens': [('4', 0.24372588098049164),\n",
       "       ('2', 0.23650020360946655),\n",
       "       ('7', 0.176993265748024),\n",
       "       ('1', 0.1740330159664154),\n",
       "       ('9', 0.1687476933002472)]},\n",
       "     {'expert_id': 8,\n",
       "      'weight': 0.15688879787921906,\n",
       "      'top_tokens': [('', 0.301845520734787),\n",
       "       (' ', 0.2116527110338211),\n",
       "       ('', 0.20402184128761292),\n",
       "       ('2', 0.15885122120380402),\n",
       "       ('', 0.12362871319055557)]},\n",
       "     {'expert_id': 28,\n",
       "      'weight': 0.15127524733543396,\n",
       "      'top_tokens': [(' ', 0.21636411547660828),\n",
       "       ('acte', 0.2132652997970581),\n",
       "       ('', 0.19800446927547455),\n",
       "       ('mirrors', 0.19076575338840485),\n",
       "       ('ue', 0.18160036206245422)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.11867058277130127,\n",
       "      'top_tokens': [('planar', 0.7285926938056946),\n",
       "       (' -', 0.08446460217237473),\n",
       "       (',.', 0.08006418496370316),\n",
       "       ('', 0.053465940058231354),\n",
       "       ('occidental', 0.053412627428770065)]},\n",
       "     {'expert_id': 60,\n",
       "      'weight': 0.11619241535663605,\n",
       "      'top_tokens': [(' herself', 0.9790615439414978),\n",
       "       (' her', 0.020424453541636467),\n",
       "       ('herself', 0.0004811293329112232),\n",
       "       (' she', 2.899265928135719e-05),\n",
       "       (' hers', 3.954186922783265e-06)]},\n",
       "     {'expert_id': 47,\n",
       "      'weight': 0.11284136772155762,\n",
       "      'top_tokens': [('ittest', 0.40130698680877686),\n",
       "       ('', 0.17694534361362457),\n",
       "       ('edas', 0.15117353200912476),\n",
       "       ('', 0.15040302276611328),\n",
       "       ('ugosl', 0.12017116695642471)]},\n",
       "     {'expert_id': 46,\n",
       "      'weight': 0.1098753809928894,\n",
       "      'top_tokens': [('', 0.7620458602905273),\n",
       "       ('', 0.08159874379634857),\n",
       "       ('', 0.07121358066797256),\n",
       "       ('itch', 0.05840069800615311),\n",
       "       ('', 0.02674110233783722)]}]}}},\n",
       " 'layer_23': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 57,\n",
       "      'weight': 0.21964871883392334,\n",
       "      'top_tokens': [('ikipedia', 0.21018072962760925),\n",
       "       ('', 0.20836834609508514),\n",
       "       ('', 0.20461857318878174),\n",
       "       ('germ', 0.19258640706539154),\n",
       "       ('cet', 0.18424594402313232)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.181731715798378,\n",
       "      'top_tokens': [('0', 0.30381810665130615),\n",
       "       ('outcome', 0.19611594080924988),\n",
       "       ('alus', 0.17971006035804749),\n",
       "       (' outcome', 0.16289420425891876),\n",
       "       (' r', 0.15746161341667175)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.14062239229679108,\n",
       "      'top_tokens': [('eered', 0.3389376997947693),\n",
       "       ('ield', 0.22093051671981812),\n",
       "       (' yourselves', 0.18602779507637024),\n",
       "       ('plication', 0.12730222940444946),\n",
       "       ('ex', 0.1268017590045929)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.1322099268436432,\n",
       "      'top_tokens': [('C', 0.5027619004249573),\n",
       "       ('M', 0.2762487530708313),\n",
       "       ('Sh', 0.11072540283203125),\n",
       "       ('D', 0.0617528073489666),\n",
       "       ('an', 0.04851112142205238)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.11794470995664597,\n",
       "      'top_tokens': [('atal', 0.28240886330604553),\n",
       "       ('', 0.20038089156150818),\n",
       "       (' PM', 0.186335027217865),\n",
       "       ('', 0.1807585507631302),\n",
       "       ('eration', 0.1501167118549347)]},\n",
       "     {'expert_id': 37,\n",
       "      'weight': 0.10538254678249359,\n",
       "      'top_tokens': [(' ', 0.6343451142311096),\n",
       "       (' Martorell', 0.12917834520339966),\n",
       "       ('issen', 0.09077917039394379),\n",
       "       ('onics', 0.07626736164093018),\n",
       "       ('osity', 0.06943003833293915)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.1024598628282547,\n",
       "      'top_tokens': [(' trade', 0.4212673008441925),\n",
       "       (' business', 0.19844697415828705),\n",
       "       (' trading', 0.1340053677558899),\n",
       "       (' Trade', 0.12614381313323975),\n",
       "       ('business', 0.12013652920722961)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 57,\n",
       "      'weight': 0.21964862942695618,\n",
       "      'top_tokens': [('ikipedia', 0.21018077433109283),\n",
       "       ('', 0.20836849510669708),\n",
       "       ('', 0.20461851358413696),\n",
       "       ('germ', 0.19258616864681244),\n",
       "       ('cet', 0.1842459887266159)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.18173177540302277,\n",
       "      'top_tokens': [('0', 0.3038182556629181),\n",
       "       ('outcome', 0.19611604511737823),\n",
       "       ('alus', 0.17970986664295197),\n",
       "       (' outcome', 0.16289429366588593),\n",
       "       (' r', 0.1574615240097046)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.14062243700027466,\n",
       "      'top_tokens': [('eered', 0.3389376699924469),\n",
       "       ('ield', 0.2209302932024002),\n",
       "       (' yourselves', 0.18602794408798218),\n",
       "       ('plication', 0.12730227410793304),\n",
       "       ('ex', 0.12680184841156006)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.13220998644828796,\n",
       "      'top_tokens': [('C', 0.5027613043785095),\n",
       "       ('M', 0.2762492299079895),\n",
       "       ('Sh', 0.11072537302970886),\n",
       "       ('D', 0.06175273284316063),\n",
       "       ('an', 0.04851124808192253)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.11794473975896835,\n",
       "      'top_tokens': [('atal', 0.28240856528282166),\n",
       "       ('', 0.2003810703754425),\n",
       "       (' PM', 0.18633535504341125),\n",
       "       ('', 0.1807580292224884),\n",
       "       ('eration', 0.15011699497699738)]},\n",
       "     {'expert_id': 37,\n",
       "      'weight': 0.10538255423307419,\n",
       "      'top_tokens': [(' ', 0.6343449354171753),\n",
       "       (' Martorell', 0.12917843461036682),\n",
       "       ('issen', 0.09077927470207214),\n",
       "       ('onics', 0.07626711577177048),\n",
       "       ('osity', 0.0694301500916481)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.10245984047651291,\n",
       "      'top_tokens': [(' trade', 0.42126691341400146),\n",
       "       (' business', 0.19844716787338257),\n",
       "       (' trading', 0.1340053677558899),\n",
       "       (' Trade', 0.12614406645298004),\n",
       "       ('business', 0.12013653665781021)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 57,\n",
       "      'weight': 0.2196485847234726,\n",
       "      'top_tokens': [('ikipedia', 0.21018081903457642),\n",
       "       ('', 0.2083682417869568),\n",
       "       ('', 0.20461836457252502),\n",
       "       ('germ', 0.1925864964723587),\n",
       "       ('cet', 0.18424610793590546)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.18173179030418396,\n",
       "      'top_tokens': [('0', 0.30381903052330017),\n",
       "       ('outcome', 0.19611598551273346),\n",
       "       ('alus', 0.17970973253250122),\n",
       "       (' outcome', 0.1628940850496292),\n",
       "       (' r', 0.15746118128299713)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.14062248170375824,\n",
       "      'top_tokens': [('eered', 0.33893781900405884),\n",
       "       ('ield', 0.2209302932024002),\n",
       "       (' yourselves', 0.18602794408798218),\n",
       "       ('plication', 0.12730221450328827),\n",
       "       ('ex', 0.12680168449878693)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.13221001625061035,\n",
       "      'top_tokens': [('C', 0.5027610659599304),\n",
       "       ('M', 0.27624934911727905),\n",
       "       ('Sh', 0.11072542518377304),\n",
       "       ('D', 0.061752766370773315),\n",
       "       ('an', 0.04851141199469566)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.11794479936361313,\n",
       "      'top_tokens': [('atal', 0.28240859508514404),\n",
       "       ('', 0.20038090646266937),\n",
       "       (' PM', 0.18633536994457245),\n",
       "       ('', 0.18075838685035706),\n",
       "       ('eration', 0.15011686086654663)]},\n",
       "     {'expert_id': 37,\n",
       "      'weight': 0.10538256168365479,\n",
       "      'top_tokens': [(' ', 0.6343450546264648),\n",
       "       (' Martorell', 0.12917844951152802),\n",
       "       ('issen', 0.09077924489974976),\n",
       "       ('onics', 0.07626724243164062),\n",
       "       ('osity', 0.06943003088235855)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.10245988517999649,\n",
       "      'top_tokens': [(' trade', 0.42126742005348206),\n",
       "       (' business', 0.1984468400478363),\n",
       "       (' trading', 0.13400541245937347),\n",
       "       (' Trade', 0.12614373862743378),\n",
       "       ('business', 0.1201365664601326)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 57,\n",
       "      'weight': 0.21964867413043976,\n",
       "      'top_tokens': [('ikipedia', 0.21018049120903015),\n",
       "       ('', 0.20836882293224335),\n",
       "       ('', 0.20461814105510712),\n",
       "       ('germ', 0.19258637726306915),\n",
       "       ('cet', 0.18424609303474426)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.18173176050186157,\n",
       "      'top_tokens': [('0', 0.30381864309310913),\n",
       "       ('outcome', 0.19611582159996033),\n",
       "       ('alus', 0.17970994114875793),\n",
       "       (' outcome', 0.16289418935775757),\n",
       "       (' r', 0.15746143460273743)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.14062243700027466,\n",
       "      'top_tokens': [('eered', 0.3389380872249603),\n",
       "       ('ield', 0.22093036770820618),\n",
       "       (' yourselves', 0.18602782487869263),\n",
       "       ('plication', 0.12730218470096588),\n",
       "       ('ex', 0.126801535487175)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.13221001625061035,\n",
       "      'top_tokens': [('C', 0.5027611255645752),\n",
       "       ('M', 0.27624964714050293),\n",
       "       ('Sh', 0.11072523146867752),\n",
       "       ('D', 0.06175253540277481),\n",
       "       ('an', 0.04851150885224342)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.11794470995664597,\n",
       "      'top_tokens': [('atal', 0.2824079394340515),\n",
       "       ('', 0.20038080215454102),\n",
       "       (' PM', 0.18633583188056946),\n",
       "       ('', 0.1807583123445511),\n",
       "       ('eration', 0.15011708438396454)]},\n",
       "     {'expert_id': 37,\n",
       "      'weight': 0.10538262873888016,\n",
       "      'top_tokens': [(' ', 0.6343446373939514),\n",
       "       (' Martorell', 0.12917836010456085),\n",
       "       ('issen', 0.09077931940555573),\n",
       "       ('onics', 0.07626748085021973),\n",
       "       ('osity', 0.06943021714687347)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.10245975106954575,\n",
       "      'top_tokens': [(' trade', 0.4212680459022522),\n",
       "       (' business', 0.1984456181526184),\n",
       "       (' trading', 0.13400638103485107),\n",
       "       (' Trade', 0.1261441558599472),\n",
       "       ('business', 0.12013571709394455)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 57,\n",
       "      'weight': 0.21964862942695618,\n",
       "      'top_tokens': [('ikipedia', 0.21018056571483612),\n",
       "       ('', 0.20836849510669708),\n",
       "       ('', 0.2046184092760086),\n",
       "       ('germ', 0.19258654117584229),\n",
       "       ('cet', 0.18424606323242188)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.18173174560070038,\n",
       "      'top_tokens': [('0', 0.3038184642791748),\n",
       "       ('outcome', 0.19611607491970062),\n",
       "       ('alus', 0.17970983684062958),\n",
       "       (' outcome', 0.16289415955543518),\n",
       "       (' r', 0.157461479306221)]},\n",
       "     {'expert_id': 14,\n",
       "      'weight': 0.14062243700027466,\n",
       "      'top_tokens': [('eered', 0.3389381468296051),\n",
       "       ('ield', 0.22093017399311066),\n",
       "       (' yourselves', 0.18602803349494934),\n",
       "       ('plication', 0.12730209529399872),\n",
       "       ('ex', 0.12680156528949738)]},\n",
       "     {'expert_id': 41,\n",
       "      'weight': 0.13221001625061035,\n",
       "      'top_tokens': [('C', 0.5027613043785095),\n",
       "       ('M', 0.2762492299079895),\n",
       "       ('Sh', 0.1107252687215805),\n",
       "       ('D', 0.0617525577545166),\n",
       "       ('an', 0.04851162061095238)]},\n",
       "     {'expert_id': 31,\n",
       "      'weight': 0.11794478446245193,\n",
       "      'top_tokens': [('atal', 0.28240808844566345),\n",
       "       ('', 0.2003811150789261),\n",
       "       (' PM', 0.18633539974689484),\n",
       "       ('', 0.18075823783874512),\n",
       "       ('eration', 0.1501171588897705)]},\n",
       "     {'expert_id': 37,\n",
       "      'weight': 0.10538256168365479,\n",
       "      'top_tokens': [(' ', 0.6343454718589783),\n",
       "       (' Martorell', 0.12917816638946533),\n",
       "       ('issen', 0.09077908843755722),\n",
       "       ('onics', 0.0762672945857048),\n",
       "       ('osity', 0.06943003833293915)]},\n",
       "     {'expert_id': 5,\n",
       "      'weight': 0.10245981812477112,\n",
       "      'top_tokens': [(' trade', 0.42126843333244324),\n",
       "       (' business', 0.1984456181526184),\n",
       "       (' trading', 0.13400572538375854),\n",
       "       (' Trade', 0.12614427506923676),\n",
       "       ('business', 0.1201358288526535)]}]}}},\n",
       " 'layer_24': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 11,\n",
       "      'weight': 0.20139551162719727,\n",
       "      'top_tokens': [('ly', 0.9996980428695679),\n",
       "       ('ing', 0.00030136917484924197),\n",
       "       ('is', 4.342217891917244e-07),\n",
       "       ('led', 9.454776517259234e-08),\n",
       "       ('ed', 2.9696689551883537e-08)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.1821983903646469,\n",
       "      'top_tokens': [('eck', 0.22579753398895264),\n",
       "       ('domen', 0.22231487929821014),\n",
       "       ('oda', 0.19814208149909973),\n",
       "       (' mano', 0.17927314341068268),\n",
       "       ('ZING', 0.17447233200073242)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.12967495620250702,\n",
       "      'top_tokens': [('[...]', 0.2779856324195862),\n",
       "       (' press', 0.1954493373632431),\n",
       "       ('lix', 0.18792952597141266),\n",
       "       ('harmonic', 0.1721772700548172),\n",
       "       ('', 0.16645830869674683)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.12894919514656067,\n",
       "      'top_tokens': [('\"', 0.47636815905570984),\n",
       "       ('\"\\\\', 0.3046919107437134),\n",
       "       ('', 0.09109385311603546),\n",
       "       ('', 0.07396024465560913),\n",
       "       ('', 0.05388579145073891)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.12220113724470139,\n",
       "      'top_tokens': [('icolon', 0.37242740392684937),\n",
       "       ('ple', 0.23353146016597748),\n",
       "       ('', 0.15310226380825043),\n",
       "       ('', 0.1382921040058136),\n",
       "       ('', 0.10264673829078674)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11779337376356125,\n",
       "      'top_tokens': [('edly', 0.45700812339782715),\n",
       "       ('', 0.18786831200122833),\n",
       "       ('ermost', 0.15403394401073456),\n",
       "       ('iation', 0.10084850341081619),\n",
       "       ('', 0.10024111717939377)]},\n",
       "     {'expert_id': 15,\n",
       "      'weight': 0.1177874431014061,\n",
       "      'top_tokens': [('ILED', 0.5314755439758301),\n",
       "       ('layer', 0.12658007442951202),\n",
       "       ('', 0.11668089032173157),\n",
       "       ('', 0.11400244385004044),\n",
       "       ('ILY', 0.1112610474228859)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 11,\n",
       "      'weight': 0.20139539241790771,\n",
       "      'top_tokens': [('ly', 0.9996980428695679),\n",
       "       ('ing', 0.00030136917484924197),\n",
       "       ('is', 4.342217891917244e-07),\n",
       "       ('led', 9.454794991370363e-08),\n",
       "       ('ed', 2.9696689551883537e-08)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.18219859898090363,\n",
       "      'top_tokens': [('eck', 0.22579768300056458),\n",
       "       ('domen', 0.22231483459472656),\n",
       "       ('oda', 0.19814184308052063),\n",
       "       (' mano', 0.17927344143390656),\n",
       "       ('ZING', 0.17447227239608765)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.1296749711036682,\n",
       "      'top_tokens': [('[...]', 0.27798569202423096),\n",
       "       (' press', 0.19544918835163116),\n",
       "       ('lix', 0.1879296600818634),\n",
       "       ('harmonic', 0.1721770465373993),\n",
       "       ('', 0.1664583534002304)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.12894918024539948,\n",
       "      'top_tokens': [('\"', 0.4763682782649994),\n",
       "       ('\"\\\\', 0.30469226837158203),\n",
       "       ('', 0.09109361469745636),\n",
       "       ('', 0.07396005839109421),\n",
       "       ('', 0.0538858063519001)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.12220108509063721,\n",
       "      'top_tokens': [('icolon', 0.3724271059036255),\n",
       "       ('ple', 0.23353150486946106),\n",
       "       ('', 0.1531025767326355),\n",
       "       ('', 0.1382921189069748),\n",
       "       ('', 0.10264665633440018)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11779333651065826,\n",
       "      'top_tokens': [('edly', 0.4570077657699585),\n",
       "       ('', 0.18786852061748505),\n",
       "       ('ermost', 0.1540341079235077),\n",
       "       ('iation', 0.1008484736084938),\n",
       "       ('', 0.10024107992649078)]},\n",
       "     {'expert_id': 15,\n",
       "      'weight': 0.11778736859560013,\n",
       "      'top_tokens': [('ILED', 0.5314757227897644),\n",
       "       ('layer', 0.12657999992370605),\n",
       "       ('', 0.1166810467839241),\n",
       "       ('', 0.11400248110294342),\n",
       "       ('ILY', 0.11126077175140381)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 11,\n",
       "      'weight': 0.20139558613300323,\n",
       "      'top_tokens': [('ly', 0.9996980428695679),\n",
       "       ('ing', 0.0003013703098986298),\n",
       "       ('is', 4.342234660725808e-07),\n",
       "       ('led', 9.454812754938757e-08),\n",
       "       ('ed', 2.969685830578328e-08)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.1821984499692917,\n",
       "      'top_tokens': [('eck', 0.2257978320121765),\n",
       "       ('domen', 0.22231517732143402),\n",
       "       ('oda', 0.19814158976078033),\n",
       "       (' mano', 0.17927320301532745),\n",
       "       ('ZING', 0.17447222769260406)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.1296749711036682,\n",
       "      'top_tokens': [('[...]', 0.2779856026172638),\n",
       "       (' press', 0.1954491287469864),\n",
       "       ('lix', 0.18792986869812012),\n",
       "       ('harmonic', 0.1721770018339157),\n",
       "       ('', 0.1664583832025528)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.12894906103610992,\n",
       "      'top_tokens': [('\"', 0.4763685464859009),\n",
       "       ('\"\\\\', 0.304691880941391),\n",
       "       ('', 0.09109339863061905),\n",
       "       ('', 0.0739603042602539),\n",
       "       ('', 0.05388588830828667)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.12220112979412079,\n",
       "      'top_tokens': [('icolon', 0.37242698669433594),\n",
       "       ('ple', 0.2335316389799118),\n",
       "       ('', 0.15310238301753998),\n",
       "       ('', 0.13829220831394196),\n",
       "       ('', 0.10264672338962555)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11779334396123886,\n",
       "      'top_tokens': [('edly', 0.45700812339782715),\n",
       "       ('', 0.18786796927452087),\n",
       "       ('ermost', 0.15403422713279724),\n",
       "       ('iation', 0.10084850341081619),\n",
       "       ('', 0.10024116188287735)]},\n",
       "     {'expert_id': 15,\n",
       "      'weight': 0.11778739839792252,\n",
       "      'top_tokens': [('ILED', 0.5314760208129883),\n",
       "       ('layer', 0.12658031284809113),\n",
       "       ('', 0.11668089032173157),\n",
       "       ('', 0.11400210857391357),\n",
       "       ('ILY', 0.11126072704792023)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 11,\n",
       "      'weight': 0.20139549672603607,\n",
       "      'top_tokens': [('ly', 0.9996980428695679),\n",
       "       ('ing', 0.0003013680106960237),\n",
       "       ('is', 4.3421849227343046e-07),\n",
       "       ('led', 9.454776517259234e-08),\n",
       "       ('ed', 2.9696632708464676e-08)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.1821984499692917,\n",
       "      'top_tokens': [('eck', 0.2257978320121765),\n",
       "       ('domen', 0.2223149687051773),\n",
       "       ('oda', 0.19814178347587585),\n",
       "       (' mano', 0.17927303910255432),\n",
       "       ('ZING', 0.1744723916053772)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.12967495620250702,\n",
       "      'top_tokens': [('[...]', 0.2779855728149414),\n",
       "       (' press', 0.1954488307237625),\n",
       "       ('lix', 0.18792976438999176),\n",
       "       ('harmonic', 0.17217731475830078),\n",
       "       ('', 0.16645850241184235)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.12894921004772186,\n",
       "      'top_tokens': [('\"', 0.4763690233230591),\n",
       "       ('\"\\\\', 0.3046915829181671),\n",
       "       ('', 0.09109332412481308),\n",
       "       ('', 0.07396023720502853),\n",
       "       ('', 0.05388583615422249)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.12220115214586258,\n",
       "      'top_tokens': [('icolon', 0.3724275529384613),\n",
       "       ('ple', 0.23353111743927002),\n",
       "       ('', 0.15310262143611908),\n",
       "       ('', 0.13829214870929718),\n",
       "       ('', 0.1026465892791748)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11779341101646423,\n",
       "      'top_tokens': [('edly', 0.45700857043266296),\n",
       "       ('', 0.18786796927452087),\n",
       "       ('ermost', 0.15403394401073456),\n",
       "       ('iation', 0.10084860771894455),\n",
       "       ('', 0.10024092346429825)]},\n",
       "     {'expert_id': 15,\n",
       "      'weight': 0.11778734624385834,\n",
       "      'top_tokens': [('ILED', 0.531475841999054),\n",
       "       ('layer', 0.126580148935318),\n",
       "       ('', 0.11668073385953903),\n",
       "       ('', 0.11400239914655685),\n",
       "       ('ILY', 0.11126089841127396)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 11,\n",
       "      'weight': 0.2013954371213913,\n",
       "      'top_tokens': [('ly', 0.9996980428695679),\n",
       "       ('ing', 0.00030136917484924197),\n",
       "       ('is', 4.342226418430073e-07),\n",
       "       ('led', 9.454812754938757e-08),\n",
       "       ('ed', 2.9696746395302398e-08)]},\n",
       "     {'expert_id': 52,\n",
       "      'weight': 0.18219861388206482,\n",
       "      'top_tokens': [('eck', 0.22579778730869293),\n",
       "       ('domen', 0.222314715385437),\n",
       "       ('oda', 0.1981419324874878),\n",
       "       (' mano', 0.17927351593971252),\n",
       "       ('ZING', 0.17447203397750854)]},\n",
       "     {'expert_id': 24,\n",
       "      'weight': 0.12967495620250702,\n",
       "      'top_tokens': [('[...]', 0.27798596024513245),\n",
       "       (' press', 0.19544900953769684),\n",
       "       ('lix', 0.1879296600818634),\n",
       "       ('harmonic', 0.17217688262462616),\n",
       "       ('', 0.16645842790603638)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.12894921004772186,\n",
       "      'top_tokens': [('\"', 0.4763679504394531),\n",
       "       ('\"\\\\', 0.3046923279762268),\n",
       "       ('', 0.09109354764223099),\n",
       "       ('', 0.07396021485328674),\n",
       "       ('', 0.05388602241873741)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.1222011148929596,\n",
       "      'top_tokens': [('icolon', 0.3724272847175598),\n",
       "       ('ple', 0.23353160917758942),\n",
       "       ('', 0.15310221910476685),\n",
       "       ('', 0.13829219341278076),\n",
       "       ('', 0.10264670103788376)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.11779338866472244,\n",
       "      'top_tokens': [('edly', 0.4570079743862152),\n",
       "       ('', 0.18786843121051788),\n",
       "       ('ermost', 0.15403403341770172),\n",
       "       ('iation', 0.10084857046604156),\n",
       "       ('', 0.10024098306894302)]},\n",
       "     {'expert_id': 15,\n",
       "      'weight': 0.11778737604618073,\n",
       "      'top_tokens': [('ILED', 0.5314756035804749),\n",
       "       ('layer', 0.12658008933067322),\n",
       "       ('', 0.11668079346418381),\n",
       "       ('', 0.11400245875120163),\n",
       "       ('ILY', 0.11126106232404709)]}]}}},\n",
       " 'layer_25': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 53,\n",
       "      'weight': 0.29011282324790955,\n",
       "      'top_tokens': [(' .../', 0.4444205164909363),\n",
       "       ('', 0.24891863763332367),\n",
       "       ('', 0.1166640892624855),\n",
       "       (' met', 0.10657119005918503),\n",
       "       ('', 0.0834256187081337)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.1341702938079834,\n",
       "      'top_tokens': [(' ', 0.3670141100883484),\n",
       "       ('Formatting', 0.22539862990379333),\n",
       "       (' inactius', 0.1407858431339264),\n",
       "       ('', 0.1407858431339264),\n",
       "       ('', 0.12601560354232788)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.13312964141368866,\n",
       "      'top_tokens': [('', 0.5137415528297424),\n",
       "       ('lehem', 0.15958209335803986),\n",
       "       ('igraphy', 0.1258346438407898),\n",
       "       ('mbol', 0.10493913292884827),\n",
       "       ('bilt', 0.09590265154838562)]},\n",
       "     {'expert_id': 11,\n",
       "      'weight': 0.12936720252037048,\n",
       "      'top_tokens': [('', 0.23863165080547333),\n",
       "       ('ohl', 0.2328409105539322),\n",
       "       ('\"><!--', 0.1837713122367859),\n",
       "       ('atol', 0.17353413999080658),\n",
       "       ('aty', 0.1712220013141632)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.1106809675693512,\n",
       "      'top_tokens': [('', 0.4705086946487427),\n",
       "       ('ives', 0.21093463897705078),\n",
       "       ('ivell', 0.12045170366764069),\n",
       "       ('/~', 0.10022295266389847),\n",
       "       ('words', 0.09788205474615097)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.10349903255701065,\n",
       "      'top_tokens': [('atur', 0.25786516070365906),\n",
       "       ('', 0.22084854543209076),\n",
       "       ('ilde', 0.18106229603290558),\n",
       "       ('atu', 0.17477889358997345),\n",
       "       ('hore', 0.16544514894485474)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.09903998672962189,\n",
       "      'top_tokens': [('', 0.47543054819107056),\n",
       "       ('', 0.2068626582622528),\n",
       "       ('', 0.1258096694946289),\n",
       "       ('', 0.09651406854391098),\n",
       "       (' ', 0.09538300335407257)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 53,\n",
       "      'weight': 0.2901129424571991,\n",
       "      'top_tokens': [(' .../', 0.4444209337234497),\n",
       "       ('', 0.24891850352287292),\n",
       "       ('', 0.11666391789913177),\n",
       "       (' met', 0.10657109320163727),\n",
       "       ('', 0.08342553675174713)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.1341702938079834,\n",
       "      'top_tokens': [(' ', 0.3670142590999603),\n",
       "       ('Formatting', 0.22539830207824707),\n",
       "       (' inactius', 0.14078590273857117),\n",
       "       ('', 0.14078563451766968),\n",
       "       ('', 0.12601590156555176)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.13312962651252747,\n",
       "      'top_tokens': [('', 0.5137417316436768),\n",
       "       ('lehem', 0.15958230197429657),\n",
       "       ('igraphy', 0.12583456933498383),\n",
       "       ('mbol', 0.10493867099285126),\n",
       "       ('bilt', 0.09590277820825577)]},\n",
       "     {'expert_id': 11,\n",
       "      'weight': 0.1293671876192093,\n",
       "      'top_tokens': [('', 0.23863162100315094),\n",
       "       ('ohl', 0.23284077644348145),\n",
       "       ('\"><!--', 0.18377137184143066),\n",
       "       ('atol', 0.173534095287323),\n",
       "       ('aty', 0.1712220460176468)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.1106809452176094,\n",
       "      'top_tokens': [('', 0.47050905227661133),\n",
       "       ('ives', 0.21093420684337616),\n",
       "       ('ivell', 0.12045185267925262),\n",
       "       ('/~', 0.10022293031215668),\n",
       "       ('words', 0.0978819876909256)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.10349902510643005,\n",
       "      'top_tokens': [('atur', 0.257865309715271),\n",
       "       ('', 0.22084835171699524),\n",
       "       ('ilde', 0.18106231093406677),\n",
       "       ('atu', 0.17477892339229584),\n",
       "       ('hore', 0.16544516384601593)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.0990399718284607,\n",
       "      'top_tokens': [('', 0.47543054819107056),\n",
       "       ('', 0.20686285197734833),\n",
       "       ('', 0.12580955028533936),\n",
       "       ('', 0.09651406854391098),\n",
       "       (' ', 0.09538291394710541)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 53,\n",
       "      'weight': 0.29011276364326477,\n",
       "      'top_tokens': [(' .../', 0.44442081451416016),\n",
       "       ('', 0.2489185631275177),\n",
       "       ('', 0.11666394025087357),\n",
       "       (' met', 0.10657106339931488),\n",
       "       ('', 0.08342563360929489)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.1341703087091446,\n",
       "      'top_tokens': [(' ', 0.36701345443725586),\n",
       "       ('Formatting', 0.22539865970611572),\n",
       "       (' inactius', 0.14078612625598907),\n",
       "       ('', 0.1407855898141861),\n",
       "       ('', 0.12601609528064728)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.13312967121601105,\n",
       "      'top_tokens': [('', 0.5137412548065186),\n",
       "       ('lehem', 0.15958231687545776),\n",
       "       ('igraphy', 0.12583468854427338),\n",
       "       ('mbol', 0.10493907332420349),\n",
       "       ('bilt', 0.0959026888012886)]},\n",
       "     {'expert_id': 11,\n",
       "      'weight': 0.12936727702617645,\n",
       "      'top_tokens': [('', 0.23863162100315094),\n",
       "       ('ohl', 0.23284099996089935),\n",
       "       ('\"><!--', 0.18377120792865753),\n",
       "       ('atol', 0.1735341101884842),\n",
       "       ('aty', 0.1712220460176468)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.11068095266819,\n",
       "      'top_tokens': [('', 0.47050872445106506),\n",
       "       ('ives', 0.21093444526195526),\n",
       "       ('ivell', 0.12045183777809143),\n",
       "       ('/~', 0.10022285580635071),\n",
       "       ('words', 0.09788206219673157)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.10349906235933304,\n",
       "      'top_tokens': [('atur', 0.2578653395175934),\n",
       "       ('', 0.22084826231002808),\n",
       "       ('ilde', 0.1810622364282608),\n",
       "       ('atu', 0.17477884888648987),\n",
       "       ('hore', 0.1654452681541443)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.09904002398252487,\n",
       "      'top_tokens': [('', 0.4754304885864258),\n",
       "       ('', 0.20686283707618713),\n",
       "       ('', 0.1258096545934677),\n",
       "       ('', 0.09651396423578262),\n",
       "       (' ', 0.09538299590349197)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 53,\n",
       "      'weight': 0.2901129126548767,\n",
       "      'top_tokens': [(' .../', 0.4444204866886139),\n",
       "       ('', 0.24891872704029083),\n",
       "       ('', 0.11666402965784073),\n",
       "       (' met', 0.10657113790512085),\n",
       "       ('', 0.0834256112575531)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.1341703087091446,\n",
       "      'top_tokens': [(' ', 0.3670142590999603),\n",
       "       ('Formatting', 0.22539830207824707),\n",
       "       ('', 0.14078590273857117),\n",
       "       (' inactius', 0.14078563451766968),\n",
       "       ('', 0.12601590156555176)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.13312971591949463,\n",
       "      'top_tokens': [('', 0.5137417316436768),\n",
       "       ('lehem', 0.15958215296268463),\n",
       "       ('igraphy', 0.12583445012569427),\n",
       "       ('mbol', 0.10493896901607513),\n",
       "       ('bilt', 0.09590268135070801)]},\n",
       "     {'expert_id': 11,\n",
       "      'weight': 0.1293671429157257,\n",
       "      'top_tokens': [('', 0.2386317402124405),\n",
       "       ('ohl', 0.23284079134464264),\n",
       "       ('\"><!--', 0.18377147614955902),\n",
       "       ('atol', 0.17353396117687225),\n",
       "       ('aty', 0.17122206091880798)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.11068091541528702,\n",
       "      'top_tokens': [('', 0.4705088436603546),\n",
       "       ('ives', 0.21093431115150452),\n",
       "       ('ivell', 0.12045180052518845),\n",
       "       ('/~', 0.10022307932376862),\n",
       "       ('words', 0.0978819951415062)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.10349903255701065,\n",
       "      'top_tokens': [('atur', 0.2578655779361725),\n",
       "       ('', 0.22084838151931763),\n",
       "       ('ilde', 0.18106205761432648),\n",
       "       ('atu', 0.17477884888648987),\n",
       "       ('hore', 0.16544510424137115)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.0990399643778801,\n",
       "      'top_tokens': [('', 0.47543054819107056),\n",
       "       ('', 0.20686306059360504),\n",
       "       ('', 0.12580955028533936),\n",
       "       ('', 0.09651397913694382),\n",
       "       (' ', 0.09538291394710541)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 53,\n",
       "      'weight': 0.2901129424571991,\n",
       "      'top_tokens': [(' .../', 0.4444206953048706),\n",
       "       ('', 0.24891860783100128),\n",
       "       ('', 0.11666391044855118),\n",
       "       (' met', 0.10657113045454025),\n",
       "       ('', 0.0834256112575531)]},\n",
       "     {'expert_id': 32,\n",
       "      'weight': 0.13417033851146698,\n",
       "      'top_tokens': [(' ', 0.36701416969299316),\n",
       "       ('Formatting', 0.2253982424736023),\n",
       "       (' inactius', 0.14078587293624878),\n",
       "       ('', 0.14078587293624878),\n",
       "       ('', 0.12601587176322937)]},\n",
       "     {'expert_id': 19,\n",
       "      'weight': 0.13312965631484985,\n",
       "      'top_tokens': [('', 0.5137417316436768),\n",
       "       ('lehem', 0.15958185493946075),\n",
       "       ('igraphy', 0.12583445012569427),\n",
       "       ('mbol', 0.10493926703929901),\n",
       "       ('bilt', 0.09590268135070801)]},\n",
       "     {'expert_id': 11,\n",
       "      'weight': 0.1293671429157257,\n",
       "      'top_tokens': [('', 0.23863165080547333),\n",
       "       ('ohl', 0.23284102976322174),\n",
       "       ('\"><!--', 0.18377149105072021),\n",
       "       ('atol', 0.1735338568687439),\n",
       "       ('aty', 0.1712220460176468)]},\n",
       "     {'expert_id': 25,\n",
       "      'weight': 0.11068091541528702,\n",
       "      'top_tokens': [('', 0.4705086350440979),\n",
       "       ('ives', 0.2109346240758896),\n",
       "       ('ivell', 0.12045174837112427),\n",
       "       ('/~', 0.10022303462028503),\n",
       "       ('words', 0.09788195043802261)]},\n",
       "     {'expert_id': 9,\n",
       "      'weight': 0.10349902510643005,\n",
       "      'top_tokens': [('atur', 0.2578653395175934),\n",
       "       ('', 0.22084826231002808),\n",
       "       ('ilde', 0.18106241524219513),\n",
       "       ('atu', 0.17477884888648987),\n",
       "       ('hore', 0.16544511914253235)]},\n",
       "     {'expert_id': 30,\n",
       "      'weight': 0.0990399718284607,\n",
       "      'top_tokens': [('', 0.47543078660964966),\n",
       "       ('', 0.20686256885528564),\n",
       "       ('', 0.12580949068069458),\n",
       "       ('', 0.09651412069797516),\n",
       "       (' ', 0.09538305550813675)]}]}}},\n",
       " 'layer_26': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.3511533737182617,\n",
       "      'top_tokens': [('', 0.26397818326950073),\n",
       "       ('', 0.2421744018793106),\n",
       "       ('', 0.17213603854179382),\n",
       "       ('', 0.16334699094295502),\n",
       "       ('equence', 0.15836437046527863)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.27489158511161804,\n",
       "      'top_tokens': [('artment', 0.28599652647972107),\n",
       "       ('odatabase', 0.19375786185264587),\n",
       "       ('', 0.19023244082927704),\n",
       "       ('ilets', 0.16709551215171814),\n",
       "       ('itudes', 0.1629176139831543)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.08714674413204193,\n",
       "      'top_tokens': [('', 0.7073812484741211),\n",
       "       ('', 0.1866752803325653),\n",
       "       ('', 0.07528924942016602),\n",
       "       ('', 0.016765715554356575),\n",
       "       ('', 0.013888591900467873)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.085422582924366,\n",
       "      'top_tokens': [('', 0.22399814426898956),\n",
       "       ('udar', 0.20890873670578003),\n",
       "       ('rores', 0.20518755912780762),\n",
       "       (' Diod', 0.19268135726451874),\n",
       "       ('', 0.16922415792942047)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.0711805671453476,\n",
       "      'top_tokens': [(' ', 0.797665536403656),\n",
       "       (' h', 0.11213535815477371),\n",
       "       (' (', 0.03539953753352165),\n",
       "       (' r', 0.030724383890628815),\n",
       "       (' m', 0.024075239896774292)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.06923319399356842,\n",
       "      'top_tokens': [('', 0.22606942057609558),\n",
       "       ('', 0.20376646518707275),\n",
       "       ('', 0.20247036218643188),\n",
       "       ('', 0.19378787279129028),\n",
       "       ('', 0.17390583455562592)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.06097192317247391,\n",
       "      'top_tokens': [('...', 0.4187781810760498),\n",
       "       ('......', 0.3123226761817932),\n",
       "       (\"'...\", 0.24015222489833832),\n",
       "       (',...', 0.023486027494072914),\n",
       "       ('...?', 0.005260831210762262)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.3511528968811035,\n",
       "      'top_tokens': [('', 0.263977974653244),\n",
       "       ('', 0.24217477440834045),\n",
       "       ('', 0.17213590443134308),\n",
       "       ('', 0.16334670782089233),\n",
       "       ('equence', 0.15836457908153534)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.2748919427394867,\n",
       "      'top_tokens': [('artment', 0.2859964370727539),\n",
       "       ('odatabase', 0.19375798106193542),\n",
       "       ('', 0.19023238122463226),\n",
       "       ('ilets', 0.16709554195404053),\n",
       "       ('itudes', 0.1629176288843155)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.08714677393436432,\n",
       "      'top_tokens': [('', 0.7073816061019897),\n",
       "       ('', 0.18667520582675934),\n",
       "       ('', 0.07528899610042572),\n",
       "       ('', 0.016765659675002098),\n",
       "       ('', 0.013888546265661716)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.08542267233133316,\n",
       "      'top_tokens': [('', 0.22399820387363434),\n",
       "       ('udar', 0.2089085876941681),\n",
       "       ('rores', 0.20518772304058075),\n",
       "       (' Diod', 0.19268131256103516),\n",
       "       ('', 0.16922420263290405)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.07118060439825058,\n",
       "      'top_tokens': [(' ', 0.7976649403572083),\n",
       "       (' h', 0.11213570088148117),\n",
       "       (' (', 0.03539961203932762),\n",
       "       (' r', 0.030724506825208664),\n",
       "       (' m', 0.02407531440258026)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.069233238697052,\n",
       "      'top_tokens': [('', 0.2260694056749344),\n",
       "       ('', 0.2037663608789444),\n",
       "       ('', 0.20247046649456024),\n",
       "       ('', 0.19378776848316193),\n",
       "       ('', 0.17390598356723785)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.06097190082073212,\n",
       "      'top_tokens': [('...', 0.4187774062156677),\n",
       "       ('......', 0.31232210993766785),\n",
       "       (\"'...\", 0.24015361070632935),\n",
       "       (',...', 0.023485984653234482),\n",
       "       ('...?', 0.005260861478745937)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.3511534035205841,\n",
       "      'top_tokens': [('', 0.2639780640602112),\n",
       "       ('', 0.24217458069324493),\n",
       "       ('', 0.17213605344295502),\n",
       "       ('', 0.16334694623947144),\n",
       "       ('equence', 0.15836437046527863)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.27489152550697327,\n",
       "      'top_tokens': [('artment', 0.28599658608436584),\n",
       "       ('odatabase', 0.1937578171491623),\n",
       "       ('', 0.19023248553276062),\n",
       "       ('ilets', 0.1670956313610077),\n",
       "       ('itudes', 0.16291755437850952)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.0871468111872673,\n",
       "      'top_tokens': [('', 0.7073817253112793),\n",
       "       ('', 0.18667541444301605),\n",
       "       ('', 0.0752887949347496),\n",
       "       ('', 0.016765614971518517),\n",
       "       ('', 0.013888509944081306)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.085422582924366,\n",
       "      'top_tokens': [('', 0.22399841248989105),\n",
       "       ('udar', 0.20890867710113525),\n",
       "       ('rores', 0.20518770813941956),\n",
       "       (' Diod', 0.19268131256103516),\n",
       "       ('', 0.16922394931316376)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.07118059694766998,\n",
       "      'top_tokens': [(' ', 0.7976650595664978),\n",
       "       (' h', 0.11213561147451401),\n",
       "       (' (', 0.03539959713816643),\n",
       "       (' r', 0.030724450945854187),\n",
       "       (' m', 0.024075282737612724)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.06923326104879379,\n",
       "      'top_tokens': [('', 0.22606930136680603),\n",
       "       ('', 0.2037663608789444),\n",
       "       ('', 0.20247036218643188),\n",
       "       ('', 0.19378803670406342),\n",
       "       ('', 0.17390590906143188)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.06097186356782913,\n",
       "      'top_tokens': [('...', 0.4187774360179901),\n",
       "       ('......', 0.31232210993766785),\n",
       "       (\"'...\", 0.24015362560749054),\n",
       "       (',...', 0.02348598651587963),\n",
       "       ('...?', 0.00526084192097187)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.3511529266834259,\n",
       "      'top_tokens': [('', 0.2639780044555664),\n",
       "       ('', 0.24217458069324493),\n",
       "       ('', 0.1721360981464386),\n",
       "       ('', 0.16334687173366547),\n",
       "       ('equence', 0.1583644449710846)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.2748921513557434,\n",
       "      'top_tokens': [('artment', 0.28599658608436584),\n",
       "       ('odatabase', 0.19375771284103394),\n",
       "       ('', 0.19023238122463226),\n",
       "       ('ilets', 0.1670956313610077),\n",
       "       ('itudes', 0.16291764378547668)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.08714673668146133,\n",
       "      'top_tokens': [('', 0.7073818445205688),\n",
       "       ('', 0.1866752803325653),\n",
       "       ('', 0.0752888098359108),\n",
       "       ('', 0.016765592619776726),\n",
       "       ('', 0.013888498768210411)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.08542263507843018,\n",
       "      'top_tokens': [('', 0.2239985167980194),\n",
       "       ('udar', 0.2089085727930069),\n",
       "       ('rores', 0.2051876038312912),\n",
       "       (' Diod', 0.19268131256103516),\n",
       "       ('', 0.16922402381896973)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.07118059694766998,\n",
       "      'top_tokens': [(' ', 0.7976647615432739),\n",
       "       (' h', 0.11213578283786774),\n",
       "       (' (', 0.03539961948990822),\n",
       "       (' r', 0.030724499374628067),\n",
       "       (' m', 0.024075308814644814)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.06923317909240723,\n",
       "      'top_tokens': [('', 0.22606949508190155),\n",
       "       ('', 0.2037663459777832),\n",
       "       ('', 0.20247043669223785),\n",
       "       ('', 0.1937878429889679),\n",
       "       ('', 0.1739058941602707)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.060971856117248535,\n",
       "      'top_tokens': [('...', 0.41877689957618713),\n",
       "       ('......', 0.3123229146003723),\n",
       "       (\"'...\", 0.24015331268310547),\n",
       "       (',...', 0.023485956713557243),\n",
       "       ('...?', 0.005260855425149202)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 33,\n",
       "      'weight': 0.35115310549736023,\n",
       "      'top_tokens': [('', 0.26397836208343506),\n",
       "       ('', 0.2421741634607315),\n",
       "       ('', 0.17213605344295502),\n",
       "       ('', 0.16334690153598785),\n",
       "       ('equence', 0.15836450457572937)]},\n",
       "     {'expert_id': 29,\n",
       "      'weight': 0.2748918831348419,\n",
       "      'top_tokens': [('artment', 0.2859964370727539),\n",
       "       ('odatabase', 0.19375787675380707),\n",
       "       ('', 0.1902322769165039),\n",
       "       ('ilets', 0.16709569096565247),\n",
       "       ('itudes', 0.16291777789592743)]},\n",
       "     {'expert_id': 51,\n",
       "      'weight': 0.08714678883552551,\n",
       "      'top_tokens': [('', 0.7073814272880554),\n",
       "       ('', 0.1866753250360489),\n",
       "       ('', 0.0752890482544899),\n",
       "       ('', 0.01676568016409874),\n",
       "       ('', 0.013888556510210037)]},\n",
       "     {'expert_id': 49,\n",
       "      'weight': 0.08542262017726898,\n",
       "      'top_tokens': [('', 0.22399836778640747),\n",
       "       ('udar', 0.2089085429906845),\n",
       "       ('rores', 0.2051875740289688),\n",
       "       (' Diod', 0.19268135726451874),\n",
       "       ('', 0.16922414302825928)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.071180559694767,\n",
       "      'top_tokens': [(' ', 0.7976648211479187),\n",
       "       (' h', 0.11213589459657669),\n",
       "       (' (', 0.03539957106113434),\n",
       "       (' r', 0.030724456533789635),\n",
       "       (' m', 0.024075288325548172)]},\n",
       "     {'expert_id': 36,\n",
       "      'weight': 0.06923320144414902,\n",
       "      'top_tokens': [('', 0.22606949508190155),\n",
       "       ('', 0.20376643538475037),\n",
       "       ('', 0.2024703323841095),\n",
       "       ('', 0.19378775358200073),\n",
       "       ('', 0.17390596866607666)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.06097188591957092,\n",
       "      'top_tokens': [('...', 0.4187779128551483),\n",
       "       ('......', 0.3123224675655365),\n",
       "       (\"'...\", 0.240152969956398),\n",
       "       (',...', 0.023485925048589706),\n",
       "       ('...?', 0.005260827951133251)]}]}}},\n",
       " 'layer_27': {'tokens': {'<beginofsentence>': {'position': 0,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.20873504877090454,\n",
       "      'top_tokens': [(' var', 0.35090741515159607),\n",
       "       ('vect', 0.1831098049879074),\n",
       "       (' vector', 0.16778631508350372),\n",
       "       (' const', 0.15541276335716248),\n",
       "       ('', 0.14278371632099152)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.18013471364974976,\n",
       "      'top_tokens': [('a', 0.28149089217185974),\n",
       "       ('land', 0.20401285588741302),\n",
       "       ('', 0.20281410217285156),\n",
       "       ('', 0.1596808135509491),\n",
       "       ('', 0.15200138092041016)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.13694019615650177,\n",
       "      'top_tokens': [(' m', 0.5183733105659485),\n",
       "       ('\\tm', 0.15255437791347504),\n",
       "       ('\\xa0m', 0.1524016112089157),\n",
       "       (' ', 0.09090783447027206),\n",
       "       (' os', 0.0857628732919693)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.13378271460533142,\n",
       "      'top_tokens': [(' theater', 0.21945320069789886),\n",
       "       ('Player', 0.21130074560642242),\n",
       "       (' Player', 0.20795133709907532),\n",
       "       (' Theater', 0.18994708359241486),\n",
       "       (' Entertainment', 0.1713477075099945)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.1283576637506485,\n",
       "      'top_tokens': [('7', 0.24706415832042694),\n",
       "       ('3', 0.2107846438884735),\n",
       "       ('9', 0.18569624423980713),\n",
       "       ('4', 0.18315477669239044),\n",
       "       ('1', 0.17330017685890198)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.10810430347919464,\n",
       "      'top_tokens': [('', 0.2181183397769928),\n",
       "       (' cryptocur', 0.21593983471393585),\n",
       "       ('', 0.1959075778722763),\n",
       "       ('', 0.18545813858509064),\n",
       "       ('ottest', 0.1845760941505432)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.10394536703824997,\n",
       "      'top_tokens': [(' ,\\\\\\\\', 0.25111597776412964),\n",
       "       (' &=&\\\\', 0.2176801562309265),\n",
       "       ('\\\\!+\\\\!', 0.18399964272975922),\n",
       "       ('&=&\\\\', 0.18100197613239288),\n",
       "       ('DOCKED', 0.16620221734046936)]}]},\n",
       "   'The': {'position': 1,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.20873484015464783,\n",
       "      'top_tokens': [(' var', 0.35090750455856323),\n",
       "       ('vect', 0.18310968577861786),\n",
       "       (' vector', 0.16778644919395447),\n",
       "       (' const', 0.15541264414787292),\n",
       "       ('', 0.1427837610244751)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.18013468384742737,\n",
       "      'top_tokens': [('a', 0.2814910113811493),\n",
       "       ('land', 0.20401285588741302),\n",
       "       ('', 0.20281408727169037),\n",
       "       ('', 0.15968087315559387),\n",
       "       ('', 0.15200123190879822)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.13694006204605103,\n",
       "      'top_tokens': [(' m', 0.5183734893798828),\n",
       "       ('\\tm', 0.15255428850650787),\n",
       "       ('\\xa0m', 0.15240152180194855),\n",
       "       (' ', 0.09090781956911087),\n",
       "       (' os', 0.08576291799545288)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.13378286361694336,\n",
       "      'top_tokens': [(' theater', 0.21945317089557648),\n",
       "       ('Player', 0.21130071580410004),\n",
       "       (' Player', 0.2079514116048813),\n",
       "       (' Theater', 0.18994705379009247),\n",
       "       (' Entertainment', 0.17134758830070496)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.1283576786518097,\n",
       "      'top_tokens': [('7', 0.24706418812274933),\n",
       "       ('3', 0.21078456938266754),\n",
       "       ('9', 0.18569625914096832),\n",
       "       ('4', 0.1831546276807785),\n",
       "       ('1', 0.1733003556728363)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.1081043928861618,\n",
       "      'top_tokens': [('', 0.21811822056770325),\n",
       "       (' cryptocur', 0.21593981981277466),\n",
       "       ('', 0.1959078460931778),\n",
       "       ('', 0.18545803427696228),\n",
       "       ('ottest', 0.18457607924938202)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.1039455309510231,\n",
       "      'top_tokens': [(' ,\\\\\\\\', 0.251116007566452),\n",
       "       (' &=&\\\\', 0.2176801860332489),\n",
       "       ('\\\\!+\\\\!', 0.18399962782859802),\n",
       "       ('&=&\\\\', 0.18100205063819885),\n",
       "       ('DOCKED', 0.166202113032341)]}]},\n",
       "   ' quick': {'position': 2,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.2087348997592926,\n",
       "      'top_tokens': [(' var', 0.35090744495391846),\n",
       "       ('vect', 0.18310999870300293),\n",
       "       (' vector', 0.16778650879859924),\n",
       "       (' const', 0.15541240572929382),\n",
       "       ('', 0.1427837312221527)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.18013499677181244,\n",
       "      'top_tokens': [('a', 0.28149113059043884),\n",
       "       ('land', 0.20401284098625183),\n",
       "       ('', 0.20281408727169037),\n",
       "       ('', 0.15968072414398193),\n",
       "       ('', 0.15200115740299225)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.1369401216506958,\n",
       "      'top_tokens': [(' m', 0.5183733701705933),\n",
       "       ('\\tm', 0.15255439281463623),\n",
       "       ('\\xa0m', 0.15240156650543213),\n",
       "       (' ', 0.09090779721736908),\n",
       "       (' os', 0.08576279878616333)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.1337825357913971,\n",
       "      'top_tokens': [(' theater', 0.2194531410932541),\n",
       "       ('Player', 0.2113007754087448),\n",
       "       (' Player', 0.20795148611068726),\n",
       "       (' Theater', 0.1899469494819641),\n",
       "       (' Entertainment', 0.17134766280651093)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.1283576935529709,\n",
       "      'top_tokens': [('7', 0.24706415832042694),\n",
       "       ('3', 0.21078474819660187),\n",
       "       ('9', 0.1856963336467743),\n",
       "       ('4', 0.1831546127796173),\n",
       "       ('1', 0.17330017685890198)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.1081044003367424,\n",
       "      'top_tokens': [('', 0.2181183397769928),\n",
       "       (' cryptocur', 0.21593964099884033),\n",
       "       ('', 0.19590777158737183),\n",
       "       ('', 0.18545806407928467),\n",
       "       ('ottest', 0.18457618355751038)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.10394536703824997,\n",
       "      'top_tokens': [(' ,\\\\\\\\', 0.2511158883571625),\n",
       "       (' &=&\\\\', 0.21768029034137726),\n",
       "       ('\\\\!+\\\\!', 0.1839996725320816),\n",
       "       ('&=&\\\\', 0.18100209534168243),\n",
       "       ('DOCKED', 0.16620208323001862)]}]},\n",
       "   ' brown': {'position': 3,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.2087351232767105,\n",
       "      'top_tokens': [(' var', 0.3509073555469513),\n",
       "       ('vect', 0.18310977518558502),\n",
       "       (' vector', 0.16778646409511566),\n",
       "       (' const', 0.15541258454322815),\n",
       "       ('', 0.14278383553028107)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.1801348626613617,\n",
       "      'top_tokens': [('a', 0.28149116039276123),\n",
       "       ('land', 0.20401276648044586),\n",
       "       ('', 0.20281411707401276),\n",
       "       ('', 0.15968075394630432),\n",
       "       ('', 0.15200117230415344)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.13693998754024506,\n",
       "      'top_tokens': [(' m', 0.5183735489845276),\n",
       "       ('\\tm', 0.15255430340766907),\n",
       "       ('\\xa0m', 0.15240155160427094),\n",
       "       (' ', 0.09090778976678848),\n",
       "       (' os', 0.08576282858848572)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.13378269970417023,\n",
       "      'top_tokens': [(' theater', 0.21945321559906006),\n",
       "       ('Player', 0.21130076050758362),\n",
       "       (' Player', 0.20795144140720367),\n",
       "       (' Theater', 0.1899470090866089),\n",
       "       (' Entertainment', 0.17134763300418854)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.12835758924484253,\n",
       "      'top_tokens': [('7', 0.24706412851810455),\n",
       "       ('3', 0.21078471839427948),\n",
       "       ('9', 0.18569621443748474),\n",
       "       ('4', 0.18315467238426208),\n",
       "       ('1', 0.17330016195774078)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.10810434073209763,\n",
       "      'top_tokens': [('', 0.21811842918395996),\n",
       "       (' cryptocur', 0.2159397304058075),\n",
       "       ('', 0.19590766727924347),\n",
       "       ('', 0.18545804917812347),\n",
       "       ('ottest', 0.18457607924938202)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.10394547879695892,\n",
       "      'top_tokens': [(' ,\\\\\\\\', 0.251116007566452),\n",
       "       (' &=&\\\\', 0.2176801860332489),\n",
       "       ('\\\\!+\\\\!', 0.18399962782859802),\n",
       "       ('&=&\\\\', 0.18100209534168243),\n",
       "       ('DOCKED', 0.16620215773582458)]}]},\n",
       "   ' fox': {'position': 4,\n",
       "    'expert_outputs': [{'expert_id': 63,\n",
       "      'weight': 0.20873504877090454,\n",
       "      'top_tokens': [(' var', 0.35090717673301697),\n",
       "       ('vect', 0.18311002850532532),\n",
       "       (' vector', 0.1677863746881485),\n",
       "       (' const', 0.15541258454322815),\n",
       "       ('', 0.14278382062911987)]},\n",
       "     {'expert_id': 53,\n",
       "      'weight': 0.1801348775625229,\n",
       "      'top_tokens': [('a', 0.2814909815788269),\n",
       "       ('land', 0.20401282608509064),\n",
       "       ('', 0.20281416177749634),\n",
       "       ('', 0.1596807986497879),\n",
       "       ('', 0.15200121700763702)]},\n",
       "     {'expert_id': 33,\n",
       "      'weight': 0.13694003224372864,\n",
       "      'top_tokens': [(' m', 0.5183737277984619),\n",
       "       ('\\tm', 0.1525541990995407),\n",
       "       ('\\xa0m', 0.15240144729614258),\n",
       "       (' ', 0.09090777486562729),\n",
       "       (' os', 0.08576279878616333)]},\n",
       "     {'expert_id': 20,\n",
       "      'weight': 0.13378268480300903,\n",
       "      'top_tokens': [(' theater', 0.21945329010486603),\n",
       "       ('Player', 0.21130073070526123),\n",
       "       (' Player', 0.2079514116048813),\n",
       "       (' Theater', 0.1899469941854477),\n",
       "       (' Entertainment', 0.17134760320186615)]},\n",
       "     {'expert_id': 26,\n",
       "      'weight': 0.1283576935529709,\n",
       "      'top_tokens': [('7', 0.24706412851810455),\n",
       "       ('3', 0.21078471839427948),\n",
       "       ('9', 0.1856963038444519),\n",
       "       ('4', 0.18315458297729492),\n",
       "       ('1', 0.17330025136470795)]},\n",
       "     {'expert_id': 1,\n",
       "      'weight': 0.1081044003367424,\n",
       "      'top_tokens': [('', 0.2181183397769928),\n",
       "       (' cryptocur', 0.21593983471393585),\n",
       "       ('', 0.19590768218040466),\n",
       "       ('', 0.18545806407928467),\n",
       "       ('ottest', 0.1845760941505432)]},\n",
       "     {'expert_id': 55,\n",
       "      'weight': 0.10394532233476639,\n",
       "      'top_tokens': [(' ,\\\\\\\\', 0.251116007566452),\n",
       "       (' &=&\\\\', 0.2176801860332489),\n",
       "       ('\\\\!+\\\\!', 0.18399962782859802),\n",
       "       ('&=&\\\\', 0.18100205063819885),\n",
       "       ('DOCKED', 0.16620215773582458)]}]}}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
