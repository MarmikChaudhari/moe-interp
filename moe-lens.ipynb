{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61735be97de4c9db9bd016c7e6a7bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_model(model_name):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True,\n",
    "        # use_flash_attention_2=True,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model(\"deepseek-ai/deepseek-moe-16b-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moe_metadata(model, input_ids):\n",
    "    \"\"\"Get both router logits and expert indices for all MoE layers\"\"\"\n",
    "    router_logits_list = []\n",
    "    expert_indices_list = []\n",
    "    hidden_states_list = []\n",
    "    \n",
    "    def hook_fn(module, input, output):\n",
    "        # output contains: (topk_idx, topk_weight, aux_loss)\n",
    "        hidden_states = input[0]\n",
    "        \n",
    "        logits = torch.matmul(hidden_states, module.weight.T)\n",
    "        router_logits_list.append(logits.detach())\n",
    "        \n",
    "        # store expert indices actually used for routing\n",
    "        expert_indices_list.append(output[0].detach())\n",
    "\n",
    "        # store the hidden states\n",
    "        hidden_states_list.append(hidden_states.detach())\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    hooks = []\n",
    "    for layer_idx, layer in enumerate(model.model.layers):\n",
    "        if layer.mlp.__class__.__name__ == 'DeepseekMoE':\n",
    "            hook = layer.mlp.gate.register_forward_hook(hook_fn)\n",
    "            hooks.append(hook)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model(input_ids)\n",
    "    \n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    moe_metadata = {\n",
    "        'router_logits': torch.stack(router_logits_list) if router_logits_list else None,\n",
    "        'expert_indices': torch.stack(expert_indices_list) if expert_indices_list else None,\n",
    "        'hidden_states': torch.stack(hidden_states_list) if hidden_states_list else None\n",
    "    }\n",
    "    \n",
    "    if moe_metadata['router_logits'] is not None:\n",
    "        print(f\"Router logits shape: {moe_metadata['router_logits'].shape}\")\n",
    "    if moe_metadata['expert_indices'] is not None:\n",
    "        print(f\"Expert indices shape: {moe_metadata['expert_indices'].shape}\")\n",
    "    if moe_metadata['hidden_states'] is not None:\n",
    "        print(f\"Hidden states shape: {moe_metadata['hidden_states'].shape}\")\n",
    "    \n",
    "    return moe_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expert_outputs(model, moe_metadata):\n",
    "    \"\"\"Compute expert outputs for top-k selected experts in all MoE layers\"\"\"\n",
    "    expert_outputs = []\n",
    "    num_layers = 27\n",
    "    \n",
    "    # Get metadata dimensions\n",
    "    # num_layers = moe_metadata['expert_indices'].shape[0]\n",
    "    print(f'expert_indices shape: {moe_metadata[\"expert_indices\"].shape}')\n",
    "    num_tokens = moe_metadata['expert_indices'].shape[1]\n",
    "    top_k = moe_metadata['expert_indices'].shape[2]\n",
    "    hidden_dim = moe_metadata['hidden_states'].shape[-1]\n",
    "\n",
    "    # Pre-allocate tensor: [layers, tokens, top_k, hidden_dim]\n",
    "    all_expert_outputs = torch.zeros(\n",
    "        (num_layers, num_tokens, top_k, hidden_dim),\n",
    "        device=model.device\n",
    "    )\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        # Get MoE components for current layer\n",
    "        expert_module = model.model.layers[layer_idx+1].mlp.experts\n",
    "        layer_hidden_states = moe_metadata['hidden_states'][layer_idx]  # [1, num_tokens, hdim]\n",
    "        layer_expert_indices = moe_metadata['expert_indices'][layer_idx]  # [num_tokens, top_k]\n",
    "\n",
    "        for token_idx in range(num_tokens):\n",
    "            # Get hidden state for this token (remove batch dim)\n",
    "            hidden_state = layer_hidden_states[0, token_idx]  # [hdim]\n",
    "\n",
    "            # Get expert indices for this token\n",
    "            expert_indices = layer_expert_indices[token_idx]\n",
    "\n",
    "            # Process through each selected expert\n",
    "            for expert_pos, expert_idx in enumerate(expert_indices):\n",
    "                expert = expert_module[expert_idx.item()]\n",
    "                \n",
    "                # Add batch dimension for processing\n",
    "                with torch.no_grad():\n",
    "                    expert_out = expert(hidden_state.unsqueeze(0))  # [1, hdim]\n",
    "                \n",
    "                all_expert_outputs[layer_idx, token_idx, expert_pos] = expert_out.squeeze(0)\n",
    "\n",
    "    print(f\"Expert outputs shape: {all_expert_outputs.shape}\")\n",
    "    return all_expert_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_expert_outputs(model, expert_outputs):\n",
    "    \"\"\"\n",
    "    Project expert outputs through LM head while maintaining structure\n",
    "    Returns tensor of shape [num_layers, num_tokens, num_experts, vocab_size]\n",
    "    \"\"\"\n",
    "    # Get model dtype from LM head\n",
    "    model_dtype = model.lm_head.weight.dtype\n",
    "    \n",
    "    # Get original shape details\n",
    "    num_layers, num_tokens, num_experts, hidden_dim = expert_outputs.shape\n",
    "    vocab_size = model.lm_head.out_features\n",
    "    print(f'vocab_size: {vocab_size}')\n",
    "    # Pre-allocate output tensor using model dtype\n",
    "    expert_logits = torch.zeros(\n",
    "        (num_layers, num_tokens, num_experts, vocab_size),\n",
    "        device=model.device,\n",
    "        dtype=model_dtype  # Match model's dtype\n",
    "    )\n",
    "\n",
    "    # Process each layer, token and expert individually\n",
    "    for layer_idx in range(num_layers):\n",
    "        for token_idx in range(num_tokens):\n",
    "            for expert_idx in range(num_experts):\n",
    "                # Get expert output and cast to model dtype\n",
    "                expert_output = expert_outputs[layer_idx, token_idx, expert_idx]\n",
    "                expert_output = expert_output.to(model_dtype)  # <-- CRITICAL CAST\n",
    "                \n",
    "                # Project through LM head\n",
    "                with torch.no_grad():\n",
    "                    logits = model.lm_head(expert_output.unsqueeze(0))\n",
    "                \n",
    "                # Store result\n",
    "                expert_logits[layer_idx, token_idx, expert_idx] = logits.squeeze(0)\n",
    "\n",
    "    print(f\"Expert logits shape: {expert_logits.shape}\")\n",
    "    return expert_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expert_topk_tokens(expert_logits, tokenizer, k=5):\n",
    "    \"\"\"\n",
    "    Get top-k tokens for each expert at each layer and token position\n",
    "    Returns nested dictionary:\n",
    "    {\n",
    "        layer_idx: {\n",
    "            token_idx: {\n",
    "                expert_idx: {\n",
    "                    'tokens': [decoded tokens],\n",
    "                    'scores': [corresponding scores],\n",
    "                    'ids': [token ids]\n",
    "                }, ...\n",
    "            }, ...\n",
    "        }, ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    num_layers, num_tokens, num_experts, _ = expert_logits.shape\n",
    "    results = {}\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        layer_results = {}\n",
    "        for token_idx in range(num_tokens):\n",
    "            token_results = {}\n",
    "            for expert_idx in range(num_experts):\n",
    "                # Get logits for this expert configuration\n",
    "                expert_logit = expert_logits[layer_idx, token_idx, expert_idx]\n",
    "                \n",
    "                # Get top-k predictions\n",
    "                topk_scores, topk_indices = torch.topk(expert_logit, k)\n",
    "                \n",
    "                # Convert to CPU/numpy for decoding\n",
    "                topk_indices_cpu = topk_indices.cpu().numpy()\n",
    "                topk_scores_cpu = topk_scores.cpu().numpy()\n",
    "                \n",
    "                # Decode tokens\n",
    "                decoded_tokens = tokenizer.batch_decode(topk_indices_cpu)\n",
    "                \n",
    "                token_results[expert_idx] = {\n",
    "                    'tokens': decoded_tokens,\n",
    "                    'scores': topk_scores_cpu.tolist(),\n",
    "                    'ids': topk_indices_cpu.tolist()\n",
    "                }\n",
    "            \n",
    "            layer_results[token_idx] = token_results\n",
    "        results[layer_idx] = layer_results\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router logits shape: torch.Size([27, 1, 5, 64])\n",
      "Expert indices shape: torch.Size([27, 5, 6])\n",
      "Hidden states shape: torch.Size([27, 1, 5, 2048])\n",
      "expert_indices shape: torch.Size([27, 5, 6])\n",
      "Expert outputs shape: torch.Size([27, 5, 6, 2048])\n",
      "vocab_size: 102400\n",
      "Expert logits shape: torch.Size([27, 5, 6, 102400])\n"
     ]
    }
   ],
   "source": [
    "input_txt = \"the quick brown fox\"\n",
    "input_ids = tokenizer.encode(input_txt, return_tensors=\"pt\")\n",
    "moe_metadata = get_moe_metadata(model, input_ids)\n",
    "expert_outputs = get_expert_outputs(model, moe_metadata)\n",
    "expert_logits = project_expert_outputs(model, expert_outputs)\n",
    "expert_topk_tokens = get_expert_topk_tokens(expert_logits, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: {'tokens': ['////////////////////////////////////////////////////////////////', '//', '\\t//', '/************************************************************************', '//----------------------------------------------------------------'], 'scores': [13.7109375, 13.4296875, 13.390625, 13.15625, 13.0], 'ids': [43041, 556, 3014, 59131, 45381]}, 1: {'tokens': ['角', '学', ' _$', '�', '待'], 'scores': [24.234375, 23.625, 23.34375, 23.1875, 23.15625], 'ids': [5607, 1159, 75594, 1293, 5918]}, 2: {'tokens': ['Magent', '<?', '<!', 'Strunz', 'package'], 'scores': [32.59375, 30.078125, 28.1875, 28.0, 27.890625], 'ids': [88706, 8484, 18121, 86689, 6420]}, 3: {'tokens': ['1', '2', ' *', '//', ' '], 'scores': [23.65625, 23.328125, 22.90625, 22.28125, 22.28125], 'ids': [16, 17, 575, 556, 207]}, 4: {'tokens': ['\\n', 'bootstrapcdn', 'makeText', ' I', '<｜end▁of▁sentence｜>'], 'scores': [23.546875, 22.5625, 22.546875, 21.875, 21.25], 'ids': [185, 47331, 62566, 304, 100001]}, 5: {'tokens': ['<｜end▁of▁sentence｜>', 'READ', 'Read', ' /*!<', '\"];'], 'scores': [6.8203125, 4.2265625, 3.87890625, 3.791015625, 3.775390625], 'ids': [100001, 17161, 4623, 27080, 24571]}}, 1: {0: {'tokens': [' nether', ' outermost', 'ymap', 'ermis', 'ограф'], 'scores': [12.6640625, 12.5, 11.671875, 11.1171875, 10.8984375], 'ids': [90704, 99790, 91064, 97648, 36224]}, 1: {'tokens': ['irat', 'baid', ' Pallars', 'ntic', ' remains'], 'scores': [11.3671875, 11.1953125, 10.609375, 10.5390625, 10.1640625], 'ids': [83977, 62627, 43386, 6466, 7544]}, 2: {'tokens': [' court', ' cause', ' victim', ' amount', 'мани'], 'scores': [10.5390625, 10.421875, 10.375, 10.328125, 10.1640625], 'ids': [6518, 4309, 17180, 3744, 27802]}, 3: {'tokens': ['��', 'odox', 'Sec', 'Co', 'Bind'], 'scores': [7.78515625, 6.84375, 6.78125, 6.640625, 6.33984375], 'ids': [689, 35024, 8508, 8854, 22641]}, 4: {'tokens': [' Braves', ' Warriors', ' Bruins', ' Reds', ' Bears'], 'scores': [18.640625, 18.546875, 18.21875, 17.78125, 17.484375], 'ids': [97762, 51354, 98696, 77886, 50243]}, 5: {'tokens': ['息', 'ipre', 'ivil', ' S', '\\tS'], 'scores': [9.5234375, 9.4453125, 9.3125, 9.1875, 8.609375], 'ids': [3714, 71905, 5525, 324, 54161]}}, 2: {0: {'tokens': [' dotted', ' seam', ' div', ' branch', ' plot'], 'scores': [9.8984375, 9.8828125, 9.7890625, 9.640625, 9.421875], 'ids': [29793, 19324, 2998, 10592, 10143]}, 1: {'tokens': [',', ' Icel', 'est', ' Бро', ' inhal'], 'scores': [7.16015625, 7.03515625, 6.91015625, 6.2109375, 5.921875], 'ids': [11, 37943, 371, 57362, 75719]}, 2: {'tokens': [' appearance', ' mistake', ' wound', ' appearances', ' warning'], 'scores': [10.9140625, 10.71875, 9.3984375, 9.3125, 9.0859375], 'ids': [8753, 13184, 20401, 32212, 11522]}, 3: {'tokens': ['outs', 'stock', 'ball', 'book', 'bar'], 'scores': [7.5390625, 7.28125, 7.1796875, 7.1640625, 7.15625], 'ids': [10313, 20107, 3087, 3234, 1684]}, 4: {'tokens': ['man', 'cell', 'hopper', 'mans', 'land'], 'scores': [8.5234375, 8.46875, 8.25, 7.953125, 7.78515625], 'ids': [1414, 7220, 91453, 20440, 1569]}, 5: {'tokens': [' understanding', ' event', ' piece', ' idea', ' item'], 'scores': [8.0703125, 8.046875, 8.03125, 7.75, 7.43359375], 'ids': [6714, 2536, 5836, 3257, 2861]}}, 3: {0: {'tokens': ['ish', 'hand', 'ier', 'ful', 'istic'], 'scores': [8.0390625, 7.640625, 7.33203125, 7.22265625, 7.04296875], 'ids': [844, 4567, 1369, 1086, 3737]}, 1: {'tokens': ['work', 'care', ' fac', 'fly', 'y'], 'scores': [8.6640625, 8.3828125, 8.046875, 7.8984375, 7.75390625], 'ids': [1597, 8601, 3569, 14239, 88]}, 2: {'tokens': ['o', 'ky', 'sky', 'ke', 'i'], 'scores': [12.4609375, 11.6953125, 11.640625, 11.3359375, 11.015625], 'ids': [78, 5834, 17410, 400, 72]}, 3: {'tokens': [' conscience', '揭', ' personage', ' Веле', ' figure'], 'scores': [5.71484375, 5.10546875, 5.015625, 5.0, 4.94921875], 'ids': [25636, 25442, 77036, 88825, 5617]}, 4: {'tokens': [' teac', ' di', ' adequat', ' heartbeat', 'ences'], 'scores': [5.74609375, 5.43359375, 5.3671875, 5.35546875, 5.3125], 'ids': [6643, 1499, 88801, 68232, 3192]}, 5: {'tokens': [' vector', ' corner', ' int', ' table', ' x'], 'scores': [14.21875, 13.2109375, 12.96875, 12.4609375, 11.78125], 'ids': [6133, 8089, 1098, 2376, 1376]}}, 4: {0: {'tokens': ['men', 'iness', 'y', 'bars', 'rates'], 'scores': [7.7265625, 6.67578125, 6.65234375, 6.58984375, 6.5390625], 'ids': [3741, 1566, 88, 32780, 29022]}, 1: {'tokens': [' turned', ' expected', 'turned', ' thought', ' stopped'], 'scores': [5.5703125, 4.8359375, 4.8359375, 4.66015625, 4.4765625], 'ids': [4540, 4061, 25815, 2215, 8583]}, 2: {'tokens': [' ends', ' works', ' looks', ' lands', ' lives'], 'scores': [9.390625, 9.359375, 9.1484375, 8.609375, 8.6015625], 'ids': [10171, 2722, 4716, 19369, 6110]}, 3: {'tokens': ['res', 'So', 'Edit', 'By', 'put'], 'scores': [6.55078125, 6.3828125, 6.37109375, 6.37109375, 6.30078125], 'ids': [379, 3139, 9907, 2716, 921]}, 4: {'tokens': ['\"；', '」', '，', '\"！', '】'], 'scores': [17.796875, 17.265625, 16.6875, 16.484375, 16.3125], 'ids': [35336, 17335, 19304, 46219, 8156]}, 5: {'tokens': [' post', ' link', ' article', ' permalink', ' posts'], 'scores': [12.515625, 11.9140625, 10.3046875, 10.2890625, 10.1796875], 'ids': [1767, 3636, 4718, 45563, 10105]}}}\n"
     ]
    }
   ],
   "source": [
    "print(expert_topk_tokens[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shared_expert_outputs(model, input_ids):\n",
    "    \"\"\"Get outputs from shared experts in all MoE layers\"\"\"\n",
    "    shared_outputs_list = []\n",
    "    hidden_states_list = []\n",
    "    moe_layers = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        # Capture hidden states entering the MoE layer\n",
    "        hidden_states = input[0]\n",
    "        hidden_states_list.append(hidden_states.squeeze(0).detach())\n",
    "        return output\n",
    "\n",
    "    hooks = []\n",
    "    # Identify MoE layers and register hooks\n",
    "    for layer in model.model.layers:\n",
    "        if layer.mlp.__class__.__name__ == 'DeepseekMoE':\n",
    "            moe_layers.append(layer.mlp)\n",
    "            hook = layer.mlp.gate.register_forward_hook(hook_fn)\n",
    "            hooks.append(hook)\n",
    "\n",
    "    # Forward pass to collect hidden states\n",
    "    with torch.no_grad():\n",
    "        model(input_ids)\n",
    "    \n",
    "    # Remove hooks after forward pass\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    # Compute shared expert outputs for each MoE layer\n",
    "    for layer_idx, moe_layer in enumerate(moe_layers):\n",
    "        hidden_states = hidden_states_list[layer_idx]\n",
    "        \n",
    "        # Get output from shared experts (which is a single DeepseekMLP)\n",
    "        with torch.no_grad():\n",
    "            expert_out = moe_layer.shared_experts(hidden_states)\n",
    "        layer_shared_outputs = [expert_out]\n",
    "        \n",
    "        # Stack outputs: [num_shared_experts=1, seq_len, hidden_dim] \n",
    "        shared_outputs_list.append(torch.stack(layer_shared_outputs, dim=0))\n",
    "\n",
    "    # Stack all layer outputs to get shape [num_layers, num_shared_experts=1, seq_len, hidden_dim]\n",
    "    shared_outputs_tensor = torch.stack(shared_outputs_list, dim=0)\n",
    "\n",
    "    return {\n",
    "        'shared_expert_outputs': shared_outputs_tensor,\n",
    "        'hidden_states': torch.stack(hidden_states_list) if hidden_states_list else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 1, 5, 2048])\n",
      "Shared expert outputs : 27\n",
      "First layer shared outputs shape: torch.Size([1, 5, 2048])\n"
     ]
    }
   ],
   "source": [
    "# Get shared expert outputs separately\n",
    "shared_data = get_shared_expert_outputs(model, input_ids)\n",
    "\n",
    "print(shared_data['shared_expert_outputs'].shape)\n",
    "print(f\"Shared expert outputs : {len(shared_data['shared_expert_outputs'])}\")\n",
    "print(f\"First layer shared outputs shape: {shared_data['shared_expert_outputs'][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 102400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert logits shape: torch.Size([27, 1, 5, 102400])\n"
     ]
    }
   ],
   "source": [
    "expert_logits = project_expert_outputs(model, expert_outputs=shared_data['shared_expert_outputs'])\n",
    "expert_topk_tokens = get_expert_topk_tokens(expert_logits, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['ა', ' <!--[', 'ა�', 'ELY', '\\tandroid'],\n",
       " 'scores': [1.1953125, 1.1025390625, 1.1005859375, 1.0888671875, 1.0205078125],\n",
       " 'ids': [46554, 69586, 56166, 70939, 97199]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_topk_tokens[19][0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_actual_experts(expert_topk_tokens, moe_metadata):\n",
    "    \"\"\"\n",
    "    Convert top-k positional indices to actual expert indices using routing data\n",
    "    Returns:\n",
    "    {\n",
    "        layer_idx: {\n",
    "            token_idx: {\n",
    "                actual_expert_idx: {\n",
    "                    'tokens': [...],\n",
    "                    'scores': [...], \n",
    "                    'ids': [...]\n",
    "                }, ...\n",
    "            }, ...\n",
    "        }, ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    actual_expert_dict = {}\n",
    "    expert_indices = moe_metadata['expert_indices'].cpu().numpy()\n",
    "    \n",
    "    for layer_idx in expert_topk_tokens:\n",
    "        layer_data = expert_topk_tokens[layer_idx]\n",
    "        actual_layer = {}\n",
    "        \n",
    "        # Get actual expert IDs for this layer [num_tokens, top_k]\n",
    "        layer_expert_ids = expert_indices[layer_idx]\n",
    "        \n",
    "        for token_idx in layer_data:\n",
    "            token_data = layer_data[token_idx]\n",
    "            actual_token = {}\n",
    "            \n",
    "            # Get actual expert IDs for this token [top_k]\n",
    "            token_expert_ids = layer_expert_ids[token_idx]\n",
    "            \n",
    "            for pos_idx in token_data:\n",
    "                # Map positional index to actual expert ID\n",
    "                actual_expert_id = int(token_expert_ids[pos_idx])\n",
    "                actual_token[actual_expert_id] = token_data[pos_idx]\n",
    "                \n",
    "            actual_token = dict(sorted(actual_token.items()))\n",
    "            actual_layer[token_idx] = actual_token\n",
    "            \n",
    "        actual_expert_dict[layer_idx] = actual_layer\n",
    "        \n",
    "    return actual_expert_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: {2: {'tokens': ['始终坚持', 'JT', 'LH', '犀', '固执'],\n",
       "    'scores': [0.290283203125,\n",
       "     0.287841796875,\n",
       "     0.285888671875,\n",
       "     0.28515625,\n",
       "     0.283203125],\n",
       "    'ids': [99612, 77201, 96732, 65146, 97881]},\n",
       "   14: {'tokens': ['钰', 'AGA', 'pei', 'LH', '始终坚持'],\n",
       "    'scores': [0.31298828125,\n",
       "     0.2880859375,\n",
       "     0.281982421875,\n",
       "     0.276611328125,\n",
       "     0.275146484375],\n",
       "    'ids': [94398, 92651, 68396, 96732, 99612]},\n",
       "   34: {'tokens': ['被迫', 'ISAM', '竣', '乞', 'INSEE'],\n",
       "    'scores': [0.491455078125,\n",
       "     0.46728515625,\n",
       "     0.46484375,\n",
       "     0.443115234375,\n",
       "     0.44189453125],\n",
       "    'ids': [64397, 57610, 69003, 61028, 18832]},\n",
       "   42: {'tokens': ['裹', '野心', '沾', '琦', '姗'],\n",
       "    'scores': [0.327392578125,\n",
       "     0.307373046875,\n",
       "     0.294921875,\n",
       "     0.293212890625,\n",
       "     0.291748046875],\n",
       "    'ids': [33403, 90530, 40540, 55105, 90230]},\n",
       "   47: {'tokens': ['HCI', ' dalt', '沾', 'JT', '*:'],\n",
       "    'scores': [0.317138671875,\n",
       "     0.314697265625,\n",
       "     0.300048828125,\n",
       "     0.298095703125,\n",
       "     0.294677734375],\n",
       "    'ids': [56553, 60634, 40540, 77201, 75868]}}},\n",
       " 1: {0: {14: {'tokens': ['INSEE', 'ndar', '翼翼', 'мира', ' Mediterrani'],\n",
       "    'scores': [2.12109375, 2.068359375, 2.05859375, 2.046875, 2.009765625],\n",
       "    'ids': [18832, 91379, 95141, 9088, 71447]},\n",
       "   31: {'tokens': ['бон', 'lic', 'BU', '�', 'oice'],\n",
       "    'scores': [0.297119140625,\n",
       "     0.27001953125,\n",
       "     0.269775390625,\n",
       "     0.259521484375,\n",
       "     0.24853515625],\n",
       "    'ids': [63588, 811, 8526, 448, 4021]},\n",
       "   42: {'tokens': ['nj', 'buk', '设法', 'YP', 'ISO'],\n",
       "    'scores': [0.2744140625,\n",
       "     0.26220703125,\n",
       "     0.25732421875,\n",
       "     0.250732421875,\n",
       "     0.2476806640625],\n",
       "    'ids': [75705, 89028, 92194, 37064, 30422]},\n",
       "   46: {'tokens': ['apac', '面目', 'etr', '懿', 'WHM'],\n",
       "    'scores': [0.24658203125,\n",
       "     0.2369384765625,\n",
       "     0.2347412109375,\n",
       "     0.23388671875,\n",
       "     0.2210693359375],\n",
       "    'ids': [94406, 91261, 97658, 75607, 61225]},\n",
       "   63: {'tokens': ['�', 'icro', '练习', '�', '菩提'],\n",
       "    'scores': [0.1790771484375,\n",
       "     0.175537109375,\n",
       "     0.169921875,\n",
       "     0.1690673828125,\n",
       "     0.16845703125],\n",
       "    'ids': [7727, 3226, 26253, 3032, 65417]}}},\n",
       " 2: {0: {20: {'tokens': ['olved', 'heses', ' Word', 'shel', 'стру'],\n",
       "    'scores': [0.384521484375,\n",
       "     0.356689453125,\n",
       "     0.33740234375,\n",
       "     0.331787109375,\n",
       "     0.3291015625],\n",
       "    'ids': [66103, 47868, 10316, 70814, 21949]},\n",
       "   22: {'tokens': ['�', '如有关于', '�', '加入', '所得'],\n",
       "    'scores': [0.2978515625,\n",
       "     0.289306640625,\n",
       "     0.28076171875,\n",
       "     0.273681640625,\n",
       "     0.271484375],\n",
       "    'ids': [2886, 46233, 681, 12554, 30082]},\n",
       "   41: {'tokens': ['ndard', 'ufact', 'тори', 'naires', 'ouble'],\n",
       "    'scores': [0.6669921875,\n",
       "     0.54736328125,\n",
       "     0.52490234375,\n",
       "     0.5205078125,\n",
       "     0.501953125],\n",
       "    'ids': [40462, 5010, 14007, 93003, 2855]},\n",
       "   46: {'tokens': ['RIX', 'ец', 'idery', '所得', 'acier'],\n",
       "    'scores': [0.35595703125,\n",
       "     0.33642578125,\n",
       "     0.332275390625,\n",
       "     0.3310546875,\n",
       "     0.322509765625],\n",
       "    'ids': [95567, 26144, 45491, 30082, 45953]},\n",
       "   62: {'tokens': ['azu', 'YL', 'alas', '�乐', 'pei'],\n",
       "    'scores': [0.27734375,\n",
       "     0.2646484375,\n",
       "     0.263427734375,\n",
       "     0.26318359375,\n",
       "     0.2626953125],\n",
       "    'ids': [93843, 76164, 79102, 12699, 68396]}}},\n",
       " 3: {0: {0: {'tokens': ['sona', 'nsol', ' sol', 'agara', 'fess'],\n",
       "    'scores': [0.40625,\n",
       "     0.399169921875,\n",
       "     0.38525390625,\n",
       "     0.373779296875,\n",
       "     0.3466796875],\n",
       "    'ids': [44766, 51173, 1197, 52910, 7575]},\n",
       "   17: {'tokens': ['9', '6', '8', '1', '3'],\n",
       "    'scores': [1.2822265625,\n",
       "     1.1806640625,\n",
       "     1.1552734375,\n",
       "     1.083984375,\n",
       "     1.056640625],\n",
       "    'ids': [24, 21, 23, 16, 18]},\n",
       "   18: {'tokens': ['abre', 'tol', 'otr', 'oelectric', 'umes'],\n",
       "    'scores': [0.2841796875,\n",
       "     0.279052734375,\n",
       "     0.260009765625,\n",
       "     0.254150390625,\n",
       "     0.24560546875],\n",
       "    'ids': [69045, 9050, 63120, 72368, 9912]},\n",
       "   43: {'tokens': ['aui', 'arella', 'icode', 'rigu', 'UEL'],\n",
       "    'scores': [0.39892578125,\n",
       "     0.375,\n",
       "     0.360595703125,\n",
       "     0.359619140625,\n",
       "     0.34423828125],\n",
       "    'ids': [33221, 60633, 26856, 87140, 84866]},\n",
       "   62: {'tokens': ['igis', 'beds', 'bed', 'bris', ' pers'],\n",
       "    'scores': [0.345947265625,\n",
       "     0.31591796875,\n",
       "     0.31103515625,\n",
       "     0.290283203125,\n",
       "     0.28955078125],\n",
       "    'ids': [91199, 74936, 3873, 29830, 4048]}}},\n",
       " 4: {0: {7: {'tokens': ['钰', '旁', 'рист', 'versely', '得意'],\n",
       "    'scores': [0.55322265625,\n",
       "     0.546875,\n",
       "     0.5166015625,\n",
       "     0.50244140625,\n",
       "     0.50146484375],\n",
       "    'ids': [94398, 16006, 20261, 31534, 74863]},\n",
       "   12: {'tokens': ['lids', '圾', '枕', 'тру', 'уди'],\n",
       "    'scores': [0.403564453125,\n",
       "     0.398681640625,\n",
       "     0.395263671875,\n",
       "     0.3935546875,\n",
       "     0.39013671875],\n",
       "    'ids': [37700, 17913, 40868, 16960, 72033]},\n",
       "   13: {'tokens': ['inada', 'semb', 'adem', 'сели', 'IEEEeqnarray'],\n",
       "    'scores': [0.40283203125,\n",
       "     0.39453125,\n",
       "     0.37939453125,\n",
       "     0.37890625,\n",
       "     0.37451171875],\n",
       "    'ids': [31371, 5680, 5925, 92585, 83865]},\n",
       "   24: {'tokens': ['ogl', 'covery', 'rize', 'oust', 'agnet'],\n",
       "    'scores': [0.36083984375,\n",
       "     0.350341796875,\n",
       "     0.3291015625,\n",
       "     0.32470703125,\n",
       "     0.323974609375],\n",
       "    'ids': [43216, 10247, 87675, 70942, 50505]},\n",
       "   36: {'tokens': ['涯', ' vector', 'oed', '穿上', '汇'],\n",
       "    'scores': [0.53955078125,\n",
       "     0.482177734375,\n",
       "     0.4794921875,\n",
       "     0.474365234375,\n",
       "     0.462158203125],\n",
       "    'ids': [27665, 6133, 80770, 53529, 11355]}}},\n",
       " 5: {0: {19: {'tokens': ['хан', 'ird', 'entren', 'BOX', 'Box'],\n",
       "    'scores': [0.458740234375,\n",
       "     0.4267578125,\n",
       "     0.404052734375,\n",
       "     0.399169921875,\n",
       "     0.3974609375],\n",
       "    'ids': [26422, 2380, 54062, 43951, 6959]},\n",
       "   29: {'tokens': [' Bourn', '北上', 'ailability', ' Bann', 'estring'],\n",
       "    'scores': [0.42724609375,\n",
       "     0.425048828125,\n",
       "     0.4208984375,\n",
       "     0.414306640625,\n",
       "     0.40185546875],\n",
       "    'ids': [92054, 83832, 27378, 95165, 92834]},\n",
       "   45: {'tokens': ['ELF', 'tel', ' WIL', 'ceptor', '�'],\n",
       "    'scores': [0.492431640625,\n",
       "     0.462158203125,\n",
       "     0.4619140625,\n",
       "     0.458984375,\n",
       "     0.453857421875],\n",
       "    'ids': [68976, 31742, 91273, 41231, 1103]},\n",
       "   48: {'tokens': ['вица', ' |^', ';=', ' Pons', ' honour'],\n",
       "    'scores': [0.77099609375,\n",
       "     0.74365234375,\n",
       "     0.7197265625,\n",
       "     0.71044921875,\n",
       "     0.70458984375],\n",
       "    'ids': [32262, 83576, 53597, 63533, 14721]},\n",
       "   63: {'tokens': ['asym', 'ERIC', '根本上', '��', 'estres'],\n",
       "    'scores': [0.233154296875,\n",
       "     0.2283935546875,\n",
       "     0.2271728515625,\n",
       "     0.2205810546875,\n",
       "     0.214599609375],\n",
       "    'ids': [56160, 35048, 85211, 689, 51119]}}},\n",
       " 6: {0: {17: {'tokens': [' prov', 'kerchief', ' instr', ' Община', 'OED'],\n",
       "    'scores': [0.44580078125,\n",
       "     0.439453125,\n",
       "     0.43505859375,\n",
       "     0.42578125,\n",
       "     0.4248046875],\n",
       "    'ids': [1093, 35409, 8098, 62399, 94753]},\n",
       "   21: {'tokens': ['AIPS', 'etapes', 'UNG', 'ODB', '都市'],\n",
       "    'scores': [0.68212890625,\n",
       "     0.58349609375,\n",
       "     0.564453125,\n",
       "     0.52490234375,\n",
       "     0.51611328125],\n",
       "    'ids': [76576, 57548, 55761, 80007, 36337]},\n",
       "   45: {'tokens': ['META', 'odynam', 'aui', 'IRE', ' musulmana'],\n",
       "    'scores': [0.662109375,\n",
       "     0.62158203125,\n",
       "     0.59912109375,\n",
       "     0.583984375,\n",
       "     0.5673828125],\n",
       "    'ids': [64689, 25081, 33221, 63258, 86313]},\n",
       "   53: {'tokens': ['enu', 'ura', '偿', 'BI', 'ules'],\n",
       "    'scores': [0.5703125,\n",
       "     0.5546875,\n",
       "     0.5537109375,\n",
       "     0.55322265625,\n",
       "     0.5458984375],\n",
       "    'ids': [7422, 2759, 12609, 14673, 2920]},\n",
       "   55: {'tokens': ['立卡', ' място', 'ikon', 'opon', '>(<'],\n",
       "    'scores': [0.2318115234375,\n",
       "     0.20947265625,\n",
       "     0.2054443359375,\n",
       "     0.204345703125,\n",
       "     0.2017822265625],\n",
       "    'ids': [97632, 16115, 44435, 78460, 35202]}}},\n",
       " 7: {0: {18: {'tokens': ['pora', 'ugosl', 'bst', 'stro', 'ropies'],\n",
       "    'scores': [0.759765625,\n",
       "     0.71630859375,\n",
       "     0.67724609375,\n",
       "     0.67041015625,\n",
       "     0.654296875],\n",
       "    'ids': [71163, 55960, 96306, 54766, 81329]},\n",
       "   43: {'tokens': ['3', 'obrir', 'WT', '4', '5'],\n",
       "    'scores': [0.6533203125,\n",
       "     0.6025390625,\n",
       "     0.599609375,\n",
       "     0.55810546875,\n",
       "     0.53515625],\n",
       "    'ids': [18, 55898, 43565, 19, 20]},\n",
       "   44: {'tokens': ['opon', 'obres', ' пряко', 'andes', 'lapse'],\n",
       "    'scores': [0.307373046875,\n",
       "     0.29736328125,\n",
       "     0.27392578125,\n",
       "     0.26171875,\n",
       "     0.260009765625],\n",
       "    'ids': [78460, 41908, 95299, 51897, 92016]},\n",
       "   49: {'tokens': ['��', '湃', 'uz', ' Rod', '$\\\\%'],\n",
       "    'scores': [0.73974609375,\n",
       "     0.70556640625,\n",
       "     0.701171875,\n",
       "     0.6982421875,\n",
       "     0.6865234375],\n",
       "    'ids': [689, 73667, 15339, 12566, 55078]},\n",
       "   62: {'tokens': [' COPY', 'cho', ' Clash', 'onium', 'nin'],\n",
       "    'scores': [0.62109375,\n",
       "     0.58935546875,\n",
       "     0.5859375,\n",
       "     0.5791015625,\n",
       "     0.57568359375],\n",
       "    'ids': [46558, 3558, 93553, 73174, 50190]}}},\n",
       " 8: {0: {10: {'tokens': ['DLINE', 'rrec', 'ExternalTask', 'rasp', 'aign'],\n",
       "    'scores': [0.77294921875,\n",
       "     0.767578125,\n",
       "     0.76171875,\n",
       "     0.70361328125,\n",
       "     0.6962890625],\n",
       "    'ids': [54489, 13580, 37835, 90137, 6734]},\n",
       "   36: {'tokens': ['��', 'яна', 'kem', '兰特', '系的'],\n",
       "    'scores': [0.27490234375,\n",
       "     0.26416015625,\n",
       "     0.247802734375,\n",
       "     0.21728515625,\n",
       "     0.2120361328125],\n",
       "    'ids': [689, 67656, 77536, 59322, 72318]},\n",
       "   43: {'tokens': ['DA', 'mens', 'das', 'нав', 'citealp'],\n",
       "    'scores': [0.80859375,\n",
       "     0.76904296875,\n",
       "     0.744140625,\n",
       "     0.732421875,\n",
       "     0.72119140625],\n",
       "    'ids': [7748, 43850, 43798, 37723, 89755]},\n",
       "   49: {'tokens': ['ropies', '婪', 'Se', 'цов', '徘'],\n",
       "    'scores': [0.51318359375,\n",
       "     0.495361328125,\n",
       "     0.479736328125,\n",
       "     0.474609375,\n",
       "     0.45361328125],\n",
       "    'ids': [81329, 86816, 3210, 77022, 83062]},\n",
       "   61: {'tokens': [' COPY', '}$~\\\\', 'CODEGEN', 'Македония', '}$\\\\,'],\n",
       "    'scores': [0.65673828125,\n",
       "     0.63525390625,\n",
       "     0.59521484375,\n",
       "     0.5908203125,\n",
       "     0.58056640625],\n",
       "    'ids': [46558, 95626, 69138, 85134, 80111]}}},\n",
       " 9: {0: {0: {'tokens': ['osure', 'unknownFields', '�乐', 'inced', 'lada'],\n",
       "    'scores': [0.281982421875,\n",
       "     0.270751953125,\n",
       "     0.2705078125,\n",
       "     0.2666015625,\n",
       "     0.26611328125],\n",
       "    'ids': [42795, 90129, 12699, 18594, 73181]},\n",
       "   24: {'tokens': ['aso', 'se', 't', '\\ufeff\\ufeff\\ufeff\\ufeff', ' partida'],\n",
       "    'scores': [0.7607421875,\n",
       "     0.6962890625,\n",
       "     0.67431640625,\n",
       "     0.6591796875,\n",
       "     0.638671875],\n",
       "    'ids': [48887, 346, 83, 99879, 47124]},\n",
       "   33: {'tokens': ['PROP', 'чер', 'prop', 'dome', 'ukes'],\n",
       "    'scores': [0.8154296875,\n",
       "     0.77880859375,\n",
       "     0.76611328125,\n",
       "     0.7529296875,\n",
       "     0.70166015625],\n",
       "    'ids': [31479, 40570, 6945, 98394, 56621]},\n",
       "   42: {'tokens': ['лата', 'etr', '@{', 'zie', 'ICS'],\n",
       "    'scores': [0.6123046875,\n",
       "     0.58056640625,\n",
       "     0.57421875,\n",
       "     0.57373046875,\n",
       "     0.56298828125],\n",
       "    'ids': [11851, 97658, 21276, 57974, 28336]},\n",
       "   45: {'tokens': ['雷', 'S', '慎', 'adem', ' Sn'],\n",
       "    'scores': [0.759765625,\n",
       "     0.6171875,\n",
       "     0.6142578125,\n",
       "     0.61279296875,\n",
       "     0.599609375],\n",
       "    'ids': [10043, 50, 22401, 5925, 13213]}}},\n",
       " 10: {0: {2: {'tokens': ['Окръг', '钰', 'riever', 'ugal', 'ORE'],\n",
       "    'scores': [0.841796875,\n",
       "     0.76171875,\n",
       "     0.74658203125,\n",
       "     0.7373046875,\n",
       "     0.736328125],\n",
       "    'ids': [73902, 94398, 87683, 52294, 81026]},\n",
       "   24: {'tokens': ['se', 'sem', \"','$\", ' elim', 'айнрих'],\n",
       "    'scores': [0.78076171875,\n",
       "     0.75439453125,\n",
       "     0.74267578125,\n",
       "     0.7099609375,\n",
       "     0.70849609375],\n",
       "    'ids': [346, 6012, 73244, 32827, 35015]},\n",
       "   37: {'tokens': ['onces', '麒', 'mirall', 'imode', 'ivitat'],\n",
       "    'scores': [0.8662109375,\n",
       "     0.79248046875,\n",
       "     0.78857421875,\n",
       "     0.74755859375,\n",
       "     0.732421875],\n",
       "    'ids': [24118, 63363, 58240, 95563, 32685]},\n",
       "   42: {'tokens': ['一笔', 'ORA', ' Qgs', 'жени', 'alleled'],\n",
       "    'scores': [0.40234375,\n",
       "     0.39697265625,\n",
       "     0.396728515625,\n",
       "     0.380859375,\n",
       "     0.362060546875],\n",
       "    'ids': [59678, 47968, 82064, 45948, 50174]},\n",
       "   53: {'tokens': ['endem', '��', 'ORE', ' tail', 'mesa'],\n",
       "    'scores': [0.91748046875,\n",
       "     0.82470703125,\n",
       "     0.78955078125,\n",
       "     0.75927734375,\n",
       "     0.7529296875],\n",
       "    'ids': [51471, 2731, 81026, 9960, 34518]}}},\n",
       " 11: {0: {1: {'tokens': ['UTO', 'utx', 'sem', 'adem', 'KY'],\n",
       "    'scores': [0.71826171875,\n",
       "     0.701171875,\n",
       "     0.69287109375,\n",
       "     0.67724609375,\n",
       "     0.6630859375],\n",
       "    'ids': [26604, 59338, 6012, 5925, 77830]},\n",
       "   33: {'tokens': ['PCA', 'вън', '华声', 'amen', '(**'],\n",
       "    'scores': [0.87451171875,\n",
       "     0.76123046875,\n",
       "     0.74560546875,\n",
       "     0.70947265625,\n",
       "     0.705078125],\n",
       "    'ids': [61270, 32138, 95073, 29134, 80750]},\n",
       "   36: {'tokens': ['rVert', '来越', ' llib', 'листи', 'CDCD'],\n",
       "    'scores': [0.59716796875,\n",
       "     0.5849609375,\n",
       "     0.58447265625,\n",
       "     0.52587890625,\n",
       "     0.52490234375],\n",
       "    'ids': [59423, 9721, 9613, 22568, 92310]},\n",
       "   48: {'tokens': ['евру', 'Македония', 'ейнт', '坷', 'ExternalTask'],\n",
       "    'scores': [0.364990234375,\n",
       "     0.360595703125,\n",
       "     0.35400390625,\n",
       "     0.34130859375,\n",
       "     0.33544921875],\n",
       "    'ids': [19192, 85134, 91006, 78453, 37835]},\n",
       "   50: {'tokens': [' Гър', 'евру', 'TOOLSET', 'CLUD', ' ска'],\n",
       "    'scores': [0.8154296875,\n",
       "     0.80517578125,\n",
       "     0.802734375,\n",
       "     0.77099609375,\n",
       "     0.7392578125],\n",
       "    'ids': [24348, 19192, 99024, 40212, 32332]}}},\n",
       " 12: {0: {7: {'tokens': ['arx', 'trx', 'agrams', 'Lear', '祺'],\n",
       "    'scores': [0.9541015625,\n",
       "     0.7939453125,\n",
       "     0.759765625,\n",
       "     0.7587890625,\n",
       "     0.701171875],\n",
       "    'ids': [34361, 85341, 58993, 16322, 64256]},\n",
       "   17: {'tokens': [' Gros', '�', 'AIPS', 'etat', 'onomia'],\n",
       "    'scores': [0.382080078125,\n",
       "     0.36669921875,\n",
       "     0.361572265625,\n",
       "     0.351806640625,\n",
       "     0.346923828125],\n",
       "    'ids': [60409, 1096, 76576, 10231, 28890]},\n",
       "   39: {'tokens': ['<\\\\/', ' Кън', 'HING', 'flame', 'unge'],\n",
       "    'scores': [0.80615234375,\n",
       "     0.71240234375,\n",
       "     0.689453125,\n",
       "     0.68017578125,\n",
       "     0.66748046875],\n",
       "    'ids': [94341, 77697, 92866, 90852, 28674]},\n",
       "   47: {'tokens': ['�', 'GB', '台', 'osed', ' Estatal'],\n",
       "    'scores': [0.68310546875,\n",
       "     0.67138671875,\n",
       "     0.63232421875,\n",
       "     0.6279296875,\n",
       "     0.626953125],\n",
       "    'ids': [3447, 6689, 3240, 16390, 65878]},\n",
       "   51: {'tokens': [' e', 'enp', 'etr', '挥', '不成'],\n",
       "    'scores': [0.8740234375,\n",
       "     0.81689453125,\n",
       "     0.814453125,\n",
       "     0.80419921875,\n",
       "     0.79736328125],\n",
       "    'ids': [301, 77141, 97658, 9703, 47967]}}},\n",
       " 13: {0: {3: {'tokens': ['ismes', ' Senat', 'semb', 'ODO', 'Habitants'],\n",
       "    'scores': [0.302490234375,\n",
       "     0.299072265625,\n",
       "     0.294677734375,\n",
       "     0.29345703125,\n",
       "     0.292724609375],\n",
       "    'ids': [26656, 60111, 5680, 15731, 30187]},\n",
       "   4: {'tokens': [' (', ' ', ' n', '(', '…'],\n",
       "    'scores': [1.291015625, 1.21484375, 0.939453125, 0.9189453125, 0.90625],\n",
       "    'ids': [334, 207, 291, 7, 2494]},\n",
       "   5: {'tokens': ['ica', 'ICA', '�乐', ' spo', 'ely'],\n",
       "    'scores': [1.052734375,\n",
       "     1.0419921875,\n",
       "     0.9423828125,\n",
       "     0.9150390625,\n",
       "     0.89111328125],\n",
       "    'ids': [1170, 45975, 12699, 16168, 733]},\n",
       "   35: {'tokens': [' Hom', 'cdc', 'Cont', '�', 'bars'],\n",
       "    'scores': [0.71240234375,\n",
       "     0.69580078125,\n",
       "     0.6884765625,\n",
       "     0.6884765625,\n",
       "     0.6787109375],\n",
       "    'ids': [13653, 92842, 2442, 16792, 32780]},\n",
       "   37: {'tokens': ['semb', ' valign', 'ACES', 'NOS', 'idly'],\n",
       "    'scores': [0.9052734375,\n",
       "     0.78759765625,\n",
       "     0.7333984375,\n",
       "     0.73046875,\n",
       "     0.72265625],\n",
       "    'ids': [5680, 22438, 96996, 43056, 36679]}}},\n",
       " 14: {0: {3: {'tokens': ['orb', 'Ping', 'WC', 'ESA', 'arb'],\n",
       "    'scores': [0.93408203125,\n",
       "     0.93017578125,\n",
       "     0.92529296875,\n",
       "     0.91357421875,\n",
       "     0.90771484375],\n",
       "    'ids': [22793, 28908, 40380, 54322, 70519]},\n",
       "   16: {'tokens': ['NonUser', 'Ungrouped', '�乐', 'IconError', 'ExternalTask'],\n",
       "    'scores': [1.58203125,\n",
       "     1.4833984375,\n",
       "     1.48046875,\n",
       "     1.4755859375,\n",
       "     1.4111328125],\n",
       "    'ids': [78742, 86645, 12699, 40274, 37835]},\n",
       "   24: {'tokens': ['isations', 'ismes', 'rils', 'anguard', 'meres'],\n",
       "    'scores': [1.109375,\n",
       "     1.0849609375,\n",
       "     0.99169921875,\n",
       "     0.9453125,\n",
       "     0.93896484375],\n",
       "    'ids': [21080, 26656, 46904, 55014, 57810]},\n",
       "   27: {'tokens': [' n', 'prop', ' s', 'ismes', 'lou'],\n",
       "    'scores': [0.69873046875,\n",
       "     0.669921875,\n",
       "     0.64111328125,\n",
       "     0.6220703125,\n",
       "     0.568359375],\n",
       "    'ids': [291, 6945, 252, 26656, 51323]},\n",
       "   35: {'tokens': ['adur', 'ifact', 'inam', 'arb', 'urally'],\n",
       "    'scores': [0.93896484375,\n",
       "     0.91455078125,\n",
       "     0.8671875,\n",
       "     0.85400390625,\n",
       "     0.8388671875],\n",
       "    'ids': [83340, 8825, 96770, 70519, 43351]}}},\n",
       " 15: {0: {1: {'tokens': ['‐', ' A', ' m', '丸', ' L'],\n",
       "    'scores': [0.7763671875,\n",
       "     0.72314453125,\n",
       "     0.701171875,\n",
       "     0.68798828125,\n",
       "     0.6787109375],\n",
       "    'ids': [51114, 338, 273, 32258, 413]},\n",
       "   3: {'tokens': ['0', '2', '3', '7', '5'],\n",
       "    'scores': [1.3359375, 1.31640625, 1.2998046875, 1.2890625, 1.267578125],\n",
       "    'ids': [15, 17, 18, 22, 20]},\n",
       "   8: {'tokens': [' e', ' m', ' b', ' (', ' S'],\n",
       "    'scores': [1.08984375,\n",
       "     1.0380859375,\n",
       "     1.0029296875,\n",
       "     0.9755859375,\n",
       "     0.955078125],\n",
       "    'ids': [301, 273, 270, 334, 324]},\n",
       "   10: {'tokens': ['NameLink', 'lou', 'стер', ' volc', 'rites'],\n",
       "    'scores': [0.82763671875,\n",
       "     0.7412109375,\n",
       "     0.73193359375,\n",
       "     0.7255859375,\n",
       "     0.67578125],\n",
       "    'ids': [37298, 51323, 26986, 50559, 30104]},\n",
       "   23: {'tokens': ['otch', 'spe', ' sup', 'PIN', '2'],\n",
       "    'scores': [1.0869140625,\n",
       "     0.84033203125,\n",
       "     0.8115234375,\n",
       "     0.8076171875,\n",
       "     0.78759765625],\n",
       "    'ids': [88999, 9462, 899, 36706, 17]}}},\n",
       " 16: {0: {22: {'tokens': ['ROID', 'aza', '默默', '横', '悠悠'],\n",
       "    'scores': [0.99755859375,\n",
       "     0.95166015625,\n",
       "     0.88916015625,\n",
       "     0.88232421875,\n",
       "     0.87890625],\n",
       "    'ids': [72976, 22551, 37416, 14810, 90977]},\n",
       "   24: {'tokens': ['anomenada', '凌', '�', 'rivia', '\\\\%}'],\n",
       "    'scores': [0.923828125,\n",
       "     0.9130859375,\n",
       "     0.90234375,\n",
       "     0.892578125,\n",
       "     0.87548828125],\n",
       "    'ids': [55053, 19298, 4002, 41428, 78792]},\n",
       "   37: {'tokens': ['}$~\\\\', 'frak', 'dens', 'poke', '直言'],\n",
       "    'scores': [0.669921875,\n",
       "     0.65185546875,\n",
       "     0.634765625,\n",
       "     0.60693359375,\n",
       "     0.6064453125],\n",
       "    'ids': [95626, 5119, 31656, 45220, 75816]},\n",
       "   44: {'tokens': ['uran', 'getLocal', 'ndar', '�', '上了'],\n",
       "    'scores': [0.884765625,\n",
       "     0.84716796875,\n",
       "     0.8330078125,\n",
       "     0.822265625,\n",
       "     0.79541015625],\n",
       "    'ids': [51736, 98191, 91379, 952, 14342]},\n",
       "   61: {'tokens': [' afr', ' заба', 'rost', '慢慢的', '避开'],\n",
       "    'scores': [0.990234375,\n",
       "     0.97021484375,\n",
       "     0.85400390625,\n",
       "     0.84033203125,\n",
       "     0.83837890625],\n",
       "    'ids': [33189, 81876, 72585, 53068, 72022]}}},\n",
       " 17: {0: {2: {'tokens': ['min', 'ie', 'ma', 'ann', ' b'],\n",
       "    'scores': [1.1337890625,\n",
       "     1.068359375,\n",
       "     1.009765625,\n",
       "     0.94189453125,\n",
       "     0.93310546875],\n",
       "    'ids': [1521, 522, 736, 1745, 270]},\n",
       "   44: {'tokens': ['edom', 'ives', '沦', 'ably', 'matically'],\n",
       "    'scores': [0.9541015625,\n",
       "     0.92529296875,\n",
       "     0.8916015625,\n",
       "     0.8759765625,\n",
       "     0.8388671875],\n",
       "    'ids': [8513, 1812, 57404, 2188, 52134]},\n",
       "   47: {'tokens': [' ', '4', '1', '2', '3'],\n",
       "    'scores': [1.5185546875,\n",
       "     1.482421875,\n",
       "     1.4462890625,\n",
       "     1.353515625,\n",
       "     1.3369140625],\n",
       "    'ids': [207, 19, 16, 17, 18]},\n",
       "   50: {'tokens': [' b', 'lish', ' p', 'ely', 'nap'],\n",
       "    'scores': [0.87109375,\n",
       "     0.86572265625,\n",
       "     0.7587890625,\n",
       "     0.720703125,\n",
       "     0.70947265625],\n",
       "    'ids': [270, 2226, 265, 733, 46355]},\n",
       "   61: {'tokens': ['жени', ' org', '嘘', '陷入', ' Pro'],\n",
       "    'scores': [0.59375,\n",
       "     0.5224609375,\n",
       "     0.493896484375,\n",
       "     0.48876953125,\n",
       "     0.48681640625],\n",
       "    'ids': [45948, 3594, 75005, 38313, 1383]}}},\n",
       " 18: {0: {9: {'tokens': ['默默', 'WL', '穿梭', '儿', 'ugosl'],\n",
       "    'scores': [0.58203125,\n",
       "     0.57958984375,\n",
       "     0.5546875,\n",
       "     0.5517578125,\n",
       "     0.5498046875],\n",
       "    'ids': [37416, 64227, 83284, 3369, 55960]},\n",
       "   10: {'tokens': [' n', ' p', ' l', ' m', ' t'],\n",
       "    'scores': [1.306640625,\n",
       "     1.2080078125,\n",
       "     1.16015625,\n",
       "     1.138671875,\n",
       "     1.138671875],\n",
       "    'ids': [291, 265, 284, 273, 244]},\n",
       "   17: {'tokens': [' n', ' R', ' g', 'xffff', ' s'],\n",
       "    'scores': [1.166015625, 1.1640625, 1.138671875, 1.1357421875, 1.0234375],\n",
       "    'ids': [291, 433, 307, 82697, 252]},\n",
       "   45: {'tokens': ['鸟', '鼠', ' птица', '猴', '灰'],\n",
       "    'scores': [2.009765625, 1.958984375, 1.8955078125, 1.87109375, 1.58984375],\n",
       "    'ids': [18483, 26649, 50980, 32170, 17645]},\n",
       "   51: {'tokens': ['spot', 'PREC', 'lada', '筒', 'esko'],\n",
       "    'scores': [0.9306640625,\n",
       "     0.88720703125,\n",
       "     0.880859375,\n",
       "     0.8779296875,\n",
       "     0.86083984375],\n",
       "    'ids': [19496, 69787, 73181, 39338, 98052]}}},\n",
       " 19: {0: {15: {'tokens': ['astically', '\\tand', '子和', ' &&\\\\', ' и'],\n",
       "    'scores': [1.0791015625,\n",
       "     1.0771484375,\n",
       "     1.05859375,\n",
       "     1.021484375,\n",
       "     1.01953125],\n",
       "    'ids': [28378, 46204, 67402, 67845, 706]},\n",
       "   30: {'tokens': ['ა', ' <!--[', 'ა�', 'ELY', '\\tandroid'],\n",
       "    'scores': [1.1953125,\n",
       "     1.1025390625,\n",
       "     1.1005859375,\n",
       "     1.0888671875,\n",
       "     1.0205078125],\n",
       "    'ids': [46554, 69586, 56166, 70939, 97199]},\n",
       "   49: {'tokens': [' L', ' .', ' D', ' R', ' s'],\n",
       "    'scores': [1.171875, 1.078125, 1.0751953125, 1.0029296875, 0.990234375],\n",
       "    'ids': [413, 1021, 414, 433, 252]},\n",
       "   53: {'tokens': ['duino', '换', 'IconError', 'exposici', 'whis'],\n",
       "    'scores': [1.154296875,\n",
       "     1.0537109375,\n",
       "     1.02734375,\n",
       "     1.0263671875,\n",
       "     1.0087890625],\n",
       "    'ids': [16182, 6381, 40274, 49553, 58641]},\n",
       "   59: {'tokens': ['=\"../_', '_-(', 'bes', ' gu', ' Ends'],\n",
       "    'scores': [0.40478515625,\n",
       "     0.37744140625,\n",
       "     0.37548828125,\n",
       "     0.358154296875,\n",
       "     0.35595703125],\n",
       "    'ids': [43079, 89011, 11034, 1243, 96310]}}},\n",
       " 20: {0: {16: {'tokens': ['обла', ' w', 'enda', ' b', ' n'],\n",
       "    'scores': [1.08203125,\n",
       "     1.0634765625,\n",
       "     1.0166015625,\n",
       "     0.97802734375,\n",
       "     0.9775390625],\n",
       "    'ids': [74668, 259, 12372, 270, 291]},\n",
       "   29: {'tokens': ['大气', '壶', '轩', '揪', 'chart'],\n",
       "    'scores': [0.98828125, 0.9453125, 0.9130859375, 0.8779296875, 0.861328125],\n",
       "    'ids': [34007, 37249, 38018, 98652, 20788]},\n",
       "   31: {'tokens': ['�乐', 'Hivern', 'dens', 'onada', 'opsi'],\n",
       "    'scores': [0.400634765625,\n",
       "     0.36572265625,\n",
       "     0.348388671875,\n",
       "     0.338623046875,\n",
       "     0.331787109375],\n",
       "    'ids': [12699, 88292, 31656, 47910, 81194]},\n",
       "   48: {'tokens': ['外援', 'thr', '开辟', '确立', '仍然'],\n",
       "    'scores': [0.9423828125,\n",
       "     0.927734375,\n",
       "     0.92529296875,\n",
       "     0.9130859375,\n",
       "     0.9072265625],\n",
       "    'ids': [66153, 19189, 73892, 65483, 17805]},\n",
       "   59: {'tokens': [' n', 'JC', ' m', 'QA', 'mars'],\n",
       "    'scores': [1.3271484375,\n",
       "     1.2041015625,\n",
       "     1.2041015625,\n",
       "     1.1806640625,\n",
       "     1.17578125],\n",
       "    'ids': [291, 50398, 273, 41466, 90990]}}},\n",
       " 21: {0: {18: {'tokens': ['jean', 'poke', '\\tand', 'čí', '\\t&&'],\n",
       "    'scores': [1.0791015625,\n",
       "     1.017578125,\n",
       "     1.013671875,\n",
       "     0.98681640625,\n",
       "     0.9560546875],\n",
       "    'ids': [92245, 45220, 46204, 49689, 26784]},\n",
       "   23: {'tokens': ['wered', 'ODO', 'CodeAttribute', '佑', '睿'],\n",
       "    'scores': [1.3076171875, 1.2578125, 1.2109375, 1.2099609375, 1.12109375],\n",
       "    'ids': [36077, 15731, 65316, 61304, 48593]},\n",
       "   53: {'tokens': ['ui', 'ACHE', '大力', 'bona', 'pip'],\n",
       "    'scores': [0.433837890625,\n",
       "     0.432373046875,\n",
       "     0.424560546875,\n",
       "     0.424072265625,\n",
       "     0.42041015625],\n",
       "    'ids': [3970, 38038, 29092, 80285, 20268]},\n",
       "   56: {'tokens': ['code', '码', 'codes', 'Code', '代码'],\n",
       "    'scores': [1.724609375,\n",
       "     1.63671875,\n",
       "     1.5595703125,\n",
       "     1.3994140625,\n",
       "     1.3935546875],\n",
       "    'ids': [2121, 9976, 39513, 4998, 47807]},\n",
       "   59: {'tokens': ['华声', 'saurus', ' dirigides', ' \\\\!\\\\!', 'CCA'],\n",
       "    'scores': [1.189453125, 1.1240234375, 1.08984375, 1.0146484375, 1.0078125],\n",
       "    'ids': [95073, 80624, 56289, 92280, 83582]}}},\n",
       " 22: {0: {10: {'tokens': ['mathbold', 'ническата', ' Кън', '雏', 'canvi'],\n",
       "    'scores': [1.484375, 1.3818359375, 1.376953125, 1.337890625, 1.33203125],\n",
       "    'ids': [63446, 73157, 77697, 91737, 55847]},\n",
       "   21: {'tokens': ['菲特', 'FRING', 'ходите', 'клопе', ' рицар'],\n",
       "    'scores': [1.888671875,\n",
       "     1.6474609375,\n",
       "     1.6220703125,\n",
       "     1.51171875,\n",
       "     1.4873046875],\n",
       "    'ids': [64033, 96119, 92180, 75358, 91036]},\n",
       "   32: {'tokens': [' repartia', ' integraven', ' aturades', 'canvi', 'eqno'],\n",
       "    'scores': [1.9248046875,\n",
       "     1.9033203125,\n",
       "     1.8251953125,\n",
       "     1.7646484375,\n",
       "     1.712890625],\n",
       "    'ids': [30498, 32866, 30660, 55847, 72686]},\n",
       "   50: {'tokens': ['ODO', ' Comen', 'KV', '加快推进', '固执'],\n",
       "    'scores': [0.7451171875,\n",
       "     0.73681640625,\n",
       "     0.728515625,\n",
       "     0.72216796875,\n",
       "     0.716796875],\n",
       "    'ids': [15731, 84091, 59149, 76744, 97881]},\n",
       "   59: {'tokens': ['ническата',\n",
       "     'NOSCRIPT',\n",
       "     'FieldLocation',\n",
       "     'headerlink',\n",
       "     'DOCKED'],\n",
       "    'scores': [1.42578125,\n",
       "     1.39453125,\n",
       "     1.3935546875,\n",
       "     1.3779296875,\n",
       "     1.3349609375],\n",
       "    'ids': [73157, 51528, 78114, 88077, 54569]}}},\n",
       " 23: {0: {11: {'tokens': [' integraven',\n",
       "     ' repartia',\n",
       "     'фове',\n",
       "     'fiques',\n",
       "     '=\"#{'],\n",
       "    'scores': [1.939453125,\n",
       "     1.876953125,\n",
       "     1.794921875,\n",
       "     1.771484375,\n",
       "     1.7607421875],\n",
       "    'ids': [32866, 30498, 58146, 25263, 97958]},\n",
       "   18: {'tokens': ['�乐', 'стики', 'ygon', 'сяка', ' L'],\n",
       "    'scores': [1.5048828125,\n",
       "     1.0615234375,\n",
       "     0.94482421875,\n",
       "     0.912109375,\n",
       "     0.9013671875],\n",
       "    'ids': [12699, 75169, 16254, 97985, 413]},\n",
       "   37: {'tokens': ['IVA', '头像', '炳', 'wxr', 'acis'],\n",
       "    'scores': [1.357421875,\n",
       "     1.31640625,\n",
       "     1.302734375,\n",
       "     1.2626953125,\n",
       "     1.2431640625],\n",
       "    'ids': [96710, 98195, 88193, 40935, 75369]},\n",
       "   49: {'tokens': ['/&', '\">&#', \"')\\\\\", '/{\\\\', 'rowColor'],\n",
       "    'scores': [1.1376953125,\n",
       "     1.080078125,\n",
       "     1.0205078125,\n",
       "     1.009765625,\n",
       "     0.99951171875],\n",
       "    'ids': [84472, 45858, 36277, 68616, 46489]},\n",
       "   59: {'tokens': ['Ungrouped', 'visi', 'getC', 'noframe', '┈┈'],\n",
       "    'scores': [0.8251953125,\n",
       "     0.791015625,\n",
       "     0.73388671875,\n",
       "     0.7177734375,\n",
       "     0.705078125],\n",
       "    'ids': [86645, 35291, 98992, 39804, 90988]}}},\n",
       " 24: {0: {2: {'tokens': ['1', '3', '6', '2', ','],\n",
       "    'scores': [5.87109375, 5.5859375, 5.5859375, 5.56640625, 5.47265625],\n",
       "    'ids': [16, 18, 21, 17, 11]},\n",
       "   41: {'tokens': [',', '\\n', ' ', 'elf', 'lo'],\n",
       "    'scores': [2.447265625, 2.3828125, 2.228515625, 2.154296875, 2.087890625],\n",
       "    'ids': [11, 185, 207, 785, 789]},\n",
       "   49: {'tokens': ['J', ',', ' with', ' and', ' '],\n",
       "    'scores': [3.990234375, 3.732421875, 3.494140625, 3.388671875, 3.30859375],\n",
       "    'ids': [41, 11, 366, 285, 207]},\n",
       "   60: {'tokens': ['4', '3', '0', '8', '5'],\n",
       "    'scores': [2.216796875,\n",
       "     2.212890625,\n",
       "     2.205078125,\n",
       "     2.177734375,\n",
       "     2.173828125],\n",
       "    'ids': [19, 18, 15, 23, 20]},\n",
       "   63: {'tokens': [' ', ',', ' t', ' O', ' \"'],\n",
       "    'scores': [2.822265625, 2.447265625, 2.34765625, 2.287109375, 2.15234375],\n",
       "    'ids': [207, 11, 244, 508, 440]}}},\n",
       " 25: {0: {31: {'tokens': [' half', ' and', ',', ' is', ' returns'],\n",
       "    'scores': [8.625, 8.59375, 8.34375, 8.2265625, 7.859375],\n",
       "    'ids': [3222, 285, 11, 317, 7578]},\n",
       "   33: {'tokens': [' ', ',', 'resume', 'neighbour', ' outlining'],\n",
       "    'scores': [10.9296875, 8.96875, 8.734375, 8.359375, 8.328125],\n",
       "    'ids': [207, 11, 53240, 58461, 83869]},\n",
       "   40: {'tokens': [',', '\\n', ' in', ' to', ' and'],\n",
       "    'scores': [12.2265625, 11.2265625, 10.90625, 10.8984375, 10.609375],\n",
       "    'ids': [11, 185, 279, 276, 285]},\n",
       "   45: {'tokens': [' is', '\\n', '...', ' last', ' us'],\n",
       "    'scores': [12.453125, 12.3203125, 12.1640625, 11.7578125, 11.3828125],\n",
       "    'ids': [317, 185, 1204, 1562, 450]},\n",
       "   57: {'tokens': [' ', ' involving', '0', ' u', ' ev'],\n",
       "    'scores': [2.54296875, 2.533203125, 2.35546875, 2.341796875, 2.30078125],\n",
       "    'ids': [207, 15231, 15, 2644, 760]}}},\n",
       " 26: {0: {14: {'tokens': [',', '.', ' ', '-', ' ('],\n",
       "    'scores': [34.375, 31.828125, 31.734375, 31.234375, 31.203125],\n",
       "    'ids': [11, 13, 207, 12, 334]},\n",
       "   30: {'tokens': ['姚明', '周杰伦', '鹿晗', '普洱茶', '雷克萨斯'],\n",
       "    'scores': [10.5625, 10.3828125, 9.8671875, 9.78125, 9.4609375],\n",
       "    'ids': [97287, 93336, 75442, 99241, 90581]},\n",
       "   54: {'tokens': [' to', ' me', ' you', ' that', ' of'],\n",
       "    'scores': [32.625, 31.578125, 30.484375, 30.296875, 30.265625],\n",
       "    'ids': [276, 525, 340, 344, 280]},\n",
       "   56: {'tokens': [' ', ',', ' and', ' to', ' for'],\n",
       "    'scores': [36.28125, 35.125, 34.25, 34.0625, 33.9375],\n",
       "    'ids': [207, 11, 285, 276, 327]},\n",
       "   62: {'tokens': [' to', ' for', ' not', ' by', ' and'],\n",
       "    'scores': [26.25, 25.15625, 25.0625, 24.875, 24.65625],\n",
       "    'ids': [276, 327, 441, 457, 285]}}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_expert_tokens = map_to_actual_experts(expert_topk_tokens, moe_metadata)\n",
    "actual_expert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mactual_expert_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Layer 26, Token 1, Expert 64\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "print(actual_expert_tokens[26][0][2])  # Layer 26, Token 1, Expert 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.6865e-02,  2.1484e-02, -3.3398e-01,  ...,  1.7578e-02,\n",
       "         -1.9434e-01,  7.4768e-03],\n",
       "        [-3.8574e-02, -4.8340e-02, -2.0605e-01,  ...,  2.0996e-02,\n",
       "         -1.5736e-04, -3.6865e-02],\n",
       "        [ 4.2969e-02,  6.4453e-02, -1.1768e-01,  ..., -2.8442e-02,\n",
       "          1.0645e-01, -1.2207e-03],\n",
       "        [ 8.9844e-02, -4.0771e-02,  7.4219e-02,  ...,  2.0630e-02,\n",
       "          1.7383e-01,  8.4839e-03],\n",
       "        [ 2.0020e-02, -1.0107e-01,  6.6895e-02,  ..., -1.3867e-01,\n",
       "          5.5176e-02,  8.9355e-02]], dtype=torch.float16,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt = \"the quick brown fox\"\n",
    "input_ids = tokenizer.encode(input_txt, return_tensors=\"pt\")\n",
    "\n",
    "x = model(input_ids, output_hidden_states=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 2048])\n",
      "oment\n",
      "\">:\n",
      "es\n",
      "es\n",
      "croft\n",
      "croft\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "issin\n",
      "IEEEeqnarray\n",
      "estrat\n",
      "IEEEeqnarray\n",
      "IEEEeqnarray\n",
      "=\"../_\n",
      " rejo\n",
      " r\n",
      "Jump\n",
      "Jump\n",
      "Jump\n",
      "Jump\n",
      "Jump\n"
     ]
    }
   ],
   "source": [
    "print(x['hidden_states'][15].shape)\n",
    "y = x['hidden_states'][15][0][-1]\n",
    "tokens = model.lm_head(y)\n",
    "\n",
    "tokenizer.decode(tokens.argmax(dim=-1))\n",
    "\n",
    "for layer in range(27):\n",
    "\n",
    "    y = x['hidden_states'][layer][0][-1]\n",
    "    tokens = model.lm_head(y)\n",
    "    print(tokenizer.decode(tokens.argmax(dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is a vector of attention scores, which are used to compute a weighted sum of the values. The attention function is used in many applications, including machine translation, question answering, and image captioning.\n",
      "\n",
      "In this post, we will discuss the attention function in detail. We will start by defining the attention function and then discuss its properties. We will also discuss how the attention function is used in various applications.\n",
      "\n",
      "## What is Attention Function?\n",
      "\n",
      "The attention function is a mathematical function that\n",
      "\n",
      "Collected 100 MLP activations from layer 5\n",
      "Activation shape: torch.Size([1, 40, 2048])\n"
     ]
    }
   ],
   "source": [
    "# Configuration for activation collection\n",
    "layer_to_hook = 5  # Change this to your desired layer number (0-based index)\n",
    "mlp_activations = []\n",
    "\n",
    "# Define hook function\n",
    "def mlp_hook(module, module_input, module_output):\n",
    "    \"\"\"Store MLP output activations after each forward pass\"\"\"\n",
    "    mlp_activations.append(module_output.detach().cpu())\n",
    "\n",
    "# Register hook on the specified layer\n",
    "try:\n",
    "    target_layer = model.model.layers[layer_to_hook].mlp\n",
    "    handle = target_layer.register_forward_hook(mlp_hook)\n",
    "except (AttributeError, IndexError) as e:\n",
    "    raise ValueError(f\"Invalid layer number: {layer_to_hook}\") from e\n",
    "\n",
    "# Run generation\n",
    "text = \"An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs.to(model.device), max_new_tokens=100)\n",
    "\n",
    "# Remove hook after use\n",
    "handle.remove()\n",
    "\n",
    "# Decode and print results\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Generated text:\\n\", result)\n",
    "\n",
    "# Print activation information\n",
    "print(f\"\\nCollected {len(mlp_activations)} MLP activations from layer {layer_to_hook}\")\n",
    "if len(mlp_activations) > 0:\n",
    "    print(f\"Activation shape: {mlp_activations[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'the quick brown fox'\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe quick brown fox\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Print final generation\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerated Text:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/d/huggingface/modules/transformers_modules/deepseek-ai/deepseek-moe-16b-base/521d2bc4fb69a3f3ae565310fcc3b65f97af2580/modeling_deepseek.py:1329\u001b[0m, in \u001b[0;36mDeepseekForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1326\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1329\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1341\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/d/huggingface/modules/transformers_modules/deepseek-ai/deepseek-moe-16b-base/521d2bc4fb69a3f3ae565310fcc3b65f97af2580/modeling_deepseek.py:1216\u001b[0m, in \u001b[0;36mDeepseekModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1207\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1208\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         use_cache,\n\u001b[1;32m   1214\u001b[0m     )\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1216\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1225\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/d/huggingface/modules/transformers_modules/deepseek-ai/deepseek-moe-16b-base/521d2bc4fb69a3f3ae565310fcc3b65f97af2580/modeling_deepseek.py:958\u001b[0m, in \u001b[0;36mDeepseekDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    957\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 958\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    961\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/d/huggingface/modules/transformers_modules/deepseek-ai/deepseek-moe-16b-base/521d2bc4fb69a3f3ae565310fcc3b65f97af2580/modeling_deepseek.py:390\u001b[0m, in \u001b[0;36mDeepseekMoE.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    388\u001b[0m     y \u001b[38;5;241m=\u001b[39m AddAuxiliaryLoss\u001b[38;5;241m.\u001b[39mapply(y, aux_loss)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoe_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_topk_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39morig_shape)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mn_shared_experts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_experts(identity)\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/huggingface/modules/transformers_modules/deepseek-ai/deepseek-moe-16b-base/521d2bc4fb69a3f3ae565310fcc3b65f97af2580/modeling_deepseek.py:408\u001b[0m, in \u001b[0;36mDeepseekMoE.moe_infer\u001b[0;34m(self, x, flat_expert_indices, flat_expert_weights)\u001b[0m\n\u001b[1;32m    406\u001b[0m exp_token_idx \u001b[38;5;241m=\u001b[39m token_idxs[start_idx:end_idx]\n\u001b[1;32m    407\u001b[0m expert_tokens \u001b[38;5;241m=\u001b[39m x[exp_token_idx]\n\u001b[0;32m--> 408\u001b[0m expert_out \u001b[38;5;241m=\u001b[39m \u001b[43mexpert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpert_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m expert_out\u001b[38;5;241m.\u001b[39mmul_(flat_expert_weights[idxs[start_idx:end_idx]])\n\u001b[1;32m    410\u001b[0m expert_cache\u001b[38;5;241m.\u001b[39mscatter_reduce_(\u001b[38;5;241m0\u001b[39m, exp_token_idx\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), expert_out, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1803\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1801\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1806\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m, in \u001b[0;36mregister_expert_hooks.<locals>.make_hook.<locals>.hook\u001b[0;34m(module, inputs, output)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhook\u001b[39m(module, inputs, output):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Extract last token activation (batch_size, hidden_dim)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     last_token_act \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Apply LM head to get logits\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlm_head(last_token_act)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "# Dictionary to store expert predictions\n",
    "expert_predictions = defaultdict(list)\n",
    "\n",
    "def register_expert_hooks():\n",
    "    \"\"\"Register hooks on all expert MLPs across all layers\"\"\"\n",
    "    for layer_idx, layer in enumerate(model.model.layers):\n",
    "        if not hasattr(layer.mlp, 'experts'):\n",
    "            continue\n",
    "            \n",
    "        for expert_idx, expert in enumerate(layer.mlp.experts):\n",
    "            # Define hook with closure to capture layer/expert indices\n",
    "            def make_hook(l, e):\n",
    "                def hook(module, inputs, output):\n",
    "                    # Extract last token activation (batch_size, hidden_dim)\n",
    "                    last_token_act = output[:, -1, :].detach()\n",
    "                    \n",
    "                    # Apply LM head to get logits\n",
    "                    logits = model.lm_head(last_token_act)\n",
    "                    \n",
    "                    # Decode token\n",
    "                    token_id = logits.argmax(-1)\n",
    "                    decoded_token = tokenizer.decode(token_id[0])\n",
    "                    \n",
    "                    # Store prediction\n",
    "                    expert_predictions[(l, e)].append(decoded_token)\n",
    "                return hook\n",
    "            \n",
    "            # Register hook for this expert\n",
    "            expert.register_forward_hook(make_hook(layer_idx, expert_idx))\n",
    "\n",
    "# Register hooks on all experts\n",
    "register_expert_hooks()\n",
    "\n",
    "# Generate text\n",
    "text = \"the quick brown fox\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs,)\n",
    "\n",
    "# Print final generation\n",
    "print(\"\\nGenerated Text:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "# Print expert predictions\n",
    "print(\"\\nExpert Predictions via Logit Lens:\")\n",
    "for (layer, expert), tokens in expert_predictions.items():\n",
    "    print(f\"Layer {layer} - Expert {expert}:\")\n",
    "    print(f\"Predicted sequence: {' '.join(tokens[:5])} [...]\")  # Show first 5 tokens as example\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
